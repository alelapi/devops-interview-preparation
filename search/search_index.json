{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DevOps Interview Preparation","text":"<p>This repository contains a collection of comprehensive answers to commonly asked questions in DevOps interviews, focusing on areas like CI/CD, Docker, Kubernetes, Monitoring, and Infrastructure as Code. Each section is tailored to provide detailed insights and practical examples to help you prepare for your interview effectively.</p>"},{"location":"architectural-patterns/bulkhead/","title":"Bulkhead Pattern","text":""},{"location":"architectural-patterns/bulkhead/#description","title":"Description","text":"<p>The Bulkhead Pattern is a resilience pattern that isolates resources (e.g., threads, connections) to prevent failures in one part of a system from affecting the entire application. It\u2019s inspired by bulkheads in ships that compartmentalize sections to prevent flooding.</p>"},{"location":"architectural-patterns/bulkhead/#how-it-works","title":"How It Works","text":"<ul> <li>Separate workloads into isolated compartments (e.g., thread pools, services).</li> <li>If one compartment fails, the others remain unaffected.</li> </ul>"},{"location":"architectural-patterns/bulkhead/#advantages","title":"Advantages","text":"<ul> <li>Fault Isolation: Limits the impact of failures.</li> <li>Improved Stability: Protects critical components from being overwhelmed.</li> </ul>"},{"location":"architectural-patterns/bulkhead/#challenges","title":"Challenges","text":"<ul> <li>Resource Management: Properly partitioning resources can be complex.</li> <li>Overhead: Requires additional infrastructure for isolation.</li> </ul>"},{"location":"architectural-patterns/bulkhead/#example-use-case","title":"Example Use Case","text":"<p>In a travel booking system:</p> <ul> <li>Payment, inventory, and notification services each have dedicated thread pools.</li> <li>A failure in the notification service does not impact payments or inventory.</li> </ul>"},{"location":"architectural-patterns/circuit_breaker/","title":"Circuit Breaker Pattern","text":""},{"location":"architectural-patterns/circuit_breaker/#description","title":"Description","text":"<p>The Circuit Breaker Pattern is a resilience design pattern that prevents a system from performing operations likely to fail. It works similarly to an electrical circuit breaker: when failures reach a certain threshold, the circuit \u201copens\u201d and subsequent requests are rejected, allowing the system to recover gracefully.</p>"},{"location":"architectural-patterns/circuit_breaker/#how-it-works","title":"How It Works","text":"<ol> <li>Closed State: The system operates normally, and requests are passed through.</li> <li>Open State: After detecting repeated failures, the circuit breaker trips, and further requests are rejected.</li> <li>Half-Open State: The system periodically allows some requests to test if the service has recovered.</li> </ol>"},{"location":"architectural-patterns/circuit_breaker/#advantages","title":"Advantages","text":"<ul> <li>Failure Isolation: Prevents cascading failures.</li> <li>Improved Stability: Allows the failing component to recover without overwhelming it.</li> </ul>"},{"location":"architectural-patterns/circuit_breaker/#challenges","title":"Challenges","text":"<ul> <li>Configuration: Setting thresholds and timeout values requires careful tuning.</li> <li>Fallback Logic: Needs proper implementation for degraded behavior.</li> </ul>"},{"location":"architectural-patterns/circuit_breaker/#example-use-case","title":"Example Use Case","text":"<ul> <li>A microservice calls an external payment gateway.</li> <li>If the payment gateway fails repeatedly, the circuit breaker opens and stops retrying requests, preventing system overload.</li> </ul>"},{"location":"architectural-patterns/event_driven/","title":"Event-Driven Architecture","text":""},{"location":"architectural-patterns/event_driven/#description","title":"Description","text":"<p>Event-Driven Architecture (EDA) is a design paradigm in which systems communicate and interact through the production, detection, and consumption of events. Events are messages that signify a change in state or an occurrence within a system. This architecture promotes loose coupling, scalability, and responsiveness, making it suitable for distributed systems and microservices.</p>"},{"location":"architectural-patterns/event_driven/#how-it-works","title":"How It Works","text":"<ol> <li>Event Producers: Generate events whenever a change or action occurs (e.g., order creation).</li> <li>Event Bus/Message Broker: Events are published to an intermediary, such as Kafka, RabbitMQ, or AWS SNS/SQS.</li> <li>Event Consumers: Services or components subscribe to and consume relevant events, acting upon them.</li> </ol>"},{"location":"architectural-patterns/event_driven/#advantages","title":"Advantages","text":"<ul> <li>Loose Coupling: Producers and consumers are decoupled.</li> <li>Scalability: Event-driven systems scale well to handle increasing event loads.</li> <li>Real-Time Processing: Enables immediate response to events.</li> </ul>"},{"location":"architectural-patterns/event_driven/#challenges","title":"Challenges","text":"<ul> <li>Complexity: Requires careful orchestration and monitoring.</li> <li>Debugging: Troubleshooting distributed events can be difficult.</li> </ul>"},{"location":"architectural-patterns/event_driven/#example-use-case","title":"Example Use Case","text":"<p>An e-commerce system:</p> <ul> <li>Producer: \u201cOrder Placed\u201d event is published.</li> <li>Consumers: Inventory service reserves stock; Payment service processes payment; Notification service sends confirmation.</li> </ul>"},{"location":"architectural-patterns/event_sourcing/","title":"Event Sourcing Pattern","text":""},{"location":"architectural-patterns/event_sourcing/#description","title":"Description","text":"<p>Event Sourcing is a design pattern where state changes in a system are stored as a series of immutable events. The current state is derived by replaying these events in sequence, rather than storing the state directly.</p>"},{"location":"architectural-patterns/event_sourcing/#how-it-works","title":"How It Works","text":"<ol> <li>Events are generated for each state change (e.g., \u201cOrder Placed\u201d).</li> <li>Events are persisted to an event store.</li> <li>The system reconstructs state by replaying events from the store.</li> </ol>"},{"location":"architectural-patterns/event_sourcing/#advantages","title":"Advantages","text":"<ul> <li>Auditability: Provides a complete history of state changes.</li> <li>Scalability: Efficiently handles high volumes of write operations.</li> </ul>"},{"location":"architectural-patterns/event_sourcing/#challenges","title":"Challenges","text":"<ul> <li>Complexity: Rebuilding state and handling event evolution can be tricky.</li> <li>Storage: Large event histories may require significant storage.</li> </ul>"},{"location":"architectural-patterns/event_sourcing/#example-use-case","title":"Example Use Case","text":"<p>A banking application:</p> <ul> <li>Events: \u201cAccount Created\u201d, \u201cDeposit Made\u201d, \u201cWithdrawal Made\u201d.</li> <li>State reconstruction: Replaying events rebuilds the account balance.</li> </ul>"},{"location":"architectural-patterns/saga_pattern/","title":"Saga Pattern","text":""},{"location":"architectural-patterns/saga_pattern/#description","title":"Description","text":"<p>The Saga Pattern is a design pattern used to manage long-running business transactions in a distributed system. It breaks the transaction into a series of smaller steps, with each step executed by a service. If a failure occurs, compensating actions are triggered to roll back previous steps.</p>"},{"location":"architectural-patterns/saga_pattern/#how-it-works","title":"How It Works","text":"<ol> <li>Choreography: Services communicate through events to execute the steps.</li> <li>Orchestration: A central controller coordinates and manages the saga\u2019s steps.</li> </ol>"},{"location":"architectural-patterns/saga_pattern/#advantages","title":"Advantages","text":"<ul> <li>Data Consistency: Ensures eventual consistency in distributed systems.</li> <li>Fault Tolerance: Compensating actions handle failures gracefully.</li> </ul>"},{"location":"architectural-patterns/saga_pattern/#challenges","title":"Challenges","text":"<ul> <li>Complexity: Implementing compensating actions and managing workflows is challenging.</li> <li>Debugging: Harder to trace failures in large-scale sagas.</li> </ul>"},{"location":"architectural-patterns/saga_pattern/#example-use-case","title":"Example Use Case","text":"<p>An e-commerce order process:</p> <ol> <li>Order service places an order.</li> <li>Inventory service reserves stock.</li> <li>Payment service processes payment.</li> <li>If payment fails, the compensating action releases the reserved stock.</li> </ol>"},{"location":"architectural-patterns/strangler/","title":"Strangler Pattern","text":""},{"location":"architectural-patterns/strangler/#description","title":"Description","text":"<p>The Strangler Pattern is a modernization strategy used to incrementally migrate functionality from a legacy system to a new system. The new system is developed alongside the old one, gradually \u201cstrangling\u201d and replacing parts of the legacy system until it can be retired.</p>"},{"location":"architectural-patterns/strangler/#how-it-works","title":"How It Works","text":"<ol> <li>A proxy or routing layer intercepts requests.</li> <li>New functionality is implemented in the new system.</li> <li>Requests for migrated features are routed to the new system.</li> <li>The legacy system is gradually decommissioned.</li> </ol>"},{"location":"architectural-patterns/strangler/#advantages","title":"Advantages","text":"<ul> <li>Low Risk: Incremental migration reduces the risk of failures.</li> <li>Continuous Delivery: New features can be delivered iteratively.</li> </ul>"},{"location":"architectural-patterns/strangler/#challenges","title":"Challenges","text":"<ul> <li>Complexity: Requires careful planning and routing of requests.</li> <li>Dual Systems: Maintaining both systems during migration increases operational overhead.</li> </ul>"},{"location":"architectural-patterns/strangler/#example-use-case","title":"Example Use Case","text":"<ul> <li>An e-commerce platform migrates its monolithic inventory management system to microservices. A routing layer gradually shifts inventory queries to the new microservices while the old system remains operational.</li> </ul>"},{"location":"aws/appsync/","title":"AppSync","text":""},{"location":"aws/appsync/#overview","title":"Overview","text":"<p>AWS AppSync is a fully managed service that enables developers to create scalable GraphQL APIs. At its core, AppSync leverages GraphQL\u2019s powerful query language to simplify how applications retrieve and manipulate data. This approach ensures applications can efficiently obtain exactly the data they need through a single endpoint, reducing unnecessary data transfer and improving performance.</p> <p>The service excels at data integration, seamlessly combining information from multiple sources into a unified API. AppSync natively supports various AWS services including DynamoDB for NoSQL storage, Aurora for relational databases, and OpenSearch for search capabilities. When developers need to integrate with custom data sources or implement complex business logic, AWS Lambda functions can be utilized to extend AppSync\u2019s functionality.</p> <p>Real-time data capabilities are built into AppSync through WebSocket connections or MQTT over WebSocket protocols. This enables applications to receive instant updates when data changes, making it ideal for building responsive, real-time applications.</p> <p>Mobile application developers particularly benefit from AppSync\u2019s features. The service provides robust support for local data access and synchronization, enabling offline functionality and ensuring data consistency across devices. This is crucial for maintaining a smooth user experience in mobile applications where network connectivity may be intermittent.</p> <p>The foundation of any AppSync implementation begins with a GraphQL schema. This schema defines the API\u2019s type system, describing the data structure and relationships between different types. By uploading a schema, developers establish the contract between their API and its clients, making it clear what data can be queried and how it can be manipulated.</p>"},{"location":"aws/appsync/#security","title":"Security","text":"<p>AppSync implements a comprehensive security model with multiple authorization mechanisms to protect your GraphQL APIs:</p> <p>API Key Authentication provides a straightforward way to secure your API during development or for simple use cases. While simple to implement, it offers basic security suitable for testing or public read-only APIs.</p> <p>AWS IAM Authentication enables fine-grained access control using AWS Identity and Access Management. This method is particularly powerful for applications running within the AWS ecosystem, supporting IAM users, roles, and even cross-account access patterns. It integrates seamlessly with other AWS services and provides detailed audit logging through AWS CloudTrail.</p> <p>OpenID Connect Authentication supports integration with third-party identity providers through JSON Web Tokens (JWT). This enables organizations to leverage their existing identity infrastructure while maintaining secure access to their GraphQL APIs.</p> <p>Amazon Cognito User Pools Authentication provides a complete identity management solution. It handles user registration, authentication, and account recovery while seamlessly integrating with AppSync. This option is particularly valuable for mobile and web applications requiring user authentication.</p> <p>For production deployments requiring custom domains and HTTPS support, AWS CloudFront can be placed in front of AppSync. This not only provides additional security through SSL/TLS encryption but also enables content caching and improved global access through CloudFront\u2019s edge locations.</p>"},{"location":"aws/cdk/","title":"Cloud Development Kit (CDK)","text":""},{"location":"aws/cdk/#introduction","title":"Introduction","text":"<p>The AWS Cloud Development Kit (CDK) is an open-source software development framework for defining cloud infrastructure as code using familiar programming languages. Instead of writing JSON or YAML templates (like in CloudFormation), you can use programming languages like TypeScript, Python, Java, C#, or Go to define your AWS infrastructure.</p>"},{"location":"aws/cdk/#key-concepts","title":"Key Concepts","text":""},{"location":"aws/cdk/#constructs","title":"Constructs","text":"<p>Constructs are the basic building blocks of CDK applications. They represent AWS resources or combinations of resources. There are three levels of constructs:</p> <ol> <li>Level 1 (L1) - Low-level constructs that directly represent AWS CloudFormation resources</li> <li>Level 2 (L2) - Higher-level constructs that provide defaults and best practices</li> <li>Level 3 (L3) - Pattern constructs that represent multi-resource patterns for common architectures</li> </ol>"},{"location":"aws/cdk/#stacks","title":"Stacks","text":"<p>Stacks are the unit of deployment in CDK. They contain constructs and map directly to CloudFormation stacks. Stacks handle: - Resource grouping - Deployment boundaries - Permission boundaries - Resource naming</p>"},{"location":"aws/cdk/#apps","title":"Apps","text":"<p>An App is the root construct that contains one or more stacks. It serves as the entry point of your CDK application and handles: - Stack synthesis - Asset bundling - Deployment orchestration</p>"},{"location":"aws/cdk/#getting-started","title":"Getting Started","text":""},{"location":"aws/cdk/#prerequisites","title":"Prerequisites","text":"<ul> <li>Node.js (&gt;= 10.13.0)</li> <li>AWS CLI configured with appropriate credentials</li> <li>IDE or text editor of choice</li> </ul>"},{"location":"aws/cdk/#installation","title":"Installation","text":"<pre><code># Install CDK CLI globally\nnpm install -g aws-cdk\n\n# Verify installation\ncdk --version\n</code></pre>"},{"location":"aws/cdk/#project-initialization","title":"Project Initialization","text":"<pre><code># Create a new CDK project\nmkdir my-cdk-app\ncd my-cdk-app\ncdk init app --language typescript\n</code></pre>"},{"location":"aws/cdk/#basic-example","title":"Basic Example","text":"<p>Here\u2019s a simple example of creating an S3 bucket using CDK in TypeScript:</p> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport * as s3 from 'aws-cdk-lib/aws-s3';\n\nexport class MyS3Stack extends cdk.Stack {\n  constructor(scope: cdk.App, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    new s3.Bucket(this, 'MyFirstBucket', {\n      versioned: true,\n      encryption: s3.BucketEncryption.S3_MANAGED,\n      removalPolicy: cdk.RemovalPolicy.DESTROY\n    });\n  }\n}\n</code></pre>"},{"location":"aws/cdk/#common-commands","title":"Common Commands","text":"<ul> <li><code>cdk init</code> - Create a new CDK project</li> <li><code>cdk synth</code> - Synthesize CloudFormation template</li> <li><code>cdk diff</code> - Compare deployed stack with current state</li> <li><code>cdk deploy</code> - Deploy the stack to AWS</li> <li><code>cdk destroy</code> - Destroy the stack</li> </ul>"},{"location":"aws/cdk/#best-practices","title":"Best Practices","text":""},{"location":"aws/cdk/#code-organization","title":"Code Organization","text":"<ul> <li>Keep stacks focused and single-purpose</li> <li>Use constructs to encapsulate reusable components</li> <li>Leverage environment-specific configuration</li> <li>Follow programming language best practices</li> </ul>"},{"location":"aws/cdk/#security","title":"Security","text":"<ul> <li>Use IAM roles with least privilege</li> <li>Enable encryption by default</li> <li>Implement security groups properly</li> <li>Use VPC endpoints where appropriate</li> </ul>"},{"location":"aws/cdk/#cost-management","title":"Cost Management","text":"<ul> <li>Use Tags for cost allocation</li> <li>Implement lifecycle rules for storage</li> <li>Consider reserved instances for stable workloads</li> <li>Monitor usage with AWS Cost Explorer</li> </ul>"},{"location":"aws/cdk/#advanced-features","title":"Advanced Features","text":""},{"location":"aws/cdk/#asset-bundling","title":"Asset Bundling","text":"<p>CDK can bundle assets (like Lambda functions or Docker images) during deployment: <pre><code>new lambda.Function(this, 'MyFunction', {\n  runtime: lambda.Runtime.NODEJS_14_X,\n  code: lambda.Code.fromAsset('lambda'),\n  handler: 'index.handler'\n});\n</code></pre></p>"},{"location":"aws/cdk/#custom-constructs","title":"Custom Constructs","text":"<p>Create reusable infrastructure patterns: <pre><code>export class CustomVpc extends Construct {\n  constructor(scope: Construct, id: string, props?: CustomVpcProps) {\n    super(scope, id);\n    // Implementation\n  }\n}\n</code></pre></p>"},{"location":"aws/cdk/#context-and-environment","title":"Context and Environment","text":"<p>Handle environment-specific configurations: <pre><code>const environmentName = this.node.tryGetContext('environment');\n</code></pre></p>"},{"location":"aws/cdk/#workflow","title":"Workflow","text":"<p>The standard AWS CDK development workflow is similar to the workflow you\u2019re already familiar as a developer. There are a few extra steps:</p> <ol> <li> <p>Create the app from a template provided by AWS CDK - Each AWS CDK app should be in its own directory, with its own local module dependencies. Create a new directory for your app. Now initialize the app using the <code>cdk init</code> command, specifying the desired template (\u201capp\u201d) and programming language. The <code>cdk init</code> command creates a number of files and folders inside the created home directory to help you organize the source code for your AWS CDK app.</p> </li> <li> <p>Add code to the app to create resources within stacks - Add custom code as is needed for your application.</p> </li> <li> <p>Build the app (optional) - In most programming environments, after making changes to your code, you\u2019d build (compile) it. This isn\u2019t strictly necessary with the AWS CDK\u2014the Toolkit does it for you so you can\u2019t forget. But you can still build manually whenever you want to catch syntax and type errors.</p> </li> <li> <p>Synthesize one or more stacks in the app to create an AWS CloudFormation template - Synthesize one or more stacks in the app to create an AWS CloudFormation template. The synthesis step catches logical errors in defining your AWS resources. If your app contains more than one stack, you\u2019d need to specify which stack(s) to synthesize.</p> </li> <li> <p>Deploy one or more stacks to your AWS account - It is optional (though good practice) to synthesize before deploying. The AWS CDK synthesizes your stack before each deployment. If your code has security implications, you\u2019ll see a summary of these and need to confirm them before deployment proceeds. <code>cdk deploy</code> is used to deploy the stack using CloudFormation templates. This command displays progress information as your stack is deployed. When it\u2019s done, the command prompt reappears.</p> </li> </ol>"},{"location":"aws/cdk/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>Deployment Failures</li> <li>Check CloudFormation console for detailed error messages</li> <li>Verify IAM permissions</li> <li> <p>Review resource limits</p> </li> <li> <p>Synthesis Issues</p> </li> <li>Validate TypeScript/programming language syntax</li> <li>Check for circular dependencies</li> <li> <p>Verify construct properties</p> </li> <li> <p>Runtime Errors</p> </li> <li>Review CloudWatch logs</li> <li>Check resource configurations</li> <li>Verify network connectivity</li> </ol>"},{"location":"aws/cdk/#resources","title":"Resources","text":"<ul> <li>Official AWS CDK Documentation</li> <li>AWS CDK API Reference</li> <li>AWS CDK Workshop</li> <li>AWS CDK GitHub Repository</li> </ul>"},{"location":"aws/cdk/#contributing","title":"Contributing","text":"<p>The AWS CDK is open source and welcomes contributions. You can: - Report bugs - Submit feature requests - Create pull requests - Share construct libraries</p>"},{"location":"aws/cdk/#conclusion","title":"Conclusion","text":"<p>The AWS CDK represents a significant evolution in infrastructure as code, enabling developers to use familiar programming languages and concepts to define cloud infrastructure. Its combination of high-level abstractions and fine-grained control makes it a powerful tool for modern cloud development.</p>"},{"location":"aws/cloudhsm/","title":"CloudHSM (Cloud Hardware Security Module)","text":""},{"location":"aws/cloudhsm/#overview","title":"Overview","text":"<p>AWS CloudHSM is a cloud-based hardware security module (HSM) that enables customers to generate and use their own encryption keys on the AWS Cloud with full control and ownership.</p>"},{"location":"aws/cloudhsm/#key-features","title":"Key Features","text":"<ul> <li>Dedicated hardware security modules</li> <li>Fully managed, single-tenant HSM instances</li> <li>Supports industry-standard encryption standards</li> <li>Compliant with various security regulations (FIPS 140-2 Level 3)</li> </ul>"},{"location":"aws/cloudhsm/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Cryptographic key management</li> <li>Secure key storage</li> <li>Encryption and decryption operations</li> <li>Public Key Infrastructure (PKI)</li> <li>Regulatory compliance requirements</li> </ul>"},{"location":"aws/cloudhsm/#security-capabilities","title":"Security Capabilities","text":"<ul> <li>Generate and protect cryptographic keys</li> <li>Perform cryptographic operations</li> <li>Secure key lifecycle management</li> <li>Isolation from other AWS customers</li> </ul>"},{"location":"aws/cloudhsm/#supported-standards","title":"Supported Standards","text":"<ul> <li>PKCS#11</li> <li>OpenSSL</li> <li>Microsoft CryptoNG (CNG)</li> <li>Java Cryptography Extensions (JCE)</li> </ul>"},{"location":"aws/cloudhsm/#benefits","title":"Benefits","text":"<ul> <li>Enhanced security through hardware-based key protection</li> <li>Meets strict compliance and regulatory requirements</li> <li>Scalable encryption infrastructure</li> <li>Reduced operational complexity</li> </ul>"},{"location":"aws/codestar/","title":"CodeStar","text":""},{"location":"aws/codestar/#overview","title":"Overview","text":"<p>AWS CodeStar is a cloud-based development service that simplifies the process of developing, building, and deploying applications on Amazon Web Services (AWS).</p>"},{"location":"aws/codestar/#key-features","title":"Key Features","text":"<ul> <li>Unified Project Management: Provides a single interface to manage software development projects</li> <li>Quick Project Setup: Offers pre-configured project templates for multiple programming languages</li> <li>Integrated Tools: Seamlessly connects with AWS development and deployment services</li> </ul>"},{"location":"aws/codestar/#core-services-integration","title":"Core Services Integration","text":"<ul> <li>AWS CodeCommit (Source Control)</li> <li>AWS CodeBuild (Continuous Integration)</li> <li>AWS CodePipeline (Continuous Delivery)</li> <li>AWS CodeDeploy (Application Deployment)</li> </ul>"},{"location":"aws/codestar/#benefits","title":"Benefits","text":"<ul> <li>Accelerates software development workflow</li> <li>Reduces complexity of managing multiple AWS services</li> <li>Enables faster project initialization</li> <li>Provides consistent development environment</li> </ul>"},{"location":"aws/codestar/#supported-languages","title":"Supported Languages","text":"<ul> <li>Python</li> <li>Java</li> <li>Node.js</li> <li>.NET</li> <li>JavaScript</li> <li>PHP</li> </ul>"},{"location":"aws/codestar/#use-cases","title":"Use Cases","text":"<ul> <li>Web Applications</li> <li>Microservices</li> <li>Backend Services</li> <li>Cloud-native Applications</li> </ul>"},{"location":"aws/sar/","title":"Serverless Application Repository (SAR)","text":""},{"location":"aws/sar/#overview","title":"Overview","text":"<p>AWS Serverless Application Repository is a managed service that enables developers to find, deploy, and publish serverless applications quickly and easily.</p>"},{"location":"aws/sar/#key-features","title":"Key Features","text":""},{"location":"aws/sar/#application-discovery","title":"Application Discovery","text":"<ul> <li>Centralized repository of pre-built serverless applications</li> <li>Discover and use applications from:</li> <li>AWS-published applications</li> <li>Community-contributed applications</li> <li>Private organizational applications</li> </ul>"},{"location":"aws/sar/#deployment-capabilities","title":"Deployment Capabilities","text":"<ul> <li>One-click deployment of serverless applications</li> <li>Instant integration with AWS Lambda, API Gateway, and other serverless services</li> <li>Simplified infrastructure setup through CloudFormation templates</li> </ul>"},{"location":"aws/sar/#publishing-options","title":"Publishing Options","text":"<ul> <li>Public sharing of serverless applications</li> <li>Private sharing within organizations</li> <li>Ability to publish your own reusable serverless components</li> </ul>"},{"location":"aws/sar/#use-cases","title":"Use Cases","text":"<ul> <li>Rapid prototyping</li> <li>Accelerating development</li> <li>Sharing common serverless patterns</li> <li>Learning serverless architecture best practices</li> </ul>"},{"location":"aws/sar/#supported-application-types","title":"Supported Application Types","text":"<ul> <li>AWS Lambda functions</li> <li>API Gateway configurations</li> <li>Serverless workflows</li> <li>Event-driven applications</li> <li>Microservices components</li> </ul>"},{"location":"aws/sar/#benefits","title":"Benefits","text":"<ul> <li>Reduces time-to-market for serverless applications</li> <li>Promotes code reuse</li> <li>Ensures consistent deployment patterns</li> <li>Simplifies serverless application management</li> <li>Facilitates knowledge sharing across development teams</li> </ul>"},{"location":"aws/sar/#security-and-governance","title":"Security and Governance","text":"<ul> <li>Configurable visibility settings</li> <li>Version control for applications</li> <li>Integration with AWS Identity and Access Management (IAM)</li> <li>Compliance with organizational policies</li> </ul>"},{"location":"aws/step_function/","title":"Step Functions","text":"<p>AWS Step Functions is a serverless orchestration service that allows you to coordinate multiple AWS services into scalable workflows. It provides a visual interface for designing and executing workflows, making it easier to build and maintain applications.</p>"},{"location":"aws/step_function/#key-features","title":"Key Features","text":""},{"location":"aws/step_function/#1-visual-workflow-design","title":"1. Visual Workflow Design","text":"<ul> <li>Provides a graphical user interface to design and visualize workflows.</li> <li>Workflows are defined using Amazon States Language (ASL), a JSON-based language.</li> </ul>"},{"location":"aws/step_function/#2-service-orchestration","title":"2. Service Orchestration","text":"<ul> <li>Integrates seamlessly with AWS services like Lambda, DynamoDB, S3, ECS, SNS, and more.</li> <li>Supports both standard and express workflows, allowing flexibility based on use case.</li> </ul>"},{"location":"aws/step_function/#3-error-handling-and-retry","title":"3. Error Handling and Retry","text":"<ul> <li>Built-in error handling and retry logic to manage failures gracefully.</li> <li>Allows branching and fallback strategies to handle errors.</li> </ul>"},{"location":"aws/step_function/#4-step-execution-monitoring","title":"4. Step Execution Monitoring","text":"<ul> <li>Provides detailed logs and metrics through Amazon CloudWatch.</li> <li>Supports step-by-step debugging and monitoring.</li> </ul>"},{"location":"aws/step_function/#5-serverless-and-fully-managed","title":"5. Serverless and Fully Managed","text":"<ul> <li>No need to manage infrastructure or scaling.</li> <li>Automatically scales based on workflow execution demand.</li> </ul>"},{"location":"aws/step_function/#workflow-types","title":"Workflow Types","text":""},{"location":"aws/step_function/#1-standard-workflows","title":"1. Standard Workflows","text":"<ul> <li>Designed for long-running, durable workflows.</li> <li>Features: </li> <li>Execution duration up to 1 year.</li> <li>Exactly-once execution semantics.</li> <li>High durability and resilience.</li> </ul>"},{"location":"aws/step_function/#2-express-workflows","title":"2. Express Workflows","text":"<ul> <li>Optimized for high-volume, short-duration workflows.</li> <li>Features:</li> <li>Execution duration up to 5 minutes.</li> <li>At-least-once execution semantics.</li> <li>Lower cost, designed for high-throughput applications.</li> </ul>"},{"location":"aws/step_function/#task-types","title":"Task Types","text":"<p>AWS Step Functions supports various task types that allow you to perform different operations in a workflow. Below are the key task types:</p>"},{"location":"aws/step_function/#1-task","title":"1. Task","text":"<ul> <li>Executes a unit of work, such as invoking an AWS Lambda function or running a job on AWS Batch.</li> <li>Defined using the <code>Resource</code> field to specify the AWS service or API action.</li> </ul>"},{"location":"aws/step_function/#2-parallel","title":"2. Parallel","text":"<ul> <li>Executes multiple branches of a workflow simultaneously.</li> <li>Useful for scenarios requiring parallel processing.</li> </ul>"},{"location":"aws/step_function/#3-map","title":"3. Map","text":"<ul> <li>Processes a collection of items iteratively.</li> <li>Similar to a \u201cfor loop\u201d and can run iterations in parallel.</li> </ul>"},{"location":"aws/step_function/#4-choice","title":"4. Choice","text":"<ul> <li>Adds conditional logic to workflows.</li> <li>Routes execution based on the evaluation of input data.</li> </ul>"},{"location":"aws/step_function/#5-wait","title":"5. Wait","text":"<ul> <li>Delays execution for a specified time or until a specific timestamp.</li> </ul>"},{"location":"aws/step_function/#6-pass","title":"6. Pass","text":"<ul> <li>Passes input to the next state without performing any work.</li> <li>Useful for testing and placeholder states.</li> </ul>"},{"location":"aws/step_function/#7-succeed","title":"7. Succeed","text":"<ul> <li>Marks the workflow as successfully completed.</li> </ul>"},{"location":"aws/step_function/#8-fail","title":"8. Fail","text":"<ul> <li>Stops the workflow and marks it as failed.</li> <li>Can include error details for debugging.</li> </ul>"},{"location":"aws/step_function/#9-activity","title":"9. Activity","text":"<ul> <li>Represents a task performed by a worker program outside of Step Functions.</li> <li>Requires integration with an external worker.</li> </ul>"},{"location":"aws/step_function/#10-service-integration","title":"10. Service Integration","text":"<ul> <li>Directly integrates with AWS services such as S3, DynamoDB, ECS, and more, without needing AWS Lambda.</li> </ul>"},{"location":"aws/step_function/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Data Processing Pipelines</li> <li> <p>Automate ETL jobs, orchestrate machine learning model training, or coordinate big data workflows.</p> </li> <li> <p>Microservices Orchestration</p> </li> <li> <p>Coordinate interactions between microservices in distributed systems.</p> </li> <li> <p>IoT Applications</p> </li> <li> <p>Process and analyze data from IoT devices, triggering workflows based on incoming data.</p> </li> <li> <p>Application Backends</p> </li> <li> <p>Automate approval workflows, payment processing, or user registration flows.</p> </li> <li> <p>Disaster Recovery</p> </li> <li>Implement failover mechanisms and ensure system resilience.</li> </ol>"},{"location":"aws/step_function/#amazon-states-language-asl","title":"Amazon States Language (ASL)","text":""},{"location":"aws/step_function/#key-elements-of-asl","title":"Key Elements of ASL","text":"<ol> <li>States</li> <li> <p>Define individual steps in the workflow, such as tasks, choices, or parallel steps.</p> </li> <li> <p>Transitions</p> </li> <li> <p>Specify how the workflow progresses from one state to another.</p> </li> <li> <p>Error Handling</p> </li> <li>Define retry policies, catch blocks, and fallback mechanisms for errors.</li> </ol>"},{"location":"aws/step_function/#example-state-machine-definition","title":"Example State Machine Definition","text":"<pre><code>{\n  \"Comment\": \"An example of a simple Step Function workflow\",\n  \"StartAt\": \"HelloWorld\",\n  \"States\": {\n    \"HelloWorld\": {\n      \"Type\": \"Task\",\n      \"Resource\": \"arn:aws:lambda:us-east-1:123456789012:function:HelloWorldFunction\",\n      \"End\": true\n    }\n  }\n}\n</code></pre>"},{"location":"aws/step_function/#integration-with-aws-services","title":"Integration with AWS Services","text":"<ul> <li>AWS Lambda: Execute serverless functions for tasks within workflows.</li> <li>Amazon DynamoDB: Store and retrieve data as part of the workflow.</li> <li>Amazon S3: Trigger workflows based on events like object creation.</li> <li>Amazon ECS: Manage containerized tasks and services.</li> <li>SNS/SQS: Send notifications or queue messages during workflows.</li> </ul>"},{"location":"aws/step_function/#benefits","title":"Benefits","text":"<ol> <li>Improved Resilience: Built-in error handling and retries ensure reliable execution.</li> <li>Faster Development: Visual interface and easy integration with AWS services reduce development effort.</li> <li>Cost-Effective: Pay-as-you-go pricing with no upfront costs.</li> <li>Scalable and Secure: Automatically scales with demand and integrates with IAM for fine-grained access control.</li> </ol>"},{"location":"aws/step_function/#pricing","title":"Pricing","text":""},{"location":"aws/step_function/#standard-workflows","title":"Standard Workflows:","text":"<ul> <li>Charged per state transition: $0.025 per 1,000 transitions.</li> </ul>"},{"location":"aws/step_function/#express-workflows","title":"Express Workflows:","text":"<ul> <li>Charged based on requests and runtime.</li> <li>Example: $1.00 per 1 million requests and $0.00000456 per GB-second runtime.</li> </ul> <p>Refer to the AWS Step Functions Pricing Page for detailed information.</p>"},{"location":"aws/step_function/#best-practices","title":"Best Practices","text":"<ol> <li>Optimize State Transitions: Minimize the number of state transitions to reduce costs.</li> <li>Use Express Workflows for High-Volume Tasks: Choose express workflows for short-duration, high-volume tasks.</li> <li>Implement Robust Error Handling: Define retries, catch blocks, and fallback states.</li> <li>Monitor and Debug: Use CloudWatch logs and metrics for monitoring and troubleshooting.</li> <li>Test Thoroughly: Use the AWS Step Functions console to simulate and test workflows before production.</li> </ol> <p>For more details, refer to the AWS Step Functions Documentation.</p>"},{"location":"aws/sts/","title":"Security Token Service (STS)","text":""},{"location":"aws/sts/#core-purpose","title":"Core Purpose","text":"<p>AWS Security Token Service enables organizations to grant limited and temporary access to AWS resources, with credential validity up to one hour.</p>"},{"location":"aws/sts/#credential-generation-methods","title":"Credential Generation Methods","text":"<p>STS provides multiple mechanisms for obtaining temporary credentials:</p>"},{"location":"aws/sts/#role-assumption-methods","title":"Role Assumption Methods","text":"<ul> <li>AssumeRole: Enables role assumption within or across AWS accounts</li> <li>AssumeRoleWithSAML: Returns credentials for SAML-authenticated users</li> <li>AssumeRoleWithWebIdentity: Generates credentials for users logged via identity providers (Facebook, Google, OIDC)</li> <li>GetSessionToken: Supports multi-factor authentication for users and root accounts</li> <li>GetFederationToken: Obtains temporary credentials for federated users</li> <li>GetCallerIdentity: Returns details about the IAM user or role used in an API call</li> <li>DecodeAuthorizationMessage: Decodes error messages when an AWS API is denied</li> </ul>"},{"location":"aws/sts/#role-assumption-process","title":"Role Assumption Process","text":"<p>To assume a role using STS: - Define an IAM Role within your account or across accounts - Specify which principals can access the role - Use the AssumeRole API to retrieve credentials - Utilize temporary credentials valid between 15 minutes to 1 hour</p>"},{"location":"aws/sts/#multi-factor-authentication-mfa-support","title":"Multi-Factor Authentication (MFA) Support","text":"<p>STS provides robust MFA capabilities through the <code>GetSessionToken</code> method: - Requires appropriate IAM policy with condition <code>aws:MultiFactorAuthPresent:true</code> - Generates temporary credentials including:     - Access ID     - Secret Key     - Session Token     - Expiration date</p>"},{"location":"aws/sts/#troubleshooting","title":"Troubleshooting","text":"<p>When an autherization error is raised like this one: <pre><code>Encoded authorization failure message: 6h34GtpmGjJJUm946eDVBfzWQJk6z5GePbbGDs9Z2T8xZj9EZtEduSnTbmrR7pMqpJrVYJCew2m8YBZQf4HRWEtrpncANrZMsnzk\n</code></pre></p> <p>It\u2019s possilble to decode the message using: <pre><code>aws sts decode-authorization-message\n</code></pre></p>"},{"location":"aws/sts/#important-note","title":"Important Note","text":"<p>For web identity authentication, AWS recommends using Cognito Identity Pools instead of direct STS web identity credential generation.</p>"},{"location":"aws/swf/","title":"Simple Workflow Service (SWF)","text":""},{"location":"aws/swf/#overview","title":"Overview","text":"<p>Amazon Simple Workflow Service (SWF) is a web service that helps developers coordinate and manage complex distributed application workflows across multiple computing devices and services.</p>"},{"location":"aws/swf/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Manages workflow coordination and execution</li> <li>Enables complex, long-running business processes</li> <li>Supports both human-driven and automated tasks</li> <li>Provides robust tracking and state management</li> </ul>"},{"location":"aws/swf/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Distributed task coordination</li> <li>Workflow state tracking</li> <li>Automatic error handling</li> <li>Flexible task scheduling</li> <li>Support for human intervention tasks</li> </ul>"},{"location":"aws/swf/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Business process management</li> <li>Media processing workflows</li> <li>E-commerce order fulfillment</li> <li>Scientific and research computational workflows</li> <li>Large-scale data processing pipelines</li> </ul>"},{"location":"aws/swf/#key-components","title":"Key Components","text":"<ul> <li>Workflow Starters</li> <li>Deciders</li> <li>Activity Workers</li> <li>Task Lists</li> </ul>"},{"location":"aws/swf/#advantages","title":"Advantages","text":"<ul> <li>Handles complex workflow logic</li> <li>Manages application state and execution</li> <li>Provides fault-tolerant workflow management</li> <li>Scales automatically with AWS infrastructure</li> </ul>"},{"location":"aws/trusted_advisor/","title":"Trusted Advisor","text":"<p>AWS Trusted Advisor is a tool designed to help AWS customers optimize their cloud environments. It provides real-time guidance on improving the performance, security, cost efficiency, fault tolerance, and service limits of AWS resources.</p>"},{"location":"aws/trusted_advisor/#key-features","title":"Key Features","text":""},{"location":"aws/trusted_advisor/#1-best-practices-checks","title":"1. Best Practices Checks","text":"<p>Trusted Advisor evaluates your AWS environment against a set of best practices in five categories: - Cost Optimization: Identify underutilized or idle resources to reduce costs. - Performance: Improve the performance of your applications. - Security: Enhance security by identifying vulnerabilities or misconfigurations. - Fault Tolerance: Increase system availability and reduce downtime. - Service Limits: Monitor usage to prevent service interruptions caused by resource limits.</p>"},{"location":"aws/trusted_advisor/#2-personalized-recommendations","title":"2. Personalized Recommendations","text":"<p>Trusted Advisor provides tailored recommendations based on your AWS environment, enabling proactive management of resources.</p>"},{"location":"aws/trusted_advisor/#3-actionable-insights","title":"3. Actionable Insights","text":"<p>Each recommendation includes detailed steps to resolve the identified issues, making it easy to implement best practices.</p>"},{"location":"aws/trusted_advisor/#4-integration-with-aws-services","title":"4. Integration with AWS Services","text":"<ul> <li>AWS Organizations: Centralized management for multi-account environments.</li> <li>AWS Support Plans: Access to additional checks and features with Business or Enterprise Support plans.</li> <li>Amazon CloudWatch: Set up alarms for specific Trusted Advisor metrics.</li> </ul>"},{"location":"aws/trusted_advisor/#5-automated-notifications","title":"5. Automated Notifications","text":"<p>Receive regular updates and notifications about your environment\u2019s health.</p>"},{"location":"aws/trusted_advisor/#core-checks","title":"Core Checks","text":""},{"location":"aws/trusted_advisor/#cost-optimization","title":"Cost Optimization","text":"<ul> <li>Identify idle or underutilized EC2 instances, EBS volumes, and load balancers.</li> <li>Recommend reserved instance purchases for cost savings.</li> </ul>"},{"location":"aws/trusted_advisor/#performance","title":"Performance","text":"<ul> <li>Monitor high-utilization EC2 instances and recommend scaling or upgrading.</li> <li>Evaluate Auto Scaling configurations for efficiency.</li> </ul>"},{"location":"aws/trusted_advisor/#security","title":"Security","text":"<ul> <li>Highlight open access permissions in security groups.</li> <li>Identify exposed IAM access keys.</li> <li>Ensure MFA (Multi-Factor Authentication) is enabled for root accounts.</li> </ul>"},{"location":"aws/trusted_advisor/#fault-tolerance","title":"Fault Tolerance","text":"<ul> <li>Detect Amazon RDS backups not configured.</li> <li>Identify instances running on single Availability Zones.</li> </ul>"},{"location":"aws/trusted_advisor/#service-limits","title":"Service Limits","text":"<ul> <li>Track usage against AWS service limits to avoid disruptions.</li> <li>Recommend actions to stay within limits or request increases.</li> </ul>"},{"location":"aws/trusted_advisor/#accessing-trusted-advisor","title":"Accessing Trusted Advisor","text":""},{"location":"aws/trusted_advisor/#aws-management-console","title":"AWS Management Console","text":"<ol> <li>Log in to the AWS Management Console.</li> <li>Navigate to Trusted Advisor from the \u201cAWS Management &amp; Governance\u201d section.</li> <li>Select a category to view specific checks and recommendations.</li> </ol>"},{"location":"aws/trusted_advisor/#api-and-sdk-access","title":"API and SDK Access","text":"<ul> <li>Use the AWS Support API to programmatically retrieve Trusted Advisor check results.</li> </ul>"},{"location":"aws/trusted_advisor/#available-checks-based-on-support-plan","title":"Available Checks Based on Support Plan","text":"Category Free Tier Business &amp; Enterprise Cost Optimization Basic Full Performance Limited Full Security Limited Full Fault Tolerance Limited Full Service Limits Basic Full"},{"location":"aws/trusted_advisor/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Cost Reduction</li> <li> <p>Identify unused resources like idle EC2 instances and unused EBS volumes to reduce costs.</p> </li> <li> <p>Improved Security</p> </li> <li> <p>Address misconfigured security groups or unused IAM credentials to strengthen security.</p> </li> <li> <p>Enhanced Performance</p> </li> <li> <p>Ensure application performance by scaling under-provisioned resources.</p> </li> <li> <p>Avoiding Downtime</p> </li> <li>Proactively monitor service limits to avoid disruptions caused by exceeded quotas.</li> </ol>"},{"location":"aws/trusted_advisor/#best-practices","title":"Best Practices","text":"<ol> <li>Regular Monitoring</li> <li> <p>Set up a schedule to review Trusted Advisor recommendations regularly.</p> </li> <li> <p>Integrate with Automation Tools</p> </li> <li> <p>Use AWS Lambda or other automation tools to act on Trusted Advisor findings.</p> </li> <li> <p>Enable Notifications</p> </li> <li> <p>Set up CloudWatch alarms to notify you about critical checks.</p> </li> <li> <p>Leverage AWS Organizations</p> </li> <li>Use Trusted Advisor for centralized management in multi-account setups.</li> </ol>"},{"location":"aws/trusted_advisor/#limitations","title":"Limitations","text":"<ol> <li>Some advanced checks require Business or Enterprise Support plans.</li> <li>Trusted Advisor does not provide deep analytics for custom applications.</li> </ol> <p>For more details, visit the AWS Trusted Advisor Documentation.</p>"},{"location":"aws/computing/amplify/","title":"Amplify","text":""},{"location":"aws/computing/amplify/#overview","title":"Overview","text":"<p>AWS Amplify is a comprehensive set of tools and services for building and deploying full-stack mobile and web applications, often described as the \u201cElastic Beanstalk for mobile and web applications\u201d.</p>"},{"location":"aws/computing/amplify/#core-components","title":"Core Components","text":""},{"location":"aws/computing/amplify/#amplify-studio","title":"Amplify Studio","text":"<ul> <li>Visually build full-stack applications</li> <li>Integrated front-end UI and backend development</li> <li>Provides graphical interface for app creation</li> </ul>"},{"location":"aws/computing/amplify/#amplify-libraries","title":"Amplify Libraries","text":"<p>Connect applications to AWS services. Support for:</p> <ul> <li>Amazon Cognito</li> <li>Amazon S3</li> <li>Other AWS services</li> </ul> <p>Front-end libraries for multiple frameworks:</p> <ul> <li>React.js</li> <li>Vue</li> <li>JavaScript</li> <li>iOS</li> <li>Android</li> <li>Flutter</li> </ul>"},{"location":"aws/computing/amplify/#amplify-cli","title":"Amplify CLI","text":"<ul> <li>Configure backend infrastructure</li> <li>Guided workflow for backend setup</li> <li>Streamlines AWS service configuration</li> </ul>"},{"location":"aws/computing/amplify/#amplify-hosting","title":"Amplify Hosting","text":"<ul> <li>Secure and reliable web app hosting</li> <li>Leverages AWS Content Delivery Network (CDN)</li> <li>Provides continuous deployment capabilities</li> </ul>"},{"location":"aws/computing/amplify/#key-features","title":"Key Features","text":""},{"location":"aws/computing/amplify/#authentication","title":"Authentication","text":"<p>Powered by Amazon Cognito. Features:</p> <ul> <li>User registration</li> <li>Authentication</li> <li>Account recovery</li> <li>Multi-factor authentication</li> <li>Social sign-in</li> <li>Pre-built UI components</li> <li>Fine-grained authorization</li> </ul>"},{"location":"aws/computing/amplify/#datastore","title":"DataStore","text":"<p>Utilizes Amazon AppSync and DynamoDB. Capabilities:</p> <ul> <li>Local data management</li> <li>Automatic cloud synchronization</li> <li>GraphQL-powered</li> <li>Offline and real-time data capabilities</li> <li>Visual data modeling</li> </ul>"},{"location":"aws/computing/amplify/#hosting-capabilities","title":"Hosting Capabilities","text":"<ul> <li>Continuous Integration/Continuous Deployment (CI/CD)</li> <li>Pull request previews</li> <li>Custom domain support</li> <li>Monitoring</li> <li>Redirect and custom header configurations</li> <li>Password protection</li> </ul>"},{"location":"aws/computing/amplify/#end-to-end-e2e-testing","title":"End-to-End (E2E) Testing","text":"<ul> <li>Integrated testing framework</li> <li>Supports Cypress testing</li> <li>Test phases:</li> <li>During build</li> <li>During deployment</li> <li>Generates UI test reports</li> </ul>"},{"location":"aws/computing/amplify/#benefits","title":"Benefits","text":"<ul> <li>Simplified full-stack development</li> <li>Incorporates AWS best practices</li> <li>Supports reliability, security, and scalability</li> <li>Rapid application development</li> <li>Seamless integration with AWS services</li> </ul>"},{"location":"aws/computing/amplify/#supported-development-workflows","title":"Supported Development Workflows","text":"<ul> <li>CLI-based development</li> <li>Visual studio development</li> <li>Hybrid approaches</li> </ul>"},{"location":"aws/computing/api_gateway/","title":"API Gateway","text":"<p>Amazon API Gateway is a fully managed service provided by AWS for creating, deploying, and managing APIs at any scale. It supports both RESTful APIs and WebSocket APIs, enabling real-time two-way communication between applications.</p>"},{"location":"aws/computing/api_gateway/#key-characteristics-of-api-gateway","title":"Key Characteristics of API Gateway","text":""},{"location":"aws/computing/api_gateway/#1-fully-managed-service","title":"1. Fully Managed Service","text":"<ul> <li>Simplifies API lifecycle management, including creation, deployment, monitoring, and versioning.</li> <li>No need for managing infrastructure.</li> </ul>"},{"location":"aws/computing/api_gateway/#2-multi-protocol-support","title":"2. Multi-Protocol Support","text":"<ul> <li>Supports both RESTful APIs and WebSocket APIs.</li> </ul>"},{"location":"aws/computing/api_gateway/#3-scalability","title":"3. Scalability","text":"<ul> <li>Automatically scales to handle thousands of concurrent API calls.</li> <li>Provides consistent performance regardless of traffic volume.</li> </ul>"},{"location":"aws/computing/api_gateway/#4-security","title":"4. Security","text":"<p>Supports multiple authentication mechanisms:</p> <ul> <li>AWS Identity and Access Management (IAM)</li> <li>API keys</li> <li>Amazon Cognito user pools</li> <li>Lambda authorizers for custom authentication</li> </ul> <p>Integration with AWS WAF for protection against DDoS attacks and common web exploits.</p>"},{"location":"aws/computing/api_gateway/#5-integration-with-aws-services","title":"5. Integration with AWS Services","text":"<ul> <li>Seamlessly integrates with AWS Lambda, DynamoDB, S3, Step Functions, and other AWS services.</li> <li>Acts as a front door for serverless and containerized applications.</li> </ul>"},{"location":"aws/computing/api_gateway/#6-monitoring-and-analytics","title":"6. Monitoring and Analytics","text":"<ul> <li>Provides built-in monitoring and logging via Amazon CloudWatch.</li> <li>Tracks metrics like latency, error rates, and request counts.</li> <li>Enables detailed request and response logging for debugging and analysis.</li> </ul>"},{"location":"aws/computing/api_gateway/#7-custom-domain-names","title":"7. Custom Domain Names","text":"<ul> <li>Supports custom domain names for APIs.</li> <li>Allows configuring HTTPS endpoints with custom certificates.</li> </ul>"},{"location":"aws/computing/api_gateway/#8-flexible-deployment-options","title":"8. Flexible Deployment Options","text":"<ul> <li>Supports multiple stages (e.g., dev, staging, production) for API deployment.</li> <li>Provides stage variables for dynamic configuration.</li> </ul>"},{"location":"aws/computing/api_gateway/#9-stages","title":"9. Stages","text":"<p>Definition: Stages represent different environments or versions of your API (e.g., development, testing, production). Key Features:</p> <ul> <li>Each stage has its own URL endpoint.</li> <li>Stages can be configured with unique settings, such as throttling limits, caching, and logging.</li> <li>Stage variables allow dynamic configuration of stage-specific values, such as Lambda function ARNs.</li> </ul> <p>Benefits:   - Simplifies versioning and environment management.   - Facilitates separate monitoring and troubleshooting for each stage.</p>"},{"location":"aws/computing/api_gateway/#10-throttling-and-quotas","title":"10. Throttling and Quotas","text":"<ul> <li>Allows setting rate limits and burst limits to protect APIs from being overwhelmed.</li> <li>Offers quota settings to manage usage by API consumers.</li> </ul>"},{"location":"aws/computing/api_gateway/#11-transformation-and-validation","title":"11. Transformation and Validation","text":"<ul> <li>Supports request and response transformation using Velocity Template Language (VTL).</li> <li>Validates incoming requests against defined schemas.</li> </ul>"},{"location":"aws/computing/api_gateway/#12-caching","title":"12. Caching","text":"<ul> <li>Provides in-built caching for reducing latency and improving API performance.</li> <li>Cache sizes range from 0.5 GB to 237 GB.</li> </ul>"},{"location":"aws/computing/api_gateway/#13-versioning","title":"13. Versioning","text":"<ul> <li>Allows managing multiple API versions simultaneously.</li> <li>Helps in seamless API transitions and backward compatibility.</li> </ul>"},{"location":"aws/computing/api_gateway/#14-pay-as-you-go-pricing","title":"14. Pay-As-You-Go Pricing","text":"<ul> <li>Pricing based on the number of API calls, data transfer out, and caching.</li> <li>No upfront costs or long-term commitments.</li> </ul>"},{"location":"aws/computing/api_gateway/#15-multi-region-deployment","title":"15. Multi-Region Deployment","text":"<ul> <li>Supports deploying APIs in multiple AWS regions.</li> <li>Ensures high availability and low latency for global users.</li> </ul>"},{"location":"aws/computing/api_gateway/#16-developer-portal","title":"16. Developer Portal","text":"<ul> <li>Provides an open-source developer portal for onboarding and managing API consumers.</li> <li>Enables API key generation, documentation browsing, and API testing.</li> </ul> <p>API Gateway simplifies API development by acting as a unified entry point for various backend systems. With its rich features, it is suitable for building scalable, secure, and performant APIs for modern applications.</p>"},{"location":"aws/computing/autoscaling_groups/","title":"Auto Scaling Groups (ASG)","text":""},{"location":"aws/computing/autoscaling_groups/#introduction","title":"Introduction","text":"<p>In real-world applications, website and application loads fluctuate constantly. AWS Auto Scaling Groups (ASG) provide a solution to dynamically manage compute resources in response to these changing demands. This service is provided at no additional cost beyond the underlying EC2 instances.</p>"},{"location":"aws/computing/autoscaling_groups/#core-functionality","title":"Core Functionality","text":"<p>Auto Scaling Groups enable automatic adjustment of EC2 instance capacity in response to application demands. The system scales out by adding instances during high load periods and scales in by removing instances when demand decreases. ASG maintains instance counts within defined minimum and maximum boundaries while automatically registering new instances with load balancers. When an instance becomes unhealthy, ASG automatically recreates it to maintain system reliability.</p>"},{"location":"aws/computing/autoscaling_groups/#architecture-components","title":"Architecture Components","text":""},{"location":"aws/computing/autoscaling_groups/#basic-structure","title":"Basic Structure","text":"<p>An Auto Scaling Group operates within defined capacity limits. The system maintains a minimum capacity to ensure service availability, adjusts the desired capacity based on demand, and enforces a maximum capacity to control costs. This flexible structure allows for dynamic resource allocation while maintaining operational control.</p>"},{"location":"aws/computing/autoscaling_groups/#integration-with-load-balancers","title":"Integration with Load Balancers","text":"<p>ASG seamlessly integrates with Elastic Load Balancers (ELB) to distribute traffic across instances. The ELB actively monitors instance health, enabling ASG to maintain service reliability by replacing unhealthy instances automatically.</p>"},{"location":"aws/computing/autoscaling_groups/#configuration-attributes","title":"Configuration Attributes","text":""},{"location":"aws/computing/autoscaling_groups/#launch-template","title":"Launch Template","text":"<p>The Launch Template (which replaces the deprecated Launch Configurations) defines the blueprint for new instances. This template includes:</p> <ul> <li>essential instance specifications including AMI and instance type</li> <li>initialization scripts through EC2 User Data</li> <li>storage configurations with EBS volumes</li> <li>security settings through Security Groups and SSH key pairs</li> <li>instance permissions via IAM roles</li> </ul> <p>The template also specifies network settings including VPC and subnet information, and load balancer configurations.</p>"},{"location":"aws/computing/autoscaling_groups/#scaling-parameters","title":"Scaling Parameters","text":"<p>ASG requires defined minimum and maximum size limits, along with an initial capacity setting. These parameters establish the operational boundaries for the scaling process. Scaling policies determine how and when the system adjusts capacity within these limits.</p>"},{"location":"aws/computing/autoscaling_groups/#scaling-mechanisms","title":"Scaling Mechanisms","text":""},{"location":"aws/computing/autoscaling_groups/#cloudwatch-integration","title":"CloudWatch Integration","text":"<p>ASG leverages CloudWatch alarms to trigger scaling actions. These alarms monitor metrics such as average CPU utilization or custom metrics across all ASG instances. When metrics cross defined thresholds, scaling policies execute to adjust instance counts appropriately.</p>"},{"location":"aws/computing/autoscaling_groups/#scaling-policy-types","title":"Scaling Policy Types","text":"<p>The system supports several scaling approaches:</p> <ul> <li>Dynamic Scaling - offers two main methods: </li> <li>Target Tracking Scaling provides straightforward setup for maintaining specific metric targets, such as keeping average CPU utilization at 40%</li> <li>Simple/Step Scaling executes specific capacity adjustments when CloudWatch alarms trigger, such as adding two instances when CPU exceeds 70%</li> <li>Scheduled Scaling enables proactive capacity adjustment based on known usage patterns, such as increasing minimum capacity during peak business hours.</li> <li>Predictive Scaling uses machine learning to forecast load patterns and schedule scaling activities in advance.</li> </ul>"},{"location":"aws/computing/autoscaling_groups/#scaling-metrics","title":"Scaling Metrics","text":"<p>Effective scaling relies on choosing appropriate metrics. Common metrics include:</p> <p>CPU Utilization provides insight into processing demands across instances. RequestCountPerTarget helps maintain consistent request distribution across instances. Network Input/Output monitoring supports scaling for network-bound applications. Custom metrics can be implemented through CloudWatch for specialized scaling requirements.</p>"},{"location":"aws/computing/autoscaling_groups/#operational-considerations","title":"Operational Considerations","text":""},{"location":"aws/computing/autoscaling_groups/#cooldown-periods","title":"Cooldown Periods","text":"<p>After each scaling activity, ASG implements a cooldown period (default 300 seconds) during which no additional scaling actions occur. This stabilization period prevents rapid scaling fluctuations and allows metric stabilization. Using pre-configured AMIs can reduce instance configuration time and enable shorter cooldown periods.</p>"},{"location":"aws/computing/autoscaling_groups/#instance-refresh","title":"Instance Refresh","text":"<p>When updating launch templates, ASG provides an Instance Refresh feature to systematically replace existing instances. This process maintains a specified minimum healthy percentage of instances while implementing updates. Administrators can define warm-up periods to ensure instances are fully operational before entering service.</p>"},{"location":"aws/computing/autoscaling_groups/#best-practices","title":"Best Practices","text":"<p>To optimize ASG operations:</p> <ul> <li>Implement appropriate monitoring metrics aligned with application characteristics</li> <li>Configure scaling policies that reflect actual application demands</li> <li>Use pre-configured AMIs to reduce instance initialization time</li> <li>Set appropriate cooldown periods to prevent scaling thrashing</li> <li>Regularly review and adjust scaling parameters based on performance data</li> <li>Implement predictive scaling for workloads with predictable patterns</li> <li>Maintain adequate minimum capacity for base load requirements</li> </ul> <p>Through careful configuration and monitoring of these components, Auto Scaling Groups provide robust, cost-effective management of compute resources in response to changing application demands.</p>"},{"location":"aws/computing/ec2/","title":"Elastic Compute Cloud (EC2)","text":""},{"location":"aws/computing/ec2/#introduction","title":"Introduction","text":"<p>Amazon Elastic Compute Cloud (EC2) is a fundamental web service providing scalable, flexible computing capacity in the AWS cloud. It enables users to launch, manage, and scale virtual server instances with complete control over computing resources, supporting a wide range of workloads from simple web hosting to complex enterprise applications.</p>"},{"location":"aws/computing/ec2/#core-architectural-components","title":"Core Architectural Components","text":""},{"location":"aws/computing/ec2/#instance-types","title":"Instance Types","text":"<p>EC2 offers diverse instance categories optimized for specific use cases:</p>"},{"location":"aws/computing/ec2/#general-purpose-instances","title":"General Purpose Instances","text":"<p>Balanced compute, memory, and networking resources suitable for a broad range of workloads. These instances provide an equilibrium between different computational resources, making them versatile for web servers, small databases, and development environments.</p>"},{"location":"aws/computing/ec2/#compute-optimized-instances","title":"Compute Optimized Instances","text":"<p>Designed for compute-intensive applications requiring high-performance processors. Ideal for batch processing, media transcoding, high-performance web servers, machine learning inference, and scientific modeling.</p>"},{"location":"aws/computing/ec2/#memory-optimized-instances","title":"Memory Optimized Instances","text":"<p>Engineered to deliver fast performance for workloads processing large datasets in memory. Critical for high-performance databases, distributed web scale cache, in-memory analytics, and real-time big data processing.</p>"},{"location":"aws/computing/ec2/#storage-optimized-instances","title":"Storage Optimized Instances","text":"<p>Provide high, sequential read/write access to large datasets. Optimal for distributed file systems, data warehousing, and high-frequency online transaction processing (OLTP) systems.</p>"},{"location":"aws/computing/ec2/#accelerated-computing-instances","title":"Accelerated Computing Instances","text":"<p>Incorporate hardware accelerators or co-processors for specialized computational tasks. Leveraged extensively in machine learning, graphics rendering, and cryptocurrency mining.</p>"},{"location":"aws/computing/ec2/#launch-and-management-strategies","title":"Launch and Management Strategies","text":""},{"location":"aws/computing/ec2/#instance-purchasing-options","title":"Instance Purchasing Options","text":""},{"location":"aws/computing/ec2/#on-demand-instances","title":"On-Demand Instances","text":"<p>Pay for compute capacity by the hour or second with no long-term commitments. Provides maximum flexibility for unpredictable workloads and short-term applications.</p>"},{"location":"aws/computing/ec2/#reserved-instances","title":"Reserved Instances","text":"<p>Offer significant cost savings by committing to specific instance configurations for 1-3 year terms. Ideal for predictable, steady-state workloads with consistent computational requirements.</p>"},{"location":"aws/computing/ec2/#spot-instances","title":"Spot Instances","text":"<p>Enable purchasing unused EC2 capacity at steep discounts, potentially up to 90% off on-demand pricing. Suitable for fault-tolerant, flexible workloads like batch processing and scientific computing.</p>"},{"location":"aws/computing/ec2/#dedicated-hosts","title":"Dedicated Hosts","text":"<p>Provide physical servers dedicated exclusively to a single customer, addressing complex licensing and compliance requirements.</p>"},{"location":"aws/computing/ec2/#networking-capabilities","title":"Networking Capabilities","text":""},{"location":"aws/computing/ec2/#network-configuration","title":"Network Configuration","text":"<p>EC2 instances operate within Virtual Private Clouds (VPCs), offering granular control over network environments. Users can configure:</p> <ul> <li>IP address ranges</li> <li>Subnet creation</li> <li>Route table management</li> <li>Network gateway configurations</li> </ul>"},{"location":"aws/computing/ec2/#best-practices","title":"Best Practices","text":"<ol> <li>Use Both: Combine Security Groups and NACLs for a layered defense approach.</li> <li>Least Privilege: Only allow traffic that is necessary for your application.</li> <li> <p>Organize Rule Sets:</p> </li> <li> <p>Use Security Groups for instance-level control.</p> </li> <li> <p>Use NACLs to block/allow traffic at the subnet level.</p> </li> <li> <p>Monitor and Audit:</p> </li> <li> <p>Regularly review and update rules to ensure compliance and avoid unnecessary exposure.</p> </li> <li> <p>Default Rules:</p> </li> <li> <p>Ensure custom NACLs deny all traffic by default until rules are explicitly added.</p> </li> </ol> <p>By leveraging Security Groups and NACLs together, you can implement a robust and secure network architecture in AWS.</p>"},{"location":"aws/computing/ec2/#storage-options","title":"Storage Options","text":""},{"location":"aws/computing/ec2/#amazon-ebs-elastic-block-store","title":"Amazon EBS (Elastic Block Store)","text":"<p>Persistent block-level storage volumes attachable to EC2 instances. Supports various volume types:</p> <ul> <li>General Purpose SSD</li> <li>Provisioned IOPS SSD</li> <li>Throughput Optimized HDD</li> <li>Cold HDD</li> </ul>"},{"location":"aws/computing/ec2/#instance-store","title":"Instance Store","text":"<p>Temporary block-level storage directly attached to the host computer, providing high I/O performance for temporary data.</p>"},{"location":"aws/computing/ec2/#monitoring-and-management","title":"Monitoring and Management","text":""},{"location":"aws/computing/ec2/#amazon-cloudwatch","title":"Amazon CloudWatch","text":"<p>Provides comprehensive monitoring capabilities:</p> <ul> <li>Performance metrics</li> <li>Resource utilization tracking</li> <li>Automated scaling</li> <li>Custom metric creation</li> </ul>"},{"location":"aws/computing/ec2/#aws-systems-manager","title":"AWS Systems Manager","text":"<p>Enables centralized operational management across AWS resources, facilitating:</p> <ul> <li>Configuration management</li> <li>Patch management</li> <li>Automated tasks</li> <li>Compliance tracking</li> </ul>"},{"location":"aws/computing/ec2/#pricing-model","title":"Pricing Model","text":""},{"location":"aws/computing/ec2/#factors-influencing-cost","title":"Factors Influencing Cost","text":"<ul> <li>Instance type</li> <li>Region</li> <li>Operating system</li> <li>Purchasing option</li> <li>Additional services and data transfer</li> </ul>"},{"location":"aws/computing/ec2/#use-cases","title":"Use Cases","text":""},{"location":"aws/computing/ec2/#enterprise-applications","title":"Enterprise Applications","text":"<ul> <li>Web hosting</li> <li>Enterprise application servers</li> <li>Development and testing environments</li> </ul>"},{"location":"aws/computing/ec2/#scientific-computing","title":"Scientific Computing","text":"<ul> <li>High-performance computing</li> <li>Genomic research</li> <li>Climate modeling</li> </ul>"},{"location":"aws/computing/ec2/#media-processing","title":"Media Processing","text":"<ul> <li>Video rendering</li> <li>Transcoding</li> <li>Content delivery</li> </ul>"},{"location":"aws/computing/ec2/#best-practices_1","title":"Best Practices","text":"<ul> <li>Right-size instances based on workload</li> <li>Implement auto-scaling</li> <li>Utilize multiple availability zones</li> <li>Leverage appropriate purchasing models</li> <li>Implement robust security configurations</li> <li>Continuously monitor performance metrics</li> </ul>"},{"location":"aws/computing/ec2/#limitations-and-considerations","title":"Limitations and Considerations","text":"<ul> <li>Maximum of 20 On-Demand instances per region</li> <li>Specific service quotas and limits</li> <li>Regional availability variations</li> <li>Potential data transfer costs</li> </ul>"},{"location":"aws/computing/ec2/#conclusion","title":"Conclusion","text":"<p>AWS EC2 represents a powerful, flexible computing platform enabling organizations to scale computational resources dynamically, efficiently, and cost-effectively. By understanding its comprehensive capabilities, users can design robust, scalable cloud architectures tailored to diverse computational requirements.</p>"},{"location":"aws/computing/ecs/","title":"Elastic Container Service (ECS)","text":""},{"location":"aws/computing/ecs/#overview","title":"Overview","text":"<p>Amazon Elastic Container Service (ECS) is a fully managed container orchestration service that enables you to run Docker containers on AWS infrastructure. This document provides a comprehensive overview of ECS components, features, and best practices.</p>"},{"location":"aws/computing/ecs/#launch-types","title":"Launch Types","text":""},{"location":"aws/computing/ecs/#ec2-launch-type","title":"EC2 Launch Type","text":"<p>ECS with EC2 launch type requires you to provision and maintain your own EC2 instances. Key characteristics include:</p> <ul> <li>You must provision and maintain the infrastructure (EC2 instances)</li> <li>Each EC2 instance must run the ECS Agent to register in the ECS Cluster</li> <li>AWS manages container starting and stopping</li> <li>Requires more management but offers more control</li> </ul>"},{"location":"aws/computing/ecs/#fargate-launch-type","title":"Fargate Launch Type","text":"<p>Fargate is a serverless compute engine for containers. Key features include:</p> <ul> <li>No infrastructure provisioning required</li> <li>Fully serverless operation</li> <li>Only requires task definitions</li> <li>AWS automatically runs ECS Tasks based on CPU/RAM requirements</li> <li>Scaling is simplified - just increase the number of tasks</li> </ul>"},{"location":"aws/computing/ecs/#iam-roles-for-ecs","title":"IAM Roles for ECS","text":""},{"location":"aws/computing/ecs/#ec2-instance-profile-ec2-launch-type-only","title":"EC2 Instance Profile (EC2 Launch Type only)","text":"<p>Used by the ECS agent for:</p> <ul> <li>Making API calls to ECS service</li> <li>Sending container logs to CloudWatch Logs</li> <li>Pulling Docker images from ECR</li> <li>Accessing sensitive data in Secrets Manager or SSM Parameter Store</li> </ul>"},{"location":"aws/computing/ecs/#ecs-task-role","title":"ECS Task Role","text":"<ul> <li>Allows each task to have a specific role</li> <li>Different roles can be used for different ECS Services</li> <li>Defined in the task definition</li> </ul>"},{"location":"aws/computing/ecs/#load-balancer-integration","title":"Load Balancer Integration","text":""},{"location":"aws/computing/ecs/#supported-load-balancers","title":"Supported Load Balancers","text":"<ul> <li>Application Load Balancer (ALB) - recommended for most use cases</li> <li>Network Load Balancer (NLB) - recommended for high throughput/performance cases or AWS Private Link</li> <li>Classic Load Balancer - supported but not recommended (no advanced features, no Fargate support)</li> </ul>"},{"location":"aws/computing/ecs/#data-volumes","title":"Data Volumes","text":""},{"location":"aws/computing/ecs/#efs-integration","title":"EFS Integration","text":"<ul> <li>Mount EFS file systems onto ECS tasks</li> <li>Compatible with both EC2 and Fargate launch types</li> <li>Tasks in any AZ share the same data</li> <li>Fargate + EFS provides fully serverless solution</li> <li>Note: Amazon S3 cannot be mounted as a file system</li> </ul>"},{"location":"aws/computing/ecs/#bind-mounts","title":"Bind Mounts","text":"<ul> <li>Share data between multiple containers in the same Task Definition</li> <li>Works for both EC2 and Fargate tasks</li> <li>EC2 Tasks: Uses EC2 instance storage (data tied to EC2 instance lifecycle)</li> <li>Fargate Tasks: Uses ephemeral storage (20-200 GiB, default 20 GiB)</li> </ul>"},{"location":"aws/computing/ecs/#auto-scaling","title":"Auto Scaling","text":""},{"location":"aws/computing/ecs/#service-auto-scaling","title":"Service Auto Scaling","text":"<ul> <li>Automatically adjusts the number of ECS tasks</li> <li>Uses AWS Application Auto Scaling</li> <li> <p>Scaling metrics:</p> </li> <li> <p>ECS Service Average CPU Utilization</p> </li> <li>ECS Service Average Memory Utilization</li> <li>ALB Request Count PerTarget</li> </ul>"},{"location":"aws/computing/ecs/#scaling-methods","title":"Scaling Methods","text":"<ul> <li>Target Tracking - based on CloudWatch metric target</li> <li>Step Scaling - based on CloudWatch Alarm</li> <li>Scheduled Scaling - based on date/time</li> </ul>"},{"location":"aws/computing/ecs/#ec2-launch-type-auto-scaling","title":"EC2 Launch Type Auto Scaling","text":"<ul> <li>Auto Scaling Group Scaling based on CPU Utilization</li> <li>ECS Cluster Capacity Provider for automatic infrastructure provisioning</li> </ul>"},{"location":"aws/computing/ecs/#task-definitions","title":"Task Definitions","text":"<p>Task definitions are JSON metadata that tell ECS how to run Docker containers. They include:</p> <ul> <li>Image Name</li> <li>Port Binding for Container and Host</li> <li>Memory and CPU requirements</li> <li>Environment variables</li> <li>Networking information</li> <li>IAM Role</li> <li>Logging configuration</li> <li>Up to 10 containers per Task Definition</li> </ul>"},{"location":"aws/computing/ecs/#environment-variables","title":"Environment Variables","text":"<p>Supported types:</p> <ul> <li>Hardcoded values (e.g., URLs)</li> <li>SSM Parameter Store (sensitive variables, API keys, configs)</li> <li>Secrets Manager (sensitive variables, DB passwords)</li> <li>Environment Files (bulk) from Amazon S3</li> </ul>"},{"location":"aws/computing/ecs/#task-placement-ec2-launch-type-only","title":"Task Placement (EC2 Launch Type Only)","text":""},{"location":"aws/computing/ecs/#placement-process","title":"Placement Process","text":"<ol> <li>Identify instances meeting CPU, memory, and port requirements</li> <li>Identify instances satisfying Task Placement Constraints</li> <li>Identify instances satisfying Task Placement Strategies</li> <li>Select instances</li> </ol>"},{"location":"aws/computing/ecs/#placement-strategies","title":"Placement Strategies","text":"<ul> <li>Binpack - optimizes resource usage by placing tasks on instances with least available CPU/memory</li> <li>Random - places tasks randomly across instances</li> <li>Spread - distributes tasks evenly based on specified values (e.g., availability zone)</li> </ul>"},{"location":"aws/computing/ecs/#placement-constraints","title":"Placement Constraints","text":"<ul> <li>distinctInstance - ensures tasks are placed on different EC2 instances</li> <li>memberOf - places tasks on instances meeting specified criteria using Cluster Query Language</li> </ul>"},{"location":"aws/computing/ecs/#rolling-updates","title":"Rolling Updates","text":"<p>Control task updates from v1 to v2 by specifying:</p> <ul> <li>Minimum Healthy Percent (0-100%)</li> <li>Maximum Percent (100-200%)</li> <li>Controls task termination and creation order during updates</li> </ul>"},{"location":"aws/computing/ecs/#load-balancing","title":"Load Balancing","text":""},{"location":"aws/computing/ecs/#ec2-launch-type_1","title":"EC2 Launch Type","text":"<ul> <li>Supports Dynamic Host Port Mapping</li> <li>ALB automatically finds correct ports on EC2 instances</li> <li>Security Group configuration required for EC2 instances</li> </ul>"},{"location":"aws/computing/ecs/#fargate","title":"Fargate","text":"<ul> <li>Each task gets unique private IP</li> <li>Only container port definition required</li> <li>Security Group configuration needed for ECS ENI and ALB</li> </ul>"},{"location":"aws/computing/elastic_beanstalk/","title":"Elastic Beanstalk","text":""},{"location":"aws/computing/elastic_beanstalk/#overview-of-aws-elastic-beanstalk","title":"Overview of AWS Elastic Beanstalk","text":"<p>AWS Elastic Beanstalk represents a sophisticated platform-as-a-service solution designed to simplify application deployment and management across multiple programming languages and web frameworks. By abstracting the underlying infrastructure complexities, Beanstalk enables developers to focus on writing code rather than managing complex cloud environments.</p>"},{"location":"aws/computing/elastic_beanstalk/#core-architectural-philosophy","title":"Core Architectural Philosophy","text":"<p>Elastic Beanstalk provides a comprehensive deployment ecosystem that automatically handles infrastructure provisioning, load balancing, auto-scaling, and application health monitoring. The service bridges the gap between manual infrastructure management and full platform abstraction, offering developers granular control while maintaining operational simplicity.</p>"},{"location":"aws/computing/elastic_beanstalk/#deployment-environment-mechanics","title":"Deployment Environment Mechanics","text":"<p>When an application is deployed through Elastic Beanstalk, the service creates a comprehensive infrastructure stack tailored to the specific application requirements. This includes selecting appropriate compute resources, configuring network settings, and establishing necessary communication pathways between different architectural components.</p>"},{"location":"aws/computing/elastic_beanstalk/#supported-platforms-and-runtime-environments","title":"Supported Platforms and Runtime Environments","text":"<p>Elastic Beanstalk supports a diverse range of programming languages and frameworks, providing native integration for:</p> <ul> <li>Java with Apache Tomcat</li> <li>.NET on Windows Server platform</li> <li>PHP applications</li> <li>Node.js web services</li> <li>Python with Django and Flask</li> <li>Ruby on Rails</li> <li>Go language web applications</li> <li>Docker containerized deployments</li> </ul>"},{"location":"aws/computing/elastic_beanstalk/#deployment-strategies","title":"Deployment Strategies","text":""},{"location":"aws/computing/elastic_beanstalk/#standard-application-deployment","title":"Standard Application Deployment","text":"<p>Developers can upload application code directly through the AWS Management Console, CLI, or SDK. Beanstalk automatically provisions the necessary infrastructure, configures environment variables, and manages application lifecycle.</p>"},{"location":"aws/computing/elastic_beanstalk/#container-based-deployments","title":"Container-Based Deployments","text":"<p>For more complex architectural requirements, Beanstalk supports Docker containerization. This approach allows developers to package applications with their dependencies, ensuring consistent behavior across different deployment environments.</p>"},{"location":"aws/computing/elastic_beanstalk/#environment-configuration","title":"Environment Configuration","text":""},{"location":"aws/computing/elastic_beanstalk/#environment-tiers","title":"Environment Tiers","text":"<p>Beanstalk offers two primary environment configurations:</p>"},{"location":"aws/computing/elastic_beanstalk/#web-server-environment","title":"Web Server Environment","text":"<p>Designed for hosting web applications and services with direct internet accessibility. These environments automatically configure load balancers and auto-scaling groups to manage incoming web traffic.</p>"},{"location":"aws/computing/elastic_beanstalk/#worker-environment","title":"Worker Environment","text":"<p>Optimized for background processing and asynchronous task execution. Worker environments integrate seamlessly with Amazon SQS for managing distributed computational workloads.</p>"},{"location":"aws/computing/elastic_beanstalk/#advanced-configuration-management","title":"Advanced Configuration Management","text":"<p>Elastic Beanstalk provides multiple mechanisms for customizing deployment environments:</p>"},{"location":"aws/computing/elastic_beanstalk/#configuration-files","title":"Configuration Files","text":"<p>Developers can include <code>.ebextensions</code> configuration files within their application package, enabling intricate environment customization without manual infrastructure modification.</p>"},{"location":"aws/computing/elastic_beanstalk/#environment-variables","title":"Environment Variables","text":"<p>Comprehensive support for dynamic configuration through environment-specific variables, allowing seamless transition between development, staging, and production environments.</p>"},{"location":"aws/computing/elastic_beanstalk/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"aws/computing/elastic_beanstalk/#health-monitoring","title":"Health Monitoring","text":"<p>Beanstalk continuously monitors application and infrastructure health, automatically replacing failed instances and providing detailed diagnostic information through integrated CloudWatch metrics.</p>"},{"location":"aws/computing/elastic_beanstalk/#logging-mechanisms","title":"Logging Mechanisms","text":"<p>Comprehensive logging capabilities capture application and system-level events, facilitating efficient troubleshooting and performance optimization.</p>"},{"location":"aws/computing/elastic_beanstalk/#security-and-compliance","title":"Security and Compliance","text":""},{"location":"aws/computing/elastic_beanstalk/#iam-integration","title":"IAM Integration","text":"<p>Deep integration with AWS Identity and Access Management allows granular access control and role-based permissions for environment management.</p>"},{"location":"aws/computing/elastic_beanstalk/#network-isolation","title":"Network Isolation","text":"<p>Support for Amazon Virtual Private Cloud (VPC) enables secure, isolated network environments with customizable security group configurations.</p>"},{"location":"aws/computing/elastic_beanstalk/#scaling-and-performance","title":"Scaling and Performance","text":""},{"location":"aws/computing/elastic_beanstalk/#auto-scaling","title":"Auto Scaling","text":"<p>Intelligent auto-scaling mechanisms automatically adjust computational resources based on predefined performance metrics, ensuring optimal application responsiveness during variable traffic conditions.</p>"},{"location":"aws/computing/elastic_beanstalk/#load-balancing","title":"Load Balancing","text":"<p>Integrated elastic load balancing distributes incoming traffic across multiple instances, providing enhanced reliability and performance.</p>"},{"location":"aws/computing/elastic_beanstalk/#pricing-considerations","title":"Pricing Considerations","text":"<p>Elastic Beanstalk itself is a free service. Customers are charged only for the underlying AWS resources provisioned during application deployment, such as EC2 instances, load balancers, and data transfer.</p>"},{"location":"aws/computing/elastic_beanstalk/#use-case-scenarios","title":"Use Case Scenarios","text":"<ul> <li>Rapid web application deployment</li> <li>Microservices architecture</li> <li>Continuous integration and deployment pipelines</li> <li>Scalable enterprise applications</li> <li>Prototype and development environment management</li> </ul>"},{"location":"aws/computing/elastic_beanstalk/#conclusion","title":"Conclusion","text":"<p>AWS Elastic Beanstalk offers a powerful, flexible platform for application deployment, removing infrastructure complexity while providing developers comprehensive control over their computational environments.</p>"},{"location":"aws/computing/elb/","title":"Elastic Load Balancer (ELB)","text":""},{"location":"aws/computing/elb/#overview","title":"Overview","text":"<p>Elastic Load Balancer is a service that forwards traffic to multiple servers (such as EC2 instances) downstream. It acts as a single point of contact for all incoming web traffic to your applications.</p>"},{"location":"aws/computing/elb/#benefits-of-load-balancing","title":"Benefits of Load Balancing","text":"<ul> <li>Spreads load across multiple downstream instances</li> <li>Provides a single point of access (DNS) to your application</li> <li>Handles failures of downstream instances automatically</li> <li>Performs regular health checks on instances</li> <li>Provides SSL termination (HTTPS) for websites</li> <li>Enforces stickiness with cookies</li> <li>Ensures high availability across zones</li> <li>Separates public traffic from private traffic</li> </ul>"},{"location":"aws/computing/elb/#why-choose-elastic-load-balancer","title":"Why Choose Elastic Load Balancer?","text":"<ul> <li>Fully managed by AWS with guaranteed uptime</li> <li>AWS handles upgrades, maintenance, and high availability</li> <li>Simplified configuration options</li> <li>Cost-effective compared to setting up your own load balancer</li> <li>Integrated with various AWS services:</li> <li>EC2 and EC2 Auto Scaling Groups</li> <li>Amazon ECS</li> <li>AWS Certificate Manager (ACM)</li> <li>CloudWatch</li> <li>Route 53</li> <li>AWS WAF</li> <li>AWS Global Accelerator</li> </ul>"},{"location":"aws/computing/elb/#types-of-load-balancers","title":"Types of Load Balancers","text":""},{"location":"aws/computing/elb/#classic-load-balancer-clb-2009","title":"Classic Load Balancer (CLB) - 2009","text":"<ul> <li>Supports HTTP, HTTPS, TCP, and SSL (secure TCP)</li> <li>Legacy load balancer (first generation)</li> </ul>"},{"location":"aws/computing/elb/#application-load-balancer-alb-2016","title":"Application Load Balancer (ALB) - 2016","text":"<ul> <li>Operates at Layer 7 (HTTP)</li> <li>Supports HTTP, HTTPS, WebSocket</li> <li>Features:</li> <li>Path-based routing</li> <li>Host-based routing</li> <li>Query string/header-based routing</li> <li>Support for HTTP/2 and WebSocket</li> <li>Support for redirects</li> <li>Container-friendly with dynamic port mapping</li> </ul>"},{"location":"aws/computing/elb/#network-load-balancer-nlb-2017","title":"Network Load Balancer (NLB) - 2017","text":"<ul> <li>Operates at Layer 4 (TCP/UDP)</li> <li>Features:</li> <li>Handles millions of requests per second</li> <li>Ultra-low latency</li> <li>Static IP per AZ with Elastic IP support</li> <li>Ideal for extreme performance needs</li> </ul>"},{"location":"aws/computing/elb/#gateway-load-balancer-gwlb-2020","title":"Gateway Load Balancer (GWLB) - 2020","text":"<ul> <li>Operates at Layer 3 (Network layer)</li> <li>Used for deploying and managing third-party virtual appliances</li> </ul> <p>Combines:</p> <ul> <li>Transparent Network Gateway</li> <li>Load Balancer functionality</li> </ul>"},{"location":"aws/computing/elb/#health-checks","title":"Health Checks","text":"<ul> <li>Essential for load balancer operation</li> <li>Monitors instance availability</li> </ul> <p>Configured with:</p> <ul> <li>Protocol</li> <li>Port</li> <li>Endpoint path</li> <li>Response code expectations</li> </ul>"},{"location":"aws/computing/elb/#security-groups","title":"Security Groups","text":"<ul> <li> <p>Load Balancer Security Group:</p> </li> <li> <p>Allows inbound HTTPS/HTTP from anywhere</p> </li> <li> <p>Application Security Group:</p> </li> <li> <p>Allows traffic only from Load Balancer</p> </li> </ul>"},{"location":"aws/computing/elb/#target-groups","title":"Target Groups","text":"<p>Support various target types depending on the load balancer:</p> <ul> <li>EC2 instances</li> <li>IP addresses (must be private IPs)</li> <li>Lambda functions (ALB only)</li> <li>Application Load Balancers (NLB only)</li> <li>Container instances</li> </ul>"},{"location":"aws/computing/elb/#sticky-sessions","title":"Sticky Sessions","text":"<ul> <li>Ensures client requests route to the same instance</li> <li>Supported by all load balancer types</li> <li> <p>Cookie types:</p> </li> <li> <p>Application-based Cookies:</p> <ul> <li>Custom cookies (generated by target)</li> <li>Application cookies (generated by load balancer - AWSALBAPP)</li> </ul> </li> <li> <p>Duration-based Cookies:</p> <ul> <li>Generated by load balancer</li> <li>AWSALB for ALB, AWSELB for CLB</li> </ul> </li> </ul>"},{"location":"aws/computing/elb/#cross-zone-load-balancing","title":"Cross-Zone Load Balancing","text":"<ul> <li>ALB: Enabled by default, no inter-AZ charges</li> <li>NLB and GWLB: Disabled by default, charges apply for inter-AZ data if enabled</li> <li>CLB: Disabled by default, no inter-AZ charges if enabled</li> </ul>"},{"location":"aws/computing/elb/#ssltls-support","title":"SSL/TLS Support","text":"<ul> <li>Provides in-flight encryption</li> <li> <p>Certificate management through AWS Certificate Manager (ACM) Features:</p> </li> <li> <p>Support for multiple certificates (ALB and NLB)</p> </li> <li>Server Name Indication (SNI) support</li> <li>Customizable security policies</li> </ul> <p>Certificate handling varies by load balancer type:</p> <ul> <li>CLB: Single SSL certificate only</li> <li>ALB/NLB: Multiple listeners with multiple SSL certificates via SNI</li> </ul>"},{"location":"aws/computing/elb/#connection-draining","title":"Connection Draining","text":"<ul> <li>Named \u201cConnection Draining\u201d for CLB</li> <li>Named \u201cDeregistration Delay\u201d for ALB &amp; NLB</li> <li> <p>Allows completion of in-flight requests during instance deregistration Configuration options:</p> </li> <li> <p>Duration: 1-3600 seconds (default 300)</p> </li> <li>Can be disabled (set to 0)</li> <li>Recommended to set lower values for short-lived requests</li> </ul>"},{"location":"aws/computing/lambda/","title":"Lambda","text":""},{"location":"aws/computing/lambda/#overview","title":"Overview","text":"<p>AWS Lambda is a serverless compute service that enables you to run code without provisioning or managing servers. It executes your code only when needed and scales automatically to handle any number of requests simultaneously. This service is particularly useful for microservices architecture, data processing, and backend applications.</p>"},{"location":"aws/computing/lambda/#core-concepts","title":"Core Concepts","text":""},{"location":"aws/computing/lambda/#execution-model","title":"Execution Model","text":"<p>Lambda functions operate on an event-driven model where code executes in response to triggers. The execution environment is completely managed by AWS, handling all aspects of infrastructure, including:</p> <ul> <li>Serverless Execution: No server management required; AWS handles all infrastructure</li> <li>Event-Driven Architecture: Functions execute in response to events from various AWS services</li> <li>Automatic Scaling: Scales automatically from a few requests per day to thousands per second</li> <li>Pay-per-Use: Billing based on actual compute time used, calculated in milliseconds</li> <li>Built-in Fault Tolerance: Automatic replication across multiple Availability Zones</li> </ul>"},{"location":"aws/computing/lambda/#supported-runtimes","title":"Supported Runtimes","text":"<p>Lambda supports multiple programming languages through runtime environments:</p> <ul> <li>Node.js (18.x, 16.x, 14.x): JavaScript/TypeScript development with extensive NPM ecosystem</li> <li>Python (3.11, 3.10, 3.9, 3.8): Popular for data processing and scripting tasks</li> <li>Java (17, 11, 8): Enterprise-grade applications with full JVM support</li> <li>.NET Core (7.0, 6.0): C# and F# development with .NET ecosystem</li> <li>Ruby (3.2, 2.7): Ruby development with gem support</li> <li>Go (1.x): High-performance applications</li> <li>Custom Runtime: Support for any additional languages via container images</li> </ul>"},{"location":"aws/computing/lambda/#deployment-options","title":"Deployment Options","text":""},{"location":"aws/computing/lambda/#zip-file-archives","title":".zip File Archives","text":"<p>The traditional method of deploying Lambda functions using compressed archives:</p> <ul> <li> <p>Size Limits: </p> </li> <li> <p>Direct upload: 50 MB compressed</p> </li> <li> <p>S3 upload: 250 MB uncompressed</p> </li> <li> <p>Deployment Process: Upload directly via AWS Console, CLI, or SDK</p> </li> <li>Version Control: Integrated with AWS versioning system</li> <li>Cold Start Impact: Generally faster cold starts compared to containers</li> <li>Use Cases: Ideal for simpler functions with minimal dependencies</li> </ul>"},{"location":"aws/computing/lambda/#container-images","title":"Container Images","text":"<p>Deploy Lambda functions as container images, offering greater flexibility and consistency:</p> <ul> <li>Size Limit: Up to 10 GB</li> <li>Format Support: Compatible with OCI (Open Container Initiative) format</li> <li>Base Images: AWS-provided base images for each runtime</li> <li>Custom Runtimes: Support for any programming language via custom containers</li> <li> <p>Architecture Support:</p> </li> <li> <p>x86_64: Standard architecture, available in all regions</p> </li> <li>arm64: AWS Graviton2, offering better price/performance ratio</li> </ul>"},{"location":"aws/computing/lambda/#lambda-layers","title":"Lambda Layers","text":"<p>A mechanism to centrally manage code and dependencies:</p>"},{"location":"aws/computing/lambda/#purpose-and-benefits","title":"Purpose and Benefits","text":"<ul> <li>Code Reuse: Share common code across multiple functions</li> <li>Dependency Management: Centralize and version control dependencies</li> <li>Size Management: Reduce individual function size</li> <li>Updates: Easier updates of shared components</li> </ul>"},{"location":"aws/computing/lambda/#technical-specifications","title":"Technical Specifications","text":"<ul> <li>Layer Limit: Up to 5 layers per function</li> <li>Size Limit: 250 MB unzipped total size</li> <li>Sharing: Can be shared across accounts and regions</li> <li>Versioning: Each layer update creates a new version</li> </ul>"},{"location":"aws/computing/lambda/#testing-and-development","title":"Testing and Development","text":""},{"location":"aws/computing/lambda/#local-testing-methods","title":"Local Testing Methods","text":""},{"location":"aws/computing/lambda/#aws-sam-cli","title":"AWS SAM CLI","text":"<p>A command-line tool that provides a local development environment:</p> <ul> <li>Local Execution: Run Lambda functions locally</li> <li>API Testing: Test API Gateway integrations</li> <li>Debugging: Step through code using IDE integrations</li> <li>Event Simulation: Generate sample events for testing</li> </ul>"},{"location":"aws/computing/lambda/#runtime-interface-emulator-rie","title":"Runtime Interface Emulator (RIE)","text":"<p>A tool for testing container image-based functions:</p> <ul> <li>Container Testing: Test functions exactly as they\u2019ll run in AWS</li> <li>API Emulation: Simulates the Lambda Runtime API locally</li> <li>Integration: Works with standard Docker tools</li> </ul>"},{"location":"aws/computing/lambda/#localstack","title":"LocalStack","text":"<p>A local AWS cloud stack for testing:</p> <ul> <li>Service Emulation: Emulate AWS services locally</li> <li>Integration Testing: Test complete architectures</li> <li>Offline Development: Develop without AWS connectivity</li> </ul>"},{"location":"aws/computing/lambda/#lambda-runtime-api","title":"Lambda Runtime API","text":""},{"location":"aws/computing/lambda/#core-components","title":"Core Components","text":"<p>The Lambda Runtime API is an HTTP interface that custom runtimes must implement:</p>"},{"location":"aws/computing/lambda/#api-endpoints","title":"API Endpoints","text":"<ul> <li>Next Invocation: Polls for new function invocations</li> <li>Response Handling: Sends function results back to Lambda</li> <li>Error Management: Reports function and runtime errors</li> <li>Initialization: Handles runtime startup and initialization</li> </ul>"},{"location":"aws/computing/lambda/#implementation-requirements","title":"Implementation Requirements","text":"<ul> <li>Event Processing: Handle incoming events and context</li> <li>Error Handling: Proper error formatting and reporting</li> <li>Lifecycle Management: Manage function and runtime lifecycle</li> <li>Environment: Handle environment variables and configuration</li> </ul>"},{"location":"aws/computing/lambda/#monitoring-and-performance","title":"Monitoring and Performance","text":""},{"location":"aws/computing/lambda/#cloudwatch-integration","title":"CloudWatch Integration","text":"<p>Comprehensive monitoring and logging capabilities:</p>"},{"location":"aws/computing/lambda/#metrics","title":"Metrics","text":"<ul> <li>Invocations: Track function calls</li> <li>Duration: Monitor execution time</li> <li>Errors: Track function errors</li> <li>Throttling: Monitor concurrency limits</li> <li>Iterator Age: Track stream processing lag</li> </ul>"},{"location":"aws/computing/lambda/#logging","title":"Logging","text":"<ul> <li>Automatic Log Creation: Each invocation logged automatically</li> <li>Log Groups: Organized by function</li> <li>Log Retention: Configurable retention periods</li> <li>Log Insights: Query and analyze logs</li> </ul>"},{"location":"aws/computing/lambda/#x-ray-integration","title":"X-Ray Integration","text":"<p>Distributed tracing and performance analysis:</p>"},{"location":"aws/computing/lambda/#features","title":"Features","text":"<ul> <li>Trace Analysis: Track requests across services</li> <li>Performance Insights: Identify bottlenecks</li> <li>Error Tracking: Debug issues across services</li> <li>Service Maps: Visualize application architecture</li> </ul>"},{"location":"aws/computing/lambda/#limits-and-quotas","title":"Limits and Quotas","text":""},{"location":"aws/computing/lambda/#function-configuration","title":"Function Configuration","text":"<ul> <li>Memory: 128 MB to 10,240 MB, in 1 MB increments</li> <li>Timeout: Maximum of 900 seconds (15 minutes)</li> <li>Deployment Package: 50 MB (zipped) for direct upload</li> <li>Container Image: 10 GB maximum</li> <li>Environment Variables: 4 KB for all variables combined</li> </ul>"},{"location":"aws/computing/lambda/#execution","title":"Execution","text":"<ul> <li>Concurrent Executions: 1,000 per region (default)</li> <li>Burst Concurrency: 500-3000 depending on region</li> <li>Temporary Storage: 512 MB at /tmp</li> <li>Function Resource Limits: 1,000 versions per function</li> </ul>"},{"location":"aws/computing/lambda/#cost-optimization","title":"Cost Optimization","text":""},{"location":"aws/computing/lambda/#execution-costs","title":"Execution Costs","text":"<p>Understanding and optimizing Lambda costs:</p>"},{"location":"aws/computing/lambda/#billing-factors","title":"Billing Factors","text":"<ul> <li>Compute Time: Billed per millisecond</li> <li>Memory Allocation: Affects both performance and cost</li> <li>Requests: Number of function invocations</li> <li>Data Transfer: Network traffic costs</li> </ul>"},{"location":"aws/computing/lambda/#optimization-strategies","title":"Optimization Strategies","text":"<ul> <li>Memory Tuning: Balance between performance and cost</li> <li>Execution Time: Optimize code for faster execution</li> <li>Concurrent Execution: Manage concurrency limits</li> <li>Cold Start: Use provisioned concurrency when needed</li> </ul>"},{"location":"aws/database/athena/","title":"Athena","text":""},{"location":"aws/database/athena/#overview","title":"Overview","text":"<p>Amazon Athena is a powerful serverless query service that enables users to analyze data stored in Amazon S3 using standard SQL. Built on the Presto framework, Athena eliminates the need for complex ETL jobs when querying data, offering a simplified yet robust solution for data analysis.</p>"},{"location":"aws/database/athena/#core-features-and-functionality","title":"Core Features and Functionality","text":""},{"location":"aws/database/athena/#query-service-capabilities","title":"Query Service Capabilities","text":"<p>Athena operates as a serverless query engine, requiring no infrastructure management while providing the ability to analyze data directly from S3 storage. The service uses standard SQL language (built on Presto), making it accessible to users familiar with SQL syntax.</p>"},{"location":"aws/database/athena/#supported-file-formats","title":"Supported File Formats","text":"<p>Athena supports multiple data formats, including:</p> <ul> <li>CSV</li> <li>JSON</li> <li>ORC</li> <li>Avro</li> <li>Parquet</li> </ul>"},{"location":"aws/database/athena/#cost-structure","title":"Cost Structure","text":"<p>The pricing model is straightforward:</p> <ul> <li>$5.00 per TB of data scanned</li> <li>Users only pay for the data they query</li> </ul>"},{"location":"aws/database/athena/#integration-with-quicksight","title":"Integration with QuickSight","text":"<p>Athena seamlessly integrates with Amazon QuickSight, enabling:</p> <ul> <li>Creation of comprehensive reports</li> <li>Building interactive dashboards</li> <li>Visual data exploration and analysis</li> </ul>"},{"location":"aws/database/athena/#common-use-cases","title":"Common Use Cases","text":"<p>Athena serves various analytical needs, including:</p> <ul> <li>Business intelligence and analytics</li> <li>Reporting and data analysis</li> <li>VPC Flow Logs analysis</li> <li>ELB Logs examination</li> <li>CloudTrail trails investigation</li> </ul>"},{"location":"aws/database/athena/#performance-optimization","title":"Performance Optimization","text":""},{"location":"aws/database/athena/#data-format-recommendations","title":"Data Format Recommendations","text":"<p>To optimize performance and reduce costs, consider the following recommendations:</p> <ol> <li> <p>Use columnar data formats:</p> </li> <li> <p>Apache Parquet or ORC are highly recommended</p> </li> <li>These formats provide significant performance improvements</li> <li> <p>AWS Glue can be used to convert existing data to Parquet or ORC</p> </li> <li> <p>Implement data compression:</p> </li> <li> <p>Supported compression formats include:</p> <ul> <li>bzip2</li> <li>gzip</li> <li>lz4</li> <li>snappy</li> <li>zlib</li> <li>zstd</li> </ul> </li> </ol>"},{"location":"aws/database/athena/#data-organization-and-storage","title":"Data Organization and Storage","text":"<p>For optimal performance:</p> <ol> <li> <p>Implement partitioning:</p> </li> <li> <p>Organize datasets in S3 using partition columns</p> </li> <li>Follow the structure:      <pre><code>s3://yourBucket/pathToTable/&lt;PARTITION_COLUMN_NAME&gt;=&lt;VALUE&gt;/\n</code></pre></li> <li> <p>Example:      <pre><code>s3://athena-examples/flight/parquet/year=1991/month=1/day=1/\n</code></pre></p> </li> <li> <p>File size optimization:</p> </li> <li>Maintain file sizes larger than 128 MB</li> <li>This approach minimizes query overhead</li> </ol>"},{"location":"aws/database/athena/#federated-query-capabilities","title":"Federated Query Capabilities","text":""},{"location":"aws/database/athena/#overview_1","title":"Overview","text":"<p>Federated queries enable SQL query execution across diverse data sources, including:</p> <ul> <li>Relational databases</li> <li>Non-relational databases</li> <li>Object stores</li> <li>Custom data sources</li> </ul>"},{"location":"aws/database/athena/#architecture-components","title":"Architecture Components","text":"<p>The federated query system consists of: 1. Data Source Connectors running on AWS Lambda 2. Support for various data sources:</p> <ul> <li>CloudWatch Logs</li> <li>DynamoDB</li> <li>RDS</li> <li>ElastiCache</li> <li>DocumentDB</li> <li>Redshift</li> <li>HBase in EMR</li> <li>MySQL</li> <li>Aurora</li> <li>SQL Server</li> <li>On-premises databases</li> </ul>"},{"location":"aws/database/athena/#functionality","title":"Functionality","text":"<ul> <li>Enables querying across multiple data sources simultaneously</li> <li>Results can be stored back in Amazon S3</li> <li>Provides unified access to distributed data sources</li> </ul>"},{"location":"aws/database/athena/#best-practices","title":"Best Practices","text":"<ol> <li>Use columnar formats (Parquet or ORC) for cost optimization</li> <li>Implement appropriate compression methods</li> <li>Partition data effectively</li> <li>Optimize file sizes</li> <li>Utilize federated queries when dealing with multiple data sources</li> </ol>"},{"location":"aws/database/aurora/","title":"Aurora","text":""},{"location":"aws/database/aurora/#overview","title":"Overview","text":"<p>Amazon Aurora represents AWS\u2019s proprietary database technology, offering compatibility with both PostgreSQL and MySQL. This compatibility ensures existing database drivers work seamlessly with Aurora deployments. The service demonstrates significant performance improvements over traditional RDS implementations, showing up to 5x better performance compared to MySQL and 3x compared to PostgreSQL on RDS.</p>"},{"location":"aws/database/aurora/#technical-capabilities","title":"Technical Capabilities","text":"<p>Aurora\u2019s storage infrastructure automatically scales in 10GB increments, supporting databases up to 128TB. The service supports up to 15 replicas with industry-leading replication performance, maintaining sub-10 millisecond replica lag. Built with high availability as a core feature, Aurora provides instantaneous failover capabilities, though it comes at a 20% cost premium over standard RDS offerings.</p>"},{"location":"aws/database/aurora/#high-availability-architecture","title":"High Availability Architecture","text":"<p>Aurora implements a sophisticated high availability model through its distributed storage system. Data is automatically replicated across three Availability Zones with six copies maintained for redundancy. The system requires four copies for write operations and three copies for read operations, ensuring data durability and availability. Storage is distributed across hundreds of volumes with self-healing peer-to-peer replication.</p> <p>The primary instance handles write operations while up to 15 read replicas can serve read requests. Master failover occurs automatically within 30 seconds, and the service supports cross-region replication for global deployment scenarios.</p>"},{"location":"aws/database/aurora/#core-features","title":"Core Features","text":"<p>Aurora delivers enterprise-grade database capabilities including automated failover, comprehensive backup and recovery options, and robust security isolation. The service maintains industry compliance standards while offering push-button scaling capabilities. Operational tasks such as patching and maintenance occur without downtime, complemented by advanced monitoring capabilities.</p> <p>A distinctive feature called Backtrack allows point-in-time restoration without relying on traditional backups, offering flexible recovery options.</p>"},{"location":"aws/database/aurora/#security-framework","title":"Security Framework","text":""},{"location":"aws/database/aurora/#encryption-capabilities","title":"Encryption Capabilities","text":"<p>Aurora provides comprehensive encryption options both at rest and in transit. Database encryption uses AWS KMS and must be configured during instance launch. Important considerations include: - Read replicas can only be encrypted if the master database is encrypted - Encrypting an unencrypted database requires creating an encrypted snapshot and restoration - TLS encryption is enabled by default for data in transit</p>"},{"location":"aws/database/aurora/#access-control","title":"Access Control","text":"<p>The service integrates with AWS IAM for authentication, allowing database access through IAM roles instead of traditional username/password combinations. Network access is controlled through Security Groups, though direct SSH access is restricted except in RDS Custom deployments.</p>"},{"location":"aws/database/aurora/#audit-and-monitoring","title":"Audit and Monitoring","text":"<p>Aurora supports audit logging with CloudWatch Logs integration for extended retention periods, enabling comprehensive activity tracking and compliance monitoring.</p>"},{"location":"aws/database/aurora/#migration-and-backup-considerations","title":"Migration and Backup Considerations","text":"<p>When deploying Aurora, organizations should consider their backup strategy, migration paths, and replication requirements. The service\u2019s automatic storage scaling and backup capabilities simplify operational management, while its compatibility with existing MySQL and PostgreSQL applications facilitates smooth migrations from traditional database deployments.</p>"},{"location":"aws/database/dynamodb/","title":"DynamoDB","text":""},{"location":"aws/database/dynamodb/#introduction-to-dynamodb","title":"Introduction to DynamoDB","text":"<p>Amazon DynamoDB is a fully managed, serverless, key-value NoSQL database designed for high-performance, scalable applications. Developed by Amazon Web Services, it provides seamless and consistent single-digit millisecond latency at any scale, making it an ideal choice for modern cloud-native and distributed applications.</p>"},{"location":"aws/database/dynamodb/#core-architectural-concepts","title":"Core Architectural Concepts","text":""},{"location":"aws/database/dynamodb/#table-structure","title":"Table Structure","text":"<p>DynamoDB organizes data in tables, which are collections of items sharing a similar structure. Each item in a table is identified by a primary key, which can be simple (partition key) or composite (partition key and sort key). This design enables efficient data retrieval and supports complex querying strategies.</p>"},{"location":"aws/database/dynamodb/#primary-key-types","title":"Primary Key Types","text":"<ol> <li>Simple Primary Key: Consists of only a partition key, ensuring unique identification of items within the table.</li> <li>Composite Primary Key: Combines a partition key with a sort key, allowing multiple items to share the same partition key while maintaining unique identification through the sort key combination.</li> </ol>"},{"location":"aws/database/dynamodb/#capacity-unit-calculations","title":"Capacity Unit Calculations","text":""},{"location":"aws/database/dynamodb/#read-capacity-units-rcus","title":"Read Capacity Units (RCUs)","text":"<p>RCUs represent the number of reads per second for items up to 4 KB in size.</p> <p>Calculation Formula: <pre><code>Strongly Consistent RCUs = (Size of Item / 4 KB) \u00d7 Number of Reads per Second\nEventual Consistent RCUs = (Size of Item / 4 KB) \u00d7 Number of Reads per Second \u00d7 0.5\n</code></pre></p>"},{"location":"aws/database/dynamodb/#read-capacity-examples","title":"Read Capacity Examples:","text":"<ul> <li>4 KB item, 1 strongly consistent read/second: 1 RCU</li> <li>4 KB item, 1 eventual consistent read/second: 0.5 RCU</li> <li>8 KB item, 1 strongly consistent read/second: 2 RCUs</li> <li>8 KB item, 1 eventual consistent read/second: 1 RCU</li> <li>4 KB item, 10 strongly consistent reads/second: 10 RCUs</li> <li>4 KB item, 10 eventual consistent reads/second: 5 RCUs</li> </ul>"},{"location":"aws/database/dynamodb/#write-capacity-units-wcus","title":"Write Capacity Units (WCUs)","text":"<p>WCUs represent the number of writes per second for items up to 1 KB in size.</p> <p>Calculation Formula: <pre><code>WCUs = (Size of Item / 1 KB) \u00d7 Number of Writes per Second\n</code></pre></p>"},{"location":"aws/database/dynamodb/#write-capacity-examples","title":"Write Capacity Examples:","text":"<ul> <li>1 KB item, 1 write/second: 1 WCU</li> <li>2 KB item, 1 write/second: 2 WCUs</li> <li>1 KB item, 10 writes/second: 10 WCUs</li> </ul>"},{"location":"aws/database/dynamodb/#practical-capacity-planning","title":"Practical Capacity Planning","text":"<ol> <li>Estimate average item size</li> <li>Determine peak read/write requirements</li> <li>Calculate base RCUs and WCUs</li> <li>Add buffer for unexpected traffic</li> <li>Consider using auto-scaling</li> </ol>"},{"location":"aws/database/dynamodb/#data-consistency-and-pricing","title":"Data Consistency and Pricing","text":""},{"location":"aws/database/dynamodb/#consistency-models","title":"Consistency Models","text":""},{"location":"aws/database/dynamodb/#eventual-consistent-reads","title":"Eventual Consistent Reads","text":"<ul> <li>Default read model in DynamoDB</li> <li>Consumes 0.5 Read Capacity Units (RCUs) per 4 KB</li> <li>Typical cost: Approximately 50% cheaper than strong consistent reads</li> <li>Reflects changes within 1 second across database replicas</li> </ul>"},{"location":"aws/database/dynamodb/#strong-consistent-reads","title":"Strong Consistent Reads","text":"<ul> <li>Guarantees most recent write</li> <li>Consumes 1 Read Capacity Unit (RCU) per 4 KB</li> <li>Provides immediate data consistency</li> <li>Approximately double the cost of eventual consistent reads</li> </ul>"},{"location":"aws/database/dynamodb/#detailed-cost-breakdown","title":"Detailed Cost Breakdown","text":""},{"location":"aws/database/dynamodb/#read-capacity-unit-pricing","title":"Read Capacity Unit Pricing","text":"<ul> <li>Eventual Consistent Reads: $0.25 per million read request units</li> <li>Strong Consistent Reads: $0.50 per million read request units</li> <li>On-Demand Mode: Pricing varies by region and request volume</li> <li>Provisioned Mode: Predictable pricing based on pre-allocated capacity</li> </ul>"},{"location":"aws/database/dynamodb/#write-capacity-pricing","title":"Write Capacity Pricing","text":"<ul> <li>Standard Write Units: $0.47 per million write request units</li> <li>Pricing varies by region and specific AWS configuration</li> </ul>"},{"location":"aws/database/dynamodb/#storage-costs","title":"Storage Costs","text":"<ul> <li>First 25 TB per month: $0.25 per GB</li> <li>Over 25 TB: Reduced rates apply</li> <li>Incremental storage charges for backups and global tables</li> </ul>"},{"location":"aws/database/dynamodb/#data-model-and-attributes","title":"Data Model and Attributes","text":"<p>Items in DynamoDB can contain attributes of various types, including: - String - Number - Binary - Boolean - List - Map - String Set - Number Set - Binary Set</p> <p>Each attribute supports flexible schema design, enabling developers to adapt data structures without extensive migrations.</p>"},{"location":"aws/database/dynamodb/#performance-and-scaling","title":"Performance and Scaling","text":""},{"location":"aws/database/dynamodb/#readwrite-capacity-modes","title":"Read/Write Capacity Modes","text":"<p>DynamoDB offers two capacity modes to manage performance and cost:</p>"},{"location":"aws/database/dynamodb/#provisioned-mode","title":"Provisioned Mode","text":"<p>Developers specify expected read and write capacity units in advance. The system allocates dedicated resources to maintain performance, with options for manual or auto-scaling adjustments.</p>"},{"location":"aws/database/dynamodb/#on-demand-mode","title":"On-Demand Mode","text":"<p>Automatically scales to accommodate varying workloads without pre-planning capacity. Ideal for unpredictable traffic patterns and applications with sporadic access patterns.</p>"},{"location":"aws/database/dynamodb/#secondary-indexes","title":"Secondary Indexes","text":""},{"location":"aws/database/dynamodb/#global-secondary-indexes-gsi","title":"Global Secondary Indexes (GSI)","text":"<p>GSIs provide alternative query paths across the entire table, independent of the primary key. Key characteristics include: - Can be created on any table attribute - Support different partition and sort keys from the base table - Consume additional read capacity units - Enable complex querying strategies beyond the primary key</p>"},{"location":"aws/database/dynamodb/#local-secondary-indexes-lsi","title":"Local Secondary Indexes (LSI)","text":"<p>LSIs share the table\u2019s partition key but offer alternative sort key configurations. Distinguishing features: - Created during table creation - Limited to five per table - Use the same partition key as the base table - Consume storage from the base table\u2019s provisioned capacity</p>"},{"location":"aws/database/dynamodb/#data-consistency-and-replication","title":"Data Consistency and Replication","text":""},{"location":"aws/database/dynamodb/#consistency-models_1","title":"Consistency Models","text":"<ul> <li>Eventually Consistent Reads: Default mode with lower latency</li> <li>Strong Consistent Reads: Guarantees retrieval of the most recent write, with slightly higher latency</li> </ul>"},{"location":"aws/database/dynamodb/#global-tables","title":"Global Tables","text":"<p>Supports multi-region, multi-master replication, enabling: - Active-active database configurations - Low-latency global access - Automatic conflict resolution</p>"},{"location":"aws/database/dynamodb/#security-and-access-control","title":"Security and Access Control","text":""},{"location":"aws/database/dynamodb/#authentication-and-authorization","title":"Authentication and Authorization","text":"<ul> <li>Integrates with AWS Identity and Access Management (IAM)</li> <li>Granular access controls at table and item levels</li> <li>Support for encryption at rest using AWS Key Management Service</li> </ul>"},{"location":"aws/database/dynamodb/#use-cases","title":"Use Cases","text":"<p>DynamoDB excels in scenarios requiring: - High-velocity web and mobile applications - Real-time bidding platforms - Gaming leaderboards - IoT data storage - Session management - Metadata caching</p>"},{"location":"aws/database/dynamodb/#cost-optimization-strategies","title":"Cost Optimization Strategies","text":"<ul> <li>Utilize on-demand capacity for unpredictable workloads</li> <li>Implement Time-to-Live (TTL) for automatic data expiration</li> <li>Use compression and efficient indexing</li> <li>Monitor and adjust capacity settings regularly</li> </ul>"},{"location":"aws/database/dynamodb/#limitations-and-considerations","title":"Limitations and Considerations","text":"<ul> <li>Maximum item size: 400 KB</li> <li>Maximum attribute name length: 64 KB</li> <li>Complex joins not natively supported</li> <li>Scan operations can be costly for large datasets</li> </ul>"},{"location":"aws/database/dynamodb/#best-practices","title":"Best Practices","text":"<ul> <li>Design with access patterns in mind</li> <li>Minimize the number of secondary indexes</li> <li>Distribute partition key values evenly</li> <li>Use compression for large attributes</li> <li>Implement caching layers for read-heavy workloads</li> </ul>"},{"location":"aws/database/dynamodb/#conclusion","title":"Conclusion","text":"<p>AWS DynamoDB represents a powerful, flexible NoSQL database solution that combines scalability, performance, and ease of management. By understanding its architectural principles and leveraging its advanced features, developers can build robust, high-performance distributed applications.</p>"},{"location":"aws/database/elasticache/","title":"ElastiCache","text":""},{"location":"aws/database/elasticache/#overview","title":"Overview","text":"<p>AWS ElastiCache provides managed Redis or Memcached services, serving as in-memory databases that deliver high performance with low latency. Similar to how RDS manages relational databases, ElastiCache handles the operational complexities of caching solutions. AWS manages all aspects including OS maintenance, patching, optimization, configuration, monitoring, failure recovery, and backups.</p>"},{"location":"aws/database/elasticache/#redis-cluster-mode","title":"Redis Cluster mode","text":"<p>Redis Cluster Mode refers to a distributed implementation of Redis that automatically partitions data across multiple nodes in a cluster. It provides high availability and horizontal scaling while maintaining the simplicity and performance Redis is known for. While using Redis with cluster mode enabled, there are some limitations: - You cannot manually promote any of the replica nodes to primary. - Multi-AZ is required. - You can only change the structure of a cluster, the node type, and the number of nodes by restoring from a backup.</p> <p>All the nodes in a Redis cluster (cluster mode enabled or cluster mode disabled) must reside in the same region.</p>"},{"location":"aws/database/elasticache/#example-usages","title":"Example usages","text":""},{"location":"aws/database/elasticache/#database-cache-pattern","title":"Database Cache Pattern","text":"<p>In this architecture, applications first query ElastiCache for data. When cache misses occur, the application retrieves data from the primary database (typically RDS), then stores it in ElastiCache for future use. This pattern significantly reduces database load for read-intensive workloads. However, implementing an effective cache invalidation strategy becomes crucial to maintain data freshness.</p>"},{"location":"aws/database/elasticache/#user-session-store-pattern","title":"User Session Store Pattern","text":"<p>ElastiCache excels at managing user session data in distributed applications. When users authenticate with any application instance, their session data is written to ElastiCache. This allows other application instances to retrieve the session data, enabling seamless user experiences across multiple application servers and making applications truly stateless.</p>"},{"location":"aws/database/elasticache/#redis-vs-memcached-comparison","title":"Redis vs Memcached Comparison","text":""},{"location":"aws/database/elasticache/#redis-capabilities","title":"Redis Capabilities","text":"<p>Redis offers robust features for enterprise applications. It supports Multi-AZ deployments with automatic failover capabilities and read replicas for enhanced read scaling and high availability. Data durability is ensured through AOF (Append-Only File) persistence, complemented by comprehensive backup and restore functionality. Redis also provides advanced data structures including Sets and Sorted Sets.</p>"},{"location":"aws/database/elasticache/#memcached-features","title":"Memcached Features","text":"<p>Memcached focuses on simplicity and multi-threaded performance. It supports data partitioning through multi-node sharding but doesn\u2019t provide replication for high availability. Being non-persistent by design, it offers basic backup and restore capabilities through a serverless approach. Its multi-threaded architecture makes it particularly efficient for specific use cases.</p>"},{"location":"aws/database/elasticache/#caching-strategies","title":"Caching Strategies","text":""},{"location":"aws/database/elasticache/#lazy-loading-cache-aside","title":"Lazy Loading (Cache-Aside)","text":"<p>This strategy loads data into the cache only when necessary. Its advantages include efficient cache space utilization and resilience to node failures. However, it introduces additional latency on cache misses due to the required database roundtrip. Data staleness can occur when database updates aren\u2019t immediately reflected in the cache.</p>"},{"location":"aws/database/elasticache/#write-through-caching","title":"Write-Through Caching","text":"<p>Write-through caching updates both the database and cache simultaneously. This approach ensures cache consistency and enables quick reads. However, it introduces write latency due to the dual update requirement. New data remains unavailable until explicitly added to the database, though this limitation can be mitigated by combining with lazy loading.</p>"},{"location":"aws/database/elasticache/#cache-management","title":"Cache Management","text":""},{"location":"aws/database/elasticache/#eviction-policies-and-ttl","title":"Eviction Policies and TTL","text":"<p>Cache entries can be removed through:  - Explicit deletion - Memory pressure-based eviction (LRU) - Time-to-live (TTL) expiration TTL proves particularly valuable for time-sensitive data such as leaderboards, comments, and activity streams, with durations ranging from seconds to days. Memory pressure and frequent evictions indicate a need for cache scaling.</p>"},{"location":"aws/database/elasticache/#implementation-considerations","title":"Implementation Considerations","text":"<p>Implementing ElastiCache requires significant application code modifications to properly handle caching logic. Developers must carefully consider caching strategies, data consistency requirements, and failure scenarios. The chosen caching pattern should align with the application\u2019s specific needs regarding data freshness, read/write patterns, and performance requirements.</p> <p>The investment in proper cache implementation pays off through reduced database load, improved application response times, and enhanced scalability. However, this requires careful consideration of cache invalidation strategies, error handling, and monitoring to ensure optimal performance.</p>"},{"location":"aws/database/rds/","title":"Relational Database Service (RDS)","text":""},{"location":"aws/database/rds/#overview","title":"Overview","text":"<p>Amazon RDS (Relational Database Service) provides managed SQL databases in the cloud. It supports multiple database engines including PostgreSQL, MySQL, MariaDB, Oracle, Microsoft SQL Server, IBM DB2, and Amazon\u2019s proprietary Aurora database. This service enables organizations to operate and scale relational databases without managing the underlying infrastructure.</p>"},{"location":"aws/database/rds/#core-benefits-over-ec2-hosted-databases","title":"Core Benefits Over EC2-Hosted Databases","text":"<p>RDS provides significant advantages through its managed service model. AWS handles routine database administration tasks including automated provisioning, operating system patching, and continuous backups with point-in-time restore capabilities. The service includes comprehensive monitoring dashboards and supports both vertical and horizontal scaling options. Storage is provided through Amazon EBS, ensuring reliable persistence. While direct SSH access to database instances isn\u2019t available, this limitation supports enhanced security and consistent management.</p>"},{"location":"aws/database/rds/#storage-management","title":"Storage Management","text":""},{"location":"aws/database/rds/#auto-scaling-capabilities","title":"Auto Scaling Capabilities","text":"<p>RDS features dynamic storage scaling, automatically increasing storage capacity when free space becomes limited. This automation requires setting a maximum storage threshold and triggers when free storage drops below 10% for at least 5 minutes, with a minimum 6-hour interval between modifications. This feature particularly benefits applications with unpredictable storage requirements and supports all RDS database engines.</p>"},{"location":"aws/database/rds/#high-availability-and-replication","title":"High Availability and Replication","text":""},{"location":"aws/database/rds/#read-replicas","title":"Read Replicas","text":"<p>RDS supports up to 15 read replicas, which can be deployed within the same Availability Zone, across different AZs, or even across regions. These replicas use asynchronous replication, resulting in eventually consistent reads. While replicas can be promoted to standalone databases, applications must explicitly manage connection strings to utilize them effectively. Read replicas excel at handling read-heavy workloads, particularly for analytical queries and reporting functions that might otherwise impact production database performance.</p>"},{"location":"aws/database/rds/#network-cost-considerations","title":"Network Cost Considerations","text":"<p>AWS typically charges for data transfer between Availability Zones. However, RDS read replicas within the same region are exempt from these transfer fees, making them cost-effective for scaling read operations.</p>"},{"location":"aws/database/rds/#multi-az-deployment","title":"Multi-AZ Deployment","text":"<p>Multi-AZ deployments provide enhanced availability through synchronous replication to a standby instance in a different Availability Zone. This configuration uses a single DNS name, enabling automatic application failover. The setup protects against various failure scenarios including AZ outages, network issues, and instance or storage failures, all while requiring no application changes. Notably, Multi-AZ deployments focus on availability rather than scaling, though read replicas can be configured with Multi-AZ for comprehensive disaster recovery.</p>"},{"location":"aws/database/rds/#operational-flexibility","title":"Operational Flexibility","text":""},{"location":"aws/database/rds/#single-az-to-multi-az-migration","title":"Single-AZ to Multi-AZ Migration","text":"<p>Converting from Single-AZ to Multi-AZ deployment is a zero-downtime operation requiring no database shutdown. The process involves creating a snapshot, restoring it in a new Availability Zone, and establishing synchronization between instances. This seamless transition maintains database availability throughout the migration process.</p>"},{"location":"aws/database/rds/#performance-and-scaling","title":"Performance and Scaling","text":"<p>RDS provides both vertical and horizontal scaling options. Vertical scaling allows adjusting compute and memory resources, while horizontal scaling through read replicas distributes read workloads. The service automatically manages the underlying storage, supporting applications as they grow and their requirements evolve.</p>"},{"location":"aws/database/rds/#backup-and-recovery","title":"Backup and Recovery","text":"<p>The service includes automated backup capabilities with point-in-time recovery options. This feature enables restoration to any moment within the retention period, providing protection against data loss and corruption while maintaining business continuity.</p>"},{"location":"aws/database/rds/#amazon-rds-proxy","title":"Amazon RDS Proxy","text":"<p>Amazon RDS Proxy is a fully managed, highly available database proxy service that makes applications more scalable, more resilient to database failures, and more secure.</p>"},{"location":"aws/database/rds/#overview_1","title":"Overview","text":"<p>Amazon RDS Proxy acts as an intermediary layer between your applications and relational databases, enabling efficient connection management and improved database performance. This managed service helps applications maintain database connections, handle failovers more gracefully, and enhance security through IAM authentication and credentials management.</p>"},{"location":"aws/database/rds/#key-features-and-benefits","title":"Key Features and Benefits","text":""},{"location":"aws/database/rds/#connection-management","title":"Connection Management","text":"<p>RDS Proxy enables applications to pool and share database connections established with the database instance. Instead of each application instance maintaining its own database connections, the proxy manages a shared pool of connections, significantly reducing the connection management overhead.</p>"},{"location":"aws/database/rds/#performance-optimization","title":"Performance Optimization","text":"<p>By efficiently managing database connections, RDS Proxy substantially reduces the stress on database resources, including CPU and RAM utilization. The service minimizes the number of open connections and helps prevent connection timeouts, leading to better overall database performance and resource utilization.</p>"},{"location":"aws/database/rds/#high-availability-and-scalability","title":"High Availability and Scalability","text":"<p>The service is built with serverless architecture, automatically scaling to accommodate your application\u2019s needs without requiring manual intervention. RDS Proxy is designed for high availability with multi-AZ deployment support, ensuring continuous operation even during infrastructure failures.</p>"},{"location":"aws/database/rds/#enhanced-failover-support","title":"Enhanced Failover Support","text":"<p>One of the most significant advantages of RDS Proxy is its ability to reduce RDS and Aurora failover times by up to 66%. During failover events, the proxy manages connection handling, making the failover process more seamless for applications and reducing downtime.</p>"},{"location":"aws/database/rds/#database-compatibility","title":"Database Compatibility","text":"<p>RDS Proxy supports a wide range of popular database engines: Amazon RDS Databases: - MySQL - PostgreSQL - MariaDB - Microsoft SQL Server</p> <p>Amazon Aurora Databases: - Aurora MySQL - Aurora PostgreSQL</p>"},{"location":"aws/database/rds/#implementation-simplicity","title":"Implementation Simplicity","text":"<p>Most applications can implement RDS Proxy without requiring any code modifications. This seamless integration allows organizations to improve their database infrastructure without investing in application rewrites or extensive development efforts.</p>"},{"location":"aws/database/rds/#security-features","title":"Security Features","text":"<p>RDS Proxy incorporates robust security features to protect your database infrastructure. It enforces IAM Authentication for database access and integrates with AWS Secrets Manager for secure credential storage and management. This integration ensures that database credentials are securely stored and rotated according to your security policies.</p>"},{"location":"aws/database/rds/#network-security","title":"Network Security","text":"<p>RDS Proxy is designed with security in mind and is never publicly accessible. All access to the proxy must occur within your Amazon VPC, ensuring that your database connections remain secure and isolated within your private network infrastructure.</p>"},{"location":"aws/database/rds/#best-practices","title":"Best Practices","text":"<p>When implementing RDS Proxy, consider the following recommendations: - Configure appropriate IAM roles and permissions for secure access - Implement connection pooling strategies that align with your application\u2019s needs - Monitor proxy metrics to optimize performance and resource utilization - Review and adjust proxy settings based on your application\u2019s connection patterns</p>"},{"location":"aws/database/rds/#conclusion","title":"Conclusion","text":"<p>Amazon RDS Proxy provides a robust solution for managing database connections, improving application scalability, and enhancing database security. Its fully managed nature, combined with advanced features for connection pooling and security management, makes it an invaluable tool for organizations looking to optimize their database infrastructure while maintaining high availability and performance.</p>"},{"location":"aws/management/appconfig/","title":"AppConfig","text":""},{"location":"aws/management/appconfig/#overview","title":"Overview","text":"<p>AWS AppConfig is a dynamic configuration management service that enables you to deploy configuration changes to applications quickly, safely, and independently of code deployments.</p>"},{"location":"aws/management/appconfig/#key-features","title":"Key Features","text":""},{"location":"aws/management/appconfig/#dynamic-configuration-management","title":"Dynamic Configuration Management","text":"<ul> <li>Deploy configuration changes without application restarts</li> <li>Supports various use cases:</li> <li>Feature flags</li> <li>Application tuning</li> <li>Allow/block listing</li> <li>Dynamic parameter adjustments</li> </ul>"},{"location":"aws/management/appconfig/#broad-platform-support","title":"Broad Platform Support","text":"<p>Compatible with multiple AWS compute services: * EC2 instances * AWS Lambda * Amazon ECS * Amazon EKS</p>"},{"location":"aws/management/appconfig/#safe-deployment","title":"Safe Deployment","text":"<ul> <li>Gradual configuration rollout</li> <li>Built-in rollback mechanisms</li> <li>Prevents widespread issues from configuration changes</li> </ul>"},{"location":"aws/management/appconfig/#configuration-validation","title":"Configuration Validation","text":"<p>Two validation methods: 1. JSON Schema Validation    * Performs syntactic checks    * Ensures configuration structure meets defined requirements 2. Lambda Function Validation    * Enables custom semantic checks    * Allows running complex validation logic via custom code</p>"},{"location":"aws/management/appconfig/#benefits","title":"Benefits","text":"<ul> <li>Reduce deployment risks</li> <li>Enable dynamic application tuning</li> <li>Separate configuration management from code deployments</li> <li>Provide fine-grained control over configuration changes</li> </ul>"},{"location":"aws/management/billing/","title":"Billing and Cost","text":"<p>AWS Billing and Cost Management is a suite of tools that helps you monitor, manage, and optimize your AWS usage and costs. It provides features for budgeting, analyzing usage patterns, and forecasting future expenses to ensure cost-effective resource management.</p>"},{"location":"aws/management/billing/#key-features-and-characteristics","title":"Key Features and Characteristics","text":""},{"location":"aws/management/billing/#1-billing-dashboard","title":"1. Billing Dashboard","text":"<ul> <li>Provides a high-level overview of your AWS usage and charges.</li> <li>Displays current and forecasted month-to-date costs.</li> <li>Offers insights into service-specific expenditures.</li> </ul>"},{"location":"aws/management/billing/#2-cost-allocation-tags","title":"2. Cost Allocation Tags","text":"<ul> <li>User-Defined Tags: Tags you define and apply to categorize AWS resources (e.g., <code>Department: Finance</code>).</li> <li>AWS-Generated Tags: Automatically generated by AWS for certain resources.</li> <li>Use Case: Track costs by projects, departments, or teams.</li> </ul>"},{"location":"aws/management/billing/#3-cost-and-usage-reports-cur","title":"3. Cost and Usage Reports (CUR)","text":"<ul> <li>Comprehensive reports detailing AWS resource usage and costs.</li> <li>Delivered to an Amazon S3 bucket in CSV or Parquet format.</li> <li>Can be integrated with analytics tools like Amazon Athena or Amazon QuickSight for further analysis.</li> </ul>"},{"location":"aws/management/billing/#4-aws-budgets","title":"4. AWS Budgets","text":"<ul> <li>Set spending thresholds for your account or specific services.</li> <li>Types of budgets:</li> <li>Cost Budgets: Track total spending.</li> <li>Usage Budgets: Monitor service usage (e.g., EC2 instance hours).</li> <li>Savings Plans Budgets: Track Savings Plans utilization.</li> <li>Reservation Budgets: Monitor Reserved Instances (RIs).</li> <li>Configurable alerts via email or SNS notifications.</li> </ul>"},{"location":"aws/management/billing/#5-cost-explorer","title":"5. Cost Explorer","text":"<ul> <li>Interactive tool for visualizing and analyzing AWS costs and usage.</li> <li>Features include:</li> <li>Custom filtering by service, tag, or linked account.</li> <li>Granular breakdowns by hourly, daily, or monthly usage.</li> <li>Forecasting based on historical trends.</li> </ul>"},{"location":"aws/management/billing/#6-savings-plans-and-reserved-instances","title":"6. Savings Plans and Reserved Instances","text":"<ul> <li>Savings Plans: Flexible pricing models offering cost savings in exchange for a usage commitment (e.g., compute hours).</li> <li>Reserved Instances (RIs): Upfront or partial upfront payment options for EC2 instances with significant savings over On-Demand pricing.</li> </ul>"},{"location":"aws/management/billing/#7-free-tier-usage-tracking","title":"7. Free Tier Usage Tracking","text":"<ul> <li>Monitors free tier usage limits to avoid unexpected charges.</li> <li>Notifications when usage approaches or exceeds free tier limits.</li> </ul>"},{"location":"aws/management/billing/#8-consolidated-billing","title":"8. Consolidated Billing","text":"<ul> <li>Allows organizations to consolidate billing across multiple AWS accounts under a management account.</li> <li>Benefits:</li> <li>Single bill for all accounts.</li> <li>Cost-sharing and pooling of usage discounts (e.g., volume discounts).</li> </ul>"},{"location":"aws/management/billing/#9-service-quotas-integration","title":"9. Service Quotas Integration","text":"<ul> <li>Monitors service usage against AWS quotas.</li> <li>Helps prevent unexpected charges due to exceeding usage limits.</li> </ul>"},{"location":"aws/management/billing/#10-tax-settings-and-invoicing","title":"10. Tax Settings and Invoicing","text":"<ul> <li>Tax Settings: Configure tax information specific to your region (e.g., VAT/GST).</li> <li>Invoicing: Access detailed, downloadable invoices for each billing period.</li> </ul>"},{"location":"aws/management/billing/#11-currency-conversion","title":"11. Currency Conversion","text":"<ul> <li>Supports viewing charges in your preferred currency.</li> <li>AWS bills are always generated in USD, with conversions provided for reference.</li> </ul>"},{"location":"aws/management/billing/#12-anomaly-detection","title":"12. Anomaly Detection","text":"<ul> <li>Automatically identifies unusual spending patterns.</li> <li>Provides actionable insights to investigate cost anomalies.</li> </ul>"},{"location":"aws/management/billing/#13-integration-with-aws-organizations","title":"13. Integration with AWS Organizations","text":"<ul> <li>Enables centralized billing and cost management for multiple accounts.</li> <li>Linked accounts share discounts and usage data with the management account.</li> </ul>"},{"location":"aws/management/billing/#14-reports-and-notifications","title":"14. Reports and Notifications","text":"<ul> <li>Cost Reports: Auto-generated reports summarizing costs by service or account.</li> <li>Alerts and Notifications:</li> <li>Triggered when budgets or thresholds are exceeded.</li> <li>Configurable for email and SNS delivery.</li> </ul>"},{"location":"aws/management/billing/#15-third-party-tool-compatibility","title":"15. Third-Party Tool Compatibility","text":"<ul> <li>Compatible with external cost management tools via APIs.</li> <li>Examples include tools for advanced cost analytics or enterprise reporting.</li> </ul>"},{"location":"aws/management/billing/#iam-access-to-billing-and-cost-management","title":"IAM Access to Billing and Cost Management","text":"<ul> <li>By default, the root user has full access to all billing and cost management tools.</li> <li>IAM User Access Activation:</li> <li>By default, IAM user access to the Billing and Cost Management console is disabled.</li> <li>The root user or an authorized IAM user must enable this access in the Billing and Cost Management preferences.</li> <li>Once activated, IAM users with appropriate permissions can access the Billing and Cost Management console.</li> <li>Common Permissions:</li> <li><code>aws-portal:*</code>: Grants full access to the Billing and Cost Management console.</li> <li><code>ce:*</code>: Provides access to Cost Explorer API and related tools.</li> <li><code>cur:*</code>: Grants access to Cost and Usage Reports.</li> <li><code>budgets:*</code>: Allows management of AWS Budgets.</li> <li>Best Practices:</li> <li>Use IAM policies to grant least privilege.</li> <li>Restrict access to sensitive billing data to authorized users only.</li> </ul> <p>AWS Billing and Cost Management tools are essential for ensuring efficient resource utilization and cost control, making them integral to managing AWS accounts effectively.</p>"},{"location":"aws/management/cloudformation/","title":"CloudFormation","text":""},{"location":"aws/management/cloudformation/#introduction","title":"Introduction","text":"<p>AWS CloudFormation is a service that enables you to model, provision, and manage AWS resources by treating infrastructure as code. It allows you to create and manage a collection of AWS resources using templates written in JSON or YAML format. Instead of manually creating and configuring resources through the AWS Console, you can describe your desired infrastructure in a template file, and CloudFormation handles the rest.</p>"},{"location":"aws/management/cloudformation/#core-concepts","title":"Core Concepts","text":""},{"location":"aws/management/cloudformation/#templates","title":"Templates","text":"<p>Templates are JSON or YAML files that serve as blueprints for building AWS environments. They define all the AWS resources and their properties. A template can include:</p> <ul> <li>Resources</li> <li>Parameters</li> <li>Mappings</li> <li>Conditions</li> <li>Outputs</li> <li>Metadata</li> </ul>"},{"location":"aws/management/cloudformation/#stacks","title":"Stacks","text":"<p>A stack is a collection of AWS resources that you manage as a single unit. All resources described in a template are managed as part of the stack. Key aspects include:</p> <ul> <li>Creation, updating, and deletion of resources as a group</li> <li>Stack policies for resource protection</li> <li>Role-based access control</li> <li>Change sets for reviewing modifications</li> </ul>"},{"location":"aws/management/cloudformation/#change-sets","title":"Change Sets","text":"<p>Change sets let you preview how proposed changes to a stack might impact your running resources before implementing them.</p>"},{"location":"aws/management/cloudformation/#template-structure","title":"Template Structure","text":"<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nDescription: \"A sample template\"\n\nParameters:\n  EnvironmentType:\n    Type: String\n    AllowedValues: \n      - prod\n      - dev\n\nMappings:\n  RegionMap:\n    us-east-1:\n      AMI: \"ami-0123456789\"\n\nResources:\n  MyEC2Instance:\n    Type: \"AWS::EC2::Instance\"\n    Properties:\n      InstanceType: t2.micro\n      ImageId: !FindInMap [RegionMap, !Ref \"AWS::Region\", AMI]\n\nOutputs:\n  InstanceID:\n    Description: \"Instance ID\"\n    Value: !Ref MyEC2Instance\n</code></pre>"},{"location":"aws/management/cloudformation/#template-components","title":"Template Components","text":""},{"location":"aws/management/cloudformation/#parameters","title":"Parameters","text":"<p>Parameters enable you to input custom values to your template each time you create or update a stack.</p> <pre><code>Parameters:\n  InstanceType:\n    Description: EC2 instance type\n    Type: String\n    Default: t2.micro\n    AllowedValues:\n      - t2.micro\n      - t2.small\n      - t2.medium\n</code></pre>"},{"location":"aws/management/cloudformation/#mappings","title":"Mappings","text":"<p>Mappings are fixed key-value pairs that you can use to specify conditional parameter values.</p> <pre><code>Mappings:\n  EnvironmentToInstanceType:\n    dev:\n      instanceType: t2.micro\n    prod:\n      instanceType: t2.small\n</code></pre>"},{"location":"aws/management/cloudformation/#resources","title":"Resources","text":"<p>Resources are the AWS components that will be created and configured.</p> <pre><code>Resources:\n  MyS3Bucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      BucketName: !Sub \"${AWS::StackName}-bucket\"\n      VersioningConfiguration:\n        Status: Enabled\n</code></pre>"},{"location":"aws/management/cloudformation/#outputs","title":"Outputs","text":"<p>Outputs declare values that you can import into other stacks or view in the AWS Console.</p> <pre><code>Outputs:\n  BucketName:\n    Description: Name of the created bucket\n    Value: !Ref MyS3Bucket\n    Export:\n      Name: !Sub \"${AWS::StackName}-BucketName\"\n</code></pre>"},{"location":"aws/management/cloudformation/#intrinsic-functions","title":"Intrinsic Functions","text":"<p>CloudFormation provides several built-in functions for template management:</p> <ul> <li><code>!Ref</code> - References parameters or resources</li> <li><code>!GetAtt</code> - Gets an attribute from a resource</li> <li><code>!Sub</code> - Substitutes variables in a string</li> <li><code>!Join</code> - Joins values with a delimiter</li> <li><code>!Split</code> - Splits a string into a list</li> <li><code>!Select</code> - Selects an item from a list</li> <li><code>!FindInMap</code> - Returns a named value from a mapping</li> </ul>"},{"location":"aws/management/cloudformation/#best-practices","title":"Best Practices","text":""},{"location":"aws/management/cloudformation/#template-design","title":"Template Design","text":"<ul> <li>Use descriptive names for resources</li> <li>Implement proper tagging strategy</li> <li>Use parameters for values that change</li> <li>Implement proper error handling</li> <li>Use nested stacks for reusable components</li> </ul>"},{"location":"aws/management/cloudformation/#security","title":"Security","text":"<ul> <li>Use IAM roles and policies</li> <li>Implement stack policies</li> <li>Enable encryption where possible</li> <li>Use VPC endpoints</li> <li>Follow the principle of least privilege</li> </ul>"},{"location":"aws/management/cloudformation/#cost-management","title":"Cost Management","text":"<ul> <li>Use cost allocation tags</li> <li>Implement lifecycle policies</li> <li>Consider reserved instances</li> <li>Monitor resource usage</li> </ul>"},{"location":"aws/management/cloudformation/#common-operations","title":"Common Operations","text":""},{"location":"aws/management/cloudformation/#creating-a-stack","title":"Creating a Stack","text":"<pre><code>aws cloudformation create-stack \\\n  --stack-name my-stack \\\n  --template-body file://template.yaml \\\n  --parameters ParameterKey=EnvironmentType,ParameterValue=prod\n</code></pre>"},{"location":"aws/management/cloudformation/#updating-a-stack","title":"Updating a Stack","text":"<pre><code>aws cloudformation update-stack \\\n  --stack-name my-stack \\\n  --template-body file://template.yaml\n</code></pre>"},{"location":"aws/management/cloudformation/#deleting-a-stack","title":"Deleting a Stack","text":"<pre><code>aws cloudformation delete-stack \\\n  --stack-name my-stack\n</code></pre>"},{"location":"aws/management/cloudformation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aws/management/cloudformation/#common-issues","title":"Common Issues","text":"<ol> <li>Stack Creation Failures</li> <li>Check resource limits</li> <li>Verify IAM permissions</li> <li> <p>Review dependency order</p> </li> <li> <p>Update Failures</p> </li> <li>Use change sets to preview changes</li> <li>Check for protected resources</li> <li> <p>Verify resource properties</p> </li> <li> <p>Deletion Failures</p> </li> <li>Check for deletion policies</li> <li>Verify termination protection</li> <li>Review stack dependencies</li> </ol>"},{"location":"aws/management/cloudformation/#integration-with-other-aws-services","title":"Integration with Other AWS Services","text":"<p>CloudFormation integrates with numerous AWS services:</p> <ul> <li>AWS Organizations</li> <li>AWS Config</li> <li>AWS Service Catalog</li> <li>AWS Systems Manager</li> <li>AWS CodePipeline</li> <li>AWS CodeBuild</li> <li>AWS CodeDeploy</li> </ul>"},{"location":"aws/management/cloudformation/#tools-and-resources","title":"Tools and Resources","text":""},{"location":"aws/management/cloudformation/#development-tools","title":"Development Tools","text":"<ul> <li>AWS CloudFormation Designer</li> <li>AWS CLI</li> <li>AWS SDK</li> <li>IDE plugins</li> </ul>"},{"location":"aws/management/cloudformation/#validation-tools","title":"Validation Tools","text":"<ul> <li>cfn-lint</li> <li>CloudFormation Guard</li> <li>TaskCat</li> </ul>"},{"location":"aws/management/cloudformation/#best-practices-for-cicd","title":"Best Practices for CI/CD","text":"<ul> <li>Use version control for templates</li> <li>Implement automated testing</li> <li>Use change sets in deployment pipeline</li> <li>Maintain separate stacks for different environments</li> <li>Implement proper rollback strategies</li> </ul>"},{"location":"aws/management/cloudformation/#conclusion","title":"Conclusion","text":"<p>AWS CloudFormation is a powerful service for infrastructure as code that enables consistent and repeatable deployments of AWS resources. By following best practices and utilizing its features effectively, you can manage complex infrastructure efficiently and reliably.</p>"},{"location":"aws/management/cloudformation/#additional-resources","title":"Additional Resources","text":"<ul> <li>Official AWS CloudFormation Documentation</li> <li>AWS CloudFormation Sample Templates</li> <li>AWS CloudFormation Workshop</li> <li>CloudFormation Registry</li> </ul>"},{"location":"aws/management/sam/","title":"Serverless Application Model (SAM)","text":""},{"location":"aws/management/sam/#overview","title":"Overview","text":"<p>AWS SAM is a framework for developing and deploying serverless applications, providing a simplified approach to creating serverless infrastructure.</p>"},{"location":"aws/management/sam/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Configuration-as-Code using YAML</li> <li>Generates complex CloudFormation templates from simple SAM templates</li> <li>Full CloudFormation compatibility</li> <li>Supports comprehensive resource configuration</li> </ul>"},{"location":"aws/management/sam/#core-components","title":"Core Components","text":""},{"location":"aws/management/sam/#template-structure","title":"Template Structure","text":"<ul> <li>Uses special transform header: <code>Transform: 'AWS::Serverless-2016-10-31'</code></li> <li>Supports key serverless resources:</li> <li><code>AWS::Serverless::Function</code></li> <li><code>AWS::Serverless::Api</code></li> <li><code>AWS::Serverless::SimpleTable</code></li> </ul>"},{"location":"aws/management/sam/#deployment-process","title":"Deployment Process","text":"<ol> <li>Build: <code>sam build</code></li> <li>Prepares application locally</li> <li>Package: <code>sam package</code></li> <li>Transforms and uploads application code to S3</li> <li>Deploy: <code>sam deploy</code></li> <li>Creates/updates CloudFormation stack</li> <li>Provisions serverless resources</li> </ol>"},{"location":"aws/management/sam/#advanced-features","title":"Advanced Features","text":""},{"location":"aws/management/sam/#sam-accelerate","title":"SAM Accelerate","text":"<ul> <li>Reduces deployment latency</li> <li>Synchronization options:</li> <li><code>sam sync</code>: Full resource synchronization</li> <li><code>sam sync --code</code>: Quick code updates</li> <li><code>sam sync --watch</code>: Automatic file change detection</li> </ul>"},{"location":"aws/management/sam/#local-development-capabilities","title":"Local Development Capabilities","text":"<ul> <li><code>sam local start-lambda</code>: Local Lambda endpoint</li> <li><code>sam local invoke</code>: Invoke Lambda functions locally</li> <li><code>sam local start-api</code>: Local API Gateway simulation</li> <li><code>sam local generate-event</code>: Generate sample event payloads</li> </ul>"},{"location":"aws/management/sam/#codedeploy-integration","title":"CodeDeploy Integration","text":"<ul> <li>Native traffic shifting for Lambda functions</li> <li>Deployment strategies:</li> <li>Canary</li> <li>Linear</li> <li>All At Once</li> <li>Support for:</li> <li>Pre/Post traffic hooks</li> <li>Automated rollback</li> <li>CloudWatch Alarm triggers</li> </ul>"},{"location":"aws/management/sam/#policy-templates","title":"Policy Templates","text":"<p>Predefined IAM permission templates for Lambda functions: * <code>S3ReadPolicy</code>: S3 read permissions * <code>SQSPollerPolicy</code>: SQS queue polling * <code>DynamoDBCrudPolicy</code>: Database CRUD operations</p>"},{"location":"aws/management/sam/#multi-environment-support","title":"Multi-Environment Support","text":"<ul> <li>Configuration via <code>samconfig.toml</code></li> <li>Environment-specific deployments</li> <li>Example: <code>sam deploy --config-env dev</code></li> </ul>"},{"location":"aws/management/sam/#benefits","title":"Benefits","text":"<ul> <li>Simplified serverless development</li> <li>Rapid local testing</li> <li>Consistent deployment patterns</li> <li>Reduced infrastructure configuration complexity</li> <li>Seamless AWS service integration</li> </ul>"},{"location":"aws/management/ssm/","title":"Systems Manager Parameter Store (SSM)","text":""},{"location":"aws/management/ssm/#overview","title":"Overview","text":"<p>AWS Systems Manager Parameter Store offers a robust and secure service for configuration and secrets management. This centralized service provides a comprehensive solution for storing and managing configuration data, secrets, and other operational parameters within your AWS infrastructure.</p>"},{"location":"aws/management/ssm/#core-features","title":"Core Features","text":""},{"location":"aws/management/ssm/#secure-storage-and-encryption","title":"Secure Storage and Encryption","text":"<p>Parameter Store provides secure storage capabilities for both configuration data and sensitive information. The service seamlessly integrates with AWS Key Management Service (KMS), offering optional encryption capabilities to ensure the security of your stored parameters. This encryption integration allows organizations to maintain strict security standards while managing their configuration data.</p>"},{"location":"aws/management/ssm/#architecture-and-implementation","title":"Architecture and Implementation","text":"<p>The service is built on a serverless architecture, eliminating the need for infrastructure management. It offers excellent scalability to accommodate growing parameter storage needs and ensures durability through AWS\u2019s reliable infrastructure. Developers can easily interact with Parameter Store through a well-designed SDK, making implementation straightforward across various applications and services.</p>"},{"location":"aws/management/ssm/#version-control","title":"Version Control","text":"<p>Parameter Store maintains version tracking for all stored configurations and secrets. This versioning capability enables organizations to maintain a history of parameter changes, roll back to previous versions when needed, and audit configuration modifications over time.</p>"},{"location":"aws/management/ssm/#security-framework","title":"Security Framework","text":"<p>Security in Parameter Store is managed through AWS Identity and Access Management (IAM). This integration allows organizations to implement fine-grained access controls, ensuring that only authorized users and applications can access specific parameters. The IAM integration provides a robust security framework for managing access to sensitive configuration data.</p>"},{"location":"aws/management/ssm/#integration-capabilities","title":"Integration Capabilities","text":"<p>The service features comprehensive integration with Amazon EventBridge, enabling automated notifications based on parameter changes or specific events. This integration allows organizations to build event-driven architectures and automated workflows around their configuration management processes.</p> <p>Parameter Store also integrates seamlessly with AWS CloudFormation, enabling infrastructure as code practices and automated resource management. This integration allows organizations to include parameter management as part of their infrastructure deployment and management processes.</p>"},{"location":"aws/management/ssm/#service-tiers","title":"Service Tiers","text":"<p>Parameter Store offers two distinct service tiers to accommodate different organizational needs:</p>"},{"location":"aws/management/ssm/#standard-tier","title":"Standard Tier","text":"<p>The standard tier provides essential parameter management capabilities suitable for many applications and use cases.</p>"},{"location":"aws/management/ssm/#advanced-tier","title":"Advanced Tier","text":"<p>The advanced tier offers enhanced features and capabilities, including support for parameter policies and larger parameter values.</p> <p></p>"},{"location":"aws/management/ssm/#parameter-policies","title":"Parameter Policies","text":"<p>Advanced parameters in Parameter Store can leverage parameter policies, which provide additional control and automation capabilities. These policies enable organizations to manage their parameters more effectively:</p>"},{"location":"aws/management/ssm/#time-to-live-ttl-management","title":"Time-to-Live (TTL) Management","text":"<p>Parameter policies allow the assignment of expiration dates (TTL) to parameters. This capability is particularly valuable for managing sensitive data such as passwords, ensuring that such information is regularly updated or removed. The TTL functionality helps organizations maintain security compliance by forcing the update or deletion of sensitive parameters after a specified period.</p>"},{"location":"aws/management/ssm/#policy-flexibility","title":"Policy Flexibility","text":"<p>Parameter Store supports the concurrent assignment of multiple policies to a single parameter. This flexibility allows organizations to implement complex parameter management strategies that combine different policy types to meet specific security and operational requirements.</p>"},{"location":"aws/management/ssm/#best-practices","title":"Best Practices","text":"<p>When implementing Parameter Store, consider these recommended practices: - Implement appropriate encryption for sensitive parameters using KMS - Establish clear naming conventions for parameters to maintain organization - Utilize parameter policies for sensitive data management - Configure EventBridge rules for critical parameter changes - Implement proper IAM policies following the principle of least privilege</p>"},{"location":"aws/management/ssm/#conclusion","title":"Conclusion","text":"<p>AWS Systems Manager Parameter Store provides a comprehensive solution for configuration and secrets management, combining secure storage, version control, and integration capabilities with other AWS services. Its flexible tier structure and policy management features make it suitable for organizations of all sizes seeking to implement robust configuration management practices.</p>"},{"location":"aws/messaging/firehose/","title":"Firehose","text":"<p>Previously known as Kinesis Data Firehose, this fully managed service provides a seamless solution for streaming data delivery and transformation. The service enables organizations to efficiently route streaming data to multiple destinations with minimal operational overhead.</p>"},{"location":"aws/messaging/firehose/#destination-capabilities","title":"Destination Capabilities","text":"<p>Amazon Data Firehose supports comprehensive data routing to various destinations, including native AWS services like Amazon Redshift, Amazon S3, and Amazon OpenSearch Service. The platform also facilitates integration with third-party platforms such as Splunk, MongoDB, Datadog, and New Relic, along with support for custom HTTP endpoints.</p>"},{"location":"aws/messaging/firehose/#service-characteristics","title":"Service Characteristics","text":"<p>The service operates as a serverless infrastructure with automatic scaling, allowing organizations to pay only for consumed resources. Data processing occurs with near real-time capabilities, utilizing intelligent buffering mechanisms based on data size and time intervals.</p>"},{"location":"aws/messaging/firehose/#data-format-flexibility","title":"Data Format Flexibility","text":"<p>Firehose demonstrates remarkable versatility in data format handling, supporting multiple input and output formats. Supported input formats include CSV, JSON, Parquet, Avro, Raw Text, and Binary data. The service offers advanced conversion capabilities, transforming data into Parquet or ORC formats and implementing compression using gzip or snappy algorithms.</p>"},{"location":"aws/messaging/firehose/#advanced-transformation-capabilities","title":"Advanced Transformation Capabilities","text":"<p>Organizations can leverage AWS Lambda for custom data transformations, enabling sophisticated data processing workflows. This feature allows complex data manipulation tasks, such as converting CSV data to JSON format, directly within the streaming pipeline.</p>"},{"location":"aws/messaging/firehose/#comparative-analysis-with-kinesis-data-streams","title":"Comparative Analysis with Kinesis Data Streams","text":"<p>While Kinesis Data Streams focuses on real-time streaming data collection with producer and consumer code management, Amazon Data Firehose provides a more streamlined approach. Key differentiations include:</p> <p>Firehose operates with near real-time processing, offers automatic scaling, and does not maintain long-term data storage. Unlike Kinesis Data Streams, Firehose lacks data replay capabilities, emphasizing immediate data routing and transformation.</p>"},{"location":"aws/messaging/firehose/#use-case-scenarios","title":"Use Case Scenarios","text":"<p>The service is particularly valuable for organizations requiring efficient, scalable data streaming solutions. Typical applications include log analytics, real-time business intelligence, website clickstream analysis, and comprehensive data warehouse loading.</p>"},{"location":"aws/messaging/firehose/#technical-architecture","title":"Technical Architecture","text":"<p>By abstracting complex streaming infrastructure challenges, Amazon Data Firehose enables developers to focus on data processing logic rather than managing underlying streaming mechanics. The serverless nature ensures seamless scalability and minimal operational complexity.</p>"},{"location":"aws/messaging/kinesis_data_analytics/","title":"Kinesis Data Analytics","text":"<p>Amazon Kinesis Data Analytics provides a powerful serverless solution for processing and analyzing streaming data in real-time using standard SQL queries. The service enables organizations to transform and derive insights from data streams without managing complex infrastructure.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#processing-capabilities","title":"Processing Capabilities","text":"<p>The service supports multiple input streams from Kinesis Data Streams and Kinesis Data Firehose, allowing sophisticated data processing and analysis. Developers can write SQL queries to perform real-time transformations, aggregations, and complex analytical operations on streaming data.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#input-and-output-flexibility","title":"Input and Output Flexibility","text":"<p>Kinesis Data Analytics supports diverse data sources and destinations. Input streams can originate from Kinesis Data Streams or Kinesis Data Firehose, while output can be directed to various endpoints including AWS Lambda, Kinesis Data Streams, and Kinesis Data Firehose.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#data-processing-features","title":"Data Processing Features","text":"<p>The platform enables sophisticated stream processing through in-application SQL transformations. Users can perform complex operations like windowing, filtering, joining streams, and generating time-series aggregations without managing underlying computational infrastructure.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#language-and-reference-data-support","title":"Language and Reference Data Support","text":"<p>Beyond standard SQL, the service provides advanced capabilities for referencing external data sources. Users can incorporate reference data from S3 to enrich stream processing, enabling more comprehensive analytical scenarios.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#performance-and-scaling","title":"Performance and Scaling","text":"<p>Kinesis Data Analytics automatically scales computational resources based on streaming data volume and complexity. The serverless architecture ensures efficient resource utilization and eliminates manual capacity management requirements.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#use-case-scenarios","title":"Use Case Scenarios","text":"<p>Typical applications include real-time analytics for IoT sensor data, log analysis, financial transaction monitoring, clickstream analysis, and dynamic business intelligence reporting. The service\u2019s flexibility supports diverse industry-specific streaming analysis requirements.</p>"},{"location":"aws/messaging/kinesis_data_analytics/#security-and-compliance","title":"Security and Compliance","text":"<p>The service integrates seamlessly with AWS security mechanisms, supporting encryption, access controls, and comprehensive compliance frameworks. Data processing occurs within secure, isolated environments managed by AWS infrastructure.</p>"},{"location":"aws/messaging/kinesis_data_streams/","title":"Kinesis Data Streams","text":"<p>Amazon Kinesis Data Streams provides a powerful real-time data collection and storage solution for streaming information across complex distributed systems. The service enables organizations to capture and process large volumes of streaming data with exceptional performance and flexibility.</p>"},{"location":"aws/messaging/kinesis_data_streams/#data-retention-and-processing-capabilities","title":"Data Retention and Processing Capabilities","text":"<p>Kinesis Data Streams offers extensive data retention capabilities, supporting streaming data storage for up to 365 days. This extended retention allows consumers to reprocess and replay data multiple times, providing remarkable flexibility in data analysis and recovery. Once data is ingested, it cannot be manually deleted and will automatically expire according to the configured retention period.</p>"},{"location":"aws/messaging/kinesis_data_streams/#data-characteristics-and-limitations","title":"Data Characteristics and Limitations","text":"<p>The service supports streaming data with individual record sizes up to 1 megabyte, making it ideal for processing numerous small real-time data points. Kinesis ensures data ordering guarantees for records sharing the same partition identifier, maintaining critical sequencing requirements for complex streaming scenarios.</p>"},{"location":"aws/messaging/kinesis_data_streams/#security-and-encryption","title":"Security and Encryption","text":"<p>Robust security mechanisms are integrated into Kinesis Data Streams. The service implements comprehensive encryption strategies, including at-rest encryption through AWS Key Management Service and in-flight encryption via HTTPS protocols. These security measures ensure data protection throughout the streaming lifecycle.</p>"},{"location":"aws/messaging/kinesis_data_streams/#optimization-libraries","title":"Optimization Libraries","text":"<p>To enhance development efficiency, AWS provides specialized libraries for producers and consumers. The Kinesis Producer Library enables developers to create optimized producer applications, while the Kinesis Client Library facilitates efficient consumer application development.</p>"},{"location":"aws/messaging/kinesis_data_streams/#capacity-management-modes","title":"Capacity Management Modes","text":""},{"location":"aws/messaging/kinesis_data_streams/#provisioned-mode","title":"Provisioned Mode","text":"<p>In the provisioned mode, organizations manually manage stream capacity by selecting specific shard configurations. Each shard supports 1 megabyte per second input (or 1000 records per second) and 2 megabytes per second output. Users pay for provisioned shards on an hourly basis and must manually scale infrastructure to meet changing throughput requirements.</p>"},{"location":"aws/messaging/kinesis_data_streams/#on-demand-mode","title":"On-Demand Mode","text":"<p>The on-demand mode eliminates complex capacity planning by automatically scaling stream infrastructure. With a default capacity of 4 megabytes per second input (or 4000 records per second), the service dynamically adjusts based on observed throughput peaks from the previous 30 days. Billing occurs per stream hour and per gigabyte of data transferred.</p>"},{"location":"aws/messaging/kinesis_data_streams/#use-cases-and-applications","title":"Use Cases and Applications","text":"<p>Kinesis Data Streams serves diverse real-time data processing scenarios, including log and event data streaming, website clickstream analysis, IoT device data processing, and complex event-driven architectural patterns. The service\u2019s flexible architecture supports rapid, scalable data ingestion across multiple industries and technological domains.</p>"},{"location":"aws/messaging/ses/","title":"Simple Email Service (SES)","text":"<p>Amazon Simple Email Service represents a comprehensive cloud-based email communication platform designed for secure, global email delivery at massive scale. This fully managed service empowers organizations to send and receive emails with unprecedented flexibility and reliability.</p>"},{"location":"aws/messaging/ses/#service-capabilities","title":"Service Capabilities","text":"<p>SES offers robust capabilities for both inbound and outbound email communications, supporting diverse business communication needs. Organizations can leverage the service for transactional, marketing, and bulk email communications across global infrastructures.</p>"},{"location":"aws/messaging/ses/#email-delivery-and-performance-management","title":"Email Delivery and Performance Management","text":"<p>The service provides extensive performance insights through a comprehensive reputation dashboard. Users gain access to detailed statistics tracking email deliveries, bounce rates, feedback loop results, and email open rates. This granular visibility enables organizations to monitor and optimize their email communication strategies effectively.</p>"},{"location":"aws/messaging/ses/#security-and-authentication-mechanisms","title":"Security and Authentication Mechanisms","text":"<p>SES implements sophisticated email authentication protocols to ensure message integrity and prevent potential spoofing. The service supports industry-standard authentication frameworks including DomainKeys Identified Mail (DKIM) and Sender Policy Framework (SPF), which enhance email deliverability and protect sender reputation.</p>"},{"location":"aws/messaging/ses/#ip-deployment-strategies","title":"IP Deployment Strategies","text":"<p>Email sending infrastructure offers remarkable flexibility through multiple IP deployment options. Organizations can choose between shared, dedicated, or customer-owned IP addresses, allowing tailored solutions that match specific compliance, performance, and scalability requirements.</p>"},{"location":"aws/messaging/ses/#sending-mechanisms","title":"Sending Mechanisms","text":"<p>Users can dispatch emails through multiple interfaces, including the AWS Console, programmatic APIs, or traditional SMTP protocols. This versatility ensures seamless integration with existing application architectures and development workflows.</p>"},{"location":"aws/messaging/ses/#communication-use-cases","title":"Communication Use Cases","text":"<p>The service accommodates diverse communication scenarios, supporting: - Transactional email communications - Marketing email campaigns - Bulk email distribution - Automated notification systems - Customer engagement communications</p>"},{"location":"aws/messaging/ses/#technical-integration","title":"Technical Integration","text":"<p>Developers can easily integrate SES into their applications, leveraging AWS\u2019s comprehensive cloud infrastructure to manage complex email communication requirements. The service\u2019s scalable architecture ensures reliable message transmission across global networks.</p>"},{"location":"aws/messaging/ses/#performance-and-reliability","title":"Performance and Reliability","text":"<p>By providing a fully managed email sending platform, SES abstracts complex email infrastructure challenges. Organizations can focus on crafting compelling content while AWS handles the intricate details of global email delivery, reputation management, and performance optimization.</p>"},{"location":"aws/messaging/sns/","title":"Simple Notification Service (SNS)","text":"<p>Amazon Simple Notification Service (SNS) is a robust pub/sub messaging service that enables distributed systems to communicate efficiently. The service allows an event producer to publish messages to a single topic, which can then be distributed to multiple subscribers across various AWS services and platforms.</p>"},{"location":"aws/messaging/sns/#core-characteristics","title":"Core Characteristics","text":"<p>SNS provides remarkable scalability, supporting up to 12.5 million subscriptions per topic with a limit of 100,000 topics per account. Every subscriber receives messages published to the topic, with recent enhancements introducing sophisticated message filtering capabilities.</p>"},{"location":"aws/messaging/sns/#publishing-methods","title":"Publishing Methods","text":"<p>Topic publishing utilizes AWS SDK, involving creating topics, establishing subscriptions, and publishing messages. For mobile applications, direct publish offers a specialized mechanism supporting integration with major mobile platforms like Google Cloud Messaging, Apple Push Notification Service, and Amazon Device Messaging.</p>"},{"location":"aws/messaging/sns/#security-and-encryption","title":"Security and Encryption","text":"<p>Security is deeply embedded in SNS\u2019s architecture. The service implements comprehensive encryption strategies, including in-flight encryption through HTTPS API, at-rest encryption via AWS Key Management Service, and optional client-side encryption for custom security requirements.</p>"},{"location":"aws/messaging/sns/#fan-out-architecture-with-sqs","title":"Fan-Out Architecture with SQS","text":"<p>SNS supports a powerful fan-out pattern that allows pushing a single message to multiple Amazon SQS queues. This approach creates a decoupled system with enhanced capabilities:</p> <ul> <li>Prevents data loss</li> <li>Enables data persistence</li> <li>Supports delayed processing</li> <li>Allows dynamic addition of queue subscribers</li> <li>Facilitates cross-region message delivery</li> </ul>"},{"location":"aws/messaging/sns/#fifo-topics","title":"FIFO Topics","text":"<p>First-In-First-Out topics provide advanced message management capabilities. This feature ensures precise message ordering within message groups, supports deduplication through multiple strategies, and maintains compatibility with both SQS Standard and FIFO queues.</p>"},{"location":"aws/messaging/sns/#message-filtering-strategies","title":"Message Filtering Strategies","text":"<p>SNS introduces sophisticated message filtering using JSON policies. This approach allows granular control over message routing, enabling subscriptions to selectively consume messages based on complex filtering rules.</p>"},{"location":"aws/messaging/sns/#specific-application-scenarios","title":"Specific Application Scenarios","text":"<p>The service offers unique solutions for various architectural challenges. For instance, it overcomes S3 event notification limitations by enabling fan-out distribution of identical events to multiple queues. Additionally, SNS can seamlessly route messages through Kinesis Data Firehose, providing flexible solution architectures.</p>"},{"location":"aws/messaging/sns/#service-ecosystem-integration","title":"Service Ecosystem Integration","text":"<p>SNS seamlessly connects with numerous AWS services, transforming it from a simple notification service into a robust event-driven architecture enabler. Whether processing cloud events, managing mobile push notifications, or coordinating distributed system communications, SNS provides a flexible, secure, and scalable messaging solution.</p>"},{"location":"aws/messaging/sns/#supported-platforms-and-endpoints","title":"Supported Platforms and Endpoints","text":"<p>The service supports a wide range of platforms, including mobile notification services like Google Cloud Messaging, Apple Push Notification Service, and Amazon Device Messaging. This extensive platform support ensures broad compatibility and easy integration across different technological ecosystems.</p>"},{"location":"aws/messaging/sqs/","title":"Simple Queue Service (SQS)","text":""},{"location":"aws/messaging/sqs/#overview-of-amazon-sqs","title":"Overview of Amazon SQS","text":"<p>Amazon Simple Queue Service (SQS) is AWS\u2019s oldest messaging service, designed to decouple applications by providing a fully managed message queuing system. As a foundational AWS service with over a decade of existence, SQS offers robust messaging capabilities with specific characteristics that make it versatile for various architectural needs.</p>"},{"location":"aws/messaging/sqs/#standard-queue-characteristics","title":"Standard Queue Characteristics","text":"<p>The Standard Queue provides unlimited throughput and message storage, allowing applications to handle massive message volumes with exceptional flexibility. Messages persist in the queue for a default retention period of 4 days, extendable up to 14 days. The service guarantees low latency, with message publishing and receiving typically occurring within 10 milliseconds.</p> <p>Key Standard Queue Attributes: - Messages are limited to 256KB in size - Supports at least once delivery mechanism - Offers best-effort message ordering - Provides unlimited throughput - Maintains messages for 4-14 days</p>"},{"location":"aws/messaging/sqs/#message-production-and-consumption","title":"Message Production and Consumption","text":""},{"location":"aws/messaging/sqs/#message-production","title":"Message Production","text":"<p>Applications produce messages using the SDK\u2019s SendMessage API, with messages persisting in the queue until explicitly deleted by a consumer. Messages can include diverse attributes such as order identifiers, customer details, or any custom metadata.</p>"},{"location":"aws/messaging/sqs/#message-consumption","title":"Message Consumption","text":"<p>Consumers, which can run on EC2 instances, servers, or AWS Lambda, interact with SQS through polling mechanisms: - Can receive up to 10 messages simultaneously - Process messages according to application logic - Delete processed messages using the DeleteMessage API</p>"},{"location":"aws/messaging/sqs/#multi-consumer-scenarios","title":"Multi-Consumer Scenarios","text":"<p>SQS supports parallel message processing across multiple EC2 instances. This approach enables horizontal scaling of consumers, improving overall message processing throughput. However, the service provides at least once delivery with best-effort ordering, which means applications must be designed to handle potential message duplicates.</p>"},{"location":"aws/messaging/sqs/#security-mechanisms","title":"Security Mechanisms","text":"<p>SQS implements comprehensive security through multiple encryption and access control strategies:</p> <p>Encryption Options: - In-flight encryption via HTTPS API - At-rest encryption using AWS KMS keys - Client-side encryption for custom encryption requirements</p> <p>Access Control: - IAM policies regulating SQS API access - SQS Access Policies enabling cross-account queue access - Permissions for service integrations with SNS, S3, and others</p>"},{"location":"aws/messaging/sqs/#advanced-message-management-features","title":"Advanced Message Management Features","text":""},{"location":"aws/messaging/sqs/#message-visibility-timeout","title":"Message Visibility Timeout","text":"<p>When a consumer polls a message, it becomes temporarily invisible to other consumers. The default visibility timeout is 30 seconds, during which the message must be processed. If processing fails within this window, the message becomes available again, potentially causing duplicate processing.</p>"},{"location":"aws/messaging/sqs/#dead-letter-queue-dlq","title":"Dead Letter Queue (DLQ)","text":"<p>DLQs provide a mechanism for managing problematic messages: - Track messages that repeatedly fail processing - Configurable maximum receive threshold - Separate queues for Standard and FIFO queue types - Supports message redriving for debugging and recovery</p>"},{"location":"aws/messaging/sqs/#delay-queues","title":"Delay Queues","text":"<p>Messages can be delayed up to 15 minutes before becoming visible to consumers, configurable at queue or message level.</p>"},{"location":"aws/messaging/sqs/#long-polling","title":"Long Polling","text":"<p>Long polling reduces API calls by allowing consumers to wait for messages, improving application efficiency and reducing latency. Wait times range from 1 to 20 seconds, with 20 seconds recommended.</p>"},{"location":"aws/messaging/sqs/#fifo-first-in-first-out-queue","title":"FIFO (First-In-First-Out) Queue","text":"<p>FIFO queues offer strict message ordering with unique capabilities: - Limited throughput (300 messages/second without batching) - Exactly-once send capability - Mandatory message group ID for ordering</p>"},{"location":"aws/messaging/sqs/#deduplication-mechanism","title":"Deduplication Mechanism","text":"<p>Deduplication is a critical feature of FIFO queues that prevents message duplication through two primary methods:</p> <ol> <li>Content-Based Deduplication:</li> <li>Automatically generates a SHA-256 hash of the message body</li> <li>If an identical message is sent within the 5-minute deduplication interval, it is rejected</li> <li> <p>Useful when message content serves as a natural unique identifier</p> </li> <li> <p>Explicit Deduplication:</p> </li> <li>Requires manually providing a Message Deduplication ID</li> <li>Developers specify a unique identifier for each message</li> <li>Allows more granular control over duplicate detection</li> <li>Useful when message content might be similar but logically distinct</li> </ol> <p>The deduplication process operates within a 5-minute interval, ensuring that duplicate messages are efficiently identified and eliminated. This approach guarantees that each unique message is processed exactly once, addressing a common challenge in distributed messaging systems.</p>"},{"location":"aws/messaging/sqs/#message-grouping","title":"Message Grouping","text":"<p>FIFO queues support message grouping through the Message Group ID: - Messages with the same Group ID are processed in order - Different Group IDs can have separate consumers - Enables parallel processing while maintaining local message sequence - Ordering is guaranteed within each group, but not across groups</p>"},{"location":"aws/messaging/sqs/#essential-sqs-apis","title":"Essential SQS APIs","text":"<p>Critical APIs include: - CreateQueue and DeleteQueue for queue management - PurgeQueue for complete message deletion - SendMessage and ReceiveMessage for message handling - ChangeMessageVisibility for timeout adjustments - Batch APIs for cost-efficient message processing</p>"},{"location":"aws/messaging/sqs/#extended-client-capabilities","title":"Extended Client Capabilities","text":"<p>For handling large messages exceeding the 256KB limit, the SQS Extended Client (Java Library) provides solutions for transmitting substantially larger payloads.</p>"},{"location":"aws/monitoring/cloudtrail/","title":"CloudTrail","text":""},{"location":"aws/monitoring/cloudtrail/#core-purpose","title":"Core Purpose","text":"<p>AWS CloudTrail serves as a critical governance, compliance, and auditing tool for AWS accounts. Enabled by default, it provides a comprehensive tracking mechanism for all activities within an AWS environment.</p> <p></p>"},{"location":"aws/monitoring/cloudtrail/#event-tracking-capabilities","title":"Event Tracking Capabilities","text":"<p>CloudTrail captures a detailed history of events and API calls across multiple interaction channels, including the AWS Console, SDKs, CLI, and various AWS services. This extensive tracking allows organizations to maintain a complete record of account-level interactions and resource modifications.</p>"},{"location":"aws/monitoring/cloudtrail/#event-types-and-logging","title":"Event Types and Logging","text":""},{"location":"aws/monitoring/cloudtrail/#management-events","title":"Management Events","text":"<p>Management events encompass operations performed on AWS resources, including critical activities such as: - Security configuration modifications - Data routing rule establishments - Logging setup processes</p> <p>These events are logged by default, with the ability to distinguish between read and write events. Read events represent non-modifying interactions, while write events capture potentially resource-altering actions.</p>"},{"location":"aws/monitoring/cloudtrail/#data-events","title":"Data Events","text":"<p>By default, data events are not logged due to their high-volume nature. However, organizations can enable specific data event tracking for services like Amazon S3 and AWS Lambda. S3 data events can track object-level activities such as GetObject, DeleteObject, and PutObject, with options to separate read and write events.</p>"},{"location":"aws/monitoring/cloudtrail/#cloudtrail-insights","title":"CloudTrail Insights","text":"<p>CloudTrail Insights provides advanced anomaly detection capabilities by: - Analyzing normal management event patterns - Continuously monitoring write events for unusual activities - Detecting potential issues like inaccurate resource provisioning - Identifying service limit breaches - Tracking sudden bursts of IAM actions - Recognizing gaps in periodic maintenance activities</p> <p>When anomalies are detected, they appear in the CloudTrail console, generate events in Amazon S3, and create EventBridge events for potential automation. It needs to be enabled and it\u2019s a paid service.</p>"},{"location":"aws/monitoring/cloudtrail/#event-storage-and-retention","title":"Event Storage and Retention","text":"<p>CloudTrail maintains event records for 90 days within its native storage. For long-term preservation, organizations can configure logging to Amazon S3 and utilize Amazon Athena for extended event analysis.</p>"},{"location":"aws/monitoring/cloudtrail/#practical-applications","title":"Practical Applications","text":"<p>CloudTrail is invaluable for forensic investigations, particularly when resources are unexpectedly deleted. By providing a comprehensive event trail, it enables detailed tracking and understanding of account-level activities.</p>"},{"location":"aws/monitoring/cloudtrail/#flexible-configuration","title":"Flexible Configuration","text":"<p>Users can configure trails to cover all AWS regions or focus on specific regional activities, providing flexible monitoring options tailored to organizational needs.</p>"},{"location":"aws/monitoring/cloudwatch/","title":"CloudWatch","text":""},{"location":"aws/monitoring/cloudwatch/#introduction-to-cloudwatch","title":"Introduction to CloudWatch","text":"<p>AWS CloudWatch serves as a comprehensive monitoring and observability service designed to provide insights into AWS resources and applications. The platform enables detailed tracking of performance metrics, log analysis, and proactive system management across the AWS ecosystem.</p>"},{"location":"aws/monitoring/cloudwatch/#metrics-and-monitoring","title":"Metrics and Monitoring","text":""},{"location":"aws/monitoring/cloudwatch/#metric-fundamentals","title":"Metric Fundamentals","text":"<p>CloudWatch tracks metrics as variables representing system performance and health. These metrics encompass various attributes such as CPU utilization, network traffic, and resource consumption. Each metric belongs to a specific namespace and can be associated with up to 30 dimensions, allowing granular performance tracking.</p>"},{"location":"aws/monitoring/cloudwatch/#ec2-monitoring-strategies","title":"EC2 Monitoring Strategies","text":"<p>For EC2 instances, CloudWatch offers standard monitoring at five-minute intervals and detailed monitoring at one-minute intervals. Detailed monitoring, available for an additional cost, provides more frequent data collection critical for rapid auto-scaling scenarios. While the AWS Free Tier supports ten detailed monitoring metrics, users should note that memory usage requires manual configuration as a custom metric.</p>"},{"location":"aws/monitoring/cloudwatch/#custom-metrics-and-advanced-tracking","title":"Custom Metrics and Advanced Tracking","text":""},{"location":"aws/monitoring/cloudwatch/#creating-custom-metrics","title":"Creating Custom Metrics","text":"<p>CloudWatch empowers users to define and send personalized metrics beyond standard AWS offerings. Developers can track specialized performance indicators like memory usage, disk space, or user authentication events using the PutMetricData API call. Custom metrics support flexible dimensioning and offer two resolution options: standard (1-minute) and high-resolution (1-30 seconds) with corresponding cost implications.</p>"},{"location":"aws/monitoring/cloudwatch/#log-management","title":"Log Management","text":""},{"location":"aws/monitoring/cloudwatch/#log-collection-and-processing","title":"Log Collection and Processing","text":"<p>CloudWatch Logs provides a robust platform for collecting, storing, and analyzing system and application logs. Users can define log groups representing applications and log streams representing specific instances or containers. The service supports comprehensive log management, including configurable retention policies and export capabilities to various AWS services like S3, Kinesis, and Lambda.</p>"},{"location":"aws/monitoring/cloudwatch/#log-insights-and-analysis","title":"Log Insights and Analysis","text":"<p>The CloudWatch Logs Insights feature enables advanced log analysis through a specialized query language. Users can search across multiple log groups, perform complex filtering, and extract specific event details. While not a real-time engine, Logs Insights facilitates deep log investigation and troubleshooting.</p>"},{"location":"aws/monitoring/cloudwatch/#monitoring-agents","title":"Monitoring Agents","text":""},{"location":"aws/monitoring/cloudwatch/#cloudwatch-agents","title":"CloudWatch Agents","text":"<p>AWS offers two primary agents for log and metric collection: the traditional CloudWatch Logs Agent and the more advanced CloudWatch Unified Agent. The Unified Agent provides comprehensive system-level metric collection, including CPU, disk, RAM, network, and process statistics, supporting both EC2 and on-premises environments.</p>"},{"location":"aws/monitoring/cloudwatch/#alarm-and-notification-system","title":"Alarm and Notification System","text":""},{"location":"aws/monitoring/cloudwatch/#cloudwatch-alarms","title":"CloudWatch Alarms","text":"<p>The alarm system allows users to define notification and response mechanisms based on specific metric thresholds. Alarms can trigger various actions such as stopping or recovering EC2 instances, initiating auto-scaling processes, or sending notifications through SNS. Composite alarms enable complex monitoring scenarios by evaluating multiple alarm states simultaneously.</p>"},{"location":"aws/monitoring/cloudwatch/#security-and-encryption","title":"Security and Encryption","text":""},{"location":"aws/monitoring/cloudwatch/#log-security","title":"Log Security","text":"<p>CloudWatch Logs are encrypted by default, with options for additional KMS-based encryption using custom keys. The service supports integration with various AWS security mechanisms, ensuring comprehensive data protection.</p>"},{"location":"aws/monitoring/cloudwatch/#use-cases-and-applications","title":"Use Cases and Applications","text":"<p>CloudWatch serves diverse monitoring needs across different domains: - Performance tracking for cloud infrastructure - Application health monitoring - Security and compliance tracking - Resource optimization - Automated system response and scaling</p>"},{"location":"aws/monitoring/cloudwatch/#best-practices","title":"Best Practices","text":"<p>Effective CloudWatch utilization involves: - Configuring appropriate metric resolutions - Implementing custom metrics for critical systems - Establishing comprehensive log retention policies - Creating intelligent alarm configurations - Regularly reviewing and optimizing monitoring strategies</p>"},{"location":"aws/monitoring/cloudwatch/#conclusion","title":"Conclusion","text":"<p>AWS CloudWatch represents a powerful, flexible monitoring solution that provides deep insights into AWS resources and applications. By offering comprehensive metrics, log management, and automated response capabilities, CloudWatch enables organizations to maintain robust, efficient cloud environments.</p>"},{"location":"aws/monitoring/eventbridge/","title":"EventBridge","text":""},{"location":"aws/monitoring/eventbridge/#core-functionality","title":"Core Functionality","text":"<p>Amazon EventBridge serves as a powerful serverless event bus that enables seamless integration and automation across AWS services and applications. It provides three primary mechanisms for event handling: scheduled jobs, event pattern matching, and cross-account event routing.</p>"},{"location":"aws/monitoring/eventbridge/#scheduling-and-event-patterns","title":"Scheduling and Event Patterns","text":"<p>EventBridge supports sophisticated scheduling through cron jobs, allowing precise timing of script executions. Beyond scheduling, it excels at event pattern recognition, enabling real-time reactions to service-level activities. Organizations can trigger diverse actions like invoking Lambda functions, dispatching messages to SQS or SNS, and orchestrating complex workflows based on specific event conditions.</p>"},{"location":"aws/monitoring/eventbridge/#advanced-event-management","title":"Advanced Event Management","text":""},{"location":"aws/monitoring/eventbridge/#event-bus-capabilities","title":"Event Bus Capabilities","text":"<p>Event buses in EventBridge offer remarkable flexibility. They can be configured with resource-based policies, permitting access from external AWS accounts. This feature enables centralized event aggregation and cross-account event sharing with granular permission controls.</p>"},{"location":"aws/monitoring/eventbridge/#event-archiving-and-replay","title":"Event Archiving and Replay","text":"<p>A standout feature of EventBridge is its comprehensive event archiving mechanism. Users can archive events comprehensively or apply sophisticated filtering, storing event data either indefinitely or for specified durations. The ability to replay archived events provides powerful debugging and recovery capabilities.</p>"},{"location":"aws/monitoring/eventbridge/#schema-registry-intelligent-event-understanding","title":"Schema Registry: Intelligent Event Understanding","text":"<p>EventBridge introduces an intelligent Schema Registry that automatically analyzes and infers schemas from events traversing the event bus. This capability allows applications to:</p> <ul> <li>Automatically generate code reflecting event structures</li> <li>Maintain versioned schema definitions</li> <li>Enhance predictability and type safety in event-driven architectures</li> </ul>"},{"location":"aws/monitoring/eventbridge/#resource-based-policy-management","title":"Resource-Based Policy Management","text":"<p>EventBridge\u2019s resource-based policies enable precise control over event bus permissions. Organizations can:</p> <ul> <li>Define granular access controls for specific event buses</li> <li>Manage cross-account and cross-region event interactions</li> <li>Implement complex event aggregation strategies</li> </ul> <p>By consolidating events from entire AWS Organizations into centralized accounts or regions, EventBridge simplifies complex event management and monitoring processes.</p>"},{"location":"aws/monitoring/xray/","title":"X-Ray","text":""},{"location":"aws/monitoring/xray/#introduction","title":"Introduction","text":"<p>AWS X-Ray provides robust troubleshooting capabilities for complex distributed systems. It enables developers to understand microservice architectures by tracing requests across different services, identifying performance bottlenecks, and pinpointing service issues.</p>"},{"location":"aws/monitoring/xray/#architecture","title":"Architecture","text":"<pre><code>Application \u2192 X-Ray SDK \u2192 X-Ray Daemon \u2192 X-Ray API\n    (2000/UDP)         (443/HTTPS)\n</code></pre>"},{"location":"aws/monitoring/xray/#compatibility-and-supported-platforms","title":"Compatibility and Supported Platforms","text":"<p>X-Ray integrates seamlessly with multiple AWS services and platforms, including: - AWS Lambda - Elastic Beanstalk - Amazon ECS - Elastic Load Balancers - API Gateway - EC2 Instances - On-premise application servers</p>"},{"location":"aws/monitoring/xray/#tracing-mechanism","title":"Tracing Mechanism","text":"<p>Tracing in X-Ray represents an end-to-end method of following a request through complex systems. Each component adds its own trace, composed of segments and subsegments. Developers can enhance traces with annotations to provide additional contextual information.</p>"},{"location":"aws/monitoring/xray/#tracing-strategies","title":"Tracing Strategies","text":"<p>X-Ray supports flexible tracing approaches: - Comprehensive tracing of every request - Sampling requests based on percentage or rate per minute</p>"},{"location":"aws/monitoring/xray/#security-features","title":"Security Features","text":"<p>The service implements robust security measures: - IAM for authorization - AWS KMS for encryption at rest</p>"},{"location":"aws/monitoring/xray/#enabling-x-ray","title":"Enabling X-Ray","text":"<p>Implementing X-Ray requires two primary steps:</p> <ol> <li>Code Instrumentation</li> <li>Import AWS X-Ray SDK in supported languages (Java, Python, Go, Node.js, .NET)</li> <li>Minimal code modification needed</li> <li> <p>Automatic capture of AWS service calls, HTTP/HTTPS requests, database interactions, and queue calls</p> </li> <li> <p>Daemon Configuration</p> </li> <li>Install X-Ray daemon or enable AWS integration</li> <li>Daemon functions as a low-level UDP packet interceptor</li> <li>AWS Lambda and other services automatically run the X-Ray daemon</li> </ol>"},{"location":"aws/monitoring/xray/#key-concepts","title":"Key Concepts","text":"<ul> <li>Segments: Performance data from each application/service</li> <li>Subsegments: Detailed breakdown of segments</li> <li>Traces: Collected segments forming end-to-end request tracking</li> <li>Sampling: Mechanism to reduce trace volume and control costs</li> <li>Annotations: Indexed key-value pairs for trace filtering</li> <li>Metadata: Non-indexed key-value pairs</li> </ul>"},{"location":"aws/monitoring/xray/#sampling-rules","title":"Sampling Rules","text":"<p>X-Ray provides sophisticated sampling control: - Default: First request per second, five percent of additional requests - Configurable rules without code changes - Reservoir ensures at least one trace per second - Customizable sampling rates and rules</p>"},{"location":"aws/monitoring/xray/#apis-and-integrations","title":"APIs and Integrations","text":"<p>X-Ray offers comprehensive APIs: - Write APIs for uploading trace segments - Read APIs for retrieving trace information - GetServiceGraph for generating service maps - BatchGetTraces for detailed trace retrieval</p>"},{"location":"aws/monitoring/xray/#platform-specific-implementation","title":"Platform-Specific Implementation","text":"<p>For platforms like Elastic Beanstalk: - X-Ray daemon included in platform - Configurable through console or configuration files - Requires proper IAM instance profile permissions</p>"},{"location":"aws/monitoring/xray/#cross-account-tracing","title":"Cross-Account Tracing","text":"<p>X-Ray supports cross-account tracing by: - Configuring daemon to send traces between accounts - Requiring correct IAM role assumptions - Enabling centralized application performance monitoring</p>"},{"location":"aws/monitoring/xray/#visualization-and-troubleshooting","title":"Visualization and Troubleshooting","text":"<p>X-Ray generates graphical service maps that transform complex trace data into intuitive visualizations, making performance analysis accessible to both technical and non-technical team members.</p>"},{"location":"aws/network/cloudfront/","title":"CloudFront","text":""},{"location":"aws/network/cloudfront/#service-definition","title":"Service Definition","text":"<p>AWS CloudFront is a Content Delivery Network (CDN) service that dramatically improves content delivery performance. With 216 global points of presence (edge locations), it offers enhanced read performance by caching content strategically worldwide.</p>"},{"location":"aws/network/cloudfront/#key-security-and-performance-features","title":"Key Security and Performance Features","text":"<p>CloudFront provides robust DDoS protection through integration with AWS Shield and Web Application Firewall. Its global infrastructure ensures content is cached close to end-users, significantly improving access speeds and user experience.</p>"},{"location":"aws/network/cloudfront/#origin-types","title":"Origin Types","text":"<p>CloudFront supports multiple origin types for content delivery:</p> <ol> <li>Enables file distribution and edge caching them. </li> <li>Implements enhanced security through Origin Access Control (OAC), guaranteeing that only Cloudfront can access them. </li> <li> <p>Can be used as an ingress point for S3 uploads</p> </li> <li> </li> <li>Supports HTTP-based origins including:</li> <li>Application Load Balancers</li> <li>EC2 instances</li> <li>Static S3 websites</li> <li>Any HTTP backend system</li> </ol>"},{"location":"aws/network/cloudfront/#s3-bucket-origins","title":"S3 Bucket Origins","text":""},{"location":"aws/network/cloudfront/#custom-origins-http","title":"Custom Origins (HTTP)","text":""},{"location":"aws/network/cloudfront/#cloudfront-vs-s3-cross-region-replication","title":"CloudFront vs S3 Cross Region Replication","text":"<ul> <li>CloudFront:</li> <li>Global Edge network</li> <li>Files are cached for a TTL (maybe a day)</li> <li>Great for static content that must be available everywhere</li> <li>S3 Cross Region Replication:</li> <li>Must be setup for each region you want replication to happen</li> <li>Files are updated in near real-time</li> <li>Read only</li> <li>Great for dynamic content that needs to be available at low-latency in few regions</li> </ul>"},{"location":"aws/network/cloudfront/#caching","title":"Caching","text":"<ul> <li>The cache lives at each CloudFront Edge Location</li> <li>CloudFront identifies each object in the cache using the Cache Key</li> <li>To maximize the Cache Hit ratio you need to minimize requests to the origin</li> <li>It\u2019s possible to invalidate part of the cache using the <code>CreateInvalidation</code> API</li> </ul>"},{"location":"aws/network/cloudfront/#cache-key","title":"Cache Key","text":"<p>The cache key is a unique identifier for each cached object, typically comprising the hostname and URL\u2019s resource portion. CloudFront allows sophisticated cache key customization by incorporating: - HTTP headers - Cookies - Query strings - Device information - User location</p>"},{"location":"aws/network/cloudfront/#cache-policies","title":"Cache Policies","text":"<p>CloudFront offers extensive cache policy configurations:</p> <ul> <li>HTTP Headers</li> <li>None: Excludes headers from cache key</li> <li> <p>Whitelist: Includes specific headers in cache key</p> </li> <li> <p>Cookies</p> </li> <li>None: Excludes cookie from cache key</li> <li>Whitelist: Includes specific cookie</li> <li>Include All-Except: Includes all cookie except specified ones</li> <li> <p>All: Includes all cookie (lowest caching performance)</p> </li> <li> <p>Query Strings</p> </li> <li>None: Excludes query strings from cache key</li> <li>Whitelist: Includes specific query strings</li> <li>Include All-Except: Includes all query strings except specified ones</li> <li>All: Includes all query strings (lowest caching performance)</li> </ul> <p>It\u2019s possible to control the TTL (0 seconds to 1 year), can be set by the origin using the <code>Cache-Control</code> header, <code>Expires</code> header or others.</p> <p>All HTTP headers, cookies, and query strings that you include in the Cache Key are automatically included in origin requests.</p>"},{"location":"aws/network/cloudfront/#origin-request-policy","title":"Origin Request Policy","text":"<p>Enables including values in origin requests without duplicating cached content, supporting: - HTTP headers configuration - Cookie management - Query string handling - Custom header addition It\u2019s possible to create custom ORP or use Predefined Managed Policies.</p>"},{"location":"aws/network/cloudfront/#cache-invalidation","title":"Cache Invalidation","text":"<p>When backend origins update, CloudFront allows forced cache refresh through: - Full cache invalidation - Partial path invalidation (e.g., /images/*)</p>"},{"location":"aws/network/cloudfront/#cache-behaviors","title":"Cache Behaviors","text":"<p>Configures distinct settings for specific URL path patterns, enabling: - Different origin routing based on content type - Customized caching for specific file types - Prioritized processing of cache behaviors</p>"},{"location":"aws/network/cloudfront/#geographical-restrictions","title":"Geographical Restrictions","text":"<p>Implements content access control based on the region users are trying to access through: - Allowlist: Permit access from specific countries - Blocklist: Prevent access from specified countries - Uses third-party Geo-IP database for determination</p>"},{"location":"aws/network/cloudfront/#cloudfront-signed-url-signed-cookies","title":"CloudFront Signed URL / Signed Cookies","text":"<p>IN case you want to distribute paid shared content to premium users over the world, Cloudfront provides secure content distribution mechanisms: - URL/cookie expiration control - IP range access restrictions - Trusted signer management - Supports individual file (Signed URL) and multiple file (Signed Cookies) access</p>"},{"location":"aws/network/cloudfront/#field-level-encryption","title":"Field-Level Encryption","text":"<p>Offers additional security layer using HTTPS by: - Encrypting sensitive information at edge locations - Supporting up to 10 encrypted fields in POST requests - Utilizing asymmetric encryption</p>"},{"location":"aws/network/cloudfront/#real-time-logging","title":"Real-Time Logging","text":"<p>Streams CloudFront requests to Kinesis Data Streams, enabling: - Real-time performance monitoring - Configurable sampling rates - Selective field and path pattern tracking</p>"},{"location":"aws/network/cloudfront/#origin-groups","title":"Origin Groups","text":"<p>Enhances availability through: - Primary and secondary origin configuration - Automatic failover mechanisms</p>"},{"location":"aws/network/cloudfront/#conclusion","title":"Conclusion","text":"<p>AWS CloudFront provides a comprehensive, flexible content delivery solution with robust security, performance optimization, and global reach.</p>"},{"location":"aws/network/elb/","title":"Elastic Load Balancer","text":""},{"location":"aws/network/elb/#introduction-to-elastic-load-balancer","title":"Introduction to Elastic Load Balancer","text":"<p>An Elastic Load Balancer (ELB) is AWS\u2019s managed load balancing solution that provides guaranteed operational reliability through AWS\u2019s maintenance, upgrades, and high availability management. While setting up a custom load balancer might be more cost-effective initially, ELB offers significant advantages through its deep integration with AWS services including EC2, EC2 Auto Scaling Groups, Amazon ECS, AWS Certificate Manager (ACM), CloudWatch, Route 53, AWS WAF, and AWS Global Accelerator.</p>"},{"location":"aws/network/elb/#health-check-mechanisms","title":"Health Check Mechanisms","text":"<p>Health checks are fundamental to load balancer operations, enabling the service to verify the availability of instances receiving traffic. These checks typically monitor a specific port and route (commonly /health), with instances being marked as unhealthy if they fail to return a 200 (OK) response.</p>"},{"location":"aws/network/elb/#load-balancer-types","title":"Load Balancer Types","text":"<p>AWS offers four distinct managed load balancer types, each designed for specific use cases:</p>"},{"location":"aws/network/elb/#classic-load-balancer-clb-2009","title":"Classic Load Balancer (CLB - 2009)","text":"<p>The first-generation load balancer supports HTTP, HTTPS, TCP, and SSL protocols. It provides TCP (Layer 4) and HTTP/HTTPS (Layer 7) load balancing with TCP or HTTP-based health checks. CLBs are assigned a fixed hostname in the format XXX.region.elb.amazonaws.com.</p>"},{"location":"aws/network/elb/#application-load-balancer-alb-2016","title":"Application Load Balancer (ALB - 2016)","text":"<p>Operating at Layer 7, ALB specializes in HTTP-based traffic management with support for HTTP/2 and WebSocket. It enables sophisticated routing to multiple applications through target groups, supporting path-based routing (/users, /posts), hostname-based routing (one.example.com, other.example.com), and query string/header-based routing (example.com/users?id=123&amp;order=false).</p> <p>ALB is particularly well-suited for microservices and container-based applications, offering dynamic port mapping for ECS. This represents a significant advantage over Classic Load Balancers, which would require multiple instances for similar functionality.</p> <p>ALB Target Groups can include:</p> <ul> <li>EC2 instances managed by Auto Scaling Groups (HTTP)</li> <li>ECS tasks (HTTP)</li> <li>Lambda functions (HTTP requests are converted to JSON events)</li> <li>Private IP addresses</li> </ul> <p>Additional ALB features include:</p> <ul> <li>Fixed hostname (XXX.region.elb.amazonaws.com)</li> <li>Client IP preservation through X-Forwarded-For header</li> <li>Port and protocol information through X-Forwarded-Port and X-Forwarded-Proto headers</li> </ul>"},{"location":"aws/network/elb/#network-load-balancer-nlb-2017","title":"Network Load Balancer (NLB - 2017)","text":"<p>NLB operates at Layer 4, handling TCP, TLS, and UDP traffic. It excels in high-performance scenarios, processing millions of requests per second with ultra-low latency. NLB provides static IP addresses per Availability Zone and supports Elastic IP assignment, making it ideal for IP whitelisting scenarios. Note that NLB is not included in the AWS free tier.</p> <p>NLB Target Groups can include:</p> <ul> <li>EC2 instances</li> <li>Private IP addresses</li> <li>Application Load Balancers</li> </ul> <p>Health checks support TCP, HTTP, and HTTPS protocols.</p>"},{"location":"aws/network/elb/#gateway-load-balancer-gwlb-2020","title":"Gateway Load Balancer (GWLB - 2020)","text":"<p>GWLB operates at Layer 3 (Network layer) using the GENEVE protocol on port 6081. It\u2019s designed for managing third-party network virtual appliances such as firewalls, intrusion detection systems, and deep packet inspection systems. GWLB combines transparent network gateway functionality with load balancing capabilities.</p> <p>GWLB Target Groups support:</p> <ul> <li>EC2 instances</li> <li>Private IP addresses</li> </ul>"},{"location":"aws/network/elb/#advanced-load-balancer-features","title":"Advanced Load Balancer Features","text":""},{"location":"aws/network/elb/#sticky-sessions","title":"Sticky Sessions","text":"<p>Sticky sessions (session affinity) ensure that clients are consistently directed to the same backend instance. This feature is available across all load balancer types, with cookie-based stickiness control for CLB and ALB. While useful for session maintenance, sticky sessions may create uneven load distribution.</p> <p>Cookie types and naming conventions include:</p> <ol> <li> <p>Application-based Cookies:</p> </li> <li> <p>Custom cookie:</p> <ul> <li>Generated by the target</li> <li>Can include any custom attributes required by the application</li> <li>Cookie name must be specified individually for each target group</li> <li>Must avoid reserved names: AWSALB, AWSALBAPP, or AWSALBTG (reserved for ELB use)</li> </ul> </li> <li> <p>Application cookie:</p> <ul> <li>Generated by the load balancer</li> <li>Uses the cookie name AWSALBAPP</li> </ul> </li> <li> <p>Duration-based Cookies:</p> </li> <li> <p>Generated by the load balancer</p> </li> <li>Uses specific names depending on the load balancer type:<ul> <li>AWSALB for Application Load Balancer</li> <li>AWSELB for Classic Load Balancer</li> </ul> </li> </ol>"},{"location":"aws/network/elb/#cross-zone-load-balancing","title":"Cross-Zone Load Balancing","text":"<p>Cross-zone load balancing enables even distribution of traffic across all registered instances in all Availability Zones.  </p> <p>Without cross-zone load balancing, requests are distributed only to instances within the load balancer node\u2019s Availability Zone.  </p> <p>The feature\u2019s default state and associated costs vary by load balancer type:</p> <ul> <li>ALB: Enabled by default, no inter-AZ charges</li> <li>NLB and GWLB: Disabled by default, inter-AZ charges apply when enabled</li> <li>CLB: Disabled by default, no inter-AZ charges when enabled</li> </ul>"},{"location":"aws/network/elb/#ssltls-certification","title":"SSL/TLS Certification","text":"<p>Load balancers support SSL/TLS certificates for in-transit encryption, managed through AWS Certificate Manager (ACM) or manual upload. SSL certificates are issued by Certificate Authorities (CA) such as Comodo, Symantec, GoDaddy, GlobalSign, Digicert, and Letsencrypt. Certificates follow the X.509 standard and must be renewed before expiration.</p> <p>HTTPS listeners require:</p> <ul> <li>A default certificate</li> <li>Optional additional certificates for multiple domains</li> <li>A security policy to support older versions of SSL/TLS for legacy clients</li> </ul> <p>Server Name Indication (SNI) allows loading multiple SSL certificates onto one web server. This newer protocol requires clients to specify the target hostname during the initial SSL handshake. SNI is supported by ALB, NLB, and CloudFront, but not by CLB.</p> <p>SSL Certificate support by load balancer type:</p> <ul> <li>CLB: Supports only one SSL certificate</li> <li>ALB and NLB: Support multiple listeners with multiple SSL certificates using SNI</li> </ul>"},{"location":"aws/network/elb/#connection-draining","title":"Connection Draining","text":"<p>Connection draining (known as Deregistration Delay for ALB and NLB) allows in-flight requests to complete while an instance is being de-registered or marked unhealthy. This feature can be configured from 1 to 3600 seconds (default 300) or disabled completely. It\u2019s recommended to use shorter values for applications with quick request processing times.</p>"},{"location":"aws/network/elb/#security-considerations","title":"Security Considerations","text":"<p>Load balancer security groups play a crucial role in controlling traffic flow. They should be configured to allow only necessary incoming traffic to the load balancer while permitting all outbound traffic to instance security groups. Instance security groups should be configured to accept traffic only from the load balancer\u2019s security group, creating a secure chain of trust.</p>"},{"location":"aws/network/route53/","title":"Route 53","text":""},{"location":"aws/network/route53/#introduction-to-dns-and-route-53","title":"Introduction to DNS and Route 53","text":"<p>Domain Name System (DNS) serves as the backbone of the Internet, functioning as a crucial translation mechanism that converts human-readable hostnames into machine-readable IP addresses. For instance, when you type www.google.com into your browser, DNS translates this into an IP address like 172.217.18.36.</p> <p></p> <p>The DNS hierarchical naming structure includes:</p> <ul> <li>.com</li> <li>example.com</li> <li>www.example.com</li> <li>api.example.com</li> </ul> <p>Essential DNS terminology includes:</p> <ul> <li>Domain Registrar: Services like Amazon Route 53, GoDaddy</li> <li>DNS Records: A, AAAA, CNAME, NS, and others</li> <li>Zone File: Contains DNS records</li> <li>Name Server: Resolves DNS queries (Authoritative or Non-Authoritative)</li> <li>Top Level Domain (TLD): .com, .us, .in, .gov, .org</li> <li>Second Level Domain (SLD): amazon.com, google.com</li> </ul>"},{"location":"aws/network/route53/#understanding-route-53","title":"Understanding Route 53","text":"<p>Amazon Route 53 is AWS\u2019s premier DNS service, characterized by:</p> <ul> <li>Highly available, scalable, and fully managed Authoritative DNS</li> <li>Authoritative nature allowing customers to update DNS records</li> <li>Domain Registrar capabilities</li> <li>Resource health checking functionality</li> <li>The only AWS service with 100% availability SLA</li> <li>Name reference to the traditional DNS port (53)</li> </ul>"},{"location":"aws/network/route53/#dns-records-in-route-53","title":"DNS Records in Route 53","text":"<p>Records define how traffic is routed for a domain. Each record contains:</p> <ul> <li>Domain/subdomain Name (e.g., example.com)</li> <li>Record Type (e.g., A or AAAA)</li> <li>Value (e.g., 12.34.56.78)</li> <li>Routing Policy</li> <li>TTL (Time to Live)</li> </ul> <p>Supported DNS record types:</p> <ul> <li>Must-know types: A, AAAA, CNAME, NS</li> <li>Advanced types: CAA, DS, MX, NAPTR, PTR, SOA, TXT, SPF, SRV</li> </ul> <p>Record Types in detail:</p> <ul> <li>A \u2013 maps a hostname to IPv4</li> <li>AAAA \u2013 maps a hostname to IPv6</li> <li>CNAME \u2013 maps a hostname to another hostname (cannot be used for zone apex)</li> <li>NS \u2013 Name Servers for the Hosted Zone</li> </ul>"},{"location":"aws/network/route53/#hosted-zones","title":"Hosted Zones","text":"<p>Route 53 uses hosted zones as containers for records, costing $0.50 per month per hosted zone. Types include: - Public Hosted Zones: For Internet traffic routing (e.g., application1.mypublicdomain.com) - Private Hosted Zones: For VPC traffic routing (e.g., application1.company.internal)</p> <p></p>"},{"location":"aws/network/route53/#ttl-considerations","title":"TTL Considerations","text":"<p>High TTL (e.g., 24 hr):</p> <ul> <li>Reduces Route 53 traffic</li> <li>May result in outdated records</li> </ul> <p>Low TTL (e.g., 60 sec):</p> <ul> <li>Increases Route 53 traffic (higher cost)</li> <li>Records outdated for less time</li> <li>Facilitates easier record changes</li> </ul> <p>TTL is mandatory for all DNS records except Alias records.</p>"},{"location":"aws/network/route53/#cname-versus-alias-records","title":"CNAME versus Alias Records","text":"<p>For AWS Resources (Load Balancer, CloudFront) with AWS hostnames:</p> <p>CNAME:</p> <ul> <li>Points hostname to any other hostname</li> <li>Only for non-root domain</li> <li>Cannot be used for zone apex</li> </ul> <p>Alias:</p> <ul> <li>Points hostname to AWS Resource</li> <li>Works for both root and non-root domains</li> <li>Free of charge</li> <li>Includes native health check</li> <li>Always type A/AAAA for AWS resources</li> <li>No TTL setting required</li> </ul> <p>Supported Alias Record Targets:</p> <ul> <li>Elastic Load Balancers</li> <li>CloudFront Distributions</li> <li>API Gateway</li> <li>Elastic Beanstalk environments</li> <li>S3 Websites</li> <li>VPC Interface Endpoints</li> <li>Global Accelerator</li> <li>Route 53 record in the same hosted zone</li> <li>Cannot target EC2 DNS names</li> </ul>"},{"location":"aws/network/route53/#routing-policies","title":"Routing Policies","text":"<p>Route 53 routing policies define DNS query responses, distinct from load balancer routing. Available policies include:</p> <ul> <li>Simple</li> <li>Weighted</li> <li>Failover</li> <li>Latency based</li> <li>Geolocation</li> <li>Multi-Value Answer</li> <li>Geoproximity (using Route 53 Traffic Flow)</li> </ul>"},{"location":"aws/network/route53/#simple-routing","title":"Simple Routing","text":"<ul> <li>Routes traffic to a single resource</li> <li>Supports multiple values in one record</li> <li>Random value selection by client</li> <li>Single AWS resource when Alias enabled</li> <li>No Health Check association</li> </ul>"},{"location":"aws/network/route53/#weighted-routing","title":"Weighted Routing","text":"<ul> <li>Controls request percentage per resource</li> <li>Uses relative weight calculation: traffic % = (Weight for a specific record)/(Sum of all weights for all records)</li> <li>Weights don\u2019t need to sum to 100</li> <li>Requires same name and type for DNS records</li> <li>Supports Health Checks</li> <li>Useful for regional load balancing and application version testing</li> <li>Zero weight stops traffic to a resource</li> </ul>"},{"location":"aws/network/route53/#latency-based-routing","title":"Latency-based Routing","text":"<ul> <li>Directs to lowest-latency resource</li> <li>Based on AWS Region-user latency</li> <li>Supports Health Checks with failover</li> <li>May direct users to unexpected regions based on latency</li> </ul>"},{"location":"aws/network/route53/#health-checks","title":"Health Checks","text":"<p>Health Check types:</p> <ol> <li>Endpoint monitoring</li> <li>Calculated Health Checks (monitoring other health checks)</li> <li>CloudWatch Alarm monitoring</li> </ol> <p>Endpoint Monitoring Details:</p> <ul> <li>15 global health checkers</li> <li>Default threshold: 3 (Healthy/Unhealthy)</li> <li>30-second interval (10-second option available)</li> <li>Supports HTTP, HTTPS, TCP</li> <li>18% healthy checker threshold</li> <li>Response must be 2xx or 3xx</li> <li>First 5120 bytes can determine pass/fail</li> <li>Requires firewall configuration for checker access</li> </ul> <p>Calculated Health Checks:</p> <ul> <li>Combines multiple check results</li> <li>Supports OR, AND, NOT operations</li> <li>Up to 256 Child Health Checks</li> <li>Customizable pass threshold</li> <li>Useful for maintenance windows</li> </ul> <p>Private Hosted Zone Health Checks:</p> <ul> <li>Checkers cannot access private endpoints</li> <li>Requires CloudWatch Metric and Alarm integration</li> </ul>"},{"location":"aws/network/route53/#routing-policies-continued","title":"Routing Policies (Continued)","text":""},{"location":"aws/network/route53/#geolocation","title":"Geolocation","text":"<ul> <li>Location-based (not latency-based)</li> <li>Supports Continent, Country, US State targeting</li> <li>Requires default record</li> <li>Ideal for content localization</li> <li>Supports Health Checks</li> </ul>"},{"location":"aws/network/route53/#geoproximity","title":"Geoproximity","text":"<ul> <li>Based on resource and user locations</li> <li>Adjustable bias values (-99 to +99)</li> <li>Supports AWS and non-AWS resources</li> <li>Requires Route 53 Traffic Flow</li> </ul>"},{"location":"aws/network/route53/#ip-based-routing","title":"IP-based Routing","text":"<ul> <li>Routes based on client IP addresses</li> <li>Requires CIDR list and endpoint mappings</li> <li>Optimizes performance and costs</li> </ul>"},{"location":"aws/network/route53/#multi-value","title":"Multi-Value","text":"<ul> <li>Routes to multiple resources</li> <li>Returns up to 8 healthy records</li> <li>Supports Health Checks</li> <li>Not a load balancer replacement</li> </ul>"},{"location":"aws/network/route53/#domain-registration-and-dns-service","title":"Domain Registration and DNS Service","text":"<p>Domain registration and DNS service can be separated:</p> <ul> <li>Annual domain registration with registrars</li> <li>DNS service choice is independent</li> <li>Route 53 can manage DNS for third-party registered domains</li> </ul> <p>Third-party domain integration steps:</p> <ol> <li>Create Route 53 Hosted Zone</li> <li>Update NS Records on third-party site</li> <li>Use Route 53\u2019s name servers</li> </ol>"},{"location":"aws/network/route53/#traffic-flow","title":"Traffic Flow","text":"<p>Traffic flow features:</p> <ul> <li>Visual editor for complex configurations</li> <li>Saveable Traffic Flow Policies</li> <li>Cross-zone policy application</li> <li>Version control support</li> </ul>"},{"location":"aws/network/vpc/","title":"Virtual Private Cloud (VPC)","text":""},{"location":"aws/network/vpc/#overview","title":"Overview","text":"<p>Amazon Virtual Private Cloud (VPC) represents a fundamental networking service in AWS that enables you to create isolated private networks for your cloud resources. This comprehensive guide covers essential VPC concepts crucial for AWS certifications, particularly the Solutions Architect Associate and SysOps Administrator certifications.</p>"},{"location":"aws/network/vpc/#core-components","title":"Core Components","text":""},{"location":"aws/network/vpc/#vpc-and-subnet-architecture","title":"VPC and Subnet Architecture","text":"<p>A VPC functions as a private network infrastructure within AWS, operating as a regional resource. Within each VPC, subnets serve as network partitions that operate at the Availability Zone level. These subnets can be categorized as either public or private, with public subnets having internet accessibility and private subnets remaining isolated from direct internet access. Route Tables govern the traffic flow between subnets and determine internet access permissions.</p>"},{"location":"aws/network/vpc/#internet-connectivity","title":"Internet Connectivity","text":"<p>Internet Gateways serve as the primary component enabling VPC resources to connect to the internet. Public subnets maintain direct routes to the Internet Gateway, facilitating outbound and inbound internet communication. For private subnets, NAT (Network Address Translation) Gateways, managed by AWS, or NAT Instances, managed by users, enable outbound internet access while maintaining the subnet\u2019s private nature.</p>"},{"location":"aws/network/vpc/#security-components","title":"Security Components","text":""},{"location":"aws/network/vpc/#network-access-control-lists-nacls","title":"Network Access Control Lists (NACLs)","text":""},{"location":"aws/network/vpc/#what-are-nacls","title":"What are NACLs?","text":"<ul> <li>Stateless firewalls that operate at the subnet level within a VPC.</li> <li>Used to control traffic entering and leaving subnets.</li> </ul>"},{"location":"aws/network/vpc/#key-characteristics","title":"Key Characteristics:","text":"<ol> <li>Subnet-Level: NACLs apply to all resources within the associated subnet(s).</li> <li>Stateless:</li> <li>Both inbound and outbound rules must be defined explicitly. Return traffic is not automatically allowed.</li> <li>Explicit Rules for Allow and Deny:</li> <li>Unlike Security Groups, NACLs support both <code>allow</code> and <code>deny</code> rules.</li> <li>Rules are Evaluated in Order:</li> <li>Each rule is evaluated in numerical order, starting from the lowest rule number.</li> <li>Traffic is allowed or denied based on the first matching rule.</li> <li>Default Behavior:</li> <li>Default NACL allows all inbound and outbound traffic.</li> <li>Custom NACLs deny all traffic unless rules are explicitly added.</li> </ol>"},{"location":"aws/network/vpc/#common-use-cases","title":"Common Use Cases:","text":"<ul> <li>Apply coarse-grained security controls at the subnet level.</li> <li>Use as an additional layer of security alongside Security Groups.</li> <li>Block specific IP addresses or ranges.</li> </ul>"},{"location":"aws/network/vpc/#example-rules","title":"Example Rules:","text":"Rule # Type Protocol Port Range Source Allow/Deny 100 HTTP TCP 80 0.0.0.0/0 Allow 200 SSH TCP 22 203.0.113.0/24 Allow 300 All Traffic All All 0.0.0.0/0 Deny"},{"location":"aws/network/vpc/#security-groups","title":"Security Groups","text":""},{"location":"aws/network/vpc/#what-are-security-groups","title":"What are Security Groups?","text":"<ul> <li>Stateful firewalls that operate at the instance level.</li> <li>Act as virtual firewalls to control inbound and outbound traffic to and from Amazon EC2 instances.</li> <li>Rules can allow or deny traffic based on IP ranges, protocols, and ports.</li> </ul>"},{"location":"aws/network/vpc/#key-characteristics_1","title":"Key Characteristics:","text":"<ol> <li>Instance-Level: Security Groups are attached directly to EC2 instances.</li> <li>Stateful:</li> <li>If you allow inbound traffic, the corresponding outbound traffic is automatically allowed, and vice versa.</li> <li>Implicit Deny:</li> <li>By default, all inbound traffic is denied, and all outbound traffic is allowed unless explicitly specified otherwise.</li> <li>Rule-Based Configuration:</li> <li>You define rules to allow traffic. Deny rules cannot be explicitly created.</li> <li>Supports Allow Only: </li> <li>Rules define what traffic is permitted, with no option to explicitly block traffic.</li> <li>Dynamic Updates:</li> <li>Modifications to a Security Group are automatically applied to all associated resources.</li> </ol>"},{"location":"aws/network/vpc/#common-use-cases_1","title":"Common Use Cases:","text":"<ul> <li>Control access to EC2 instances based on port (e.g., 22 for SSH, 80/443 for HTTP/HTTPS).</li> <li>Restrict traffic to specific IP ranges or other resources within the same VPC.</li> </ul>"},{"location":"aws/network/vpc/#example-rules_1","title":"Example Rules:","text":"Type Protocol Port Range Source SSH TCP 22 198.51.100.1/32 HTTP TCP 80 0.0.0.0/0 HTTPS TCP 443 0.0.0.0/0"},{"location":"aws/network/vpc/#comparison-between-security-groups-and-nacls","title":"Comparison Between Security Groups and NACLs","text":"Aspect Security Groups NACLs Level of Operation Instance Level Subnet Level Statefulness Stateful Stateless Allow/Deny Rules Allow only Allow and Deny Evaluation of Rules All rules evaluated equally Rules evaluated in order Direction of Traffic Separate inbound and outbound Separate inbound and outbound Default Behavior Inbound: Deny, Outbound: Allow Inbound &amp; Outbound: Allow all (default NACL)"},{"location":"aws/network/vpc/#vpc-flow-logs","title":"VPC Flow Logs","text":"<p>VPC Flow Logs capture detailed information about IP traffic traversing network interfaces within your VPC. This monitoring capability extends to various levels including VPC-wide, subnet-specific, and individual network interfaces. The logs prove invaluable for troubleshooting connectivity issues between subnets, internet communication, and internal network traffic. The service also monitors AWS-managed interfaces for services like Elastic Load Balancers, ElastiCache, RDS, and Aurora. Flow log data can be directed to multiple destinations including Amazon S3, CloudWatch Logs, and Kinesis Data Firehose.</p>"},{"location":"aws/network/vpc/#vpc-peering","title":"VPC Peering","text":"<p>VPC Peering enables private connectivity between two VPCs using AWS\u2019s internal network infrastructure. This connection allows VPCs to interact as if they existed within the same network, though they must maintain non-overlapping CIDR ranges. Importantly, peering connections are not transitive, requiring explicit establishment between each pair of VPCs that need to communicate.</p>"},{"location":"aws/network/vpc/#vpc-endpoints","title":"VPC Endpoints","text":"<p>VPC Endpoints provide private access to AWS services without requiring internet connectivity. This approach enhances security and reduces latency when accessing AWS services. Two types of endpoints exist: - Gateway Endpoints, specifically designed for Amazon S3 and DynamoDB - Interface Endpoints, supporting all other compatible AWS services</p>"},{"location":"aws/network/vpc/#hybrid-connectivity","title":"Hybrid Connectivity","text":""},{"location":"aws/network/vpc/#site-to-site-vpn","title":"Site-to-Site VPN","text":"<p>This service enables secure connections between on-premises networks and AWS using encrypted tunnels over the public internet. It provides a relatively quick way to establish hybrid connectivity.</p>"},{"location":"aws/network/vpc/#aws-direct-connect","title":"AWS Direct Connect","text":"<p>Direct Connect establishes dedicated physical connections between on-premises facilities and AWS. While requiring longer setup times (typically a month or more), it offers private, secure, and high-performance connectivity through a private network infrastructure.</p>"},{"location":"aws/network/vpc/#certification-focus","title":"Certification Focus","text":"<p>For the AWS Certified Developer examination, candidates should focus on understanding: - VPC and subnet fundamentals - Internet and NAT Gateway functionality - Security Groups and NACLs - VPC Peering and Endpoints - Hybrid connectivity options including Site-to-Site VPN and Direct Connect</p> <p>Throughout the certification preparation, various scenarios will highlight the practical applications of these VPC concepts in real-world architectures.</p>"},{"location":"aws/network/vpc/#best-practices","title":"Best Practices","text":"<p>When implementing VPC architecture, consider: - Proper CIDR range planning to avoid overlapping IP addresses - Implementation of both public and private subnets for appropriate resource isolation - Effective use of security groups and NACLs for defense in depth - Regular monitoring of VPC Flow Logs for security and troubleshooting - Strategic placement of VPC endpoints to optimize AWS service access</p>"},{"location":"aws/security/cognito/","title":"Cognito","text":""},{"location":"aws/security/cognito/#introduction","title":"Introduction","text":"<p>Amazon Cognito is a service that enables user identity and access management for web and mobile applications. It provides two main components: Cognito User Pools (CUP) and Cognito Identity Pools (Federated Identities), each serving distinct purposes in the authentication and authorization workflow.</p>"},{"location":"aws/security/cognito/#cognito-user-pools-cup","title":"Cognito User Pools (CUP)","text":""},{"location":"aws/security/cognito/#overview","title":"Overview","text":"<p>Cognito User Pools provide a serverless database solution for managing user identities in web and mobile applications. As the primary authentication mechanism, CUP handles user sign-up, sign-in, and integrates seamlessly with various identity providers to create a comprehensive identity management system.</p>"},{"location":"aws/security/cognito/#core-features","title":"Core Features","text":"<p>The User Authentication system in Cognito User Pools offers a comprehensive set of features for secure user management. Users can sign in using either username or email combined with their password. The system includes built-in password reset functionality and supports both email and phone number verification to ensure user authenticity. Multi-factor authentication (MFA) adds an additional layer of security, while federated identity support enables integration with providers such as Facebook, Google, and SAML. The system actively protects against compromised credentials and issues JSON Web Tokens (JWT) upon successful authentication.</p>"},{"location":"aws/security/cognito/#lambda-triggers-integration","title":"Lambda Triggers Integration","text":"<p>Cognito User Pools can invoke Lambda functions at various stages of the authentication process. During authentication events, pre-authentication triggers enable custom validation of sign-in requests, while post-authentication triggers facilitate event logging for analytics purposes. The pre-token generation phase allows for token claim modification.</p> <p>For sign-up operations, the system provides pre-sign-up validation capabilities, post-confirmation processing for welcome messages, and user migration support from existing directories. Additional customization options include message personalization and token attribute modification through pre-token generation triggers.</p>"},{"location":"aws/security/cognito/#hosted-authentication-ui","title":"Hosted Authentication UI","text":"<p>Cognito provides a hosted authentication interface that includes pre-built sign-up and sign-in workflows. This UI seamlessly integrates with social logins, OIDC, and SAML providers. Organizations can customize the interface with their own logos and CSS styles. Custom domain support is available, though it requires an ACM certificate in the us-east-1 region.</p>"},{"location":"aws/security/cognito/#adaptive-authentication","title":"Adaptive Authentication","text":"<p>The adaptive authentication system provides sophisticated security measures by analyzing login attempts and assigning risk scores (low, medium, high) based on various factors. The system monitors device usage, location patterns, and IP addresses to detect suspicious activities. It includes protection against compromised credentials and account takeover attempts. For monitoring and analysis, the system integrates with CloudWatch Logs to track sign-in attempts, risk scores, and authentication challenges.</p>"},{"location":"aws/security/cognito/#jwt-token-structure","title":"JWT Token Structure","text":"<p>The JSON Web Token issued by Cognito consists of three main components: a header, payload, and signature. The payload contains essential user information, including the user UUID (sub), given name, email, phone number, and any additional custom attributes. The signature verification ensures the token\u2019s authenticity and trustworthiness.</p>"},{"location":"aws/security/cognito/#application-load-balancer-integration","title":"Application Load Balancer Integration","text":""},{"location":"aws/security/cognito/#authentication-capabilities","title":"Authentication Capabilities","text":"<p>The Application Load Balancer can handle user authentication, removing this burden from application servers. It supports various identity providers that are OIDC compliant and integrates directly with Cognito User Pools. Authentication rules require HTTPS listeners, and administrators can configure how the system handles unauthenticated requests through authenticate, deny, or allow options.</p>"},{"location":"aws/security/cognito/#implementation-requirements","title":"Implementation Requirements","text":"<p>Implementing ALB authentication requires proper setup of the Cognito User Pool, Client, and Domain. The configuration must ensure proper ID token return and handle URL redirections appropriately. When integrating social or corporate identity providers, careful attention must be paid to callback URL configuration.</p>"},{"location":"aws/security/cognito/#cognito-identity-pools-federated-identities","title":"Cognito Identity Pools (Federated Identities)","text":""},{"location":"aws/security/cognito/#core-functionality","title":"Core Functionality","text":"<p>Identity Pools extend Cognito\u2019s capabilities by providing temporary AWS credentials to users. This system supports multiple identity sources and enables both authenticated and guest access to AWS services. Users can interact directly with AWS services or through API Gateway, with access controlled by customizable IAM policies based on user identity.</p>"},{"location":"aws/security/cognito/#identity-source-support","title":"Identity Source Support","text":"<p>The system accepts identities from various sources, including public providers like Amazon, Facebook, Google, and Apple. It integrates with Cognito User Pools and supports OpenID Connect and SAML identity providers. Organizations can also implement custom login servers through Developer Authenticated Identities.</p>"},{"location":"aws/security/cognito/#iam-role-management","title":"IAM Role Management","text":"<p>Identity Pools manage AWS access through IAM roles, with separate default roles for authenticated and guest users. Role selection can be customized based on user attributes, and access can be partitioned using policy variables. The system obtains credentials through AWS STS and requires appropriate trust policies.</p>"},{"location":"aws/security/cognito/#comparing-user-pools-and-identity-pools","title":"Comparing User Pools and Identity Pools","text":"<p>Understanding the distinction between User Pools and Identity Pools is crucial for implementing effective authentication and authorization strategies. User Pools focus on authentication, providing user directory management, federated login support, and customizable interfaces. Identity Pools handle authorization by managing AWS credentials and access control through IAM policies.</p>"},{"location":"aws/security/cognito/#security-best-practices","title":"Security Best Practices","text":"<p>Security in Cognito requires a comprehensive approach that includes proper IAM policy implementation, MFA enablement for sensitive operations, and regular monitoring through CloudWatch. Organizations should carefully configure trust relationships, implement least privilege access principles, and conduct regular security assessments to maintain a robust security posture.</p>"},{"location":"aws/security/iam/","title":"Identity and Access Management (IAM)","text":""},{"location":"aws/security/iam/#introduction","title":"Introduction","text":"<p>AWS Identity and Access Management (IAM) is a global service that provides secure control over access to AWS resources. This guide outlines the core components and best practices for implementing IAM effectively in your AWS environment.</p>"},{"location":"aws/security/iam/#users-and-groups","title":"Users and Groups","text":"<p>IAM begins with the root account, which is created by default for every AWS account. However, the root account shouldn\u2019t be used for daily operations or shared among users. Instead, organizations should create individual IAM users for people within their organization.</p> <p>Users can be organized into groups for easier management. While groups can contain multiple users, they cannot contain other groups. It\u2019s important to note that users have flexibility in group membership - they can belong to multiple groups or no group at all, depending on organizational needs.</p>"},{"location":"aws/security/iam/#iam-permissions","title":"IAM Permissions","text":"<p>Permission management in IAM is handled through JSON documents called policies. These policies define the specific permissions granted to users or groups. AWS emphasizes the principle of least privilege, meaning users should only receive permissions necessary for their tasks.</p> <p>The policy structure consists of several key components. The Version field specifies the policy language version, typically \u201c2012-10-17\u201d. An optional Id field provides a policy identifier. The Statement section, which is required, contains one or more individual statements that define specific permissions.</p> <p>Each statement includes several elements: - A Sid (Statement ID) for optional identification - An Effect that specifies whether to Allow or Deny access - A Principal that defines the account, user, or role affected - Action fields listing permitted or denied actions - Resource specifications indicating which AWS resources are affected - Optional Condition elements that define when the policy takes effect</p>"},{"location":"aws/security/iam/#password-policy","title":"Password Policy","text":"<p>IAM enables robust password security through customizable password policies. Organizations can establish requirements for password complexity, including minimum length and character type requirements such as uppercase letters, lowercase letters, numbers, and special characters. The system can enforce password expiration periods, prevent password reuse, and allow IAM users to manage their own passwords.</p>"},{"location":"aws/security/iam/#multi-factor-authentication-mfa","title":"Multi-Factor Authentication (MFA)","text":"<p>Multi-Factor Authentication adds an essential security layer to AWS accounts. It combines something users know (their password) with something they own (an MFA device). This protection is crucial for both root accounts and IAM users, as it prevents unauthorized access even if passwords are compromised.</p> <p>AWS supports several MFA device options. Virtual MFA devices include Google Authenticator and Authy for mobile devices. Physical security keys include Universal 2<sup>nd</sup> Factor (U2F) devices like YubiKey. Hardware key fob options are available from providers like Gemalto, with special versions for AWS GovCloud from SurePassID.</p>"},{"location":"aws/security/iam/#aws-access-methods","title":"AWS Access Methods","text":"<p>Users can interact with AWS through three primary methods: the AWS Management Console, Command Line Interface (CLI), and Software Development Kit (SDK). The Console requires password and MFA protection, while CLI and SDK access is secured through access keys.</p> <p>Access keys consist of an Access Key ID (similar to a username) and a Secret Access Key (similar to a password). These credentials must be carefully managed and never shared. Users are responsible for managing their own access keys through the AWS Console.</p>"},{"location":"aws/security/iam/#aws-cli-and-sdk","title":"AWS CLI and SDK","text":"<p>The AWS Command Line Interface provides a tool for interacting with AWS services through command-line shells. It enables direct access to AWS service APIs and supports script development for resource management. The CLI is open-source and serves as an alternative to the AWS Management Console.</p> <p>The AWS Software Development Kit provides language-specific APIs for programmatic AWS access. It supports multiple programming languages including JavaScript, Python, PHP, .NET, Ruby, Java, Go, Node.js, and C++. The SDK also includes support for mobile development (Android, iOS) and IoT devices (Embedded C, Arduino).</p>"},{"location":"aws/security/iam/#iam-roles-for-services","title":"IAM Roles for Services","text":"<p>AWS services often need to perform actions on behalf of users. IAM Roles facilitate this by providing temporary credentials to AWS services. Common implementations include EC2 Instance Roles, Lambda Function Roles, and Roles for CloudFormation.</p>"},{"location":"aws/security/iam/#security-tools","title":"Security Tools","text":"<p>IAM provides two primary security assessment tools. The IAM Credentials Report offers account-level insights by listing all users and their credential status. The IAM Access Advisor provides user-level analysis of service permissions and their usage, helping administrators refine access policies.</p>"},{"location":"aws/security/iam/#best-practices","title":"Best Practices","text":"<p>AWS recommends several IAM best practices: - Reserve root account use for initial AWS account setup only - Create individual AWS users for each physical user - Manage permissions through groups rather than individual users - Implement and enforce strong password policies - Require MFA for all users - Use roles for AWS service permissions - Utilize access keys for programmatic access - Regular auditing using IAM security tools - Maintain strict control over IAM credentials</p>"},{"location":"aws/security/iam/#shared-responsibility-model","title":"Shared Responsibility Model","text":"<p>The IAM service operates under AWS\u2019s shared responsibility model. AWS maintains infrastructure security, performs configuration and vulnerability analysis, and ensures compliance validation. Customers are responsible for managing users, groups, roles, and policies, enabling MFA, rotating access keys, implementing appropriate permissions, and monitoring access patterns.</p> <p>Through proper implementation of these IAM components and best practices, organizations can maintain secure and efficient access to their AWS resources while minimizing security risks.</p>"},{"location":"aws/security/inspector/","title":"Inspector","text":""},{"location":"aws/security/inspector/#overview","title":"Overview","text":"<p>AWS Inspector is an automated security assessment service that helps improve the security and compliance of applications deployed on AWS by identifying potential security vulnerabilities and deviations from best practices.</p>"},{"location":"aws/security/inspector/#key-features","title":"Key Features","text":"<ul> <li>Automated security assessment</li> <li>Continuous monitoring of AWS resources</li> <li>Detailed security findings and recommendations</li> <li>Integration with AWS security ecosystem</li> </ul>"},{"location":"aws/security/inspector/#assessment-types","title":"Assessment Types","text":"<ul> <li>Network accessibility assessments</li> <li>Host vulnerability assessments</li> <li>Runtime behavior analysis</li> <li>Configuration compliance checks</li> </ul>"},{"location":"aws/security/inspector/#supported-resources","title":"Supported Resources","text":"<ul> <li>Amazon EC2 instances</li> <li>Container images</li> <li>Lambda functions</li> <li>Amazon ECR repositories</li> </ul>"},{"location":"aws/security/inspector/#core-capabilities","title":"Core Capabilities","text":"<ul> <li>Automated vulnerability scanning</li> <li>Security benchmarking</li> <li>Risk prioritization</li> <li>Comprehensive reporting</li> <li>Continuous monitoring</li> </ul>"},{"location":"aws/security/inspector/#benefits","title":"Benefits","text":"<ul> <li>Proactive security management</li> <li>Reduced manual security assessment effort</li> <li>Detailed security insights</li> <li>Compliance support</li> <li>Integration with AWS security tools</li> </ul>"},{"location":"aws/security/inspector/#compliance-standards","title":"Compliance Standards","text":"<ul> <li>NIST</li> <li>PCI DSS</li> <li>HIPAA</li> <li>SOC</li> <li>ISO</li> </ul>"},{"location":"aws/security/inspector/#assessment-workflow","title":"Assessment Workflow","text":"<ol> <li>Define assessment target</li> <li>Configure assessment rules</li> <li>Run security assessment</li> <li>Review and prioritize findings</li> <li>Remediate identified vulnerabilities</li> </ol>"},{"location":"aws/security/kms/","title":"Key Management Service (KMS)","text":""},{"location":"aws/security/kms/#overview","title":"Overview","text":"<p>AWS Key Management Service (KMS) represents a cornerstone of cloud security, providing a robust, centralized system for creating, managing, and controlling cryptographic keys across AWS services and applications. At its core, KMS transforms the complex landscape of encryption key management into a streamlined, secure, and highly integrated solution.</p> <p>Modern digital infrastructure demands sophisticated encryption strategies that balance security, compliance, and operational efficiency. KMS emerges as a critical solution, offering granular control over cryptographic processes while abstracting away the intricate complexities of key generation, rotation, and lifecycle management.</p>"},{"location":"aws/security/kms/#fundamental-concepts-of-cryptographic-key-management","title":"Fundamental Concepts of Cryptographic Key Management","text":""},{"location":"aws/security/kms/#key-types-and-their-purposes","title":"Key Types and Their Purposes","text":""},{"location":"aws/security/kms/#customer-master-keys-cmks","title":"Customer Master Keys (CMKs)","text":"<p>Customer Master Keys form the foundation of AWS KMS, serving as the primary resources for cryptographic operations. These keys can be categorized into two primary classifications:</p> <ol> <li> <p>AWS Managed Keys AWS automatically creates and manages these keys for specific AWS services. They provide a baseline level of encryption with minimal configuration overhead. Services like Amazon S3, Amazon EBS, and AWS CloudTrail leverage these keys by default.</p> </li> <li> <p>Customer Managed Keys These keys offer the highest degree of customization and control. Customers can define precise policies, enable or disable key capabilities, and implement sophisticated rotation strategies. Customer managed keys support more advanced use cases requiring nuanced encryption requirements.</p> </li> </ol>"},{"location":"aws/security/kms/#data-keys","title":"Data Keys","text":"<p>Data keys represent a critical mechanism for envelope encryption. Unlike master keys, data keys are used to encrypt actual data payloads. KMS generates these keys dynamically, allowing for efficient and secure large-scale data encryption scenarios.</p>"},{"location":"aws/security/kms/#encryption-capabilities","title":"Encryption Capabilities","text":""},{"location":"aws/security/kms/#encryption-context-and-additional-authentication","title":"Encryption Context and Additional Authentication","text":"<p>KMS introduces the powerful concept of encryption context, a mechanism that provides additional authentication and audit capabilities. This feature allows associating additional metadata with encryption operations, enhancing security and providing rich contextual information for monitoring and compliance purposes.</p> <p>An encryption context acts as an additional layer of authentication, ensuring that decryption can only occur with the exact metadata that was present during encryption. This approach significantly reduces the risk of unauthorized decryption attempts.</p>"},{"location":"aws/security/kms/#envelope-encryption-strategy","title":"Envelope Encryption Strategy","text":"<p>The envelope encryption approach represents a sophisticated method of securing data. Instead of directly encrypting large datasets with master keys, KMS generates unique data keys for each encryption task. The data key encrypts the actual content, while the master key protects the data key itself.</p> <p>This strategy offers multiple advantages: - Improved performance for large-scale encryption - Reduced computational complexity - Enhanced key rotation and management flexibility</p>"},{"location":"aws/security/kms/#types-of-encryption-in-aws-s3","title":"Types of Encryption in AWS S3","text":""},{"location":"aws/security/kms/#sse-s3-server-side-encryption-with-amazon-s3-managed-keys","title":"SSE-S3 (Server-Side Encryption with Amazon S3-Managed Keys)","text":"<p>SSE-S3 represents a straightforward encryption method managed entirely by Amazon S3. It uses 256-bit Advanced Encryption Standard (AES-256), with encryption keys automatically generated and managed by AWS. Each object receives a unique data key, encrypted with a master key controlled by Amazon.</p>"},{"location":"aws/security/kms/#sse-c-server-side-encryption-with-customer-provided-keys","title":"SSE-C (Server-Side Encryption with Customer-Provided Keys)","text":"<p>SSE-C provides maximum encryption control to customers. Users must provide their own 32-byte encryption keys for each API request. Unlike SSE-S3, AWS does not store these keys, placing complete key management responsibility on the customer. This approach supports AES-256 encryption and requires key transmission over HTTPS.</p>"},{"location":"aws/security/kms/#access-control-and-governance","title":"Access Control and Governance","text":""},{"location":"aws/security/kms/#iam-integration","title":"IAM Integration","text":"<p>AWS Identity and Access Management (IAM) provides granular control over KMS key usage. Administrators can define precise policies determining which users, roles, and services can perform specific cryptographic operations.</p> <p>The integration allows for extremely fine-grained access controls, such as limiting key usage to specific AWS services, restricting decryption operations, or implementing time-based access restrictions.</p>"},{"location":"aws/security/kms/#auditing-and-compliance","title":"Auditing and Compliance","text":"<p>AWS CloudTrail integration enables comprehensive logging of all KMS-related activities. Every key generation, encryption, decryption, and administrative action can be meticulously tracked, providing an immutable audit trail crucial for regulatory compliance and security investigations.</p>"},{"location":"aws/security/kms/#advanced-security-features","title":"Advanced Security Features","text":""},{"location":"aws/security/kms/#key-rotation-mechanisms","title":"Key Rotation Mechanisms","text":"<p>KMS supports automatic and manual key rotation strategies. Automatic rotation can occur annually, ensuring that cryptographic keys are regularly refreshed without manual intervention. Manual rotation provides additional flexibility for organizations with specific compliance requirements.</p>"},{"location":"aws/security/kms/#multi-region-keys","title":"Multi-Region Keys","text":"<p>For global organizations requiring consistent encryption across multiple geographic regions, KMS offers multi-region key capabilities. These keys can be replicated across AWS regions, maintaining cryptographic consistency while adhering to data residency requirements.</p>"},{"location":"aws/security/kms/#practical-implementation-scenarios","title":"Practical Implementation Scenarios","text":""},{"location":"aws/security/kms/#secure-storage-encryption","title":"Secure Storage Encryption","text":"<p>Amazon S3 buckets can leverage KMS for transparent, server-side encryption. By associating a KMS key with a storage bucket, all objects are automatically encrypted at rest, with decryption handled seamlessly during access.</p>"},{"location":"aws/security/kms/#database-encryption","title":"Database Encryption","text":"<p>Databases like Amazon RDS can integrate KMS for column-level or full-disk encryption. This approach ensures that sensitive information remains protected, even if underlying storage systems are compromised.</p>"},{"location":"aws/security/kms/#application-level-encryption","title":"Application-Level Encryption","text":"<p>Developers can directly integrate KMS into applications using AWS SDKs, enabling sophisticated encryption workflows that extend beyond infrastructure-level protection.</p>"},{"location":"aws/security/kms/#performance-and-scalability-considerations","title":"Performance and Scalability Considerations","text":"<p>While providing robust security, KMS is designed with performance in mind. The service can handle millions of cryptographic requests per second, with minimal latency. Cryptographic operations are offloaded to specialized hardware security modules, ensuring both speed and security.</p>"},{"location":"aws/security/kms/#cost-management","title":"Cost Management","text":"<p>KMS follows a usage-based pricing model. Costs are primarily associated with key storage, key usage, and the number of cryptographic operations. The service offers a free tier for basic usage, making it accessible for both small and large-scale deployments.</p>"},{"location":"aws/security/kms/#emerging-trends-and-future-directions","title":"Emerging Trends and Future Directions","text":"<p>As cloud security evolves, KMS continues to expand its capabilities. Emerging trends include enhanced machine learning-driven anomaly detection, more sophisticated key lifecycle management, and deeper integration with emerging compliance frameworks.</p>"},{"location":"aws/security/kms/#conclusion","title":"Conclusion","text":"<p>AWS Key Management Service represents more than a technical solution\u2014it\u2019s a comprehensive approach to cryptographic governance in cloud environments. By providing a flexible, secure, and integrated key management platform, KMS empowers organizations to implement robust security strategies without sacrificing operational efficiency.</p> <p>The true power of KMS lies not just in its technical capabilities, but in its ability to transform complex security challenges into manageable, transparent processes.</p>"},{"location":"aws/security/macie/","title":"Macie","text":""},{"location":"aws/security/macie/#overview","title":"Overview","text":"<p>AWS Macie is a fully managed data security and privacy service that leverages machine learning and pattern matching to discover and protect sensitive data in AWS environments.</p>"},{"location":"aws/security/macie/#key-features","title":"Key Features","text":""},{"location":"aws/security/macie/#data-discovery","title":"Data Discovery","text":"<ul> <li>Identifies sensitive information across AWS storage services</li> <li>Specializes in detecting Personally Identifiable Information (PII)</li> <li>Focuses primarily on Amazon S3 bucket content analysis</li> </ul>"},{"location":"aws/security/macie/#machine-learning-capabilities","title":"Machine Learning Capabilities","text":"<ul> <li>Uses advanced pattern matching techniques</li> <li>Automatically identifies potential data privacy risks</li> <li>Continuously learns and improves detection accuracy</li> </ul>"},{"location":"aws/security/macie/#integration-ecosystem","title":"Integration Ecosystem","text":"<ul> <li>Seamless integration with Amazon EventBridge</li> <li>Provides notification mechanisms for detected sensitive data</li> <li>Enables automated response and alerting workflows</li> </ul>"},{"location":"aws/security/macie/#primary-use-cases","title":"Primary Use Cases","text":"<ul> <li>Data privacy compliance</li> <li>Sensitive information protection</li> <li>Risk assessment and mitigation</li> <li>Regulatory compliance support</li> </ul>"},{"location":"aws/security/macie/#benefits","title":"Benefits","text":"<ul> <li>Automated sensitive data detection</li> <li>Reduced manual security monitoring</li> <li>Enhanced data protection</li> <li>Proactive risk identification</li> <li>Supports various compliance frameworks</li> </ul>"},{"location":"aws/security/macie/#supported-data-types","title":"Supported Data Types","text":"<ul> <li>Personally Identifiable Information (PII)</li> <li>Financial data</li> <li>Personal health information</li> <li>Confidential corporate data</li> </ul>"},{"location":"aws/security/macie/#alerting-and-reporting","title":"Alerting and Reporting","text":"<ul> <li>Real-time sensitive data discovery alerts</li> <li>Detailed findings and risk assessments</li> <li>Configurable notification mechanisms</li> </ul>"},{"location":"aws/security/secrets_manager/","title":"Secrets Manager","text":""},{"location":"aws/security/secrets_manager/#overview","title":"Overview","text":"<p>AWS Secrets Manager is a specialized service designed for storing and managing sensitive information in AWS cloud environments. As a newer addition to AWS\u2019s security services portfolio, it provides enhanced capabilities specifically focused on secrets management and rotation.</p>"},{"location":"aws/security/secrets_manager/#core-features","title":"Core Features","text":""},{"location":"aws/security/secrets_manager/#secret-storage-and-security","title":"Secret Storage and Security","text":"<p>Secrets Manager provides robust encryption for all stored secrets using AWS Key Management Service (KMS). This mandatory encryption ensures that sensitive information remains secure at rest and during transmission. The service is particularly optimized for managing database credentials, especially for Amazon RDS instances.</p>"},{"location":"aws/security/secrets_manager/#automated-secret-rotation","title":"Automated Secret Rotation","text":"<p>One of the most powerful features of Secrets Manager is its ability to force automatic rotation of secrets at defined intervals. Organizations can configure the service to rotate secrets every specified number of days, enhancing security through regular credential updates. This rotation process is automated through AWS Lambda functions, which handle the generation and distribution of new secrets.</p>"},{"location":"aws/security/secrets_manager/#database-integration","title":"Database Integration","text":"<p>Secrets Manager offers seamless integration with various Amazon RDS database engines, including MySQL, PostgreSQL, and Aurora. This integration simplifies the management of database credentials and supports automated rotation of database access credentials, making it particularly valuable for organizations using RDS services.</p>"},{"location":"aws/security/secrets_manager/#multi-region-secrets-management","title":"Multi-Region Secrets Management","text":""},{"location":"aws/security/secrets_manager/#secret-replication","title":"Secret Replication","text":"<p>Secrets Manager supports the replication of secrets across multiple AWS regions. This capability enables organizations to maintain synchronized copies of their secrets across different geographical locations, ensuring high availability and disaster recovery readiness.</p>"},{"location":"aws/security/secrets_manager/#synchronization-and-management","title":"Synchronization and Management","text":"<p>The service maintains automatic synchronization between the primary secret and its read replicas across regions. When the primary secret is updated, Secrets Manager automatically propagates these changes to all replica secrets, ensuring consistency across regions.</p>"},{"location":"aws/security/secrets_manager/#replica-promotion","title":"Replica Promotion","text":"<p>Organizations have the flexibility to promote a read replica secret to a standalone secret when needed. This feature provides additional management options and supports various architectural patterns.</p>"},{"location":"aws/security/secrets_manager/#use-cases","title":"Use Cases","text":"<p>Multi-region secrets management supports several critical scenarios: - Multi-region application deployments - Disaster recovery planning and implementation - Multi-region database deployments - Global application architecture requirements</p>"},{"location":"aws/security/secrets_manager/#comparison-with-ssm-parameter-store","title":"Comparison with SSM Parameter Store","text":""},{"location":"aws/security/secrets_manager/#cost-considerations","title":"Cost Considerations","text":"<p>Secrets Manager is positioned as a premium service with higher associated costs, reflecting its specialized features and capabilities. While more expensive than Parameter Store, it offers advanced functionality specifically designed for secrets management.</p>"},{"location":"aws/security/secrets_manager/#functionality-differences","title":"Functionality Differences","text":""},{"location":"aws/security/secrets_manager/#secrets-manager-advantages","title":"Secrets Manager Advantages","text":"<p>Secrets Manager provides built-in secret rotation capabilities through AWS Lambda, with pre-configured Lambda functions available for RDS, Redshift, and DocumentDB. The service mandates KMS encryption for all secrets and offers native integration with CloudFormation for infrastructure as code implementations.</p>"},{"location":"aws/security/secrets_manager/#parameter-store-features","title":"Parameter Store Features","text":"<p>Parameter Store offers a simpler API and more cost-effective solution for basic parameter management. While it doesn\u2019t include built-in secret rotation, organizations can implement rotation using Lambda functions triggered by EventBridge. KMS encryption remains optional in Parameter Store, providing flexibility in security implementation. The service supports CloudFormation integration and can access Secrets Manager secrets through its API.</p>"},{"location":"aws/security/secrets_manager/#best-practices","title":"Best Practices","text":"<p>When implementing Secrets Manager, consider these recommended practices: - Implement appropriate secret rotation schedules based on security requirements - Utilize multi-region replication for globally distributed applications - Configure proper IAM policies for secret access - Monitor secret rotation events and failures - Regularly audit secret access and usage</p>"},{"location":"aws/security/secrets_manager/#conclusion","title":"Conclusion","text":"<p>AWS Secrets Manager provides a comprehensive solution for organizations requiring robust secrets management with automated rotation capabilities. Its strong integration with RDS services and support for multi-region deployments makes it particularly valuable for organizations with complex database management requirements or global application architectures. While more costly than Parameter Store, its specialized features justify the investment for use cases requiring advanced secrets management capabilities.</p>"},{"location":"aws/security/shield/","title":"Shield","text":""},{"location":"aws/security/shield/#overview","title":"Overview","text":"<p>AWS Shield is a managed Distributed Denial of Service (DDoS) protection service designed to safeguard web applications running on AWS infrastructure.</p>"},{"location":"aws/security/shield/#protection-levels","title":"Protection Levels","text":"<ul> <li>AWS Shield Standard: </li> <li>Automatic protection for all AWS customers</li> <li>Free service for AWS resources</li> <li> <p>Protects against common DDoS attacks</p> </li> <li> <p>AWS Shield Advanced: </p> </li> <li>Paid service with comprehensive protection</li> <li>Detailed attack diagnostics</li> <li>Custom incident response team</li> </ul>"},{"location":"aws/security/shield/#supported-resources","title":"Supported Resources","text":"<ul> <li>Amazon CloudFront distributions</li> <li>Amazon Route 53 hosted zones</li> <li>Elastic Load Balancers</li> <li>AWS Global Accelerator</li> <li>Amazon EC2 instances</li> </ul>"},{"location":"aws/security/shield/#key-features","title":"Key Features","text":"<ul> <li>Real-time attack detection</li> <li>Traffic filtering</li> <li>Automatic traffic rate limiting</li> <li>Layer \u00be and Layer 7 protection</li> <li>Comprehensive threat mitigation</li> </ul>"},{"location":"aws/security/shield/#attack-types-mitigated","title":"Attack Types Mitigated","text":"<ul> <li>SYN floods</li> <li>UDP reflection attacks</li> <li>HTTP/HTTPS floods</li> <li>Volumetric attacks</li> <li>Protocol attacks</li> <li>Application-layer attacks</li> </ul>"},{"location":"aws/security/shield/#benefits","title":"Benefits","text":"<ul> <li>Minimizes application downtime</li> <li>Reduces infrastructure vulnerability</li> <li>Scalable protection</li> <li>Seamless integration with AWS services</li> <li>Continuous monitoring and protection</li> </ul>"},{"location":"aws/security/shield/#threat-detection-mechanisms","title":"Threat Detection Mechanisms","text":"<ul> <li>Machine learning algorithms</li> <li>Behavioral analysis</li> <li>Traffic pattern recognition</li> <li>Anomaly detection</li> </ul>"},{"location":"aws/security/sso/","title":"Single Sign-On (SSO)","text":""},{"location":"aws/security/sso/#overview","title":"Overview","text":"<p>AWS Single Sign-On (SSO) is a cloud-based service that simplifies user access management across multiple AWS accounts and business applications, enabling centralized access control and authentication.</p>"},{"location":"aws/security/sso/#key-features","title":"Key Features","text":"<ul> <li>Centralized access management</li> <li>Single login for multiple AWS accounts</li> <li>Integration with corporate directories</li> <li>Simplified user provisioning and deprovisioning</li> <li>Role-based access control</li> </ul>"},{"location":"aws/security/sso/#authentication-methods","title":"Authentication Methods","text":"<ul> <li>Active Directory integration</li> <li>SAML 2.0 identity providers</li> <li>AWS Organizations support</li> <li>Multi-factor authentication</li> <li>Custom identity source</li> </ul>"},{"location":"aws/security/sso/#access-management-capabilities","title":"Access Management Capabilities","text":"<ul> <li>Manage user permissions</li> <li>Assign application access</li> <li>Control account-level access</li> <li>Automated user provisioning</li> <li>Granular permission settings</li> </ul>"},{"location":"aws/security/sso/#supported-integrations","title":"Supported Integrations","text":"<ul> <li>Microsoft Active Directory</li> <li>Okta</li> <li>Azure AD</li> <li>Google Workspace</li> <li>SAML-compatible identity providers</li> </ul>"},{"location":"aws/security/sso/#use-cases","title":"Use Cases","text":"<ul> <li>Enterprise access management</li> <li>Simplified cloud account administration</li> <li>Secure application access</li> <li>Centralized identity governance</li> <li>Multi-account AWS environment management</li> </ul>"},{"location":"aws/security/sso/#security-benefits","title":"Security Benefits","text":"<ul> <li>Reduced credential management overhead</li> <li>Centralized access policy enforcement</li> <li>Enhanced authentication security</li> <li>Simplified compliance management</li> <li>Consistent access controls</li> </ul>"},{"location":"aws/storage/ebs/","title":"Elastic Block Store (EBS)","text":"<p>Amazon Elastic Block Store (EBS) is a scalable, high-performance block storage service designed for Amazon Elastic Compute Cloud (EC2) instances. It provides persistent storage that can be attached to EC2 instances to store data in a highly available and durable manner.</p>"},{"location":"aws/storage/ebs/#key-features","title":"Key Features","text":""},{"location":"aws/storage/ebs/#1-persistence-and-durability","title":"1. Persistence and Durability","text":"<p>EBS volumes are designed to be highly durable, with data replicated within the same Availability Zone (AZ) to prevent data loss from hardware failures.</p>"},{"location":"aws/storage/ebs/#2-scalability","title":"2. Scalability","text":"<p>You can dynamically scale the storage capacity of EBS volumes without disrupting operations, allowing your applications to adapt to changing workloads.</p>"},{"location":"aws/storage/ebs/#3-performance-options","title":"3. Performance Options","text":"<p>EBS offers a range of volume types with varying performance characteristics: - General Purpose SSD (gp2, gp3): Balanced price and performance for general workloads. - Provisioned IOPS SSD (io1, io2): High performance for mission-critical applications. - Throughput Optimized HDD (st1): Optimized for large, sequential workloads. - Cold HDD (sc1): Low-cost storage for infrequent access. - Magnetic Volumes (standard): Legacy storage option (deprecated in many regions).</p>"},{"location":"aws/storage/ebs/#4-snapshots","title":"4. Snapshots","text":"<p>EBS supports incremental snapshots to Amazon S3, allowing you to back up volumes at any point in time.</p>"},{"location":"aws/storage/ebs/#5-encryption","title":"5. Encryption","text":"<p>Data stored on EBS volumes can be encrypted using AWS Key Management Service (KMS). Encryption includes data at rest, data in transit, and volume snapshots.</p>"},{"location":"aws/storage/ebs/#6-multi-attach","title":"6. Multi-Attach","text":"<p>EBS io2 volumes support Multi-Attach, allowing a single volume to be attached to multiple EC2 instances within the same AZ.</p>"},{"location":"aws/storage/ebs/#7-integration-with-ec2-auto-scaling","title":"7. Integration with EC2 Auto Scaling","text":"<p>EBS integrates seamlessly with EC2 Auto Scaling, ensuring that storage scales along with compute resources.</p>"},{"location":"aws/storage/ebs/#volume-types","title":"Volume Types","text":"Volume Type Use Case Performance gp2 (General Purpose SSD) General-purpose workloads Baseline: 3 IOPS/GB, burst up to 16,000 IOPS gp3 General-purpose workloads Baseline: 3,000 IOPS, adjustable up to 16,000 IOPS io1 High-performance applications Provisioned up to 64,000 IOPS io2 Mission-critical, high-durability apps Provisioned up to 64,000 IOPS with durability of 99.999% st1 (Throughput Optimized HDD) Large, sequential I/O workloads Max throughput: 500 MiB/s sc1 (Cold HDD) Infrequent data access Max throughput: 250 MiB/s"},{"location":"aws/storage/ebs/#common-use-cases","title":"Common Use Cases","text":"<ol> <li>Relational Databases: Store transactional data for applications like MySQL, PostgreSQL, and Oracle.</li> <li>Big Data Analytics: Provide high throughput for processing large datasets in Hadoop and Spark.</li> <li>Content Management Systems: Host media files or application data.</li> <li>Backup and Recovery: Use snapshots to create point-in-time backups and ensure business continuity.</li> <li>Boot Volumes: Serve as boot devices for EC2 instances.</li> <li>Shared File Systems: Support shared storage with Multi-Attach-enabled volumes.</li> </ol>"},{"location":"aws/storage/ebs/#snapshots","title":"Snapshots","text":""},{"location":"aws/storage/ebs/#key-features-of-snapshots","title":"Key Features of Snapshots:","text":"<ol> <li>Incremental Backups: Only changes since the last snapshot are saved, reducing storage costs.</li> <li>Cross-Region Copy: Snapshots can be copied to other regions for disaster recovery.</li> <li>Lifecycle Policies: Automate snapshot creation and retention using Amazon Data Lifecycle Manager.</li> </ol>"},{"location":"aws/storage/ebs/#creating-a-snapshot","title":"Creating a Snapshot:","text":"<p>Using AWS CLI: <pre><code>aws ec2 create-snapshot \\\n    --volume-id vol-0abcd1234efgh5678 \\\n    --description \"My EBS Snapshot\"\n</code></pre></p>"},{"location":"aws/storage/ebs/#restoring-from-a-snapshot","title":"Restoring from a Snapshot:","text":"<p>Using AWS CLI: <pre><code>aws ec2 create-volume \\\n    --snapshot-id snap-0abcd1234efgh5678 \\\n    --availability-zone us-east-1a\n</code></pre></p>"},{"location":"aws/storage/ebs/#encryption","title":"Encryption","text":""},{"location":"aws/storage/ebs/#how-ebs-encryption-works","title":"How EBS Encryption Works","text":"<ol> <li>Encryption uses AWS KMS-managed keys or customer-managed keys.</li> <li>Encryption applies to data at rest, data in transit between the volume and the instance, and all backups.</li> </ol>"},{"location":"aws/storage/ebs/#enabling-encryption","title":"Enabling Encryption:","text":"<ol> <li>Default Encryption: Enable default encryption for all new volumes in your AWS account.</li> <li>Volume-Specific Encryption: Specify encryption when creating a volume.</li> </ol> <p>Using AWS CLI: <pre><code>aws ec2 create-volume \\\n    --size 10 \\\n    --availability-zone us-east-1a \\\n    --encrypted\n</code></pre></p>"},{"location":"aws/storage/ebs/#performance-optimization","title":"Performance Optimization","text":""},{"location":"aws/storage/ebs/#1-choose-the-right-volume-type","title":"1. Choose the Right Volume Type","text":"<ul> <li>Match volume type to workload characteristics (e.g., SSD for random I/O, HDD for sequential workloads).</li> </ul>"},{"location":"aws/storage/ebs/#2-monitor-performance-metrics","title":"2. Monitor Performance Metrics","text":"<ul> <li>Use Amazon CloudWatch to monitor IOPS, throughput, and latency.</li> </ul>"},{"location":"aws/storage/ebs/#3-use-elastic-volumes","title":"3. Use Elastic Volumes","text":"<ul> <li>Modify volume size, type, or IOPS without downtime.</li> </ul>"},{"location":"aws/storage/ebs/#pricing","title":"Pricing","text":"<p>EBS costs depend on several factors: 1. Volume Type: Cost per GB varies by type (e.g., gp3 vs. io2). 2. Provisioned IOPS: Additional charges for provisioned IOPS for io1/io2 volumes. 3. Snapshots: Charged based on the storage used by the snapshot. 4. Data Transfer: Charges may apply for data transfer across regions.</p> <p>Refer to the EBS Pricing Page for detailed information.</p>"},{"location":"aws/storage/ebs/#limits-and-considerations","title":"Limits and Considerations","text":""},{"location":"aws/storage/ebs/#limits","title":"Limits:","text":"<ul> <li>Volume Size: Up to 16 TiB.</li> <li>IOPS: Up to 64,000 IOPS (for io1/io2).</li> <li>Throughput: Up to 1,000 MiB/s.</li> <li>Provisioned IOPS Ratio: The maximum ratio of provisioned IOPS to volume size is 50:1 for io1 and io2 volumes.</li> </ul>"},{"location":"aws/storage/ebs/#considerations","title":"Considerations:","text":"<ol> <li>AZ-Specific: Volumes are tied to a specific AZ; cross-AZ usage requires snapshots or replication.</li> <li>Performance Throttling: Exceeding IOPS/throughput limits can lead to throttling.</li> <li>Data Durability: Snapshots are critical for long-term data durability.</li> </ol>"},{"location":"aws/storage/ebs/#best-practices","title":"Best Practices","text":"<ol> <li>Backup Regularly: Use snapshots for periodic backups.</li> <li>Use Tags: Organize EBS volumes and snapshots with meaningful tags.</li> <li>Monitor Costs: Regularly analyze usage and optimize volume types to control costs.</li> <li>Use Elastic Volumes: Resize or change volume types as workloads evolve.</li> <li>Enable Encryption: Protect sensitive data with EBS encryption.</li> </ol> <p>For more details, refer to the EBS Documentation.</p>"},{"location":"aws/storage/efs/","title":"Elastic File System (EFS)","text":""},{"location":"aws/storage/efs/#introduction","title":"Introduction","text":"<p>Amazon Elastic File System (EFS) is a managed Network File System (NFS) designed to provide scalable, shared storage for EC2 instances. The service enables multiple EC2 instances to simultaneously access a common file system across multiple Availability Zones (AZs).</p>"},{"location":"aws/storage/efs/#core-functionality","title":"Core Functionality","text":"<p>EFS operates as a fully managed NFS service that supports concurrent mounting from multiple EC2 instances. The system delivers high availability by working across multiple AZs within a region. While it comes at a higher cost point (approximately three times that of gp2), its scalability and pay-per-use pricing model make it suitable for various enterprise applications.</p>"},{"location":"aws/storage/efs/#use-cases-and-compatibility","title":"Use Cases and Compatibility","text":"<p>The service excels in several key applications, including content management systems, web serving, data sharing, and WordPress hosting. EFS implements the NFSv4.1 protocol and is specifically designed for Linux-based AMIs, making it incompatible with Windows environments. The system provides POSIX-compliant file system access with standard file APIs, enabling seamless integration with existing Linux-based applications.</p> <p>Security is managed through AWS security groups, which control access to EFS resources. Data security is enhanced through KMS-based encryption at rest. The file system\u2019s automatic scaling capability eliminates the need for capacity planning, allowing users to pay only for the storage they consume.</p>"},{"location":"aws/storage/efs/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"aws/storage/efs/#scaling-capabilities","title":"Scaling Capabilities","text":"<p>EFS demonstrates impressive scaling capabilities, supporting thousands of concurrent NFS clients with throughput exceeding 10 GB/s. The system can automatically expand to petabyte-scale, requiring no manual intervention for growth management.</p>"},{"location":"aws/storage/efs/#performance-modes","title":"Performance Modes","text":"<p>EFS offers two performance modes, which must be selected during creation:</p> <p>The General Purpose mode serves as the default option, optimized for latency-sensitive applications such as web servers and content management systems. The Max I/O mode caters to high-throughput requirements and parallel processing scenarios, commonly used in big data analytics and media processing, though it may introduce higher latency.</p>"},{"location":"aws/storage/efs/#throughput-options","title":"Throughput Options","text":"<p>EFS provides three throughput modes to match different workload requirements:</p> <p>The Bursting mode provides baseline throughput of 50MiB/s per TB of storage, with burst capability up to 100MiB/s. Provisioned mode allows setting specific throughput requirements independent of storage size, supporting configurations up to 1 GiB/s per TB of storage. The Elastic mode automatically adjusts throughput based on workload demands, supporting up to 3GiB/s for reads and 1GiB/s for writes, making it ideal for unpredictable workload patterns.</p>"},{"location":"aws/storage/efs/#storage-classes-and-management","title":"Storage Classes and Management","text":""},{"location":"aws/storage/efs/#tiered-storage","title":"Tiered Storage","text":"<p>EFS implements a lifecycle management feature that enables automatic file movement between storage tiers based on access patterns:</p> <p>The Standard tier serves frequently accessed files with optimal performance. The Infrequent Access tier (EFS-IA) offers lower storage costs but includes retrieval fees. The Archive tier provides the most cost-effective storage for rarely accessed data, offering up to 50% cost savings for files accessed only a few times annually.</p>"},{"location":"aws/storage/efs/#availability-options","title":"Availability Options","text":"<p>EFS offers two availability configurations:</p> <p>The Standard configuration provides Multi-AZ redundancy, making it suitable for production environments. The One Zone configuration limits storage to a single AZ, offering a more cost-effective solution for development environments while maintaining backup capabilities by default. One Zone storage is compatible with IA storage (EFS One Zone-IA) and can provide over 90% cost savings compared to standard configurations.</p>"},{"location":"aws/storage/efs/#ebs-vs-efs-comparison","title":"EBS vs EFS Comparison","text":""},{"location":"aws/storage/efs/#storage-characteristics","title":"Storage Characteristics","text":"<p>EFS differs significantly from EBS in several key aspects. While EBS volumes are typically limited to single instance attachment (except for multi-attach io1/io2) and confined to specific AZs, EFS provides simultaneous access to hundreds of instances across multiple AZs. This makes EFS particularly suitable for shared file system requirements, such as WordPress installations.</p>"},{"location":"aws/storage/efs/#cost-and-performance-considerations","title":"Cost and Performance Considerations","text":"<p>Though EFS commands a higher price point than EBS, it offers cost optimization through storage tiers. The decision between EFS, EBS, and Instance Store should consider factors such as access patterns, performance requirements, and budget constraints. EFS\u2019s ability to serve as a centralized storage solution can often justify its higher cost through reduced operational complexity and improved data consistency across instances.</p> <p>The choice between these storage solutions should be guided by specific application requirements, considering factors such as access patterns, performance needs, sharing requirements, and cost constraints.</p>"},{"location":"aws/storage/s3/","title":"Simple Storage Service (S3)","text":""},{"location":"aws/storage/s3/#introduction","title":"Introduction","text":"<p>Amazon S3 (Simple Storage Service) is an object storage service offering industry-leading scalability, data availability, security, and performance. It can store and retrieve any amount of data from anywhere on the web, making it a versatile solution for backup, archiving, content distribution, and data lakes.</p>"},{"location":"aws/storage/s3/#core-concepts","title":"Core Concepts","text":""},{"location":"aws/storage/s3/#buckets","title":"Buckets","text":"<ul> <li>Containers for objects stored in S3</li> <li>Must have a globally unique name</li> <li>Region-specific</li> <li>No limit to objects in a bucket</li> <li>Flat structure (no real hierarchy)</li> </ul>"},{"location":"aws/storage/s3/#objects","title":"Objects","text":"<ul> <li>Basic storage unit in S3</li> <li>Consists of:</li> <li>Data (the file)</li> <li>Key (the file name)</li> <li>Metadata (data about the data)</li> <li>Version ID (if versioning enabled)</li> <li>Size limits:</li> <li>Single object: 5TB</li> <li>Single PUT: 5GB</li> </ul>"},{"location":"aws/storage/s3/#storage-classes","title":"Storage Classes","text":""},{"location":"aws/storage/s3/#s3-standard","title":"S3 Standard","text":"<ul> <li>Default storage class</li> <li>99.99% availability</li> <li>11 9\u2019s durability</li> <li>Multiple AZ replication</li> <li>Best for: Frequently accessed data</li> </ul>"},{"location":"aws/storage/s3/#s3-intelligent-tiering","title":"S3 Intelligent-Tiering","text":"<ul> <li>Automatic cost optimization</li> <li>Moves objects between access tiers</li> <li>No retrieval fees</li> <li>Small monthly monitoring fee</li> <li>Best for: Unknown or changing access patterns</li> </ul>"},{"location":"aws/storage/s3/#s3-standard-ia-infrequent-access","title":"S3 Standard-IA (Infrequent Access)","text":"<ul> <li>Lower storage cost than Standard</li> <li>Higher retrieval cost</li> <li>99.9% availability</li> <li>Best for: Less frequently accessed data</li> </ul>"},{"location":"aws/storage/s3/#s3-one-zone-ia","title":"S3 One Zone-IA","text":"<ul> <li>Single AZ storage</li> <li>Lower cost than Standard-IA</li> <li>99.5% availability</li> <li>Best for: Reproducible, infrequently accessed data</li> </ul>"},{"location":"aws/storage/s3/#s3-glacier","title":"S3 Glacier","text":"<ul> <li>Long-term archival storage</li> <li>Retrieval times: minutes to hours</li> <li>Significantly lower storage cost</li> <li>Best for: Long-term backups and archives</li> </ul>"},{"location":"aws/storage/s3/#s3-glacier-deep-archive","title":"S3 Glacier Deep Archive","text":"<ul> <li>Lowest cost storage option</li> <li>Retrieval time: 12 hours</li> <li>Best for: Long-term data retention (7-10 years)</li> </ul>"},{"location":"aws/storage/s3/#data-protection","title":"Data Protection","text":""},{"location":"aws/storage/s3/#versioning","title":"Versioning","text":"<p><pre><code>{\n    \"VersioningConfiguration\": {\n        \"Status\": \"Enabled\"\n    }\n}\n</code></pre> - Maintains multiple versions of objects - Protects against accidental deletions - Can be suspended but not disabled - Increases storage costs</p>"},{"location":"aws/storage/s3/#replication","title":"Replication","text":"<p>Types: 1. Cross-Region Replication (CRR) 2. Same-Region Replication (SRR)</p> <pre><code>{\n    \"ReplicationConfiguration\": {\n        \"Role\": \"arn:aws:iam::account-id:role/role-name\",\n        \"Rules\": [\n            {\n                \"Status\": \"Enabled\",\n                \"Destination\": {\n                    \"Bucket\": \"arn:aws:s3:::destination-bucket\"\n                }\n            }\n        ]\n    }\n}\n</code></pre>"},{"location":"aws/storage/s3/#object-lock","title":"Object Lock","text":"<ul> <li>Write-once-read-many (WORM)</li> <li>Retention periods</li> <li>Legal holds</li> <li>Compliance mode</li> </ul>"},{"location":"aws/storage/s3/#security","title":"Security","text":""},{"location":"aws/storage/s3/#access-control","title":"Access Control","text":"<ol> <li> <p>IAM Policies <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"s3:GetObject\",\n                \"s3:PutObject\"\n            ],\n            \"Resource\": \"arn:aws:s3:::bucket-name/*\"\n        }\n    ]\n}\n</code></pre></p> </li> <li> <p>Bucket Policies <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Sid\": \"PublicRead\",\n            \"Effect\": \"Allow\",\n            \"Principal\": \"*\",\n            \"Action\": \"s3:GetObject\",\n            \"Resource\": \"arn:aws:s3:::bucket-name/*\"\n        }\n    ]\n}\n</code></pre></p> </li> <li> <p>Access Control Lists (ACLs)</p> </li> <li>Legacy access control mechanism</li> <li>Granular permissions at object level</li> </ol>"},{"location":"aws/storage/s3/#s3-encryption","title":"S3 Encryption","text":"<p>Amazon S3 provides robust object encryption capabilities through multiple approaches. Encryption ensures data confidentiality and protection at rest, with users having flexibility in key management and encryption strategies.</p>"},{"location":"aws/storage/s3/#server-side-encryption-sse-encryption-at-rest","title":"Server-Side Encryption (SSE) - Encryption at rest","text":"<p>Limitation: - If you use SSE-KMS, you may be impacted by the KMS limits: when you upload, it calls the <code>GenerateDataKey</code> KMS API, when you download, it calls the <code>Decrypt</code> KMS API - Count towards the KMS quota per second (5500, 10000, 30000 req/s based on region) - You can request a quota increase using the Service Quotas Console</p>"},{"location":"aws/storage/s3/#sse-s3-aws-managed-encryption","title":"SSE-S3 (AWS-Managed Encryption)","text":"<p>AWS provides default server-side encryption using keys entirely managed by Amazon. This method uses AES-256 encryption and is automatically enabled for new buckets and objects. When using SSE-S3, AWS handles all aspects of key management, simplifying the encryption process for users. Must set header <code>\"x-amz-server-side-encryption\": \"AES256\"</code></p>"},{"location":"aws/storage/s3/#sse-kms-aws-key-management-service","title":"SSE-KMS (AWS Key Management Service)","text":"<p>This encryption method leverages AWS Key Management Service for enhanced control and auditability. Users can manage encryption keys through KMS, enabling granular control and the ability to track key usage via CloudTrail. However, users should be aware of KMS request quotas, which vary by region and may require service quota increases for high-volume operations. Must set header <code>\"x-amz-server-side-encryption\": \"aws:kms\"</code></p>"},{"location":"aws/storage/s3/#sse-c-customer-provided-keys","title":"SSE-C (Customer-Provided Keys)","text":"For organizations requiring complete key management control, SSE-C allows customers to manage their encryption keys externally from AWS. Critical requirements include using HTTPS and providing encryption keys with every HTTP request. Importantly, Amazon S3 does not store the provided encryption keys, maintaining maximum customer control."},{"location":"aws/storage/s3/#client-side-encryption","title":"Client-Side Encryption","text":"<p>In client-side encryption, data is encrypted by the client before transmission to Amazon S3. Clients use specialized libraries like the Amazon S3 Client-Side Encryption Library, managing the entire encryption lifecycle independently. This approach provides maximum control but requires more complex implementation.</p>"},{"location":"aws/storage/s3/#encryption-in-transit","title":"Encryption in Transit","text":"<p>Amazon S3 supports encryption during data transfer through SSL/TLS. While HTTP endpoints exist, HTTPS is strongly recommended and mandatory for certain encryption methods like SSE-C. Most clients default to the encrypted HTTPS endpoint, ensuring secure data transmission.</p>"},{"location":"aws/storage/s3/#access-control-and-security-mechanisms","title":"Access Control and Security Mechanisms","text":""},{"location":"aws/storage/s3/#bucket-policies-and-encryption-enforcement","title":"Bucket Policies and Encryption Enforcement","text":"<p>S3 allows enforcing encryption through bucket policies. Administrators can configure policies to reject API calls that do not include proper encryption headers, ensuring all stored objects meet security requirements. These policies are evaluated before default encryption settings.</p>"},{"location":"aws/storage/s3/#multi-factor-authentication-mfa-delete","title":"Multi-Factor Authentication (MFA) Delete","text":"<p>For critical buckets, MFA Delete provides an additional security layer. Bucket owners can require multi-factor authentication for sensitive operations like permanently deleting object versions or suspending versioning.</p>"},{"location":"aws/storage/s3/#access-points","title":"Access Points","text":"<p>S3 Access Points simplify security management by providing: - Unique DNS names - Granular access policies - VPC-origin configurations for enhanced network security</p>"},{"location":"aws/storage/s3/#logging-and-auditing","title":"Logging and Auditing","text":"<p>S3 supports comprehensive access logging, recording all bucket access attempts regardless of authorization status. These logs can be stored in a separate S3 bucket and analyzed using various data tools, enabling thorough security monitoring.</p>"},{"location":"aws/storage/s3/#cross-origin-resource-sharing-cors","title":"Cross-Origin Resource Sharing (CORS)","text":"<p>S3 supports CORS, allowing controlled cross-origin web browser requests. By configuring CORS headers, administrators can specify which origins can interact with S3 resources, enhancing web application security.</p>"},{"location":"aws/storage/s3/#pre-signed-urls","title":"Pre-Signed URLs","text":"<p>For temporary, controlled access, S3 generates pre-signed URLs with configurable expiration. These URLs inherit the permissions of the generating user, enabling secure, time-limited access to specific objects.</p>"},{"location":"aws/storage/s3/#advanced-security-features-s3-object-lambda","title":"Advanced Security Features: S3 Object Lambda","text":"<p>S3 Object Lambda introduces dynamic object transformation using AWS Lambda functions. This feature allows real-time modifications like: - Redacting sensitive information - Converting data formats - Dynamically modifying object content before retrieval</p> <p>By integrating these security strategies, AWS S3 provides a comprehensive, flexible approach to data protection, giving users multiple options to secure their cloud storage infrastructure.</p>"},{"location":"aws/storage/s3/#best-practices-for-encryption","title":"Best Practices for Encryption","text":"<ol> <li>Key Management</li> <li>Regularly rotate encryption keys</li> <li>Use different keys for different environments</li> <li>Implement key backup and recovery procedures</li> <li> <p>Monitor key usage with CloudTrail</p> </li> <li> <p>Policy Enforcement</p> </li> <li>Use bucket policies to enforce encryption</li> <li>Implement default encryption at bucket level</li> <li>Regular audit of encryption settings</li> <li> <p>Monitor for encryption-related events</p> </li> <li> <p>Compliance</p> </li> <li>Document encryption procedures</li> <li>Regular compliance audits</li> <li>Maintain encryption configuration inventory</li> <li>Test key rotation procedures</li> </ol>"},{"location":"aws/storage/s3/#data-management","title":"Data Management","text":""},{"location":"aws/storage/s3/#lifecycle-rules","title":"Lifecycle Rules","text":"<pre><code>{\n    \"Rules\": [\n        {\n            \"Status\": \"Enabled\",\n            \"Transition\": {\n                \"Days\": 30,\n                \"StorageClass\": \"STANDARD_IA\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"aws/storage/s3/#event-notifications","title":"Event Notifications","text":"<ul> <li>Triggers on object operations</li> <li>Destinations:</li> <li>SNS</li> <li>SQS</li> <li>Lambda</li> </ul>"},{"location":"aws/storage/s3/#performance-optimization","title":"Performance Optimization","text":""},{"location":"aws/storage/s3/#best-practices","title":"Best Practices","text":"<ol> <li>Prefix Naming</li> <li>Use random prefixes for high throughput</li> <li> <p>Example: <code>hex-hash/filename</code> instead of <code>date/filename</code></p> </li> <li> <p>Multipart Upload</p> </li> <li>Recommended for files &gt; 100MB</li> <li>Required for files &gt; 5GB</li> <li> <p>Parallel upload capability</p> </li> <li> <p>Transfer Acceleration</p> </li> <li>Uses CloudFront edge locations</li> <li>Faster long-distance transfers</li> <li>Additional cost per GB</li> </ol>"},{"location":"aws/storage/s3/#monitoring-and-analytics","title":"Monitoring and Analytics","text":""},{"location":"aws/storage/s3/#cloudwatch-metrics","title":"CloudWatch Metrics","text":"<ul> <li>Request metrics</li> <li>Replication metrics</li> <li>Storage metrics</li> </ul>"},{"location":"aws/storage/s3/#s3-analytics","title":"S3 Analytics","text":"<ul> <li>Storage class analysis</li> <li>Access pattern insights</li> <li>Lifecycle optimization recommendations</li> </ul>"},{"location":"aws/storage/s3/#storage-lens","title":"Storage Lens","text":"<ul> <li>Organization-wide visibility</li> <li>Usage and activity metrics</li> <li>Recommendations for optimization</li> </ul>"},{"location":"aws/storage/s3/#common-operations","title":"Common Operations","text":""},{"location":"aws/storage/s3/#basic-operations","title":"Basic Operations","text":"<pre><code># Upload file\naws s3 cp file.txt s3://bucket-name/\n\n# Download file\naws s3 cp s3://bucket-name/file.txt .\n\n# List objects\naws s3 ls s3://bucket-name/\n\n# Delete object\naws s3 rm s3://bucket-name/file.txt\n</code></pre>"},{"location":"aws/storage/s3/#bucket-operations","title":"Bucket Operations","text":"<pre><code># Create bucket\naws s3 mb s3://bucket-name\n\n# Delete bucket\naws s3 rb s3://bucket-name\n\n# Sync directories\naws s3 sync local-dir s3://bucket-name/remote-dir\n</code></pre>"},{"location":"aws/storage/s3/#cost-optimization","title":"Cost Optimization","text":""},{"location":"aws/storage/s3/#cost-components","title":"Cost Components","text":"<ol> <li>Storage pricing</li> <li>Per GB-month rates</li> <li> <p>Varies by storage class</p> </li> <li> <p>Request pricing</p> </li> <li>PUT, COPY, POST, LIST</li> <li> <p>GET, SELECT, and retrieval</p> </li> <li> <p>Data transfer</p> </li> <li>Inbound: usually free</li> <li>Outbound: charged per GB</li> </ol>"},{"location":"aws/storage/s3/#cost-reduction-strategies","title":"Cost Reduction Strategies","text":"<ol> <li>Use appropriate storage classes</li> <li>Implement lifecycle policies</li> <li>Enable compression</li> <li>Monitor usage with Cost Explorer</li> <li>Use S3 Analytics for optimization</li> </ol>"},{"location":"aws/storage/s3/#integration-with-other-aws-services","title":"Integration with Other AWS Services","text":"<ul> <li>CloudFront (Content Distribution)</li> <li>Lambda (Serverless Computing)</li> <li>Athena (SQL Queries)</li> <li>EMR (Big Data Processing)</li> <li>Redshift (Data Warehousing)</li> <li>CloudTrail (Audit Logging)</li> </ul>"},{"location":"aws/storage/s3/#best-practices_1","title":"Best Practices","text":""},{"location":"aws/storage/s3/#security_1","title":"Security","text":"<ol> <li>Enable encryption at rest</li> <li>Use VPC endpoints</li> <li>Implement least privilege access</li> <li>Enable access logging</li> <li>Regular security audits</li> </ol>"},{"location":"aws/storage/s3/#performance","title":"Performance","text":"<ol> <li>Use multipart upload</li> <li>Implement retry mechanism</li> <li>Use appropriate prefix strategy</li> <li>Enable transfer acceleration</li> <li>Implement caching where appropriate</li> </ol>"},{"location":"aws/storage/s3/#durability","title":"Durability","text":"<ol> <li>Enable versioning</li> <li>Implement cross-region replication</li> <li>Regular backup validation</li> <li>Monitor data integrity</li> <li>Test restore procedures</li> </ol>"},{"location":"aws/storage/s3/#troubleshooting","title":"Troubleshooting","text":""},{"location":"aws/storage/s3/#common-issues","title":"Common Issues","text":"<ol> <li>Access Denied</li> <li>Check IAM permissions</li> <li>Verify bucket policy</li> <li> <p>Check object ACLs</p> </li> <li> <p>Slow Performance</p> </li> <li>Review prefix strategy</li> <li>Check multipart upload usage</li> <li> <p>Verify network configuration</p> </li> <li> <p>Error Responses</p> </li> <li>403: Permission issues</li> <li>404: Object not found</li> <li>503: Service unavailable</li> </ol>"},{"location":"aws/storage/s3/#resources","title":"Resources","text":"<ul> <li>Official S3 Documentation</li> <li>S3 Best Practices</li> <li>S3 Pricing</li> <li>S3 FAQ</li> </ul>"},{"location":"aws/tools/cloud9/","title":"Cloud9","text":""},{"location":"aws/tools/cloud9/#overview","title":"Overview","text":"<p>AWS Cloud9 is a cloud-based integrated development environment (IDE) that allows developers to write, run, and debug code directly from a web browser.</p>"},{"location":"aws/tools/cloud9/#key-features","title":"Key Features","text":""},{"location":"aws/tools/cloud9/#development-environment","title":"Development Environment","text":"<ul> <li>Fully cloud-hosted IDE</li> <li>Accessible from any device with a web browser</li> <li>Eliminates local development environment setup</li> <li>Supports multiple programming languages</li> </ul>"},{"location":"aws/tools/cloud9/#collaboration-capabilities","title":"Collaboration Capabilities","text":"<ul> <li>Real-time code editing</li> <li>Shared development environments</li> <li>Live pair programming</li> <li>Built-in chat and communication tools</li> </ul>"},{"location":"aws/tools/cloud9/#development-tools","title":"Development Tools","text":"<ul> <li>Terminal access</li> <li>Code editor with syntax highlighting</li> <li>Integrated debugger</li> <li>Built-in package manager</li> <li>Version control integration</li> </ul>"},{"location":"aws/tools/cloud9/#language-and-runtime-support","title":"Language and Runtime Support","text":"<ul> <li>Multiple programming language support:</li> <li>Python</li> <li>JavaScript</li> <li>Node.js</li> <li>C++</li> <li>PHP</li> <li>And more</li> </ul>"},{"location":"aws/tools/cloud9/#aws-integration","title":"AWS Integration","text":"<ul> <li>Direct access to AWS services</li> <li>Pre-configured AWS CLI</li> <li>Simple environment management</li> <li>Seamless interaction with AWS resources</li> </ul>"},{"location":"aws/tools/cloud9/#benefits","title":"Benefits","text":"<ul> <li>No local software installation required</li> <li>Consistent development environment</li> <li>Easy team collaboration</li> <li>Reduced setup complexity</li> <li>Quick start for development projects</li> </ul>"},{"location":"aws/tools/cloud9/#use-cases","title":"Use Cases","text":"<ul> <li>Web application development</li> <li>Serverless application testing</li> <li>Cloud-native development</li> <li>Remote coding</li> <li>Quick prototyping</li> <li>Learning and training</li> </ul>"},{"location":"aws/tools/cloud9/#security","title":"Security","text":"<ul> <li>Isolated development environments</li> <li>AWS Identity and Access Management (IAM) integration</li> <li>Secure access controls</li> <li>Managed by AWS infrastructure</li> </ul>"},{"location":"aws/tools/codeartifact/","title":"CodeArtifact","text":""},{"location":"aws/tools/codeartifact/#overview","title":"Overview","text":"<p>Modern software development relies heavily on code dependencies, where software packages interconnect and depend on each other for successful builds. As development progresses, new dependencies are continuously created, making artifact management - the process of storing and retrieving these dependencies - a crucial aspect of the development lifecycle.</p> <p>Traditionally, organizations needed to invest significant resources in setting up and maintaining their own artifact management systems. AWS CodeArtifact eliminates this overhead by providing a secure, scalable, and cost-effective artifact management solution specifically designed for software development teams.</p>"},{"location":"aws/tools/codeartifact/#integration-with-package-managers","title":"Integration with Package Managers","text":"<p>CodeArtifact offers seamless integration with popular dependency management tools that developers use in their daily workflows. The service supports a wide range of package managers including:</p> <ul> <li>Maven and Gradle for Java dependencies</li> <li>npm and yarn for JavaScript and Node.js packages</li> <li>twine and pip for Python packages</li> <li>NuGet for .NET dependencies</li> </ul> <p>This broad compatibility ensures that developers can continue using their preferred tools while leveraging CodeArtifact\u2019s enterprise-grade capabilities. Furthermore, AWS CodeBuild can directly retrieve dependencies from CodeArtifact, streamlining the continuous integration process.</p>"},{"location":"aws/tools/codeartifact/#resource-policy-and-access-management","title":"Resource Policy and Access Management","text":"<p>CodeArtifact implements a straightforward but powerful access control mechanism through its resource policy feature. This policy framework enables cross-account access to CodeArtifact repositories, facilitating collaboration across different AWS accounts within an organization.</p> <p>A notable characteristic of CodeArtifact\u2019s access control is its all-or-nothing approach to package access: when a principal (user or role) is granted access to a repository, they can either read all packages within that repository or none at all. This simplifies access management while ensuring consistent security controls across all packages within a repository.</p>"},{"location":"aws/tools/codebuild/","title":"CodeBuild","text":""},{"location":"aws/tools/codebuild/#overview","title":"Overview","text":"<p>AWS CodeBuild represents Amazon\u2019s fully managed continuous integration service, designed to eliminate the operational overhead of managing build servers. Unlike traditional CI tools such as Jenkins that require server provisioning and maintenance, CodeBuild automatically scales to meet your build requirements without managing infrastructure or build queues.</p> <p>The service handles essential development tasks including source code compilation, test execution, and software package creation. By charging only for the compute time consumed during builds, CodeBuild offers a cost-effective solution for development teams of any size.</p>"},{"location":"aws/tools/codebuild/#technical-architecture","title":"Technical Architecture","text":"<p>At its foundation, CodeBuild utilizes Docker containers to ensure consistent and reproducible builds across different environments. Developers can choose from AWS\u2019s prepackaged Docker images or create custom images to meet specific build requirements. This containerized approach guarantees that builds remain consistent across different environments and team members.</p> <p></p>"},{"location":"aws/tools/codebuild/#security-framework","title":"Security Framework","text":"<p>CodeBuild implements a comprehensive security model that integrates with multiple AWS services. Build artifacts are protected through AWS Key Management Service (KMS) encryption, while AWS Identity and Access Management (IAM) handles access controls and permissions. For network security, CodeBuild can operate within Virtual Private Clouds (VPCs). All API interactions are logged through AWS CloudTrail, providing a complete audit trail of build activities.</p>"},{"location":"aws/tools/codebuild/#source-control-integration","title":"Source Control Integration","text":"<p>CodeBuild seamlessly integrates with various source code repositories including AWS CodeCommit, Amazon S3, Bitbucket, and GitHub. This flexibility allows teams to maintain their existing version control workflows while leveraging CodeBuild\u2019s capabilities.</p>"},{"location":"aws/tools/codebuild/#build-configuration-and-monitoring","title":"Build Configuration and Monitoring","text":"<p>Build instructions can be defined either through a buildspec.yml file in the source code repository or manually through the AWS Console. Build outputs and logs are automatically stored in Amazon S3 and CloudWatch Logs for easy access and archival.</p> <p>The service provides comprehensive monitoring capabilities through CloudWatch Metrics, enabling teams to track build statistics and performance metrics. Amazon EventBridge integration allows for automated notifications on build failures, while CloudWatch Alarms can be configured to alert based on specific failure thresholds.</p> <p>CodeBuild projects can be managed independently or integrated into broader CI/CD workflows through AWS CodePipeline, offering flexibility in pipeline design and implementation.</p>"},{"location":"aws/tools/codebuild/#supported-development-environments","title":"Supported Development Environments","text":"<p>CodeBuild provides native support for numerous programming languages and frameworks including: Java, Ruby, Python, Go, Node.js, Android, .NET Core, and PHP. The Docker support enables teams to extend these environments or create entirely custom build environments as needed.</p>"},{"location":"aws/tools/codebuild/#buildspec-configuration","title":"BuildSpec Configuration","text":"<p>The buildspec.yml file serves as the blueprint for your build process and must be located at the root of your source code repository. This file contains several key sections:</p>"},{"location":"aws/tools/codebuild/#environment-variables","title":"Environment Variables","text":"<p>CodeBuild supports various types of environment variables, from plaintext variables for basic configuration to more secure options using AWS Systems Manager Parameter Store or AWS Secrets Manager for sensitive information.</p>"},{"location":"aws/tools/codebuild/#build-phases","title":"Build Phases","text":"<p>The build process is organized into distinct phases:</p> <ul> <li>The <code>install</code> phase handles dependency installation and initial setup requirements. </li> <li>During the <code>pre-build</code> phase, final preparations and validations occur before the main build process. </li> <li>The <code>build</code> phase executes the primary build commands</li> <li>The <code>post-build</code> phase handles final tasks such as packaging and preparing artifacts for deployment.</li> </ul>"},{"location":"aws/tools/codebuild/#artifacts-and-caching","title":"Artifacts and Caching","text":"<p>Build outputs designated as artifacts are automatically uploaded to S3 with KMS encryption. To optimize build performance, CodeBuild supports caching of specified files (typically dependencies) to S3, significantly reducing build times for subsequent executions by reusing cached components.</p> <p>This caching mechanism is particularly valuable for projects with substantial dependencies, as it can dramatically improve build efficiency by eliminating the need to repeatedly download and process unchanged dependencies.</p>"},{"location":"aws/tools/codecommit/","title":"CodeCommit","text":""},{"location":"aws/tools/codecommit/#introduction-to-aws-codecommit","title":"Introduction to AWS CodeCommit","text":"<p>AWS CodeCommit is a fully managed source control service provided by Amazon Web Services that enables organizations to host secure and scalable private Git repositories. Designed as a cloud-based version control system, CodeCommit facilitates collaborative software development by offering robust repository management without the need for self-hosted infrastructure.</p>"},{"location":"aws/tools/codecommit/#core-architectural-features","title":"Core Architectural Features","text":""},{"location":"aws/tools/codecommit/#repository-management","title":"Repository Management","text":"<p>CodeCommit provides a comprehensive platform for creating, managing, and interacting with Git repositories. Developers can seamlessly store and version their source code, documentation, and binary files within a secure, highly available cloud environment. The service supports standard Git commands and integrates natively with existing development workflows.</p>"},{"location":"aws/tools/codecommit/#security-and-access-control","title":"Security and Access Control","text":"<p>Security represents a fundamental design principle of CodeCommit. The service leverages AWS Identity and Access Management (IAM) to implement granular access controls. Organizations can define precise repository permissions, controlling who can view, modify, or delete repository contents.  Multi-factor authentication and encryption at rest and in transit ensure comprehensive data protection.</p> <ul> <li>Repositories are automatically encrypted at rest using AWS KMS.</li> <li>Encryption in transit is guaranteed by using HTTPS or SSH.</li> </ul> <p>For cross-account access sharing use a IAM Role and STS AssumeRole</p>"},{"location":"aws/tools/codecommit/#integration-capabilities","title":"Integration Capabilities","text":""},{"location":"aws/tools/codecommit/#aws-development-ecosystem","title":"AWS Development Ecosystem","text":"<p>CodeCommit seamlessly integrates with other AWS development and deployment services, creating a cohesive software development lifecycle. Developers can easily connect CodeCommit repositories with services like AWS CodeBuild, CodePipeline, and CodeDeploy, enabling streamlined continuous integration and continuous deployment (CI/CD) workflows.</p>"},{"location":"aws/tools/codecommit/#development-tool-compatibility","title":"Development Tool Compatibility","text":"<p>The service supports standard Git client tools, including command-line interfaces, desktop applications, and integrated development environments. Developers can utilize familiar Git workflows without requiring significant tool modifications or learning new interfaces.</p>"},{"location":"aws/tools/codecommit/#authentication-mechanisms","title":"Authentication Mechanisms","text":""},{"location":"aws/tools/codecommit/#iam-user-authentication","title":"IAM User Authentication","text":"<p>AWS provides multiple authentication methods for accessing CodeCommit repositories. IAM users can generate:</p> <ul> <li>SSH Keys: User can generate SSH Keys in the IAM console</li> <li>HTTPS: with AWS CLI Credentials helper or Git Credentials for IAM User</li> </ul> <p>The credential management system allows for easy rotation and revocation of access keys.</p>"},{"location":"aws/tools/codecommit/#federated-access","title":"Federated Access","text":"<p>Organizations using corporate directory services can implement federated access through AWS Single Sign-On (SSO) or third-party identity providers. This approach simplifies authentication while maintaining robust security standards.</p>"},{"location":"aws/tools/codecommit/#repository-management-features","title":"Repository Management Features","text":""},{"location":"aws/tools/codecommit/#branch-protection","title":"Branch Protection","text":"<p>CodeCommit enables sophisticated branch management strategies. Administrators can implement branch protection rules, requiring pull request reviews before merging code into critical branches. These governance mechanisms help maintain code quality and enforce collaborative development practices.</p>"},{"location":"aws/tools/codecommit/#metadata-and-tagging","title":"Metadata and Tagging","text":"<p>Repositories support comprehensive metadata management. Developers can attach tags and annotations to commits, facilitating better tracking and documentation of code changes. These metadata features enhance traceability and support advanced repository management strategies.</p>"},{"location":"aws/tools/codecommit/#performance-and-scalability","title":"Performance and Scalability","text":""},{"location":"aws/tools/codecommit/#storage-and-performance","title":"Storage and Performance","text":"<p>CodeCommit automatically scales to accommodate repositories of varying sizes. The service supports repositories containing large files and complex version histories while maintaining high performance. AWS manages the underlying infrastructure, ensuring consistent repository access and minimal latency.</p>"},{"location":"aws/tools/codecommit/#global-accessibility","title":"Global Accessibility","text":"<p>Repositories are designed with global accessibility in mind. Distributed teams can collaborate effectively, with AWS providing low-latency access across multiple geographic regions.</p>"},{"location":"aws/tools/codecommit/#pricing-and-cost-management","title":"Pricing and Cost Management","text":""},{"location":"aws/tools/codecommit/#pricing-structure","title":"Pricing Structure","text":"<p>AWS CodeCommit offers a flexible pricing model based on active repository storage and data transfer. The service provides a generous free tier, allowing small teams and individual developers to leverage its capabilities without immediate financial commitment.</p>"},{"location":"aws/tools/codecommit/#use-cases","title":"Use Cases","text":""},{"location":"aws/tools/codecommit/#enterprise-software-development","title":"Enterprise Software Development","text":"<p>CodeCommit serves diverse software development scenarios, from small startup projects to large enterprise applications. Its robust security, scalability, and integration capabilities make it suitable for complex software development environments.</p>"},{"location":"aws/tools/codecommit/#open-source-project-management","title":"Open Source Project Management","text":"<p>While primarily designed for private repositories, CodeCommit can support open-source project management strategies, providing a secure and reliable version control platform.</p>"},{"location":"aws/tools/codecommit/#best-practices","title":"Best Practices","text":""},{"location":"aws/tools/codecommit/#repository-design","title":"Repository Design","text":"<p>Implement clear branching strategies, utilize meaningful commit messages, and leverage CodeCommit\u2019s advanced features like branch protection and pull request reviews.</p>"},{"location":"aws/tools/codecommit/#security-configuration","title":"Security Configuration","text":"<p>Regularly audit IAM permissions, implement least-privilege access models, and utilize multi-factor authentication to enhance repository security.</p>"},{"location":"aws/tools/codecommit/#limitations-and-considerations","title":"Limitations and Considerations","text":""},{"location":"aws/tools/codecommit/#service-constraints","title":"Service Constraints","text":"<p>CodeCommit imposes certain limitations on repository size, number of branches, and data transfer. Organizations should review these constraints during architectural planning.</p>"},{"location":"aws/tools/codecommit/#conclusion","title":"Conclusion","text":"<p>AWS CodeCommit represents a sophisticated, secure, and scalable source control solution integrated deeply within the AWS ecosystem. By providing a robust, managed Git repository service, AWS empowers development teams to collaborate effectively while maintaining high security and performance standards.</p>"},{"location":"aws/tools/codedeploy/","title":"CodeDeploy","text":""},{"location":"aws/tools/codedeploy/#overview","title":"Overview","text":"<p>AWS CodeDeploy is an automated deployment service that streamlines the process of deploying applications across various AWS compute platforms. The service supports deployments to Amazon EC2 instances, on-premises servers, AWS Lambda functions, and Amazon ECS services. CodeDeploy provides sophisticated deployment control features, including automated rollback capabilities triggered by deployment failures or CloudWatch alarms. The entire deployment process is defined in an appspec.yml file.</p> <p></p>"},{"location":"aws/tools/codedeploy/#platform-support","title":"Platform Support","text":""},{"location":"aws/tools/codedeploy/#ec2-and-on-premises-platform","title":"EC2 and On-premises Platform","text":"<p>CodeDeploy provides comprehensive support for deploying applications to EC2 instances and on-premises servers. The service supports both in-place and blue/green deployment strategies, with the requirement that target instances run the CodeDeploy Agent.</p> <p>Deployment speeds can be customized through various options:</p> <ul> <li>AllAtOnce: Fastest deployment with maximum downtime</li> <li>HalfAtATime: Balanced approach with 50% capacity reduction</li> <li>OneAtATime: Minimal availability impact with longest deployment time</li> <li>Custom: User-defined percentage-based deployment</li> </ul>"},{"location":"aws/tools/codedeploy/#lambda-platform","title":"Lambda Platform","text":"<p>For Lambda deployments, CodeDeploy automates traffic shifting for Lambda aliases, featuring tight integration with the AWS Serverless Application Model (SAM) framework. Traffic shifting patterns include:</p> <p>Linear deployments:</p> <ul> <li>LambdaLinear10PercentEvery3Minutes</li> <li>LambdaLinear10PercentEvery10Minutes</li> </ul> <p>Canary deployments:</p> <ul> <li>LambdaCanary10Percent5Minutes</li> <li>LambdaCanary10Percent30Minutes</li> </ul> <p>AllAtOnce deployment for immediate traffic shifting</p>"},{"location":"aws/tools/codedeploy/#ecs-platform","title":"ECS Platform","text":"<p>CodeDeploy automates the deployment of new ECS Task Definitions exclusively through blue/green deployments. Traffic shifting patterns include:</p> <p>Linear deployments:</p> <ul> <li>ECSLinear10PercentEvery3Minutes</li> <li>ECSLinear10PercentEvery10Minutes</li> </ul> <p>Canary deployments:</p> <ul> <li>ECSCanary10Percent5Minutes</li> <li>ECSCanary10Percent30Minutes</li> </ul> <p>AllAtOnce deployment for immediate updates</p>"},{"location":"aws/tools/codedeploy/#codedeploy-agent","title":"CodeDeploy Agent","text":"<p>The CodeDeploy Agent is a crucial component that must be running on target EC2 instances prior to deployment. The agent can be automatically installed and updated using AWS Systems Manager. Instances must have appropriate IAM permissions to access deployment bundles stored in Amazon S3.</p>"},{"location":"aws/tools/codedeploy/#deployment-configurations","title":"Deployment Configurations","text":""},{"location":"aws/tools/codedeploy/#ec2-deployment-process","title":"EC2 Deployment Process","text":"<p>Deployments to EC2 instances are governed by the appspec.yml file and the chosen deployment strategy. The process supports deployment hooks for verification at various phases of the deployment lifecycle.</p>"},{"location":"aws/tools/codedeploy/#auto-scaling-group-integration","title":"Auto Scaling Group Integration","text":"<p>In-place Deployments:</p> <ul> <li>Updates existing EC2 instances</li> <li>Automatically includes newly created instances in the deployment process</li> </ul> <p>Blue/Green Deployments:</p> <ul> <li>Creates a new Auto Scaling Group with copied settings</li> <li>Requires an Elastic Load Balancer</li> <li>Allows customization of instance retention period for the old ASG</li> </ul>"},{"location":"aws/tools/codedeploy/#rollback-management","title":"Rollback Management","text":"<p>CodeDeploy offers flexible rollback capabilities to maintain application reliability:</p> <p>Automatic Rollbacks:</p> <ul> <li>Triggered by deployment failures</li> <li>Initiated when CloudWatch Alarm thresholds are exceeded</li> </ul> <p>Manual Rollbacks:</p> <ul> <li>User-initiated rollback to previous version</li> <li>Option to disable rollbacks for specific deployments</li> </ul> <p>When a rollback occurs, CodeDeploy creates a new deployment using the last known good revision rather than restoring a previous version. This approach ensures consistent deployment processes and maintains deployment history.</p>"},{"location":"aws/tools/codedeploy/#best-practices","title":"Best Practices","text":"<ul> <li>Thoroughly test deployment configurations in non-production environments</li> <li>Implement appropriate CloudWatch Alarms for automated rollbacks</li> <li>Maintain proper version control of your appspec.yml file</li> <li>Regular monitoring and maintenance of the CodeDeploy Agent</li> <li>Implement appropriate security controls and IAM permissions</li> <li>Use deployment hooks effectively for validation</li> <li>Maintain comprehensive documentation of deployment configurations</li> </ul>"},{"location":"aws/tools/codeguru/","title":"CodeGuru","text":""},{"location":"aws/tools/codeguru/#overview","title":"Overview","text":"<p>Amazon CodeGuru is a machine learning-powered service that provides automated code reviews and application performance monitoring. The service consists of two main components: CodeGuru Reviewer for static code analysis during development, and CodeGuru Profiler for runtime performance analysis in production environments.</p>"},{"location":"aws/tools/codeguru/#codeguru-reviewer","title":"CodeGuru Reviewer","text":"<p>CodeGuru Reviewer leverages machine learning and automated reasoning to perform sophisticated code analysis. The service has been trained on millions of code reviews from thousands of open-source and Amazon repositories, incorporating extensive real-world experience into its analysis capabilities.</p> <p>The reviewer excels at identifying critical issues that might otherwise go unnoticed, including:</p> <ul> <li>Security vulnerabilities</li> <li>Resource leaks</li> <li>Input validation problems</li> <li>Deviations from coding best practices</li> <li>Hard-to-detect bugs</li> </ul> <p>Currently, CodeGuru Reviewer supports Java and Python codebases and integrates seamlessly with popular version control systems including GitHub and Bitbucket.</p>"},{"location":"aws/tools/codeguru/#codeguru-profiler","title":"CodeGuru Profiler","text":"<p>CodeGuru Profiler provides deep insights into application runtime behavior, helping developers understand and optimize their applications\u2019 performance characteristics. This component is particularly valuable for identifying resource-intensive operations, such as excessive CPU usage in routine operations like logging.</p>"},{"location":"aws/tools/codeguru/#key-profiler-features","title":"Key Profiler Features","text":"<p>The profiler offers comprehensive performance optimization capabilities by helping developers identify and eliminate code inefficiencies. This leads to improved application performance, particularly in areas of CPU utilization, ultimately resulting in decreased compute costs.</p> <p>Memory management is another crucial aspect of the profiler, which provides detailed heap summaries to help developers identify objects consuming excessive memory. The service also includes anomaly detection capabilities to identify unusual behavior patterns.</p> <p>The profiler supports applications running both on AWS infrastructure and on-premise environments, with minimal performance impact on the monitored applications.</p>"},{"location":"aws/tools/codeguru/#agent-configuration-parameters","title":"Agent Configuration Parameters","text":"<p>CodeGuru Profiler\u2019s agent can be fine-tuned through several important configuration parameters:</p> <p>MaxStackDepth: This parameter controls the maximum depth of stack traces that the profiler analyzes. For instance, in a call chain where method A calls B, which calls C, which then calls D (depth of 4), setting MaxStackDepth to 2 would limit analysis to methods A and B only.</p> <p>MemoryUsageLimitPercent: Defines the maximum percentage of system memory that the profiler can utilize during its operation.</p> <p>MinimumTimeForReportingInMilliseconds: Establishes the minimum interval between successive profiling reports, measured in milliseconds.</p> <p>ReportingIntervalInMilliseconds: Determines how frequently the profiler sends its collected data, specified in milliseconds.</p> <p>SamplingIntervalInMilliseconds: Controls how often the profiler collects sample data, measured in milliseconds. Reducing this value increases the sampling rate, providing more detailed profiling data at the cost of increased overhead.</p>"},{"location":"aws/tools/codeguru/#performance-considerations","title":"Performance Considerations","text":"<p>The profiler is designed to maintain minimal overhead on application performance, making it suitable for use in production environments. However, careful configuration of the sampling and reporting intervals is recommended to balance between detailed profiling data and system performance impact.</p>"},{"location":"aws/tools/codeguru/#integration-capabilities","title":"Integration Capabilities","text":"<p>CodeGuru works alongside existing development tools and processes, making it an adaptable addition to various development environments. Its insights can be integrated into continuous integration/continuous deployment (CI/CD) pipelines to automate performance monitoring and code quality checks.</p>"},{"location":"aws/tools/codepipeline/","title":"CodePipeline","text":""},{"location":"aws/tools/codepipeline/#overview","title":"Overview","text":"<p>AWS CodePipeline serves as a fully managed continuous integration and continuous delivery (CI/CD) service that enables users to create visual workflows for their software release process. This service orchestrates the entire development pipeline from source code through deployment.</p>"},{"location":"aws/tools/codepipeline/#integration-capabilities","title":"Integration Capabilities","text":"<p>CodePipeline offers extensive integration with various services across different stages of the development process:</p>"},{"location":"aws/tools/codepipeline/#source-control-integration","title":"Source Control Integration","text":"<p>CodePipeline can pull source code from multiple repositories including AWS CodeCommit, Amazon ECR, Amazon S3, Bitbucket, and GitHub. This flexibility allows teams to maintain their preferred source control solutions while leveraging CodePipeline\u2019s capabilities.</p>"},{"location":"aws/tools/codepipeline/#build-service-integration","title":"Build Service Integration","text":"<p>The service seamlessly connects with various build tools including AWS CodeBuild, Jenkins, CloudBees, and TeamCity. This enables teams to maintain their existing build processes while incorporating them into an automated pipeline.</p>"},{"location":"aws/tools/codepipeline/#testing-integration","title":"Testing Integration","text":"<p>For testing purposes, CodePipeline integrates with AWS CodeBuild, AWS Device Farm, and various third-party testing tools. This ensures comprehensive testing coverage across different aspects of the application.</p>"},{"location":"aws/tools/codepipeline/#deployment-options","title":"Deployment Options","text":"<p>CodePipeline supports multiple deployment targets including AWS CodeDeploy, Elastic Beanstalk, CloudFormation, Amazon ECS, and S3. This variety of deployment options accommodates different application architectures and hosting requirements.</p>"},{"location":"aws/tools/codepipeline/#advanced-workflows","title":"Advanced Workflows","text":"<p>For complex operations, CodePipeline can invoke AWS Lambda functions and AWS Step Functions, enabling sophisticated automation and orchestration capabilities.</p>"},{"location":"aws/tools/codepipeline/#pipeline-structure","title":"Pipeline Structure","text":"<p>CodePipeline organizes workflows into stages, with each stage capable of containing both sequential and parallel actions. A typical pipeline might flow from build to test to deploy, and then to load testing, with each stage performing specific actions in the software delivery process.</p> <p>The service also supports manual approval stages, which can be inserted at any point in the pipeline. This feature is particularly useful for controlling deployments to production environments or when human verification is required.</p>"},{"location":"aws/tools/codepipeline/#artifact-management","title":"Artifact Management","text":"<p>CodePipeline implements a robust artifact management system where each pipeline stage can generate artifacts. These artifacts are automatically stored in an Amazon S3 bucket and passed to subsequent stages, ensuring proper version control and traceability throughout the pipeline.</p>"},{"location":"aws/tools/codepipeline/#troubleshooting-and-monitoring","title":"Troubleshooting and Monitoring","text":""},{"location":"aws/tools/codepipeline/#event-monitoring","title":"Event Monitoring","text":"<p>CodePipeline integrates with Amazon EventBridge (formerly CloudWatch Events) to monitor pipeline, action, and stage execution state changes. This enables teams to:</p> <ul> <li>Create alerts for failed pipelines</li> <li>Monitor cancelled stages</li> <li>Track pipeline execution progress</li> <li>Set up automated responses to pipeline events</li> </ul>"},{"location":"aws/tools/codepipeline/#error-handling","title":"Error Handling","text":"<p>When a stage fails, the pipeline automatically stops, and detailed information is available in the AWS Management Console. Common issues often relate to IAM permissions, where the pipeline\u2019s service role may need additional permissions to perform certain actions.</p>"},{"location":"aws/tools/codepipeline/#audit-and-compliance","title":"Audit and Compliance","text":"<p>AWS CloudTrail integration provides comprehensive audit logging of all API calls made to CodePipeline, supporting security analysis, resource change tracking, and compliance auditing requirements.</p>"},{"location":"aws/tools/codepipeline/#best-practices","title":"Best Practices","text":"<p>To ensure optimal pipeline operation:</p> <ul> <li>Regularly review and update IAM roles and permissions</li> <li>Implement appropriate monitoring and alerting through EventBridge</li> <li>Use manual approval stages strategically in sensitive environments</li> <li>Maintain clear stage and action naming conventions</li> <li>Regularly clean up unused artifacts to manage storage costs</li> </ul>"},{"location":"gcp/","title":"Index","text":"<ul> <li>Connection (??)<ul> <li>Partner interconnect</li> <li>Dedicated interconnect</li> </ul> </li> <li>Databases</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/","title":"GKE Cluster Types","text":""},{"location":"gcp/kubernetes/cluster-types/#description","title":"Description","text":"<p>GKE offers two distinct cluster modes of operation: Standard and Autopilot. Each provides different levels of control, management responsibility, and pricing models. Understanding the differences is crucial for choosing the right cluster type for your workload.</p>"},{"location":"gcp/kubernetes/cluster-types/#standard-gke-clusters","title":"Standard GKE Clusters","text":""},{"location":"gcp/kubernetes/cluster-types/#description_1","title":"Description","text":"<p>Standard GKE clusters give you complete control over cluster configuration and node management. You\u2019re responsible for configuring node pools, managing scaling, security, and updates while Google manages the control plane.</p> <p>Model: You manage nodes, Google manages control plane.</p>"},{"location":"gcp/kubernetes/cluster-types/#key-features","title":"Key Features","text":""},{"location":"gcp/kubernetes/cluster-types/#full-node-control","title":"Full Node Control","text":"<ul> <li>Custom Machine Types: Choose any Compute Engine machine type</li> <li>Node Customization: Configure boot disk, local SSDs, GPUs, taints, labels</li> <li>SSH Access: Direct SSH access to nodes for debugging</li> <li>Custom Images: Use custom node images if needed</li> <li>DaemonSets: Run privileged pods on all nodes</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#flexible-node-pools","title":"Flexible Node Pools","text":"<ul> <li>Multiple Node Pools: Create pools with different machine types</li> <li>Node Taints and Labels: Control pod scheduling</li> <li>Spot VMs: Use preemptible/spot VMs for cost savings</li> <li>Node Pool Management: Manual or automated scaling per pool</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#networking-options","title":"Networking Options","text":"<ul> <li>Routes-Based: Traditional Kubernetes networking</li> <li>VPC-Native: Alias IP ranges (recommended)</li> <li>Network Policies: Calico or GKE Dataplane V2</li> <li>Private Clusters: No public IPs on nodes</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#advanced-features","title":"Advanced Features","text":"<ul> <li>Windows Node Pools: Run Windows containers</li> <li>Multi-Cluster Ingress: Share load balancers across clusters</li> <li>Config Connector: Manage GCP resources as Kubernetes objects</li> <li>Istio/ASM: Full service mesh capabilities</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#important-limits","title":"Important Limits","text":"Limit Value Notes Nodes per cluster 15,000 Across all node pools Node pools per cluster 1,000 Different configurations Pods per node 110 (default), 256 (max) Via \u2013max-pods-per-node Pods per cluster 200,000 Theoretical maximum Services per cluster 10,000 LoadBalancer type limited"},{"location":"gcp/kubernetes/cluster-types/#when-to-use-standard-gke","title":"When to Use Standard GKE","text":"<p>\u2705 Use Standard When:</p> <ol> <li> <p>Custom Infrastructure Requirements</p> </li> <li> <p>Need specific machine types or custom configurations</p> </li> <li>Require GPU or TPU nodes</li> <li>Need local SSDs for high-performance storage</li> <li> <p>Custom kernel modules or system-level modifications</p> </li> <li> <p>Full Control Over Nodes</p> </li> <li> <p>Need SSH access to nodes for debugging</p> </li> <li>Want to run privileged pods or DaemonSets</li> <li>Require custom node images</li> <li> <p>Need to configure node-level security</p> </li> <li> <p>Windows Workloads</p> </li> <li> <p>Running Windows containers</p> </li> <li>Mixed Linux/Windows workloads</li> <li> <p>.NET Framework applications</p> </li> <li> <p>Cost Optimization with Spot VMs</p> </li> <li> <p>Fault-tolerant batch workloads</p> </li> <li>CI/CD pipelines</li> <li>Development/testing environments</li> <li> <p>Up to 91% cost savings acceptable with interruptions</p> </li> <li> <p>Complex Networking Requirements</p> </li> <li> <p>Multiple network interfaces</p> </li> <li>Custom CNI plugins</li> <li>Advanced network policies</li> <li>Specific IP address management</li> </ol> <p>\u274c Don\u2019t Use Standard When:</p> <ol> <li> <p>Want Minimal Management</p> </li> <li> <p>Team lacks Kubernetes operations expertise</p> </li> <li>Prefer hands-off infrastructure management</li> <li> <p>Don\u2019t want to manage node scaling/updates</p> </li> <li> <p>Unpredictable Workloads</p> </li> <li> <p>Highly variable traffic patterns</p> </li> <li>Sporadic batch jobs</li> <li> <p>Cost efficiency more important than control</p> </li> <li> <p>Simplicity is Priority</p> </li> <li> <p>Small team without dedicated platform engineers</p> </li> <li>Rapid prototyping and development</li> <li>Quick time-to-market needed</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#pricing","title":"Pricing","text":"<p>Standard GKE Costs:</p> <ul> <li>Control Plane: </li> <li>Zonal clusters: Free</li> <li> <p>Regional clusters: $0.10/hour</p> </li> <li> <p>Nodes: Standard Compute Engine pricing</p> </li> <li>e2-medium: ~$0.03/hour</li> <li> <p>Spot VMs: ~$0.008/hour (up to 91% discount)</p> </li> <li> <p>Networking: Egress charges apply</p> </li> </ul> <p>Cost Optimization:</p> <pre><code># Use Spot VMs (preemptible) for cost savings\ngcloud container node-pools create spot-pool \\\n  --cluster=my-cluster \\\n  --machine-type=e2-medium \\\n  --spot \\\n  --num-nodes=3\n\n# Enable cluster autoscaling\ngcloud container clusters update my-cluster \\\n  --enable-autoscaling \\\n  --min-nodes=1 \\\n  --max-nodes=10\n</code></pre>"},{"location":"gcp/kubernetes/cluster-types/#autopilot-gke-clusters","title":"Autopilot GKE Clusters","text":""},{"location":"gcp/kubernetes/cluster-types/#description_2","title":"Description","text":"<p>Autopilot is a fully managed GKE mode where Google manages the entire cluster infrastructure including nodes, node pools, scaling, security, and networking. You only configure and deploy your pods.</p> <p>Model: Google manages everything, you manage workloads.</p>"},{"location":"gcp/kubernetes/cluster-types/#key-features_1","title":"Key Features","text":""},{"location":"gcp/kubernetes/cluster-types/#fully-managed-infrastructure","title":"Fully Managed Infrastructure","text":"<ul> <li>No Node Management: Google provisions and scales nodes automatically</li> <li>Automatic Scaling: Nodes scale based on pod resource requests</li> <li>Hardened Security: Security best practices enforced by default</li> <li>Automatic Updates: Both control plane and nodes updated automatically</li> <li>Optimized Configuration: Google-optimized settings for performance and cost</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#simplified-operations","title":"Simplified Operations","text":"<ul> <li>No Node Pools: Infrastructure abstracted away</li> <li>Per-Pod Billing: Pay only for CPU and memory requested by pods</li> <li>Resource-Based Scaling: Nodes added/removed based on pod requests</li> <li>Hands-Off Upgrades: No maintenance windows or disruption management</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#built-in-security","title":"Built-In Security","text":"<ul> <li>Workload Identity: Enabled by default</li> <li>Shielded Nodes: All nodes use shielded GKE nodes</li> <li>Secure by Default: Security best practices enforced</li> <li>No SSH Access: Nodes are not directly accessible (improved security)</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#restrictions-for-security-and-optimization","title":"Restrictions (for Security and Optimization)","text":"<ul> <li>No Privileged Pods: Cannot run privileged containers</li> <li>No Host Network: Pods can\u2019t use host networking</li> <li>No DaemonSets: With node selectors (some exceptions apply)</li> <li>Predefined Pod Resources: Must specify CPU/memory requests</li> <li>No Windows Nodes: Linux only</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#important-limits_1","title":"Important Limits","text":"Limit Value Notes Pods per cluster Auto-managed Scales based on demand Pod CPU request 0.25 to 32 vCPU In 0.25 vCPU increments Pod memory request 0.5 to 128 GB Specific ratios to CPU Ephemeral storage Up to 10 GB included Per pod Persistent volumes Unlimited (quota-based) Standard limits apply Services (LoadBalancer) Auto-managed Google handles capacity"},{"location":"gcp/kubernetes/cluster-types/#pod-resource-classes","title":"Pod Resource Classes","text":"<p>Autopilot uses predefined CPU-to-memory ratios:</p> Class CPU:Memory Ratio Example General Purpose 1:4 GB 1 vCPU : 4 GB RAM Scale-Out 1:1 GB 1 vCPU : 1 GB RAM Balanced 1:2 GB 1 vCPU : 2 GB RAM Memory-Optimized 1:6.5 GB 1 vCPU : 6.5 GB RAM"},{"location":"gcp/kubernetes/cluster-types/#when-to-use-autopilot-gke","title":"When to Use Autopilot GKE","text":"<p>\u2705 Use Autopilot When:</p> <ol> <li> <p>Minimal Operational Overhead</p> </li> <li> <p>Small team or no dedicated platform engineers</p> </li> <li>Want Google to handle all infrastructure decisions</li> <li>Prefer hands-off cluster management</li> <li> <p>Focus on application deployment, not infrastructure</p> </li> <li> <p>Unpredictable or Variable Workloads</p> </li> <li> <p>Traffic patterns vary significantly</p> </li> <li>Batch jobs with sporadic execution</li> <li>Development and testing environments</li> <li> <p>Cost efficiency through automatic scaling</p> </li> <li> <p>Security is Critical</p> </li> <li> <p>Want hardened defaults</p> </li> <li>Need compliance with security baselines</li> <li>Prefer least-privilege by default</li> <li> <p>Don\u2019t need privileged containers</p> </li> <li> <p>Optimal Cost Management</p> </li> <li> <p>Pay only for what you use (per-pod resources)</p> </li> <li>No over-provisioning nodes</li> <li>Automatic right-sizing</li> <li> <p>Scale-to-zero capability</p> </li> <li> <p>Standard Kubernetes Workloads</p> </li> <li> <p>Stateless applications</p> </li> <li>Microservices</li> <li>HTTP services and APIs</li> <li>Standard containerized applications</li> </ol> <p>\u274c Don\u2019t Use Autopilot When:</p> <ol> <li> <p>Need Privileged Access</p> </li> <li> <p>Running privileged containers</p> </li> <li>DaemonSets with node selectors</li> <li>Host networking required</li> <li> <p>SSH access to nodes needed</p> </li> <li> <p>Custom Node Configuration</p> </li> <li> <p>Specific machine types required</p> </li> <li>GPUs or TPUs needed</li> <li>Local SSDs for storage</li> <li> <p>Custom node images</p> </li> <li> <p>Windows Workloads</p> </li> <li> <p>Running Windows containers</p> </li> <li>.NET Framework applications</li> <li> <p>Windows-specific requirements</p> </li> <li> <p>Special Network Requirements</p> </li> <li> <p>Custom CNI plugins</p> </li> <li>Multiple network interfaces</li> <li> <p>Non-standard networking configurations</p> </li> <li> <p>Very Stable, Predictable Workloads</p> </li> <li> <p>24/7 steady-state traffic</p> </li> <li>Reserved capacity might be cheaper</li> <li>Committed use discounts apply (Standard with CUDs may be cheaper)</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#pricing_1","title":"Pricing","text":"<p>Autopilot GKE Costs:</p> <ul> <li>vCPU: $0.0445/hour per vCPU requested</li> <li>Memory: $0.00488/hour per GB requested</li> <li>Control Plane: Included in pod pricing</li> <li>Networking: Egress charges apply</li> </ul> <p>Example Cost Calculation:</p> <pre><code>Pod Request: 1 vCPU, 4 GB RAM\nHourly Cost: (1 \u00d7 $0.0445) + (4 \u00d7 $0.00488) = $0.064/hour\nMonthly Cost: $0.064 \u00d7 730 hours = ~$46.72/month per pod\n</code></pre> <p>Cost Optimization:</p> <pre><code># Right-size pod resources - you pay for requests\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-app\nspec:\n  containers:\n\n  - name: app\n    image: my-app:latest\n    resources:\n      requests:\n        cpu: \"250m\"      # 0.25 vCPU\n        memory: \"512Mi\"  # 0.5 GB\n      limits:\n        cpu: \"1000m\"\n        memory: \"2Gi\"\n</code></pre>"},{"location":"gcp/kubernetes/cluster-types/#comparison-matrix","title":"Comparison Matrix","text":"Feature Standard GKE Autopilot GKE Node Management Manual configuration Fully automated Pricing Per node-hour Per pod resource request Scaling Configure autoscaling Automatic Node Pools Manual creation/config Not applicable Machine Types Full choice Google-optimized SSH to Nodes Yes No Privileged Pods Yes No DaemonSets Yes (unrestricted) Limited GPU/TPU Yes Limited GPU support Windows Nodes Yes No Local SSDs Yes No Control Plane Cost $0.10/hr (regional) Included Security Baseline Manual config Hardened by default Best For Custom requirements Simplicity, cost efficiency"},{"location":"gcp/kubernetes/cluster-types/#choosing-between-standard-and-autopilot","title":"Choosing Between Standard and Autopilot","text":""},{"location":"gcp/kubernetes/cluster-types/#decision-framework","title":"Decision Framework","text":"<pre><code>Start Here: Do you need Windows nodes, GPUs, or privileged containers?\n    \u2502\n    \u251c\u2500 Yes \u2192 Standard GKE\n    \u2502\n    \u2514\u2500 No\n        \u2502\n        Do you have dedicated platform/ops team?\n        \u2502\n        \u251c\u2500 Yes \u2192 Do you need custom node configuration?\n        \u2502   \u2502\n        \u2502   \u251c\u2500 Yes \u2192 Standard GKE\n        \u2502   \u2514\u2500 No \u2192 Autopilot GKE (less operational overhead)\n        \u2502\n        \u2514\u2500 No \u2192 Autopilot GKE (hands-off management)\n</code></pre>"},{"location":"gcp/kubernetes/cluster-types/#when-to-choose-standard","title":"When to Choose Standard","text":"<ul> <li>Full control over infrastructure</li> <li>Custom hardware requirements (GPU, TPU, local SSD)</li> <li>Windows workloads</li> <li>Privileged containers or DaemonSets</li> <li>Spot VMs for cost optimization</li> <li>Experienced Kubernetes operations team</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#when-to-choose-autopilot","title":"When to Choose Autopilot","text":"<ul> <li>Minimal operational overhead</li> <li>Pay-per-pod cost model</li> <li>Unpredictable or variable workloads</li> <li>Security hardening by default</li> <li>Small team or no dedicated ops</li> <li>Standard containerized applications</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#migration-considerations","title":"Migration Considerations","text":""},{"location":"gcp/kubernetes/cluster-types/#standard-to-autopilot","title":"Standard to Autopilot","text":"<p>Potential Issues:</p> <ul> <li>Privileged pods will be rejected</li> <li>DaemonSets with node selectors may not work</li> <li>Need to define resource requests/limits</li> <li>Custom node configurations lost</li> </ul> <p>Migration Path:</p> <ol> <li>Audit existing workloads for incompatibilities</li> <li>Add resource requests/limits to all pods</li> <li>Remove privileged security contexts</li> <li>Test in new Autopilot cluster</li> <li>Migrate workloads gradually</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#autopilot-to-standard","title":"Autopilot to Standard","text":"<p>Reasons to Switch:</p> <ul> <li>Need GPU/TPU support</li> <li>Require Windows nodes</li> <li>Want Spot VM cost savings</li> <li>Need privileged containers</li> </ul> <p>Migration Path:</p> <ol> <li>Create Standard cluster with similar configuration</li> <li>Configure node pools and autoscaling</li> <li>Migrate workloads</li> <li>Optimize node pool configuration</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#regional-vs-zonal-clusters","title":"Regional vs Zonal Clusters","text":"<p>Both Standard and Autopilot support regional and zonal deployments:</p>"},{"location":"gcp/kubernetes/cluster-types/#zonal-clusters","title":"Zonal Clusters","text":"<p>Characteristics:</p> <ul> <li>Control plane in single zone</li> <li>Nodes in single zone (Standard) or multi-zone (Standard with manual pools)</li> <li>Lower cost (free control plane for Standard)</li> <li>Lower SLA (no SLA for zonal)</li> </ul> <p>Use Cases:</p> <ul> <li>Development and testing</li> <li>Non-critical workloads</li> <li>Cost-sensitive applications</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#regional-clusters","title":"Regional Clusters","text":"<p>Characteristics:</p> <ul> <li>Control plane replicated across 3 zones</li> <li>Nodes distributed across zones</li> <li>Higher availability (99.95% SLA)</li> <li>Higher cost ($0.10/hour for Standard, included for Autopilot)</li> </ul> <p>Use Cases:</p> <ul> <li>Production workloads</li> <li>High-availability requirements</li> <li>Mission-critical applications</li> </ul>"},{"location":"gcp/kubernetes/cluster-types/#best-practices","title":"Best Practices","text":""},{"location":"gcp/kubernetes/cluster-types/#for-standard-clusters","title":"For Standard Clusters","text":"<ol> <li> <p>Use Multiple Node Pools</p> </li> <li> <p>Separate pools for different workload types</p> </li> <li>Production vs. batch workloads</li> <li> <p>Different machine types for different needs</p> </li> <li> <p>Enable Autoscaling</p> </li> <li> <p>Configure cluster autoscaler</p> </li> <li>Set appropriate min/max nodes</li> <li> <p>Use node affinity for workload placement</p> </li> <li> <p>Use Spot VMs Wisely</p> </li> <li> <p>Only for fault-tolerant workloads</p> </li> <li>Not for critical services</li> <li> <p>Implement pod disruption budgets</p> </li> <li> <p>Right-Size Nodes</p> </li> <li> <p>Don\u2019t over-provision nodes</p> </li> <li>Use smaller nodes for better bin packing</li> <li>Monitor utilization and adjust</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#for-autopilot-clusters","title":"For Autopilot Clusters","text":"<ol> <li> <p>Define Resource Requests</p> </li> <li> <p>Required for all pods</p> </li> <li>Directly impacts cost</li> <li> <p>Use VPA for recommendations</p> </li> <li> <p>Optimize Pod Resources</p> </li> <li> <p>Right-size requests to actual usage</p> </li> <li>Avoid over-requesting resources</li> <li> <p>Use Vertical Pod Autoscaler</p> </li> <li> <p>Understand Restrictions</p> </li> <li> <p>No privileged pods</p> </li> <li>Limited DaemonSet capabilities</li> <li> <p>Plan accordingly</p> </li> <li> <p>Leverage Auto-Scaling</p> </li> <li> <p>HPA for pod replicas</p> </li> <li>Let Autopilot handle nodes</li> <li>No need to configure cluster autoscaler</li> </ol>"},{"location":"gcp/kubernetes/cluster-types/#related-resources","title":"Related Resources","text":"<ul> <li>GKE Overview</li> <li>GKE Deployments</li> <li>GKE Scaling</li> <li>kubectl</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/","title":"GKE Overview","text":""},{"location":"gcp/kubernetes/gke-overview/#description","title":"Description","text":"<p>Google Kubernetes Engine (GKE) is a managed Kubernetes service that provides a platform for deploying, managing, and scaling containerized applications using Google\u2019s infrastructure. GKE abstracts away the complexity of managing Kubernetes control planes and provides deep integration with Google Cloud services.</p> <p>Architecture: Managed Kubernetes clusters consisting of a control plane (managed by Google) and worker nodes (managed by Google or you, depending on cluster type).</p>"},{"location":"gcp/kubernetes/gke-overview/#key-features","title":"Key Features","text":""},{"location":"gcp/kubernetes/gke-overview/#managed-control-plane","title":"Managed Control Plane","text":"<ul> <li>Fully Managed: Google manages the Kubernetes API server, etcd, and other control plane components</li> <li>Automatic Updates: Control plane automatically updated with latest Kubernetes versions</li> <li>High Availability: Multi-zone control plane with 99.95% or 99.99% SLA (depending on cluster type)</li> <li>No Control Plane Costs: Standard clusters don\u2019t charge for control plane (Autopilot includes it in per-pod pricing)</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#cluster-management","title":"Cluster Management","text":"<ul> <li>Multiple Cluster Types: Standard (manual management) and Autopilot (fully managed)</li> <li>Auto-Scaling: Cluster autoscaling for nodes, Horizontal/Vertical Pod Autoscaling</li> <li>Auto-Repair: Automatically repairs unhealthy nodes</li> <li>Auto-Upgrade: Automatically upgrades nodes to match control plane version</li> <li>Node Pools: Logical grouping of nodes with same configuration</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#integration-with-google-cloud","title":"Integration with Google Cloud","text":"<ul> <li>Cloud Load Balancing: Automatic integration for Service type LoadBalancer</li> <li>Cloud Logging &amp; Monitoring: Native integration with Cloud Operations</li> <li>Workload Identity: Securely access Google Cloud APIs from pods</li> <li>Binary Authorization: Ensure only trusted container images are deployed</li> <li>VPC-Native Clusters: Pods get IP addresses from VPC subnet ranges</li> <li>Private Clusters: Control plane and nodes isolated from public internet</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#security","title":"Security","text":"<ul> <li>Workload Identity: Map Kubernetes service accounts to Google Cloud service accounts</li> <li>Shielded GKE Nodes: Verifiable node integrity</li> <li>Binary Authorization: Deploy-time security policy enforcement</li> <li>GKE Sandbox: Run untrusted workloads using gVisor</li> <li>Security Posture Dashboard: Centralized security recommendations</li> <li>Network Policies: Control pod-to-pod communication</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#developer-experience","title":"Developer Experience","text":"<ul> <li>Cloud Code: IDE integration for development and debugging</li> <li>Config Connector: Manage GCP resources through Kubernetes</li> <li>kubectl: Standard Kubernetes CLI</li> <li>Cloud Console UI: Web-based cluster management</li> <li>Cloud Shell: Browser-based CLI with pre-installed tools</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#important-limits","title":"Important Limits","text":"Limit Value Notes Max nodes per cluster 15,000 (Standard), 1,000 node pools Autopilot scales automatically Max pods per node 110 (default), up to 256 Configurable with <code>--max-pods-per-node</code> Max pods per cluster 200,000 (Standard) Autopilot manages this automatically Clusters per project 100 per location Soft limit, can be increased Node pools per cluster 1,000 Each pool can have different configurations Max PVs per cluster 256 PD per node, 128 local SSDs per node Persistent disk limits Services (LoadBalancer) 5 per node, 300 per cluster Network load balancer limits"},{"location":"gcp/kubernetes/gke-overview/#cluster-types-comparison","title":"Cluster Types Comparison","text":"Feature Standard GKE Autopilot GKE Node Management Manual Fully automated Pricing Model Per node-hour Per pod resource request Scaling Configure autoscaling Automatic Node Configuration Full control Google-managed SSH Access to Nodes Yes No Custom Machine Types Yes Predefined pod specs Node Pools Manual creation Automatically managed Security Baseline Configure manually Hardened by default Best For Custom requirements, full control Simplicity, hands-off operations"},{"location":"gcp/kubernetes/gke-overview/#when-to-use","title":"When to Use","text":""},{"location":"gcp/kubernetes/gke-overview/#use-gke-when","title":"\u2705 Use GKE When:","text":"<ol> <li> <p>Container Orchestration Needed</p> </li> <li> <p>Running microservices architectures</p> </li> <li>Need automatic scaling, self-healing, and rolling updates</li> <li> <p>Managing multiple containerized applications</p> </li> <li> <p>Kubernetes Expertise Available</p> </li> <li> <p>Team has Kubernetes knowledge</p> </li> <li>Want standard Kubernetes APIs and ecosystem</li> <li> <p>Need portability across clouds</p> </li> <li> <p>Google Cloud Integration Required</p> </li> <li> <p>Leveraging Google Cloud services (Cloud SQL, Pub/Sub, BigQuery)</p> </li> <li>Using Workload Identity for secure GCP access</li> <li> <p>Need integration with Cloud Load Balancing</p> </li> <li> <p>High Availability and Scalability</p> </li> <li> <p>Applications require 99.95%+ uptime</p> </li> <li>Need to scale from handful to thousands of pods</li> <li> <p>Multi-region or multi-zone deployments</p> </li> <li> <p>Managed Infrastructure Preferred</p> </li> <li> <p>Want Google to manage control plane</p> </li> <li>Prefer automatic updates and patches</li> <li>Need security hardening by default (Autopilot)</li> </ol>"},{"location":"gcp/kubernetes/gke-overview/#dont-use-gke-when","title":"\u274c Don\u2019t Use GKE When:","text":"<ol> <li> <p>Simple Applications</p> </li> <li> <p>Single container application better suited for Cloud Run</p> </li> <li>Serverless functions (use Cloud Functions)</li> <li> <p>Static websites (use Cloud Storage/Firebase Hosting)</p> </li> <li> <p>No Container Experience</p> </li> <li> <p>Team lacks container and Kubernetes knowledge</p> </li> <li>Learning curve not justified by requirements</li> <li> <p>Simpler solutions available (App Engine, Cloud Run)</p> </li> <li> <p>Windows-Heavy Workloads</p> </li> <li> <p>Primarily Windows containers (GKE supports Windows but consider GCE)</p> </li> <li> <p>Legacy Windows applications not containerized</p> </li> <li> <p>Extremely Cost-Sensitive Small Workloads</p> </li> <li> <p>Single small VM might be cheaper than minimum cluster</p> </li> <li>Very low traffic applications</li> <li> <p>Development environments (unless Autopilot)</p> </li> <li> <p>Complete Infrastructure Control Needed</p> </li> <li> <p>Need to modify control plane configuration</p> </li> <li>Require kernel-level modifications</li> <li>Custom network overlays incompatible with GKE</li> </ol>"},{"location":"gcp/kubernetes/gke-overview/#common-use-cases","title":"Common Use Cases","text":""},{"location":"gcp/kubernetes/gke-overview/#microservices-architecture","title":"Microservices Architecture","text":"<pre><code>GKE Cluster\n\u251c\u2500\u2500 Frontend Service (Deployment)\n\u2502   \u2514\u2500\u2500 Pods: 3 replicas\n\u251c\u2500\u2500 API Service (Deployment)\n\u2502   \u2514\u2500\u2500 Pods: 5 replicas\n\u251c\u2500\u2500 Auth Service (Deployment)\n\u2502   \u2514\u2500\u2500 Pods: 2 replicas\n\u2514\u2500\u2500 Database (StatefulSet)\n    \u2514\u2500\u2500 Pods: 3 replicas (with persistent volumes)\n\nIngress: HTTPS load balancer\nService Mesh: Istio for service-to-service communication\n</code></pre>"},{"location":"gcp/kubernetes/gke-overview/#cicd-pipeline","title":"CI/CD Pipeline","text":"<pre><code>GitHub \u2192 Cloud Build \u2192 Artifact Registry \u2192 GKE\n                                            \u251c\u2500\u2500 Dev Cluster\n                                            \u251c\u2500\u2500 Staging Cluster\n                                            \u2514\u2500\u2500 Production Cluster\n</code></pre>"},{"location":"gcp/kubernetes/gke-overview/#batch-processing","title":"Batch Processing","text":"<pre><code>GKE Autopilot\n\u2514\u2500\u2500 Jobs/CronJobs\n    \u251c\u2500\u2500 Data processing jobs (scales to zero when complete)\n    \u251c\u2500\u2500 ML training jobs\n    \u2514\u2500\u2500 ETL pipelines\n</code></pre>"},{"location":"gcp/kubernetes/gke-overview/#gke-vs-other-google-services","title":"GKE vs Other Google Services","text":"<p>GKE vs Cloud Run</p> <ul> <li>GKE: Full Kubernetes, more control, stateful workloads</li> <li>Cloud Run: Serverless containers, simpler, stateless HTTP services</li> </ul> <p>GKE vs Compute Engine</p> <ul> <li>GKE: Container orchestration, automatic scaling/healing</li> <li>Compute Engine: Full VM control, traditional applications</li> </ul> <p>GKE vs App Engine</p> <ul> <li>GKE: More flexibility, any language/runtime, complex apps</li> <li>App Engine: Simpler PaaS, limited languages, quick deployment</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#pricing-considerations","title":"Pricing Considerations","text":"<p>Standard GKE</p> <ul> <li>Control Plane: Free for zonal clusters, $0.10/hour for regional</li> <li>Nodes: Standard Compute Engine pricing for VMs</li> <li>Network: Egress charges apply</li> <li>Cost Optimization: Use Spot VMs, committed use discounts, right-size nodes</li> </ul> <p>Autopilot GKE</p> <ul> <li>No Node Charges: Pay only for pod resource requests</li> <li>Control Plane: Included in pod pricing</li> <li>vCPU: $0.0445/hour per vCPU requested</li> <li>Memory: $0.00488/hour per GB requested</li> <li>Cost Optimization: Right-size pod requests, use vertical pod autoscaler</li> </ul> <p>General Tips</p> <ul> <li>Use Autopilot for unpredictable workloads (pay only for used resources)</li> <li>Use Standard with Spot VMs for batch/fault-tolerant workloads (up to 91% discount)</li> <li>Enable cluster autoscaling to scale down during off-hours</li> <li>Use resource quotas to prevent cost overruns</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#getting-started","title":"Getting Started","text":""},{"location":"gcp/kubernetes/gke-overview/#create-a-gke-cluster-standard","title":"Create a GKE Cluster (Standard)","text":"<pre><code># Create zonal cluster\ngcloud container clusters create my-cluster \\\n  --zone=us-central1-a \\\n  --num-nodes=3 \\\n  --machine-type=e2-medium \\\n  --enable-autoscaling \\\n  --min-nodes=1 \\\n  --max-nodes=10\n\n# Get credentials\ngcloud container clusters get-credentials my-cluster --zone=us-central1-a\n\n# Verify connection\nkubectl get nodes\n</code></pre>"},{"location":"gcp/kubernetes/gke-overview/#create-a-gke-cluster-autopilot","title":"Create a GKE Cluster (Autopilot)","text":"<pre><code># Create Autopilot cluster (regional by default)\ngcloud container clusters create-auto my-autopilot-cluster \\\n  --region=us-central1\n\n# Get credentials\ngcloud container clusters get-credentials my-autopilot-cluster --region=us-central1\n\n# Deploy application - nodes provisioned automatically\nkubectl apply -f deployment.yaml\n</code></pre>"},{"location":"gcp/kubernetes/gke-overview/#best-practices","title":"Best Practices","text":""},{"location":"gcp/kubernetes/gke-overview/#1-cluster-configuration","title":"1. Cluster Configuration","text":"<ul> <li>Use regional clusters for production (99.95% SLA)</li> <li>Enable Workload Identity for secure GCP access</li> <li>Use VPC-native clusters (alias IP ranges)</li> <li>Enable Binary Authorization for production</li> <li>Configure maintenance windows for upgrades</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#2-security","title":"2. Security","text":"<ul> <li>Enable Workload Identity (not metadata server)</li> <li>Use least-privilege IAM roles</li> <li>Implement Network Policies</li> <li>Use Private clusters for sensitive workloads</li> <li>Enable GKE Dataplane V2 for improved networking</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#3-resource-management","title":"3. Resource Management","text":"<ul> <li>Set resource requests and limits on all pods</li> <li>Use resource quotas and limit ranges per namespace</li> <li>Enable Horizontal Pod Autoscaler for variable workloads</li> <li>Use Vertical Pod Autoscaler to right-size requests</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#4-monitoring-logging","title":"4. Monitoring &amp; Logging","text":"<ul> <li>Enable GKE monitoring and logging (now default)</li> <li>Use Workload metrics for application-level monitoring</li> <li>Set up alerts for cluster and pod health</li> <li>Use Cloud Trace for distributed tracing</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#5-cost-optimization","title":"5. Cost Optimization","text":"<ul> <li>Use Spot VMs for fault-tolerant workloads</li> <li>Enable cluster autoscaling</li> <li>Right-size node pools and pod resources</li> <li>Use Autopilot for variable or unpredictable workloads</li> <li>Clean up unused resources (PVs, LoadBalancers)</li> </ul>"},{"location":"gcp/kubernetes/gke-overview/#related-services","title":"Related Services","text":"<ul> <li>Artifact Registry: Store container images</li> <li>Cloud Build: CI/CD for containers</li> <li>Cloud Operations: Monitoring, logging, and tracing</li> <li>Config Connector: Manage GCP resources via Kubernetes</li> <li>Anthos: Multi-cloud and hybrid Kubernetes management</li> <li>Cloud Run: Serverless container alternative</li> </ul>"},{"location":"gcp/kubernetes/scaling/","title":"GKE Scaling","text":""},{"location":"gcp/kubernetes/scaling/#description","title":"Description","text":"<p>Scaling in GKE encompasses multiple dimensions: horizontal pod scaling (adding more pod replicas), vertical pod scaling (increasing pod resources), and cluster scaling (adding more nodes). GKE provides automated scaling mechanisms to handle variable workloads efficiently while optimizing costs.</p> <p>Concept: Automatically adjust resources (pods and nodes) based on demand to maintain performance while optimizing costs.</p>"},{"location":"gcp/kubernetes/scaling/#types-of-scaling","title":"Types of Scaling","text":""},{"location":"gcp/kubernetes/scaling/#horizontal-pod-autoscaler-hpa","title":"Horizontal Pod Autoscaler (HPA)","text":"<p>Scales the number of pod replicas based on observed metrics.</p>"},{"location":"gcp/kubernetes/scaling/#vertical-pod-autoscaler-vpa","title":"Vertical Pod Autoscaler (VPA)","text":"<p>Adjusts CPU and memory requests/limits for containers.</p>"},{"location":"gcp/kubernetes/scaling/#cluster-autoscaler","title":"Cluster Autoscaler","text":"<p>Adds or removes nodes based on pod resource requirements.</p>"},{"location":"gcp/kubernetes/scaling/#multidimensional-pod-autoscaler-mpa","title":"Multidimensional Pod Autoscaler (MPA)","text":"<p>Scales both pod replicas and resources (GKE Autopilot feature).</p>"},{"location":"gcp/kubernetes/scaling/#horizontal-pod-autoscaler-hpa_1","title":"Horizontal Pod Autoscaler (HPA)","text":""},{"location":"gcp/kubernetes/scaling/#description_1","title":"Description","text":"<p>HPA automatically scales the number of pods in a deployment, replica set, or stateful set based on observed CPU utilization, memory usage, or custom metrics.</p>"},{"location":"gcp/kubernetes/scaling/#key-features","title":"Key Features","text":"<ul> <li>CPU-based Scaling: Scale based on CPU utilization (most common)</li> <li>Memory-based Scaling: Scale based on memory usage</li> <li>Custom Metrics: Scale on application-specific metrics (Pub/Sub queue length, HTTP requests/sec)</li> <li>External Metrics: Scale based on metrics from external systems</li> <li>Multiple Metrics: Combine different metrics for scaling decisions</li> <li>Configurable Behavior: Set min/max replicas, scaling velocity</li> </ul>"},{"location":"gcp/kubernetes/scaling/#hpa-configuration","title":"HPA Configuration","text":"<p>Basic CPU-based HPA:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\n  namespace: production\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre> <p>Advanced HPA with Multiple Metrics:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: advanced-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 3\n  maxReplicas: 50\n\n  # Scaling behavior configuration\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300  # Wait 5 min before scaling down\n      policies:\n\n      - type: Percent\n        value: 50\n        periodSeconds: 60  # Scale down max 50% per minute\n\n      - type: Pods\n        value: 2\n        periodSeconds: 60  # Or max 2 pods per minute\n      selectPolicy: Min  # Use most conservative policy\n\n    scaleUp:\n      stabilizationWindowSeconds: 0  # Scale up immediately\n      policies:\n\n      - type: Percent\n        value: 100\n        periodSeconds: 30  # Double pods every 30 seconds\n\n      - type: Pods\n        value: 5\n        periodSeconds: 30  # Or add 5 pods every 30 seconds\n      selectPolicy: Max  # Use most aggressive policy\n\n  metrics:\n\n  # CPU utilization\n\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n\n  # Memory utilization\n\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n\n  # Custom metric (e.g., HTTP requests per second)\n\n  - type: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: \"1000\"\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#hpa-with-custom-metrics","title":"HPA with Custom Metrics","text":"<p>Using Pub/Sub Queue Depth:</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: pubsub-worker-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: pubsub-worker\n  minReplicas: 1\n  maxReplicas: 50\n  metrics:\n\n  - type: External\n    external:\n      metric:\n        name: pubsub.googleapis.com|subscription|num_undelivered_messages\n        selector:\n          matchLabels:\n            resource.labels.subscription_id: my-subscription\n      target:\n        type: AverageValue\n        averageValue: \"30\"  # Scale to maintain 30 messages per pod\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#create-hpa-via-kubectl","title":"Create HPA via kubectl","text":"<pre><code># CPU-based autoscaling\nkubectl autoscale deployment web-app \\\n  --cpu-percent=70 \\\n  --min=2 \\\n  --max=10\n\n# View HPA status\nkubectl get hpa\n\n# Describe HPA\nkubectl describe hpa web-app-hpa\n\n# Delete HPA\nkubectl delete hpa web-app-hpa\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#important-limits","title":"Important Limits","text":"Limit Value Notes Min replicas 1 Can be 0 with specific setup Max replicas Cluster capacity Limited by resources Metrics evaluation Every 15 seconds Default, configurable Scaling cooldown 3 min (down), 0 (up) Configurable via behavior Target metrics Up to 10 Multiple metrics supported"},{"location":"gcp/kubernetes/scaling/#when-to-use-hpa","title":"When to Use HPA","text":"<p>\u2705 Use HPA When:</p> <ul> <li>Traffic varies throughout the day</li> <li>Want automatic scaling based on load</li> <li>Cost optimization through dynamic scaling</li> <li>Stateless applications that can scale horizontally</li> </ul> <p>\u274c Don\u2019t Use HPA When:</p> <ul> <li>Stateful applications that can\u2019t easily add replicas</li> <li>Applications with long startup times (scale-up lag)</li> <li>Need vertical scaling (use VPA instead)</li> </ul>"},{"location":"gcp/kubernetes/scaling/#vertical-pod-autoscaler-vpa_1","title":"Vertical Pod Autoscaler (VPA)","text":""},{"location":"gcp/kubernetes/scaling/#description_2","title":"Description","text":"<p>VPA automatically adjusts CPU and memory requests and limits for containers based on historical usage patterns.</p>"},{"location":"gcp/kubernetes/scaling/#key-features_1","title":"Key Features","text":"<ul> <li>Right-Sizing: Automatically set appropriate resource requests</li> <li>Historical Analysis: Based on actual resource usage patterns</li> <li>Update Modes: Recommend, auto-update, or initial-only</li> <li>Container-Level: Can configure per-container in a pod</li> </ul>"},{"location":"gcp/kubernetes/scaling/#vpa-configuration","title":"VPA Configuration","text":"<pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: web-app-vpa\n  namespace: production\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n\n  updatePolicy:\n    updateMode: \"Auto\"  # Auto, Recreate, Initial, or Off\n\n  resourcePolicy:\n    containerPolicies:\n\n    - containerName: web-app\n      minAllowed:\n        cpu: 100m\n        memory: 128Mi\n      maxAllowed:\n        cpu: 2000m\n        memory: 2Gi\n      controlledResources:\n\n      - cpu\n      - memory\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#vpa-update-modes","title":"VPA Update Modes","text":"<p>Off (Recommendation Only):</p> <pre><code>updatePolicy:\n  updateMode: \"Off\"\n</code></pre> <ul> <li>VPA only generates recommendations</li> <li>No automatic updates</li> <li>Use for analysis before implementing</li> </ul> <p>Initial:</p> <pre><code>updatePolicy:\n  updateMode: \"Initial\"\n</code></pre> <ul> <li>Set resources only when pods are created</li> <li>No updates to running pods</li> <li>Good for stateful workloads</li> </ul> <p>Auto:</p> <pre><code>updatePolicy:\n  updateMode: \"Auto\"\n</code></pre> <ul> <li>Automatically update running pods</li> <li>Evicts and recreates pods to apply new resources</li> <li>Best for stateless workloads</li> </ul> <p>Recreate:</p> <pre><code>updatePolicy:\n  updateMode: \"Recreate\"\n</code></pre> <ul> <li>Similar to Auto but always recreates pods</li> <li>More disruptive</li> </ul>"},{"location":"gcp/kubernetes/scaling/#install-vpa","title":"Install VPA","text":"<pre><code># VPA not installed by default, install manually\ngit clone https://github.com/kubernetes/autoscaler.git\ncd autoscaler/vertical-pod-autoscaler\n./hack/vpa-up.sh\n\n# Verify installation\nkubectl get vpa -A\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#view-vpa-recommendations","title":"View VPA Recommendations","text":"<pre><code># Get VPA status\nkubectl get vpa\n\n# Describe VPA (see recommendations)\nkubectl describe vpa web-app-vpa\n\n# View recommendations\nkubectl get vpa web-app-vpa -o yaml\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#important-considerations","title":"Important Considerations","text":"<p>VPA Limitations:</p> <ul> <li>Cannot be used with HPA on same CPU/memory metrics</li> <li>Requires pod eviction to apply changes (except Initial mode)</li> <li>May cause brief downtime during updates</li> </ul> <p>VPA + HPA Together:</p> <pre><code># HPA on custom metric\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\nspec:\n  metrics:\n\n  - type: Pods\n    pods:\n      metric:\n        name: http_requests_per_second\n      target:\n        type: AverageValue\n        averageValue: \"1000\"\n\n---\n# VPA for right-sizing\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: web-app-vpa\nspec:\n  updatePolicy:\n    updateMode: \"Auto\"\n  # HPA handles CPU scaling, VPA handles right-sizing\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#when-to-use-vpa","title":"When to Use VPA","text":"<p>\u2705 Use VPA When:</p> <ul> <li>Resource requests are incorrect or unknown</li> <li>Want automatic right-sizing based on usage</li> <li>Applications with varying resource needs over time</li> <li>Optimizing cost by eliminating over-provisioning</li> </ul> <p>\u274c Don\u2019t Use VPA When:</p> <ul> <li>Already using HPA on CPU/memory</li> <li>Cannot tolerate pod evictions</li> <li>Resource requirements are well-known and stable</li> <li>Application startup time is very long</li> </ul>"},{"location":"gcp/kubernetes/scaling/#cluster-autoscaler_1","title":"Cluster Autoscaler","text":""},{"location":"gcp/kubernetes/scaling/#description_3","title":"Description","text":"<p>Cluster Autoscaler automatically adjusts the number of nodes in a cluster based on pod resource requests that cannot be scheduled on existing nodes.</p>"},{"location":"gcp/kubernetes/scaling/#how-it-works","title":"How It Works","text":"<ol> <li>Pods are unschedulable due to insufficient resources</li> <li>Cluster Autoscaler detects pending pods</li> <li>New nodes added to accommodate pods</li> <li>When nodes are underutilized, they\u2019re removed</li> </ol>"},{"location":"gcp/kubernetes/scaling/#key-features_2","title":"Key Features","text":"<ul> <li>Automatic Scale-Up: Add nodes when pods can\u2019t be scheduled</li> <li>Automatic Scale-Down: Remove nodes when underutilized</li> <li>Node Pool Awareness: Scale specific node pools</li> <li>Cost Optimization: Reduce costs by removing unused nodes</li> <li>Configurable Behavior: Set min/max nodes, scale-down delays</li> </ul>"},{"location":"gcp/kubernetes/scaling/#enable-cluster-autoscaler-standard-gke","title":"Enable Cluster Autoscaler (Standard GKE)","text":"<pre><code># Enable on existing cluster\ngcloud container clusters update my-cluster \\\n  --enable-autoscaling \\\n  --min-nodes=1 \\\n  --max-nodes=10 \\\n  --zone=us-central1-a\n\n# Enable on specific node pool\ngcloud container node-pools update default-pool \\\n  --cluster=my-cluster \\\n  --enable-autoscaling \\\n  --min-nodes=1 \\\n  --max-nodes=10 \\\n  --zone=us-central1-a\n\n# Create cluster with autoscaling\ngcloud container clusters create my-cluster \\\n  --enable-autoscaling \\\n  --min-nodes=1 \\\n  --max-nodes=10 \\\n  --zone=us-central1-a\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#cluster-autoscaler-configuration","title":"Cluster Autoscaler Configuration","text":"<p>Node Pool Settings:</p> <pre><code># Set autoscaling limits\ngcloud container node-pools update pool-name \\\n  --enable-autoscaling \\\n  --min-nodes=2 \\\n  --max-nodes=20\n\n# Location policy for multi-zone\ngcloud container node-pools update pool-name \\\n  --location-policy=BALANCED  # or ANY\n</code></pre> <p>Advanced Configuration via ConfigMap:</p> <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: cluster-autoscaler-config\n  namespace: kube-system\ndata:\n  scale-down-delay-after-add: \"10m\"\n  scale-down-unneeded-time: \"10m\"\n  scale-down-utilization-threshold: \"0.5\"\n  skip-nodes-with-local-storage: \"false\"\n  skip-nodes-with-system-pods: \"false\"\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#important-limits_1","title":"Important Limits","text":"Limit Value Notes Min nodes per pool 0 Can scale to zero Max nodes per pool 1000 Configurable Max nodes per cluster 15,000 Total limit Scale-up time ~2-5 minutes Node provisioning time Scale-down time 10 minutes (default) Configurable delay"},{"location":"gcp/kubernetes/scaling/#preventing-scale-down","title":"Preventing Scale-Down","text":"<p>Safe-to-Evict Annotation:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  annotations:\n    cluster-autoscaler.kubernetes.io/safe-to-evict: \"false\"\n</code></pre> <p>PodDisruptionBudget:</p> <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: my-app\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#when-to-use-cluster-autoscaler","title":"When to Use Cluster Autoscaler","text":"<p>\u2705 Use Cluster Autoscaler When:</p> <ul> <li>Workload varies significantly</li> <li>Want automatic infrastructure scaling</li> <li>Cost optimization important</li> <li>Using HPA (complement to pod autoscaling)</li> </ul> <p>\u274c Don\u2019t Use Cluster Autoscaler When:</p> <ul> <li>Workload is stable and predictable</li> <li>Cannot tolerate 2-5 minute scale-up delay</li> <li>Using Autopilot (handles this automatically)</li> </ul>"},{"location":"gcp/kubernetes/scaling/#autopilot-scaling-gke-autopilot","title":"Autopilot Scaling (GKE Autopilot)","text":""},{"location":"gcp/kubernetes/scaling/#description_4","title":"Description","text":"<p>In Autopilot mode, Google manages all scaling automatically. No cluster autoscaler configuration needed.</p>"},{"location":"gcp/kubernetes/scaling/#how-it-works_1","title":"How It Works","text":"<ul> <li>Nodes provisioned automatically based on pod requests</li> <li>Scales to zero when no workloads running</li> <li>Right-sized nodes for pod requirements</li> <li>No over-provisioning</li> </ul>"},{"location":"gcp/kubernetes/scaling/#autopilot-scaling-features","title":"Autopilot Scaling Features","text":"<p>Automatic:</p> <ul> <li>Node provisioning and removal</li> <li>Perfect bin-packing</li> <li>Cost optimization</li> <li>No configuration needed</li> </ul> <p>You Still Configure:</p> <ul> <li>HPA for pod replica scaling</li> <li>VPA for resource recommendations (optional)</li> <li>Pod resource requests (required)</li> </ul> <pre><code># Autopilot pod with HPA\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 3  # Initial, HPA will adjust\n  template:\n    spec:\n      containers:\n\n      - name: web-app\n        resources:\n          requests:  # Required for Autopilot\n            cpu: \"500m\"\n            memory: \"1Gi\"\n          limits:\n            cpu: \"1000m\"\n            memory: \"2Gi\"\n\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: web-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: web-app\n  minReplicas: 3\n  maxReplicas: 50\n  metrics:\n\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#scaling-best-practices","title":"Scaling Best Practices","text":""},{"location":"gcp/kubernetes/scaling/#1-always-set-resource-requests","title":"1. Always Set Resource Requests","text":"<pre><code>resources:\n  requests:\n    cpu: \"250m\"\n    memory: \"512Mi\"\n  limits:\n    cpu: \"1000m\"\n    memory: \"1Gi\"\n</code></pre> <p>Why:</p> <ul> <li>Required for HPA and cluster autoscaler</li> <li>Proper pod scheduling</li> <li>Cost calculation (Autopilot)</li> </ul>"},{"location":"gcp/kubernetes/scaling/#2-use-appropriate-minmax-replicas","title":"2. Use Appropriate Min/Max Replicas","text":"<pre><code>spec:\n  minReplicas: 3  # Enough for availability\n  maxReplicas: 50  # Reasonable upper bound\n</code></pre> <p>Why:</p> <ul> <li>Prevent scaling to zero (availability)</li> <li>Prevent runaway scaling (cost control)</li> <li>Faster response to traffic spikes</li> </ul>"},{"location":"gcp/kubernetes/scaling/#3-configure-scaling-behavior","title":"3. Configure Scaling Behavior","text":"<pre><code>behavior:\n  scaleDown:\n    stabilizationWindowSeconds: 300  # Prevent flapping\n  scaleUp:\n    stabilizationWindowSeconds: 0  # React quickly\n</code></pre> <p>Why:</p> <ul> <li>Prevent rapid scaling up/down</li> <li>Reduce pod churn</li> <li>Smoother scaling behavior</li> </ul>"},{"location":"gcp/kubernetes/scaling/#4-use-pod-disruption-budgets","title":"4. Use Pod Disruption Budgets","text":"<pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: app-pdb\nspec:\n  minAvailable: 2\n</code></pre> <p>Why:</p> <ul> <li>Maintain availability during scaling</li> <li>Prevent all pods being removed</li> <li>Safe cluster operations</li> </ul>"},{"location":"gcp/kubernetes/scaling/#5-monitor-scaling-metrics","title":"5. Monitor Scaling Metrics","text":"<pre><code># Watch HPA status\nkubectl get hpa -w\n\n# Check cluster autoscaler events\nkubectl get events -A | grep cluster-autoscaler\n\n# Monitor node count\nkubectl get nodes -w\n</code></pre> <p>Set up Alerts:</p> <ul> <li>HPA at max replicas</li> <li>Cluster at max nodes</li> <li>High pod pending time</li> <li>Scaling failures</li> </ul>"},{"location":"gcp/kubernetes/scaling/#6-test-scaling-behavior","title":"6. Test Scaling Behavior","text":"<pre><code># Generate load for testing\nkubectl run -i --tty load-generator \\\n  --rm --image=busybox \\\n  --restart=Never \\\n  -- /bin/sh -c \"while sleep 0.01; do wget -q -O- http://web-app; done\"\n\n# Watch scaling\nkubectl get hpa -w\nkubectl get deployment web-app -w\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#7-use-vpa-for-right-sizing","title":"7. Use VPA for Right-Sizing","text":"<pre><code># Start with VPA in recommendation mode\nupdatePolicy:\n  updateMode: \"Off\"\n\n# Analyze recommendations, then switch to Auto\nupdatePolicy:\n  updateMode: \"Auto\"\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#8-combine-scaling-strategies","title":"8. Combine Scaling Strategies","text":"<p>Pattern:</p> <ul> <li>HPA: Scale pod replicas (horizontal)</li> <li>VPA: Right-size pod resources (vertical)</li> <li>Cluster Autoscaler: Scale nodes (infrastructure)</li> </ul> <p>Example:</p> <pre><code># HPA on custom metric\n\n- Scale replicas based on request rate\n\n# VPA for resource optimization\n\n- Right-size CPU/memory requests\n\n# Cluster Autoscaler\n\n- Add nodes when pods can't schedule\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#troubleshooting-scaling","title":"Troubleshooting Scaling","text":""},{"location":"gcp/kubernetes/scaling/#hpa-not-scaling","title":"HPA Not Scaling","text":"<p>Check metrics availability:</p> <pre><code>kubectl get hpa\nkubectl describe hpa &lt;hpa-name&gt;\n\n# Check metrics server\nkubectl get apiservice v1beta1.metrics.k8s.io\nkubectl get --raw /apis/metrics.k8s.io/v1beta1/nodes\n</code></pre> <p>Common Issues:</p> <ul> <li>Metrics server not running</li> <li>Resource requests not set</li> <li>Target already at min/max</li> <li>Insufficient metrics data</li> </ul>"},{"location":"gcp/kubernetes/scaling/#cluster-not-scaling-up","title":"Cluster Not Scaling Up","text":"<pre><code># Check pending pods\nkubectl get pods --field-selector=status.phase=Pending\n\n# Check node pool autoscaling\ngcloud container node-pools describe pool-name \\\n  --cluster=cluster-name\n\n# View cluster autoscaler logs\nkubectl logs -n kube-system deployment/cluster-autoscaler\n</code></pre> <p>Common Issues:</p> <ul> <li>Max nodes reached</li> <li>Resource quotas exceeded</li> <li>Pod resource requests too large</li> <li>Node taints/tolerations mismatch</li> </ul>"},{"location":"gcp/kubernetes/scaling/#nodes-not-scaling-down","title":"Nodes Not Scaling Down","text":"<p>Check:</p> <ul> <li>Pods with safe-to-evict=false</li> <li>Pods with local storage</li> <li>System pods on nodes</li> <li>PodDisruptionBudgets</li> </ul> <pre><code># Check node utilization\nkubectl top nodes\n\n# Check what's preventing scale-down\nkubectl describe node &lt;node-name&gt;\n</code></pre>"},{"location":"gcp/kubernetes/scaling/#related-resources","title":"Related Resources","text":"<ul> <li>GKE Deployments - Managing workloads</li> <li>GKE Pods - Pod resource configuration</li> <li>GKE Cluster Types - Standard vs Autopilot</li> <li>kubectl - Scaling commands</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/","title":"GKE Service Mesh - Istio","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#description","title":"Description","text":"<p>A service mesh is an infrastructure layer that manages service-to-service communication in microservices architectures. On GKE, you can use Anthos Service Mesh (ASM), Google\u2019s managed Istio distribution, or open-source Istio. The service mesh provides traffic management, security, and observability without changing application code.</p> <p>Concept: Transparent proxy layer (sidecar) injected into pods to control, secure, and observe service communication.</p>"},{"location":"gcp/kubernetes/service-mesh-istio/#service-mesh-options-on-gke","title":"Service Mesh Options on GKE","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#anthos-service-mesh-asm-recommended","title":"Anthos Service Mesh (ASM) - Recommended","text":"<ul> <li>Managed by Google: Google handles control plane</li> <li>Automatic Updates: Managed upgrades and patches</li> <li>Google Cloud Integration: Deep integration with Cloud Ops</li> <li>Support: Enterprise support from Google</li> <li>Certificate Management: Automatic with Certificate Authority Service</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#open-source-istio","title":"Open Source Istio","text":"<ul> <li>Self-Managed: You manage control plane</li> <li>Latest Features: Access to newest Istio features</li> <li>Full Control: Complete configuration control</li> <li>Community Support: Istio community forums</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#anthos-service-mesh-vs-istio","title":"Anthos Service Mesh vs Istio","text":"Feature Anthos Service Mesh Open Source Istio Management Fully managed by Google Self-managed Updates Automatic (managed) Manual Support Google Cloud Support Community Pricing Included with GKE (vCPU hours) Free (infrastructure costs) Control Plane Managed (in-cluster or managed) Self-hosted in-cluster Best For Production, enterprise Advanced users, latest features"},{"location":"gcp/kubernetes/service-mesh-istio/#key-features","title":"Key Features","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#traffic-management","title":"Traffic Management","text":"<ul> <li>Intelligent Routing: Route requests based on headers, paths, weights</li> <li>Load Balancing: Advanced algorithms (round-robin, least request, random)</li> <li>Traffic Splitting: A/B testing, canary deployments</li> <li>Circuit Breaking: Prevent cascading failures</li> <li>Retries and Timeouts: Automatic retry logic</li> <li>Fault Injection: Test resilience by injecting failures</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#security","title":"Security","text":"<ul> <li>Mutual TLS (mTLS): Automatic encryption of service-to-service traffic</li> <li>Authentication: Verify service identity</li> <li>Authorization: Fine-grained access control policies</li> <li>Certificate Management: Automatic certificate rotation</li> <li>Security Policies: Namespace and workload-level policies</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#observability","title":"Observability","text":"<ul> <li>Distributed Tracing: Request flow across services (Cloud Trace integration)</li> <li>Metrics Collection: Automatic metrics for all service traffic</li> <li>Access Logs: Detailed logs of service communication</li> <li>Service Graph: Visualize service dependencies</li> <li>Dashboards: Pre-built monitoring dashboards</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#resilience","title":"Resilience","text":"<ul> <li>Circuit Breakers: Prevent overwhelming failing services</li> <li>Outlier Detection: Remove unhealthy instances from load balancing</li> <li>Request Timeouts: Prevent indefinite waits</li> <li>Retries: Automatic retry with exponential backoff</li> <li>Connection Pooling: Limit connections to downstream services</li> </ul>"},{"location":"gcp/kubernetes/service-mesh-istio/#architecture","title":"Architecture","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#components","title":"Components","text":"<p>Data Plane:</p> <ul> <li>Envoy Proxy: Sidecar container injected into each pod</li> <li>Intercepts Traffic: All inbound/outbound traffic goes through Envoy</li> <li>Policy Enforcement: Applies routing, security, observability</li> </ul> <p>Control Plane:</p> <ul> <li>istiod: Single binary consolidating Pilot, Citadel, Galley</li> <li>Configuration Management: Distributes configuration to Envoy proxies</li> <li>Certificate Authority: Issues and rotates certificates for mTLS</li> <li>Service Discovery: Tracks services and endpoints</li> </ul> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Control Plane (istiod)          \u2502\n\u2502  - Configuration Distribution           \u2502\n\u2502  - Certificate Authority (CA)           \u2502\n\u2502  - Service Discovery                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u2502 Configuration &amp; Certs\n            \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Data Plane                 \u2502\n\u2502                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Pod A          \u2502 \u2502  Pod B       \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502\n\u2502  \u2502  \u2502 Container \u2502  \u2502 \u2502 \u2502Container \u2502 \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502\n\u2502  \u2502  \u2502Envoy Proxy\u2502\u25c4\u2500\u253c\u2500\u253c\u25ba\u2502Envoy Prox\u2502\u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#installation","title":"Installation","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#install-anthos-service-mesh-recommended","title":"Install Anthos Service Mesh (Recommended)","text":"<pre><code># Download asmcli\ncurl https://storage.googleapis.com/csm-artifacts/asm/asmcli_1.18 &gt; asmcli\nchmod +x asmcli\n\n# Install ASM (managed control plane)\n./asmcli install \\\n  --project_id PROJECT_ID \\\n  --cluster_name CLUSTER_NAME \\\n  --cluster_location CLUSTER_LOCATION \\\n  --fleet_id PROJECT_ID \\\n  --output_dir ./asm-output \\\n  --enable_all \\\n  --option managed \\\n  --ca mesh_ca\n\n# Verify installation\nkubectl get pods -n istio-system\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#install-open-source-istio","title":"Install Open Source Istio","text":"<pre><code># Download Istio\ncurl -L https://istio.io/downloadIstio | sh -\ncd istio-*\nexport PATH=$PWD/bin:$PATH\n\n# Install Istio with default profile\nistioctl install --set profile=default -y\n\n# Verify installation\nkubectl get pods -n istio-system\n\n# Enable sidecar injection for namespace\nkubectl label namespace default istio-injection=enabled\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#sidecar-injection","title":"Sidecar Injection","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#automatic-sidecar-injection","title":"Automatic Sidecar Injection","text":"<p>Enable for entire namespace:</p> <pre><code># Label namespace for auto-injection\nkubectl label namespace default istio-injection=enabled\n\n# Verify label\nkubectl get namespace default --show-labels\n\n# Deploy application - sidecars injected automatically\nkubectl apply -f deployment.yaml\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#manual-sidecar-injection","title":"Manual Sidecar Injection","text":"<p>Inject sidecar into specific deployment:</p> <pre><code># Inject sidecar into YAML\nistioctl kube-inject -f deployment.yaml | kubectl apply -f -\n\n# Or inject and save to file\nistioctl kube-inject -f deployment.yaml &gt; deployment-injected.yaml\nkubectl apply -f deployment-injected.yaml\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#verify-sidecar-injection","title":"Verify Sidecar Injection","text":"<pre><code># Check pod has 2 containers (app + envoy)\nkubectl get pods\n\n# Should show 2/2 ready\n# Describe pod to see containers\nkubectl describe pod &lt;pod-name&gt;\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#traffic-management_1","title":"Traffic Management","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#virtualservice","title":"VirtualService","text":"<p>Define routing rules for a service:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: reviews-route\nspec:\n  hosts:\n\n  - reviews\n\n  http:\n\n  # Route 90% traffic to v1\n\n  - match:\n\n    - headers:\n        end-user:\n          exact: jason\n    route:\n\n    - destination:\n        host: reviews\n        subset: v2\n\n  # Default route for other users\n\n  - route:\n\n    - destination:\n        host: reviews\n        subset: v1\n      weight: 90\n\n    - destination:\n        host: reviews\n        subset: v2\n      weight: 10\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#destinationrule","title":"DestinationRule","text":"<p>Define subsets and traffic policies:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: reviews\nspec:\n  host: reviews\n\n  trafficPolicy:\n    loadBalancer:\n      simple: LEAST_REQUEST\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 50\n        maxRequestsPerConnection: 2\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 30s\n\n  subsets:\n\n  - name: v1\n    labels:\n      version: v1\n\n  - name: v2\n    labels:\n      version: v2\n    trafficPolicy:\n      loadBalancer:\n        simple: ROUND_ROBIN\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#gateway","title":"Gateway","text":"<p>Expose services outside the mesh:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: Gateway\nmetadata:\n  name: bookinfo-gateway\nspec:\n  selector:\n    istio: ingressgateway\n  servers:\n\n  - port:\n      number: 80\n      name: http\n      protocol: HTTP\n    hosts:\n\n    - \"bookinfo.example.com\"\n\n  - port:\n      number: 443\n      name: https\n      protocol: HTTPS\n    tls:\n      mode: SIMPLE\n      credentialName: bookinfo-cert\n    hosts:\n\n    - \"bookinfo.example.com\"\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#traffic-splitting-canary-deployment","title":"Traffic Splitting (Canary Deployment)","text":"<pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: canary-rollout\nspec:\n  hosts:\n\n  - myapp\n\n  http:\n\n  - route:\n\n    - destination:\n        host: myapp\n        subset: stable\n      weight: 90\n\n    - destination:\n        host: myapp\n        subset: canary\n      weight: 10\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#security_1","title":"Security","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#mutual-tls-mtls","title":"Mutual TLS (mTLS)","text":"<p>Enable mTLS for entire mesh:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: istio-system\nspec:\n  mtls:\n    mode: STRICT  # STRICT, PERMISSIVE, or DISABLE\n</code></pre> <p>Enable mTLS for specific namespace:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: production\nspec:\n  mtls:\n    mode: STRICT\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#authorization-policies","title":"Authorization Policies","text":"<p>Deny all traffic by default:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: deny-all\n  namespace: default\nspec:\n  {}  # Empty spec denies all\n</code></pre> <p>Allow specific traffic:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: allow-frontend\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: backend\n\n  action: ALLOW\n\n  rules:\n\n  - from:\n\n    - source:\n        principals:\n\n        - \"cluster.local/ns/default/sa/frontend\"\n    to:\n\n    - operation:\n        methods:\n\n        - \"GET\"\n        - \"POST\"\n        paths:\n\n        - \"/api/*\"\n</code></pre> <p>HTTP-based authorization:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: AuthorizationPolicy\nmetadata:\n  name: httpbin-viewer\nspec:\n  selector:\n    matchLabels:\n      app: httpbin\n\n  action: ALLOW\n\n  rules:\n\n  - from:\n\n    - source:\n        requestPrincipals:\n\n        - \"*\"\n\n    when:\n\n    - key: request.auth.claims[groups]\n      values:\n\n      - \"viewer\"\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#request-authentication","title":"Request Authentication","text":"<p>Validate JWT tokens:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: RequestAuthentication\nmetadata:\n  name: jwt-auth\n  namespace: default\nspec:\n  selector:\n    matchLabels:\n      app: httpbin\n\n  jwtRules:\n\n  - issuer: \"https://accounts.google.com\"\n    jwksUri: \"https://www.googleapis.com/oauth2/v3/certs\"\n    audiences:\n\n    - \"my-app\"\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#observability_1","title":"Observability","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#distributed-tracing","title":"Distributed Tracing","text":"<p>View traces in Cloud Trace:</p> <pre><code># Enable Cloud Trace integration (ASM)\n# Already integrated by default with ASM\n\n# View traces in Cloud Console\n# Navigation: Operations \u2192 Trace \u2192 Trace List\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#metrics","title":"Metrics","text":"<p>View metrics in Cloud Monitoring:</p> <pre><code># ASM metrics automatically exported to Cloud Monitoring\n# Navigate to Cloud Console \u2192 Monitoring \u2192 Metrics Explorer\n\n# Query Istio metrics\n# Metric type: istio.io/service/server/request_count\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#service-dashboard","title":"Service Dashboard","text":"<p>Access Istio dashboards:</p> <pre><code># Install Kiali (service mesh dashboard)\nkubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/kiali.yaml\n\n# Port forward to access Kiali\nkubectl port-forward -n istio-system svc/kiali 20001:20001\n\n# Open browser to http://localhost:20001\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#access-logs","title":"Access Logs","text":"<p>Enable access logs:</p> <pre><code>apiVersion: telemetry.istio.io/v1alpha1\nkind: Telemetry\nmetadata:\n  name: mesh-default\n  namespace: istio-system\nspec:\n  accessLogging:\n\n  - providers:\n\n    - name: envoy\n</code></pre> <p>View logs:</p> <pre><code># View Envoy proxy logs\nkubectl logs &lt;pod-name&gt; -c istio-proxy\n\n# Stream access logs\nkubectl logs -f &lt;pod-name&gt; -c istio-proxy\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#advanced-features","title":"Advanced Features","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#circuit-breaking","title":"Circuit Breaking","text":"<p>Prevent overwhelming failing services:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: circuit-breaker\nspec:\n  host: myservice\n  trafficPolicy:\n    connectionPool:\n      tcp:\n        maxConnections: 100\n      http:\n        http1MaxPendingRequests: 10\n        maxRequestsPerConnection: 2\n    outlierDetection:\n      consecutiveErrors: 5\n      interval: 30s\n      baseEjectionTime: 1m\n      maxEjectionPercent: 50\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#fault-injection","title":"Fault Injection","text":"<p>Test resilience by injecting failures:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: fault-injection\nspec:\n  hosts:\n\n  - ratings\n\n  http:\n\n  - fault:\n      delay:\n        percentage:\n          value: 10\n        fixedDelay: 5s\n      abort:\n        percentage:\n          value: 10\n        httpStatus: 500\n    route:\n\n    - destination:\n        host: ratings\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#retry-logic","title":"Retry Logic","text":"<p>Automatic retries with backoff:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: retry-policy\nspec:\n  hosts:\n\n  - myservice\n\n  http:\n\n  - route:\n\n    - destination:\n        host: myservice\n    retries:\n      attempts: 3\n      perTryTimeout: 2s\n      retryOn: 5xx,reset,connect-failure,refused-stream\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#request-timeouts","title":"Request Timeouts","text":"<p>Set global timeout:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: VirtualService\nmetadata:\n  name: timeout-policy\nspec:\n  hosts:\n\n  - myservice\n\n  http:\n\n  - route:\n\n    - destination:\n        host: myservice\n    timeout: 10s\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#important-limits","title":"Important Limits","text":"Limit Value Notes Services per mesh 1000s Based on cluster capacity Virtual Services 1000s No hard limit Gateways Depends on ingress capacity Sidecar overhead ~50-100MB RAM Per pod CPU overhead ~0.1-0.5 vCPU Varies with traffic Latency overhead 1-10ms P99 typically &lt;5ms"},{"location":"gcp/kubernetes/service-mesh-istio/#when-to-use","title":"When to Use","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#use-service-mesh-when","title":"\u2705 Use Service Mesh When:","text":"<ol> <li> <p>Microservices Architecture</p> </li> <li> <p>Multiple services communicating</p> </li> <li>Need traffic management between services</li> <li> <p>Service-to-service security required</p> </li> <li> <p>Advanced Traffic Management</p> </li> <li> <p>Canary deployments</p> </li> <li>A/B testing</li> <li>Traffic splitting and routing</li> <li> <p>Blue-green deployments</p> </li> <li> <p>Security Requirements</p> </li> <li> <p>Need mTLS for service communication</p> </li> <li>Fine-grained authorization policies</li> <li> <p>Compliance requirements for encrypted traffic</p> </li> <li> <p>Observability Needed</p> </li> <li> <p>Distributed tracing across services</p> </li> <li>Service-level metrics</li> <li> <p>Service dependency visualization</p> </li> <li> <p>Resilience Patterns</p> </li> <li> <p>Circuit breaking</p> </li> <li>Retry logic</li> <li>Timeout management</li> <li>Fault injection for testing</li> </ol>"},{"location":"gcp/kubernetes/service-mesh-istio/#dont-use-service-mesh-when","title":"\u274c Don\u2019t Use Service Mesh When:","text":"<ol> <li> <p>Simple Architecture</p> </li> <li> <p>Monolithic application</p> </li> <li>Few services (&lt; 5)</li> <li> <p>Complexity not justified</p> </li> <li> <p>Performance Critical</p> </li> <li> <p>Cannot tolerate 1-10ms latency overhead</p> </li> <li>Extremely high throughput requirements</li> <li> <p>Resource-constrained environment</p> </li> <li> <p>Limited Team Expertise</p> </li> <li> <p>Small team without service mesh experience</p> </li> <li>Cannot invest in learning curve</li> <li> <p>Lack operational expertise</p> </li> <li> <p>Resource Constraints</p> </li> <li> <p>Very small cluster</p> </li> <li>Cannot afford sidecar overhead (memory/CPU)</li> <li>Budget constraints</li> </ol>"},{"location":"gcp/kubernetes/service-mesh-istio/#best-practices","title":"Best Practices","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#1-start-with-permissive-mtls","title":"1. Start with Permissive mTLS","text":"<pre><code># Begin with PERMISSIVE mode\nspec:\n  mtls:\n    mode: PERMISSIVE\n\n# Migrate to STRICT after all services have sidecars\nspec:\n  mtls:\n    mode: STRICT\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#2-use-namespace-level-policies","title":"2. Use Namespace-Level Policies","text":"<pre><code># Apply policies at namespace level\nmetadata:\n  namespace: production\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#3-monitor-sidecar-resource-usage","title":"3. Monitor Sidecar Resource Usage","text":"<pre><code># Check sidecar memory/CPU\nkubectl top pods\n\n# Set resource limits for sidecars\n# In ASM, configured via MeshConfig\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#4-enable-access-logging-selectively","title":"4. Enable Access Logging Selectively","text":"<pre><code># Enable only for specific services\nspec:\n  selector:\n    matchLabels:\n      app: critical-service\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#5-test-with-fault-injection","title":"5. Test with Fault Injection","text":"<pre><code># Test resilience before production\nfault:\n  delay:\n    percentage:\n      value: 10\n    fixedDelay: 3s\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#6-use-circuit-breakers","title":"6. Use Circuit Breakers","text":"<pre><code># Prevent cascading failures\noutlierDetection:\n  consecutiveErrors: 5\n  interval: 30s\n  baseEjectionTime: 30s\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#7-implement-gradual-rollouts","title":"7. Implement Gradual Rollouts","text":"<pre><code># Start with small percentage\n\n- destination:\n    host: myapp\n    subset: v2\n  weight: 10  # 10% canary traffic\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gcp/kubernetes/service-mesh-istio/#sidecar-not-injecting","title":"Sidecar Not Injecting","text":"<pre><code># Check namespace label\nkubectl get namespace default --show-labels\n\n# Verify webhook exists\nkubectl get mutatingwebhookconfigurations\n\n# Check injection status\nkubectl get pods -o jsonpath='{.items[*].spec.containers[*].name}'\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#mtls-connection-issues","title":"mTLS Connection Issues","text":"<pre><code># Check PeerAuthentication\nkubectl get peerauthentication -A\n\n# Verify certificates\nistioctl proxy-config secret &lt;pod-name&gt;\n\n# Check mutual TLS status\nistioctl authn tls-check &lt;pod-name&gt;\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#traffic-not-routing-correctly","title":"Traffic Not Routing Correctly","text":"<pre><code># Validate configuration\nistioctl analyze\n\n# Check VirtualService\nkubectl get virtualservice &lt;name&gt; -o yaml\n\n# View Envoy configuration\nistioctl proxy-config routes &lt;pod-name&gt;\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#high-latency","title":"High Latency","text":"<pre><code># Check Envoy stats\nkubectl exec &lt;pod-name&gt; -c istio-proxy -- curl localhost:15000/stats\n\n# View traces\n# Navigate to Cloud Trace in Console\n\n# Analyze metrics\nkubectl top pods\n</code></pre>"},{"location":"gcp/kubernetes/service-mesh-istio/#related-resources","title":"Related Resources","text":"<ul> <li>GKE Overview - GKE fundamentals</li> <li>GKE Deployments - Application deployment</li> <li>GKE Scaling - Scaling considerations</li> <li>kubectl - Command-line operations</li> </ul>"},{"location":"gcp/networking/bgp/","title":"BGP (Border Gateway Protocol)","text":""},{"location":"gcp/networking/bgp/#description","title":"Description","text":"<p>BGP is the standard exterior gateway protocol used to exchange routing information between autonomous systems (AS) on the internet and within private networks. In Google Cloud, BGP is used with Cloud Router to enable dynamic routing between VPC networks and on-premises or other cloud networks via Cloud VPN and Cloud Interconnect.</p> <p>Purpose: Automatically exchange route information, enabling dynamic network topology changes without manual route updates.</p>"},{"location":"gcp/networking/bgp/#bgp-fundamentals","title":"BGP Fundamentals","text":""},{"location":"gcp/networking/bgp/#autonomous-system-as","title":"Autonomous System (AS)","text":"<ul> <li>Definition: Collection of IP networks under single administrative control</li> <li>ASN: Unique number identifying the AS</li> <li>Types:</li> <li>Public ASN: Registered with IANA (1-64511, 65536-4199999999)</li> <li>Private ASN: For internal use only (64512-65534, 4200000000-4294967294)</li> </ul>"},{"location":"gcp/networking/bgp/#bgp-session-types","title":"BGP Session Types","text":"<p>eBGP (External BGP):</p> <ul> <li>Between different autonomous systems</li> <li>Default: On-premises AS to Google Cloud AS</li> <li>TTL: 1 (directly connected peers)</li> <li>Use case: Cloud VPN, Cloud Interconnect</li> </ul> <p>iBGP (Internal BGP):</p> <ul> <li>Within same autonomous system</li> <li>TTL: Maximum (255)</li> <li>Use case: Less common in GCP, more for traditional networks</li> </ul>"},{"location":"gcp/networking/bgp/#bgp-attributes","title":"BGP Attributes","text":"<p>BGP uses various attributes to determine best path selection:</p> <ol> <li>AS-PATH: List of ASNs the route has traversed</li> <li>Next-Hop: IP address of next router in path</li> <li>MED (Multi-Exit Discriminator): Suggest preferred entry point</li> <li>Local Preference: Prefer specific exit point (iBGP only)</li> <li>Weight: Cisco proprietary (highest = best)</li> <li>Origin: How route was learned (IGP, EGP, Incomplete)</li> </ol>"},{"location":"gcp/networking/bgp/#bgp-path-selection","title":"BGP Path Selection","text":"<p>BGP selects the best path using these criteria in order:</p> <ol> <li>Highest Weight (Cisco-specific, local to router)</li> <li>Highest Local Preference (default: 100)</li> <li>Locally originated routes (network, aggregate, redistribute)</li> <li>Shortest AS-PATH</li> <li>Lowest Origin type (IGP &lt; EGP &lt; Incomplete)</li> <li>Lowest MED (if from same AS)</li> <li>eBGP over iBGP</li> <li>Lowest IGP metric to BGP next hop</li> <li>Oldest route (for eBGP paths)</li> <li>Lowest Router ID</li> </ol> <p>In GCP Context: You primarily control path selection via MED (from Cloud Router) and AS-PATH prepending (from on-premises).</p>"},{"location":"gcp/networking/bgp/#bgp-in-google-cloud","title":"BGP in Google Cloud","text":""},{"location":"gcp/networking/bgp/#cloud-router-asn-configuration","title":"Cloud Router ASN Configuration","text":"<p>When creating a Cloud Router, you specify an ASN:</p> <p>Private ASN Ranges:</p> <ul> <li>16-bit: 64512 - 65534 (for compatibility)</li> <li>32-bit: 4200000000 - 4294967294 (recommended)</li> </ul> <p>Best Practices:</p> <ul> <li>Use 32-bit private ASN (4-byte ASN) for better uniqueness</li> <li>Document ASN assignments across your organization</li> <li>Ensure Cloud Router ASN differs from peer ASN</li> <li>Use consistent ASN scheme (e.g., 4200000000 + project_number)</li> </ul>"},{"location":"gcp/networking/bgp/#bgp-session-configuration","title":"BGP Session Configuration","text":"<p>Each BGP session requires:</p> <pre><code>Cloud Router Configuration:\n\n  - Router ASN: 64512 (example)\n  - Interface: VPN tunnel or VLAN attachment\n  - Peer ASN: 65001 (on-premises ASN)\n  - Peer IP: Automatically assigned (VPN) or manually configured (Interconnect)\n  - Advertised Route Priority (MED): 100 (default)\n  - MD5 Authentication: Optional shared secret\n  - BFD: Enabled/Disabled\n</code></pre> <p>On-Premises Router Configuration:</p> <ul> <li>Must configure complementary BGP session</li> <li>Neighbor IP: Cloud Router\u2019s interface IP</li> <li>Neighbor ASN: Cloud Router\u2019s ASN</li> <li>Route advertisement: On-premises networks to advertise</li> </ul>"},{"location":"gcp/networking/bgp/#route-advertisement","title":"Route Advertisement","text":""},{"location":"gcp/networking/bgp/#from-cloud-router-to-on-premises","title":"From Cloud Router to On-Premises","text":"<p>Default Mode:</p> <ul> <li>Advertises all VPC subnet routes automatically</li> <li>Regional routing: Only subnets in the same region</li> <li>Global routing: All subnets in all regions</li> </ul> <p>Custom Mode:</p> <ul> <li>Manually specify IP ranges to advertise</li> <li>Can advertise:</li> <li>VPC subnet ranges</li> <li>Secondary subnet ranges</li> <li>Custom IP ranges</li> <li>Summary routes (supernets)</li> </ul> <p>Example: <pre><code>VPC Subnets:\n\n  - 10.1.0.0/24\n  - 10.2.0.0/24\n  - 10.3.0.0/24\n\nCustom Advertisement:\n\n  - 10.0.0.0/8 (summary route instead of individual /24s)\n</code></pre></p>"},{"location":"gcp/networking/bgp/#from-on-premises-to-cloud-router","title":"From On-Premises to Cloud Router","text":"<ul> <li>Configure on your on-premises router</li> <li>Advertise on-premises network ranges</li> <li>Cloud Router learns these routes via BGP</li> <li>Routes are programmed into VPC routing table</li> </ul> <p>Important: Learned routes count against quota (default 250, max 5000 per Cloud Router).</p>"},{"location":"gcp/networking/bgp/#route-priority-and-traffic-engineering","title":"Route Priority and Traffic Engineering","text":""},{"location":"gcp/networking/bgp/#using-med-multi-exit-discriminator","title":"Using MED (Multi-Exit Discriminator)","text":"<p>MED influences inbound traffic (from on-premises to GCP):</p> <p>Configuration on Cloud Router: <pre><code>Cloud Router 1 (Primary Path):\n\n  - Advertised Route Priority: 50 (lower = preferred)\n\nCloud Router 2 (Backup Path):\n\n  - Advertised Route Priority: 100 (higher = less preferred)\n</code></pre></p> <p>Result: On-premises router prefers routes via Cloud Router 1.</p> <p>Important:</p> <ul> <li>Lower MED = higher priority</li> <li>MED is compared only for routes from same neighboring AS</li> <li>Default MED: 100</li> </ul>"},{"location":"gcp/networking/bgp/#using-as-path-prepending","title":"Using AS-PATH Prepending","text":"<p>AS-PATH prepending influences outbound traffic (from GCP to on-premises):</p> <p>Configuration on On-Premises Router: <pre><code>Primary Path:\n\n  - Advertise: 192.168.0.0/16 (AS-PATH: 65001)\n\nBackup Path:\n\n  - Advertise: 192.168.0.0/16 (AS-PATH: 65001 65001 65001)\n  - Prepend AS 65001 twice to make path \"longer\"\n</code></pre></p> <p>Result: Cloud Router prefers routes via primary path (shorter AS-PATH).</p>"},{"location":"gcp/networking/bgp/#active-active-vs-active-passive","title":"Active-Active vs Active-Passive","text":"<p>Active-Active:</p> <ul> <li>Equal cost multi-path (ECMP)</li> <li>Same MED values on both paths</li> <li>Traffic load-balanced across both paths</li> <li>Use case: Maximize bandwidth, high availability</li> </ul> <p>Active-Passive:</p> <ul> <li>Primary path with lower MED</li> <li>Backup path with higher MED</li> <li>Traffic uses primary path unless it fails</li> <li>Use case: Controlled failover, predictable routing</li> </ul>"},{"location":"gcp/networking/bgp/#bfd-bidirectional-forwarding-detection","title":"BFD (Bidirectional Forwarding Detection)","text":""},{"location":"gcp/networking/bgp/#purpose","title":"Purpose","text":"<p>Fast failure detection for BGP sessions:</p> <ul> <li>BGP keepalive: 60 seconds (slow)</li> <li>BFD: 1-3 seconds (fast)</li> </ul>"},{"location":"gcp/networking/bgp/#how-it-works","title":"How It Works","text":"<ul> <li>Lightweight \u201chello\u201d packets exchanged between peers</li> <li>Independent of BGP protocol</li> <li>Detects link/path failures quickly</li> <li>Triggers BGP session teardown on failure</li> </ul>"},{"location":"gcp/networking/bgp/#configuration-in-gcp","title":"Configuration in GCP","text":"<pre><code>BGP Session:\n\n  - BFD: Enabled\n  - Min Transmit Interval: 1000 ms (default)\n  - Min Receive Interval: 1000 ms (default)\n  - Multiplier: 3 (default)\n</code></pre> <p>Calculation: 3 missed packets \u00d7 1000ms = ~3 second failure detection</p>"},{"location":"gcp/networking/bgp/#when-to-use-bfd","title":"When to Use BFD","text":"<ul> <li>\u2705 Production environments</li> <li>\u2705 Active-active configurations requiring fast failover</li> <li>\u2705 Critical workloads with HA requirements</li> <li>\u274c Non-production environments (adds complexity)</li> </ul>"},{"location":"gcp/networking/bgp/#common-scenarios","title":"Common Scenarios","text":""},{"location":"gcp/networking/bgp/#scenario-1-prefer-primary-vpn-tunnel","title":"Scenario 1: Prefer Primary VPN Tunnel","text":"<p>Requirement: Route traffic via Tunnel 1, use Tunnel 2 as backup.</p> <p>Solution: <pre><code>Cloud Router BGP Sessions:\n\n  - Tunnel 1: MED = 50\n  - Tunnel 2: MED = 100\n\nOn-premises routes traffic via Tunnel 1 (lower MED preferred).\n</code></pre></p>"},{"location":"gcp/networking/bgp/#scenario-2-regional-preference","title":"Scenario 2: Regional Preference","text":"<p>Requirement: US traffic uses US region, Europe traffic uses Europe region.</p> <p>Solution: <pre><code>Cloud Router US (us-central1):\n\n  - Advertises US subnets with MED = 50\n  - Advertises EU subnets with MED = 100\n\nCloud Router EU (europe-west1):\n\n  - Advertises EU subnets with MED = 50\n  - Advertises US subnets with MED = 100\n\nOn-premises router learns both, prefers regional routes (lower MED).\n</code></pre></p>"},{"location":"gcp/networking/bgp/#scenario-3-controlled-outbound-path","title":"Scenario 3: Controlled Outbound Path","text":"<p>Requirement: Force GCP to use specific on-premises path.</p> <p>Solution: <pre><code>On-Premises Router:\n\n  - Primary path: AS-PATH = 65001\n  - Backup path: AS-PATH = 65001 65001 65001 (prepended)\n\nCloud Router prefers primary (shorter AS-PATH).\n</code></pre></p>"},{"location":"gcp/networking/bgp/#scenario-4-load-balancing-across-tunnels","title":"Scenario 4: Load Balancing Across Tunnels","text":"<p>Requirement: Distribute traffic evenly across multiple VPN tunnels.</p> <p>Solution: <pre><code>Cloud Router:\n\n  - Tunnel 1: MED = 100\n  - Tunnel 2: MED = 100\n  - Tunnel 3: MED = 100\n  - Tunnel 4: MED = 100\n\nEqual cost paths enable ECMP load balancing.\n</code></pre></p>"},{"location":"gcp/networking/bgp/#md5-authentication","title":"MD5 Authentication","text":""},{"location":"gcp/networking/bgp/#purpose_1","title":"Purpose","text":"<p>Secure BGP sessions from spoofing and unauthorized peers.</p>"},{"location":"gcp/networking/bgp/#configuration","title":"Configuration","text":"<p>In GCP: <pre><code>gcloud compute routers add-bgp-peer ROUTER_NAME \\\n  --peer-name=PEER_NAME \\\n  --peer-asn=PEER_ASN \\\n  --interface=INTERFACE \\\n  --md5-authentication-key=\"SHARED_SECRET\"\n</code></pre></p> <p>On On-Premises Router (example): <pre><code>router bgp 65001\n  neighbor 169.254.1.1 remote-as 64512\n  neighbor 169.254.1.1 password SHARED_SECRET\n</code></pre></p> <p>Best Practices:</p> <ul> <li>Use strong, random keys (16+ characters)</li> <li>Store keys securely (secrets management)</li> <li>Rotate keys periodically</li> <li>Consistent configuration on both sides</li> </ul>"},{"location":"gcp/networking/bgp/#limits-and-quotas","title":"Limits and Quotas","text":"Item Limit Notes BGP sessions per Cloud Router 128 Default Learned routes per Cloud Router 250 (default), 5000 (max) Request increase if needed Advertised routes Unlimited Based on VPC subnets ASN range (private) 64512-65534, 4200000000-4294967294 RFC 6996 BGP keepalive 20 seconds Not configurable BGP hold timer 60 seconds Not configurable BFD intervals Min 1000ms Configurable per session"},{"location":"gcp/networking/bgp/#best-practices","title":"Best Practices","text":""},{"location":"gcp/networking/bgp/#1-asn-planning","title":"1. ASN Planning","text":"<ul> <li>Document all ASN assignments</li> <li>Use 32-bit ASNs to avoid conflicts</li> <li>Reserve ASN ranges for different purposes (prod, dev, regions)</li> <li>Ensure uniqueness across entire network</li> </ul>"},{"location":"gcp/networking/bgp/#2-route-management","title":"2. Route Management","text":"<ul> <li>Start with default advertisement, move to custom if needed</li> <li>Use route summarization to reduce route count</li> <li>Monitor learned routes against quotas</li> <li>Implement route filtering on both sides</li> </ul>"},{"location":"gcp/networking/bgp/#3-redundancy","title":"3. Redundancy","text":"<ul> <li>Configure multiple BGP sessions per Cloud Router</li> <li>Use diverse physical paths when possible</li> <li>Enable BFD for fast failover</li> <li>Test failover scenarios regularly</li> </ul>"},{"location":"gcp/networking/bgp/#4-traffic-engineering","title":"4. Traffic Engineering","text":"<ul> <li>Document MED and AS-PATH configurations</li> <li>Use consistent MED values for similar paths</li> <li>Avoid excessive AS-PATH prepending (3x max)</li> <li>Monitor traffic flow and adjust as needed</li> </ul>"},{"location":"gcp/networking/bgp/#5-security","title":"5. Security","text":"<ul> <li>Enable MD5 authentication on all BGP sessions</li> <li>Use firewall rules to restrict BGP peers</li> <li>Monitor BGP session status for anomalies</li> <li>Regular security audits of BGP configurations</li> </ul>"},{"location":"gcp/networking/bgp/#6-monitoring","title":"6. Monitoring","text":"<ul> <li>Set up alerts for BGP session down</li> <li>Monitor route count approaching limits</li> <li>Track route flapping (unstable routes)</li> <li>Use VPC Flow Logs to verify traffic paths</li> </ul>"},{"location":"gcp/networking/bgp/#troubleshooting","title":"Troubleshooting","text":""},{"location":"gcp/networking/bgp/#bgp-session-not-establishing","title":"BGP Session Not Establishing","text":"<p>Symptoms: BGP state stuck in \u201cIdle\u201d or \u201cActive\u201d</p> <p>Common Causes:</p> <ol> <li>ASN mismatch (peer ASN incorrect)</li> <li>MD5 authentication mismatch</li> <li>Incorrect peer IP address</li> <li>Firewall blocking TCP 179</li> <li>Interface down (VPN tunnel down)</li> </ol> <p>Debug Steps: <pre><code># Check BGP session status\ngcloud compute routers get-status ROUTER_NAME --region=REGION\n\n# Check interface status  \ngcloud compute vpn-tunnels describe TUNNEL_NAME --region=REGION\n\n# Verify configuration\ngcloud compute routers describe ROUTER_NAME --region=REGION\n</code></pre></p>"},{"location":"gcp/networking/bgp/#routes-not-being-advertisedlearned","title":"Routes Not Being Advertised/Learned","text":"<p>Symptoms: Expected routes missing from routing table</p> <p>Common Causes:</p> <ol> <li>VPC dynamic routing mode (regional vs global)</li> <li>Custom advertisement not configured</li> <li>Route quota exceeded</li> <li>AS-PATH loop detection</li> <li>Route filtering on peer side</li> </ol> <p>Debug Steps: <pre><code># Check advertised routes\ngcloud compute routers get-status ROUTER_NAME --region=REGION\n\n# Check VPC routing table\ngcloud compute routes list --filter=\"network:NETWORK_NAME\"\n\n# Verify learned routes count\ngcloud compute routers get-status ROUTER_NAME --region=REGION \\\n  --format=\"value(result.bgpPeerStatus[].numLearnedRoutes)\"\n</code></pre></p>"},{"location":"gcp/networking/bgp/#asymmetric-routing","title":"Asymmetric Routing","text":"<p>Symptoms: Inbound and outbound traffic taking different paths</p> <p>Diagnosis:</p> <ul> <li>Use VPC Flow Logs to trace traffic paths</li> <li>Check MED values on all BGP sessions</li> <li>Verify AS-PATH prepending configuration</li> <li>Review on-premises routing policy</li> </ul> <p>Solutions:</p> <ul> <li>Adjust MED to align inbound path with outbound</li> <li>Modify AS-PATH prepending on outbound path</li> <li>Ensure symmetric route advertisements</li> </ul>"},{"location":"gcp/networking/bgp/#related-concepts","title":"Related Concepts","text":"<ul> <li>Cloud Router: GCP service that implements BGP</li> <li>VPC Dynamic Routing: Determines scope of route advertisement</li> <li>Cloud VPN: Uses BGP for dynamic routing (HA VPN)</li> <li>Cloud Interconnect: Uses BGP for route exchange</li> <li>ECMP: Equal-Cost Multi-Path routing for load balancing</li> <li>VRF: Virtual Routing and Forwarding (used internally by Google)</li> </ul>"},{"location":"gcp/networking/bgp/#further-reading","title":"Further Reading","text":"<ul> <li>RFC 4271: BGP-4 Protocol Specification</li> <li>RFC 6996: Private Use AS Numbers</li> <li>RFC 5880: BFD Protocol</li> <li>RFC 4456: BGP Route Reflection</li> <li>Google Cloud Documentation: Cloud Router BGP Configuration</li> </ul>"},{"location":"gcp/networking/cloud-router/","title":"Cloud Router","text":""},{"location":"gcp/networking/cloud-router/#description","title":"Description","text":"<p>Cloud Router is a fully distributed and managed Google Cloud service that uses Border Gateway Protocol (BGP) to dynamically exchange routes between your Google Cloud VPC network and on-premises or other cloud networks. It eliminates the need for static routes and enables automatic failover, scalability, and simplified network management.</p> <p>Architecture: Software-defined router that runs in Google\u2019s network, enabling dynamic route propagation without physical router appliances.</p>"},{"location":"gcp/networking/cloud-router/#key-features","title":"Key Features","text":""},{"location":"gcp/networking/cloud-router/#dynamic-routing","title":"Dynamic Routing","text":"<ul> <li>BGP Protocol: Industry-standard protocol for route exchange</li> <li>Automatic Route Updates: Routes automatically updated when topology changes</li> <li>Multi-Path: Supports ECMP (Equal-Cost Multi-Path) routing</li> <li>Route Priorities: Control route selection with MED and AS-PATH</li> </ul>"},{"location":"gcp/networking/cloud-router/#high-availability","title":"High Availability","text":"<ul> <li>Fully Managed: No VMs to manage, patch, or scale</li> <li>No Single Point of Failure: Distributed service across Google infrastructure</li> <li>Redundant BGP Sessions: Multiple sessions for failover</li> <li>BFD Support: Bidirectional Forwarding Detection for fast failure detection</li> </ul>"},{"location":"gcp/networking/cloud-router/#integration","title":"Integration","text":"<ul> <li>Cloud VPN: Required for dynamic routing with HA VPN</li> <li>Cloud Interconnect: Enables BGP for Dedicated and Partner Interconnect</li> <li>Router Appliances: Integrates with third-party network virtual appliances</li> <li>Multiple Interfaces: Can peer with multiple VPN tunnels or VLAN attachments</li> </ul>"},{"location":"gcp/networking/cloud-router/#route-management","title":"Route Management","text":"<ul> <li>Route Advertisement: Automatically advertises VPC subnet routes</li> <li>Custom Route Advertisement: Selectively advertise specific IP ranges</li> <li>Learned Routes: Receives routes from on-premises via BGP</li> <li>Route Filtering: Control which routes to accept or advertise</li> <li>Route Priorities: Configure local preference and MED values</li> </ul>"},{"location":"gcp/networking/cloud-router/#important-limits","title":"Important Limits","text":"Limit Value Notes Cloud Routers per VPC 5 per region Can be increased BGP sessions per router 128 8 per tunnel/VLAN for redundancy Learned routes per router 250 (default), 5000 (max) Requires custom route advertisement mode Advertised routes Based on VPC subnets + custom ranges BGP route priority (MED) 0-4294967295 Lower is preferred ASN range (private) 64512-65534, 4200000000-4294967294 RFC 6996 BGP keepalive interval 20 seconds (default) Not configurable BGP hold time 60 seconds (default) Not configurable"},{"location":"gcp/networking/cloud-router/#route-advertisement-modes","title":"Route Advertisement Modes","text":""},{"location":"gcp/networking/cloud-router/#default-mode","title":"Default Mode","text":"<ul> <li>Automatically advertises all subnet routes in the VPC</li> <li>Simple configuration, minimal management</li> <li>Routes added/removed automatically as subnets change</li> <li>Cannot selectively control which subnets to advertise</li> </ul>"},{"location":"gcp/networking/cloud-router/#custom-mode","title":"Custom Mode","text":"<ul> <li>Manually specify which IP ranges to advertise</li> <li>Greater control over route advertisement</li> <li>Required for advertising &gt; 250 routes</li> <li>Can advertise routes outside VPC CIDR ranges</li> <li>Useful for summarizing routes</li> </ul> <p>Example Use Cases for Custom Mode:</p> <ul> <li>Advertising summary routes instead of individual subnets</li> <li>Advertising secondary IP ranges</li> <li>Advertising IP ranges from other VPCs (via VPC peering)</li> <li>Limiting route advertisements to specific subnets</li> </ul>"},{"location":"gcp/networking/cloud-router/#bgp-configuration","title":"BGP Configuration","text":""},{"location":"gcp/networking/cloud-router/#asn-autonomous-system-number","title":"ASN (Autonomous System Number)","text":"<ul> <li>Cloud Router ASN: Assigned to the Cloud Router</li> <li>Peer ASN: On-premises or partner router ASN</li> <li>Private ASNs: 64512-65534 (16-bit), 4200000000-4294967294 (32-bit)</li> <li>Public ASNs: Registered with IANA (if you own one)</li> </ul> <p>Important: ASN must be unique across your BGP topology. Cloud Router and peer must have different ASNs.</p>"},{"location":"gcp/networking/cloud-router/#bgp-peering","title":"BGP Peering","text":"<p>Each BGP session requires:</p> <ul> <li>Peer IP: On-premises router IP (for VPN, automatically assigned)</li> <li>Peer ASN: Autonomous System Number of peer router</li> <li>Interface: Cloud Router interface (VPN tunnel or VLAN attachment)</li> <li>Advertised Route Priority: MED value for this session</li> <li>MD5 Authentication: Optional but recommended for security</li> </ul>"},{"location":"gcp/networking/cloud-router/#route-priorities","title":"Route Priorities","text":"<p>MED (Multi-Exit Discriminator):</p> <ul> <li>Lower MED = higher priority</li> <li>Default: 100</li> <li>Range: 0-4294967295</li> <li>Use case: Prefer specific paths for inbound traffic from on-premises</li> </ul> <p>AS-PATH Prepending:</p> <ul> <li>Configured on peer side (on-premises router)</li> <li>Longer AS path = lower priority</li> <li>Use case: Influence route selection from Cloud Router perspective</li> </ul>"},{"location":"gcp/networking/cloud-router/#when-to-use","title":"When to Use","text":""},{"location":"gcp/networking/cloud-router/#use-cloud-router-when","title":"\u2705 Use Cloud Router When:","text":"<ol> <li>Hybrid Connectivity with Dynamic Routing</li> <li>Cloud VPN (HA VPN requires Cloud Router)</li> <li>Cloud Interconnect (Dedicated or Partner)</li> <li> <p>Need automatic route updates between GCP and on-premises</p> </li> <li> <p>High Availability Requirements</p> </li> <li>Automatic failover between redundant connections</li> <li>Multiple VPN tunnels or VLAN attachments</li> <li> <p>BFD for sub-second failure detection</p> </li> <li> <p>Complex Network Topologies</p> </li> <li>Multiple on-premises sites</li> <li>Multi-region GCP deployments</li> <li> <p>Hub-and-spoke architectures with dynamic routing</p> </li> <li> <p>Scalable Route Management</p> </li> <li>Large number of subnets that change frequently</li> <li>Want to avoid manual route updates</li> <li> <p>Need route summarization</p> </li> <li> <p>Network Virtual Appliances</p> </li> <li>Integrate third-party routers/firewalls</li> <li>Custom routing requirements</li> <li>Advanced traffic inspection/manipulation</li> </ol>"},{"location":"gcp/networking/cloud-router/#dont-use-cloud-router-when","title":"\u274c Don\u2019t Use Cloud Router When:","text":"<ol> <li>Simple Static Routing Sufficient</li> <li>Few static routes that rarely change</li> <li>Small-scale deployments</li> <li> <p>Classic VPN with static routes is adequate</p> </li> <li> <p>No Hybrid Connectivity</p> </li> <li>Pure cloud-only deployments with no on-premises integration</li> <li> <p>VPC-to-VPC routing handled by VPC peering</p> </li> <li> <p>Layer 2 Requirements</p> </li> <li>Need Layer 2 connectivity (Cloud Router is Layer 3)</li> <li>Use Dedicated Interconnect Layer 2 connections directly</li> </ol>"},{"location":"gcp/networking/cloud-router/#common-architectures","title":"Common Architectures","text":""},{"location":"gcp/networking/cloud-router/#ha-vpn-with-redundant-cloud-routers","title":"HA VPN with Redundant Cloud Routers","text":"<pre><code>On-Premises Router\n    \u251c\u2500\u2500 BGP Session 1 \u2500\u2500\u25b6 Cloud Router 1 (us-central1)\n    \u2502                         \u251c\u2500\u2500 VPN Tunnel 1\n    \u2502                         \u2514\u2500\u2500 VPN Tunnel 2\n    \u2514\u2500\u2500 BGP Session 2 \u2500\u2500\u25b6 Cloud Router 2 (us-central1)\n                              \u251c\u2500\u2500 VPN Tunnel 3\n                              \u2514\u2500\u2500 VPN Tunnel 4\n\nRoute Advertisement: All VPC subnets\nLearned Routes: On-premises CIDRs\nFailover: Automatic via BGP + BFD\n</code></pre>"},{"location":"gcp/networking/cloud-router/#multi-region-with-cloud-interconnect","title":"Multi-Region with Cloud Interconnect","text":"<pre><code>On-Premises\n    \u2514\u2500\u2500 Dedicated Interconnect\n            \u251c\u2500\u2500 VLAN Attachment 1 \u2500\u2500\u25b6 Cloud Router (us-central1)\n            \u2502                              \u2514\u2500\u2500 Advertises: us-central1 subnets\n            \u2514\u2500\u2500 VLAN Attachment 2 \u2500\u2500\u25b6 Cloud Router (europe-west1)\n                                           \u2514\u2500\u2500 Advertises: europe-west1 subnets\n\nVPC Network Mode: Regional dynamic routing\nRoute Preference: Regional (routes preferred in same region)\n</code></pre>"},{"location":"gcp/networking/cloud-router/#router-appliance-with-cloud-router","title":"Router Appliance with Cloud Router","text":"<pre><code>VPC Network\n    \u251c\u2500\u2500 Cloud Router (us-central1)\n    \u2502       \u251c\u2500\u2500 BGP Session \u2500\u2500\u25b6 Third-party Firewall/Router VM\n    \u2502       \u2514\u2500\u2500 Advertises: Custom route 0.0.0.0/0 (default route)\n    \u2502\n    \u2514\u2500\u2500 Subnets\n            \u2514\u2500\u2500 Routes: Default route via appliance VM\n</code></pre>"},{"location":"gcp/networking/cloud-router/#vpc-dynamic-routing-modes","title":"VPC Dynamic Routing Modes","text":"<p>Cloud Router behavior depends on VPC network\u2019s dynamic routing mode:</p>"},{"location":"gcp/networking/cloud-router/#regional-dynamic-routing-default","title":"Regional Dynamic Routing (Default)","text":"<ul> <li>Cloud Router only advertises regional subnet routes</li> <li>Cloud Router only programs learned routes in the same region</li> <li>Use case: Keep traffic regional, reduce inter-region costs</li> </ul> <p>Example: <pre><code>VPC with Regional Dynamic Routing\n\u251c\u2500\u2500 Cloud Router (us-central1)\n\u2502       \u2514\u2500\u2500 Advertises: Only us-central1 subnet routes\n\u2514\u2500\u2500 Cloud Router (europe-west1)\n        \u2514\u2500\u2500 Advertises: Only europe-west1 subnet routes\n</code></pre></p>"},{"location":"gcp/networking/cloud-router/#global-dynamic-routing","title":"Global Dynamic Routing","text":"<ul> <li>Cloud Router advertises all subnet routes across all regions</li> <li>Cloud Router programs learned routes globally in all regions</li> <li>Use case: Global access to on-premises, multi-region failover</li> </ul> <p>Example: <pre><code>VPC with Global Dynamic Routing\n\u251c\u2500\u2500 Cloud Router (us-central1)\n\u2502       \u2514\u2500\u2500 Advertises: ALL subnets (us-central1 + europe-west1 + asia-east1)\n\u2514\u2500\u2500 Cloud Router (europe-west1)\n        \u2514\u2500\u2500 Advertises: ALL subnets (us-central1 + europe-west1 + asia-east1)\n</code></pre></p> <p>Consideration: Global routing enables VMs in any region to reach on-premises via any Cloud Router, but may increase latency and inter-region egress costs.</p>"},{"location":"gcp/networking/cloud-router/#bfd-bidirectional-forwarding-detection","title":"BFD (Bidirectional Forwarding Detection)","text":""},{"location":"gcp/networking/cloud-router/#purpose","title":"Purpose","text":"<p>Provides fast failure detection (sub-second) for BGP sessions, enabling rapid failover.</p>"},{"location":"gcp/networking/cloud-router/#configuration","title":"Configuration","text":"<ul> <li>Enabled per BGP session</li> <li>Min transmit interval: 1000 ms (default)</li> <li>Min receive interval: 1000 ms (default)</li> <li>Multiplier: 3 (default) - 3 missed packets = failure</li> </ul>"},{"location":"gcp/networking/cloud-router/#benefits","title":"Benefits","text":"<ul> <li>Default BGP keepalive (60s) is slow; BFD detects failures in ~3 seconds</li> <li>Faster convergence on path failures</li> <li>Recommended for production deployments</li> </ul>"},{"location":"gcp/networking/cloud-router/#when-to-enable","title":"When to Enable","text":"<ul> <li>\u2705 Production environments requiring high availability</li> <li>\u2705 Active-active VPN tunnel configurations</li> <li>\u2705 Critical workloads needing fast failover</li> <li>\u274c Development/test environments (to reduce complexity)</li> </ul>"},{"location":"gcp/networking/cloud-router/#configuration-best-practices","title":"Configuration Best Practices","text":"<ol> <li>Redundancy</li> <li>Deploy at least two Cloud Routers per region for HA</li> <li>Use multiple BGP sessions per Cloud Router</li> <li> <p>Configure different route priorities for traffic steering</p> </li> <li> <p>Route Management</p> </li> <li>Start with default advertisement mode, switch to custom if needed</li> <li>Use route summarization to reduce advertised route count</li> <li>Document custom route advertisements clearly</li> <li> <p>Monitor learned routes vs quota limits</p> </li> <li> <p>BGP Tuning</p> </li> <li>Enable BFD for fast failure detection</li> <li>Set appropriate MED values for traffic steering</li> <li>Use MD5 authentication on BGP sessions</li> <li> <p>Coordinate AS-PATH prepending with network team</p> </li> <li> <p>Naming Conventions</p> </li> <li>Use descriptive names: <code>cloud-router-us-central1-vpn-primary</code></li> <li>Include region and purpose in the name</li> <li> <p>Document ASN assignments</p> </li> <li> <p>Monitoring</p> </li> <li>Monitor BGP session status</li> <li>Track learned routes count</li> <li>Alert on route quota approaching limits</li> <li>Monitor route propagation delays</li> </ol>"},{"location":"gcp/networking/cloud-router/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"gcp/networking/cloud-router/#bgp-session-not-establishing","title":"BGP Session Not Establishing","text":"<p>Check:</p> <ul> <li>Peer ASN configured correctly</li> <li>Interface (tunnel/VLAN) is UP</li> <li>On-premises router BGP configuration</li> <li>MD5 authentication matches (if used)</li> <li>Firewall allows BGP (TCP 179)</li> </ul>"},{"location":"gcp/networking/cloud-router/#routes-not-being-advertised","title":"Routes Not Being Advertised","text":"<p>Check:</p> <ul> <li>Cloud Router advertisement mode (default vs custom)</li> <li>VPC dynamic routing mode (regional vs global)</li> <li>Custom route ranges configured correctly</li> <li>Route quota not exceeded</li> </ul>"},{"location":"gcp/networking/cloud-router/#routes-not-being-learned","title":"Routes Not Being Learned","text":"<p>Check:</p> <ul> <li>BGP session established</li> <li>On-premises router advertising routes</li> <li>Learned route quota not exceeded</li> <li>Route priority/AS-PATH not causing rejection</li> </ul>"},{"location":"gcp/networking/cloud-router/#asymmetric-routing","title":"Asymmetric Routing","text":"<p>Cause: Different paths for inbound and outbound traffic</p> <p>Solutions:</p> <ul> <li>Adjust MED values to align inbound path</li> <li>Use AS-PATH prepending on outbound path</li> <li>Review VPC dynamic routing mode</li> <li>Check for multiple Cloud Routers with different priorities</li> </ul>"},{"location":"gcp/networking/cloud-router/#cost-considerations","title":"Cost Considerations","text":"<ul> <li>No direct charge for Cloud Router itself</li> <li>Charges apply for associated resources:</li> <li>VPN tunnels (per tunnel-hour)</li> <li>Interconnect VLAN attachments (per attachment-hour)</li> <li>Egress traffic via VPN/Interconnect</li> <li>Cost optimization:</li> <li>Use regional routing mode if global routing not needed (reduces inter-region egress)</li> <li>Consolidate BGP sessions where possible (within limits)</li> </ul>"},{"location":"gcp/networking/cloud-router/#related-services","title":"Related Services","text":"<ul> <li>Cloud VPN: Uses Cloud Router for dynamic routing</li> <li>Cloud Interconnect: Requires Cloud Router for BGP</li> <li>VPC Peering: Does not use Cloud Router (static routing)</li> <li>Network Connectivity Center: Centralized management of hybrid connectivity</li> <li>Router Appliances: Third-party NVAs integrated with Cloud Router</li> <li>Private Service Connect: Access Google services privately (doesn\u2019t use Cloud Router)</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/","title":"Hybrid Connectivity","text":""},{"location":"gcp/networking/hybrid-connectivity/#description","title":"Description","text":"<p>Hybrid connectivity solutions enable secure connections between on-premises networks and Google Cloud VPC networks. GCP offers two primary options: Cloud VPN (encrypted tunnels over the internet) and Cloud Interconnect (dedicated physical connections). Both work with Cloud Router to enable dynamic routing using BGP.</p>"},{"location":"gcp/networking/hybrid-connectivity/#cloud-vpn","title":"Cloud VPN","text":""},{"location":"gcp/networking/hybrid-connectivity/#description_1","title":"Description","text":"<p>IPsec VPN tunnels that encrypt traffic between your on-premises network and GCP VPC over the public internet.</p>"},{"location":"gcp/networking/hybrid-connectivity/#types","title":"Types","text":"<p>HA VPN (High Availability VPN)</p> <ul> <li>SLA: 99.99% availability</li> <li>Architecture: Two interfaces, two external IP addresses, redundant tunnels</li> <li>Routing: Dynamic (BGP) only</li> <li>Recommended: Standard option for production workloads</li> </ul> <p>Classic VPN</p> <ul> <li>SLA: 99.9% availability  </li> <li>Architecture: Single interface, single external IP</li> <li>Routing: Static or dynamic (BGP)</li> <li>Status: Legacy, HA VPN preferred</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#key-features","title":"Key Features","text":"<ul> <li>Encryption: IPsec tunnel with IKEv1 or IKEv2</li> <li>Bandwidth: Up to 3 Gbps per tunnel, use multiple tunnels for more</li> <li>Routing: Dynamic routing with Cloud Router (BGP)</li> <li>Redundancy: Active-active configuration with HA VPN</li> <li>Cost-Effective: No dedicated hardware required</li> <li>Topology: Supports VPN to on-premises, VPN to another cloud, VPC-to-VPC</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#limits","title":"Limits","text":"Limit Value Notes Throughput per tunnel 3 Gbps Use multiple tunnels for higher bandwidth Tunnels per gateway 8 (HA VPN) Can create multiple gateways Tunnels per Cloud Router 128 Default limit MTU 1460 bytes Due to IPsec overhead Encryption Overhead ~10-15% Impacts throughput"},{"location":"gcp/networking/hybrid-connectivity/#when-to-use-cloud-vpn","title":"When to Use Cloud VPN","text":"<p>\u2705 Use When:</p> <ul> <li>Moderate bandwidth requirements (&lt; 10 Gbps aggregate)</li> <li>Quick setup needed (hours, not weeks)</li> <li>Cost sensitivity (cheaper than Interconnect)</li> <li>Geographic flexibility (works anywhere with internet)</li> <li>Temporary connectivity needs</li> <li>Disaster recovery secondary path</li> </ul> <p>\u274c Don\u2019t Use When:</p> <ul> <li>Require &gt; 10 Gbps consistent throughput</li> <li>Need lowest possible latency (Interconnect is better)</li> <li>Compliance requires dedicated connection</li> <li>Require 99.99% SLA with deterministic routing (use Dedicated Interconnect)</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#cloud-interconnect","title":"Cloud Interconnect","text":""},{"location":"gcp/networking/hybrid-connectivity/#description_2","title":"Description","text":"<p>Dedicated physical connections between on-premises infrastructure and Google Cloud, providing higher bandwidth and lower latency than VPN.</p>"},{"location":"gcp/networking/hybrid-connectivity/#types_1","title":"Types","text":"<p>Dedicated Interconnect</p> <ul> <li>Connection: Direct physical connection to Google network</li> <li>Bandwidth: 10 Gbps or 100 Gbps per circuit</li> <li>Location: Must be in a supported colocation facility</li> <li>SLA: 99.99% with proper redundancy configuration</li> <li>Use Case: High bandwidth, low latency, dedicated connectivity</li> </ul> <p>Partner Interconnect </p> <ul> <li>Connection: Through supported service provider</li> <li>Bandwidth: 50 Mbps to 50 Gbps per VLAN attachment</li> <li>Location: Service provider handles physical connectivity</li> <li>SLA: 99.99% with proper redundancy (depends on provider)</li> <li>Use Case: When not near Google edge location, or need managed service</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#key-features_1","title":"Key Features","text":"<ul> <li>Private Connectivity: Traffic doesn\u2019t traverse public internet</li> <li>Low Latency: Direct connection to Google network</li> <li>High Bandwidth: 10-200 Gbps (Dedicated), 50 Mbps - 50 Gbps (Partner)</li> <li>Flexible Routing: BGP with Cloud Router</li> <li>Layer 2 or Layer 3: Dedicated supports both, Partner is Layer 3</li> <li>VLAN Attachments: Multiple VLANs over single physical connection</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#limits_1","title":"Limits","text":"<p>Dedicated Interconnect</p> Limit Value Notes Bandwidth per connection 10 or 100 Gbps Fixed circuit sizes VLAN attachments per interconnect 16 Per cloud router Maximum total bandwidth 8 x 100 Gbps 800 Gbps per VPC MTU 1500 bytes (default), up to 1440 for Partner Standard Ethernet MTU <p>Partner Interconnect</p> Limit Value Notes Bandwidth per attachment 50 Mbps - 50 Gbps Varies by provider VLAN attachments per router 16 Can use multiple routers Provider availability Geographic dependent Check provider coverage"},{"location":"gcp/networking/hybrid-connectivity/#when-to-use-cloud-interconnect","title":"When to Use Cloud Interconnect","text":"<p>\u2705 Use Dedicated Interconnect When:</p> <ul> <li>Require &gt; 10 Gbps bandwidth</li> <li>Already have presence in Google colocation facility</li> <li>Need lowest latency to Google Cloud</li> <li>Large-scale enterprise workloads</li> <li>Compliance requires dedicated physical connection</li> <li>Predictable network performance required</li> </ul> <p>\u2705 Use Partner Interconnect When:</p> <ul> <li>Need &gt; 3 Gbps but not near Google colocation</li> <li>Want managed service from network provider</li> <li>Need flexible bandwidth (can start small, scale up)</li> <li>Faster deployment than Dedicated Interconnect</li> <li>Provider already serves your location</li> </ul> <p>\u274c Don\u2019t Use Interconnect When:</p> <ul> <li>Bandwidth requirements &lt; 1 Gbps (VPN more cost-effective)</li> <li>Quick POC or temporary project</li> <li>Budget constraints (VPN is cheaper)</li> <li>Geographic distance makes latency gains negligible</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#architecture-patterns","title":"Architecture Patterns","text":""},{"location":"gcp/networking/hybrid-connectivity/#ha-vpn-with-redundancy","title":"HA VPN with Redundancy","text":"<p><pre><code>On-Premises Router 1 \u2550\u2550\u2550 Tunnel 1 \u2550\u2550\u2550\u2557\n                                      \u2560\u2550\u2550\u2550 HA VPN Gateway (Interface 0)\nOn-Premises Router 1 \u2550\u2550\u2550 Tunnel 2 \u2550\u2550\u2550\u255d\n\nOn-Premises Router 2 \u2550\u2550\u2550 Tunnel 3 \u2550\u2550\u2550\u2557\n                                      \u2560\u2550\u2550\u2550 HA VPN Gateway (Interface 1)\nOn-Premises Router 2 \u2550\u2550\u2550 Tunnel 4 \u2550\u2550\u2550\u255d\n</code></pre> Result: 99.99% SLA, survives any single router or tunnel failure</p>"},{"location":"gcp/networking/hybrid-connectivity/#dedicated-interconnect-with-redundancy","title":"Dedicated Interconnect with Redundancy","text":"<p><pre><code>On-Premises \u2550\u2550 Metro 1 Circuit 1 \u2550\u2550 Interconnect Location A \u2550\u2550\u2557\n                                                               \u2560\u2550\u2550 VPC Network\nOn-Premises \u2550\u2550 Metro 2 Circuit 2 \u2550\u2550 Interconnect Location B \u2550\u2550\u255d\n</code></pre> Result: 99.99% SLA, geographic and circuit redundancy</p>"},{"location":"gcp/networking/hybrid-connectivity/#hybrid-interconnect-vpn-backup","title":"Hybrid: Interconnect + VPN Backup","text":"<p><pre><code>Primary:   On-Premises \u2550\u2550 Interconnect \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 VPC\nBackup:    On-Premises \u2550\u2550 HA VPN \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550= VPC\n</code></pre> Result: High availability with failover to VPN if Interconnect fails</p>"},{"location":"gcp/networking/hybrid-connectivity/#comparison-matrix","title":"Comparison Matrix","text":"Feature HA VPN Dedicated Interconnect Partner Interconnect Bandwidth Up to 3 Gbps/tunnel 10 or 100 Gbps 50 Mbps - 50 Gbps Latency Medium (internet) Low (direct) Low (direct) SLA 99.99% 99.99%* 99.99%* Setup Time Hours Weeks/months Days/weeks Cost Low High Medium Location Requirement None Colocation facility Provider coverage Encryption IPsec (built-in) Optional (MACsec) Optional Use Case Small-medium workloads Large enterprise Medium-large workloads <p>*With proper redundancy configuration</p>"},{"location":"gcp/networking/hybrid-connectivity/#configuration-requirements","title":"Configuration Requirements","text":""},{"location":"gcp/networking/hybrid-connectivity/#cloud-router","title":"Cloud Router","text":"<ul> <li>Required: For dynamic routing (BGP) with VPN and Interconnect</li> <li>ASN: Private ASN (64512-65534, 4200000000-4294967294) or public ASN</li> <li>BGP Sessions: One per tunnel/VLAN attachment</li> <li>Route Advertisement: Automatically advertises VPC subnet routes</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#bgp-configuration","title":"BGP Configuration","text":"<ul> <li>BGP Peer: Configure on-premises router and Cloud Router</li> <li>ASN: Unique ASN for on-premises and Cloud Router</li> <li>MD5 Authentication: Optional but recommended</li> <li>Route Priorities: Set MED or local preference for failover</li> <li>BFD: Enable for faster failure detection (sub-second)</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#firewall-considerations","title":"Firewall Considerations","text":"<ul> <li>Allow IKE (UDP 500, 4500) for VPN</li> <li>Allow BGP (TCP 179) if using dynamic routing</li> <li>Configure VPC firewall rules for on-premises IP ranges</li> <li>Consider hierarchical firewall policies for organization-wide rules</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#best-practices","title":"Best Practices","text":"<ol> <li>Redundancy</li> <li>Always configure redundant tunnels/circuits</li> <li>Use separate physical paths when possible</li> <li> <p>Test failover scenarios regularly</p> </li> <li> <p>Route Management</p> </li> <li>Use BGP for dynamic routing</li> <li>Set appropriate route priorities (MED, AS-PATH prepend)</li> <li>Limit route advertisements (use route filters)</li> <li> <p>Enable BFD for fast failure detection</p> </li> <li> <p>Monitoring</p> </li> <li>Monitor tunnel/circuit status</li> <li>Set up alerts for connection failures</li> <li>Track bandwidth utilization</li> <li> <p>Use VPC Flow Logs for traffic analysis</p> </li> <li> <p>Security</p> </li> <li>Use strong encryption (AES-256-GCM for VPN)</li> <li>Enable MD5 authentication on BGP sessions</li> <li>Consider MACsec for Interconnect encryption</li> <li> <p>Implement principle of least privilege for route advertisements</p> </li> <li> <p>Capacity Planning</p> </li> <li>Size connections for peak + 30-50% headroom</li> <li>Plan for growth (easier to add VPN tunnels than Interconnect circuits)</li> <li>Consider burst traffic patterns</li> <li>Monitor usage trends</li> </ol>"},{"location":"gcp/networking/hybrid-connectivity/#cost-optimization","title":"Cost Optimization","text":"<p>Cloud VPN</p> <ul> <li>Charged per tunnel hour + egress bandwidth</li> <li>Multiple tunnels increase cost (but provide redundancy)</li> <li>Egress to on-premises charged at internet egress rates</li> </ul> <p>Cloud Interconnect</p> <ul> <li>Dedicated: Fixed port fee + egress bandwidth (discounted)</li> <li>Partner: Varies by provider + egress bandwidth</li> <li>Generally cheaper egress rates than VPN at scale</li> <li>Break-even typically around 1-3 Gbps sustained traffic</li> </ul>"},{"location":"gcp/networking/hybrid-connectivity/#related-services","title":"Related Services","text":"<ul> <li>Cloud Router: Dynamic routing for VPN and Interconnect</li> <li>Cloud DNS: Extend DNS resolution to on-premises</li> <li>Private Google Access: Access Google services without public IPs</li> <li>Network Connectivity Center: Central hub for managing hybrid connectivity</li> </ul>"},{"location":"gcp/networking/iam-roles/","title":"IAM Roles for Networking","text":""},{"location":"gcp/networking/iam-roles/#description","title":"Description","text":"<p>IAM (Identity and Access Management) controls who can perform what actions on which GCP networking resources. Proper IAM configuration is critical for security, compliance, and operational efficiency. This guide covers the key predefined roles for networking and when to use them.</p>"},{"location":"gcp/networking/iam-roles/#role-hierarchy","title":"Role Hierarchy","text":""},{"location":"gcp/networking/iam-roles/#primitive-roles-avoid-for-production","title":"Primitive Roles (Avoid for Production)","text":"<ul> <li>Owner: Full access (too permissive)</li> <li>Editor: Modify resources (too permissive)</li> <li>Viewer: Read-only access (acceptable for read operations)</li> </ul> <p>Recommendation: Use predefined or custom roles instead of primitive roles for networking.</p>"},{"location":"gcp/networking/iam-roles/#core-networking-roles","title":"Core Networking Roles","text":""},{"location":"gcp/networking/iam-roles/#compute-network-admin-rolescomputenetworkadmin","title":"Compute Network Admin (<code>roles/compute.networkAdmin</code>)","text":"<p>Permissions: Full control over networking resources</p> <p>Can:</p> <ul> <li>Create, modify, delete VPC networks, subnets, routes</li> <li>Configure firewall rules, firewall policies</li> <li>Manage VPN gateways, tunnels, Cloud Routers</li> <li>Configure load balancers and SSL certificates</li> <li>Create and delete Private Service Connect endpoints</li> <li>Manage network peering connections</li> <li>Configure Cloud NAT</li> <li>Administer Private Google Access settings</li> </ul> <p>Cannot:</p> <ul> <li>Create instances (requires <code>compute.instanceAdmin</code>)</li> <li>Modify organization policies</li> <li>Manage billing</li> <li>Create Shared VPC host projects (requires <code>compute.xpnAdmin</code>)</li> </ul> <p>Use Case:</p> <ul> <li>Network administrators managing VPC infrastructure</li> <li>Platform teams responsible for network design and implementation</li> <li>DevOps engineers managing cloud networking</li> </ul> <p>Scope: Project-level (can also grant at folder/org level)</p>"},{"location":"gcp/networking/iam-roles/#compute-network-user-rolescomputenetworkuser","title":"Compute Network User (<code>roles/compute.networkUser</code>)","text":"<p>Permissions: Use existing network resources but cannot create or modify them</p> <p>Can:</p> <ul> <li>Use VPC subnets to create instances</li> <li>Attach instances to existing subnets</li> <li>View network, subnet, route information (read-only)</li> <li>Use shared VPC subnets (critical for service projects)</li> </ul> <p>Cannot:</p> <ul> <li>Create or delete networks, subnets</li> <li>Modify firewall rules</li> <li>Create VPN or load balancers</li> <li>Change network configurations</li> </ul> <p>Use Case:</p> <ul> <li>Application teams creating VMs in service projects</li> <li>Developers deploying workloads to existing infrastructure</li> <li>Service accounts for GKE, Cloud Run needing network access</li> <li>Users in Shared VPC service projects</li> </ul> <p>Scope: Project-level or subnet-level (for granular access)</p> <p>Important: In Shared VPC, grant this role at subnet level in host project to service project service accounts.</p>"},{"location":"gcp/networking/iam-roles/#compute-network-viewer-rolescomputenetworkviewer","title":"Compute Network Viewer (<code>roles/compute.networkViewer</code>)","text":"<p>Permissions: Read-only access to networking resources</p> <p>Can:</p> <ul> <li>View VPC networks, subnets, routes</li> <li>View firewall rules and policies</li> <li>View VPN gateways, Cloud Routers, load balancers</li> <li>View network topology and configuration</li> <li>Access networking metrics and logs (if logging viewer role also granted)</li> </ul> <p>Cannot:</p> <ul> <li>Create, modify, or delete any resources</li> <li>Use network resources to create instances</li> </ul> <p>Use Case:</p> <ul> <li>Auditors reviewing network configurations</li> <li>Read-only access for troubleshooting</li> <li>Security teams reviewing firewall rules</li> <li>Junior team members learning infrastructure</li> </ul> <p>Scope: Project, folder, or organization level</p>"},{"location":"gcp/networking/iam-roles/#compute-security-admin-rolescomputesecurityadmin","title":"Compute Security Admin (<code>roles/compute.securityAdmin</code>)","text":"<p>Permissions: Manage security-related networking resources</p> <p>Can:</p> <ul> <li>Create, modify, delete firewall rules</li> <li>Manage SSL certificates and SSL policies</li> <li>Configure Cloud Armor security policies</li> <li>Manage organization firewall policies (if org-level)</li> <li>View network resources (read-only)</li> </ul> <p>Cannot:</p> <ul> <li>Create or modify VPC networks, subnets</li> <li>Create VPN or load balancers (only security configs)</li> <li>Modify routes</li> </ul> <p>Use Case:</p> <ul> <li>Security teams managing firewall rules</li> <li>Compliance teams enforcing security policies</li> <li>Separation of duties (security vs networking)</li> </ul> <p>Scope: Project, folder, or organization level</p>"},{"location":"gcp/networking/iam-roles/#shared-vpc-specific-roles","title":"Shared VPC Specific Roles","text":""},{"location":"gcp/networking/iam-roles/#compute-shared-vpc-admin-rolescomputexpnadmin","title":"Compute Shared VPC Admin (<code>roles/compute.xpnAdmin</code>)","text":"<p>Permissions: Enable and manage Shared VPC configuration</p> <p>Can:</p> <ul> <li>Enable/disable a project as Shared VPC host</li> <li>Attach/detach service projects to host projects</li> <li>View Shared VPC configuration</li> </ul> <p>Cannot:</p> <ul> <li>Create networks or subnets (requires <code>networkAdmin</code>)</li> <li>Grant networkUser role (requires IAM admin permissions)</li> </ul> <p>Use Case:</p> <ul> <li>Organization admins setting up Shared VPC</li> <li>Platform teams managing multi-project architectures</li> </ul> <p>Scope: Organization or folder level only (cannot grant at project level)</p> <p>Important: Typically paired with <code>compute.networkAdmin</code> for full Shared VPC management.</p>"},{"location":"gcp/networking/iam-roles/#service-project-admin-no-specific-role","title":"Service Project Admin (No specific role)","text":"<p>Pattern: Combine multiple roles for service project administrators</p> <p>Typical Combination:</p> <ul> <li><code>roles/compute.instanceAdmin</code>: Create VMs</li> <li><code>roles/compute.networkUser</code>: Use shared subnets (granted on host project subnets)</li> <li><code>roles/iam.serviceAccountUser</code>: Attach service accounts</li> </ul> <p>Use Case: Users who manage resources in service projects of Shared VPC</p>"},{"location":"gcp/networking/iam-roles/#specialized-networking-roles","title":"Specialized Networking Roles","text":""},{"location":"gcp/networking/iam-roles/#compute-load-balancer-admin-rolescomputeloadbalanceradmin","title":"Compute Load Balancer Admin (<code>roles/compute.loadBalancerAdmin</code>)","text":"<p>Permissions: Manage load balancing resources</p> <p>Can:</p> <ul> <li>Create, modify, delete load balancers</li> <li>Configure backend services, health checks</li> <li>Manage SSL certificates for load balancers</li> <li>Configure URL maps, target proxies</li> <li>Manage network endpoint groups (NEGs)</li> </ul> <p>Cannot:</p> <ul> <li>Modify VPC networks or subnets</li> <li>Create instances (backend resources)</li> </ul> <p>Use Case:</p> <ul> <li>Application teams managing their own load balancers</li> <li>Separation of duties for load balancer management</li> </ul>"},{"location":"gcp/networking/iam-roles/#compute-public-ip-admin-rolescomputepublicipadmin","title":"Compute Public IP Admin (<code>roles/compute.publicIpAdmin</code>)","text":"<p>Permissions: Manage external IP addresses</p> <p>Can:</p> <ul> <li>Reserve and release external IP addresses</li> <li>Promote ephemeral IPs to static</li> <li>View IP address usage</li> </ul> <p>Cannot:</p> <ul> <li>Attach IPs to instances (requires instance admin)</li> <li>Modify networks or subnets</li> </ul> <p>Use Case:</p> <ul> <li>IP address management teams</li> <li>Resource optimization (releasing unused IPs)</li> </ul>"},{"location":"gcp/networking/iam-roles/#service-networking-admin-rolesservicenetworkingnetworksadmin","title":"Service Networking Admin (<code>roles/servicenetworking.networksAdmin</code>)","text":"<p>Permissions: Manage private service connections</p> <p>Can:</p> <ul> <li>Create Private Service Connect endpoints</li> <li>Configure private IP allocations for Google services</li> <li>Manage peered VPC connections for managed services (e.g., Cloud SQL)</li> <li>Configure Private Service Connect forwarding rules</li> </ul> <p>Cannot:</p> <ul> <li>Modify VPC networks (requires <code>networkAdmin</code>)</li> </ul> <p>Use Case:</p> <ul> <li>Platform teams configuring private access to Google services</li> <li>Database administrators setting up Cloud SQL private IP</li> </ul>"},{"location":"gcp/networking/iam-roles/#dns-administrator-rolesdnsadmin","title":"DNS Administrator (<code>roles/dns.admin</code>)","text":"<p>Permissions: Manage Cloud DNS resources</p> <p>Can:</p> <ul> <li>Create, modify, delete DNS zones</li> <li>Manage DNS records</li> <li>Configure DNS peering</li> <li>Manage DNS policies (split horizon, inbound/outbound forwarding)</li> </ul> <p>Cannot:</p> <ul> <li>Modify VPC networks directly (but can peer DNS zones)</li> </ul> <p>Use Case:</p> <ul> <li>DNS administrators managing internal and external DNS</li> <li>Multi-cloud DNS integration</li> </ul>"},{"location":"gcp/networking/iam-roles/#custom-roles","title":"Custom Roles","text":""},{"location":"gcp/networking/iam-roles/#when-to-create-custom-roles","title":"When to Create Custom Roles","text":"<p>\u2705 Use Custom Roles When:</p> <ul> <li>Predefined roles are too permissive</li> <li>Need specific combination of permissions</li> <li>Compliance requires fine-grained access control</li> <li>Implementing least-privilege security model</li> </ul> <p>\u274c Avoid Custom Roles When:</p> <ul> <li>Predefined roles meet requirements</li> <li>Organization lacks resources to maintain custom roles</li> <li>Complexity outweighs security benefits</li> </ul>"},{"location":"gcp/networking/iam-roles/#example-custom-role-vpn-operator","title":"Example Custom Role: VPN Operator","text":"<p>Use Case: Allow VPN tunnel management without full network admin access</p> <pre><code>title: \"VPN Operator\"\ndescription: \"Manage VPN tunnels and Cloud Routers\"\nincludedPermissions:\n\n  - compute.vpnGateways.*\n  - compute.vpnTunnels.*\n  - compute.routers.*\n  - compute.routes.get\n  - compute.routes.list\n  - compute.networks.get\n  - compute.networks.list\n  - compute.regions.get\n  - compute.regions.list\n</code></pre>"},{"location":"gcp/networking/iam-roles/#example-custom-role-firewall-rule-manager","title":"Example Custom Role: Firewall Rule Manager","text":"<p>Use Case: Manage firewall rules without network creation permissions</p> <pre><code>title: \"Firewall Rule Manager\"\ndescription: \"Create and modify firewall rules only\"\nincludedPermissions:\n\n  - compute.firewalls.*\n  - compute.networks.get\n  - compute.networks.list\n  - compute.networks.updatePolicy\n</code></pre>"},{"location":"gcp/networking/iam-roles/#iam-best-practices-for-networking","title":"IAM Best Practices for Networking","text":""},{"location":"gcp/networking/iam-roles/#1-principle-of-least-privilege","title":"1. Principle of Least Privilege","text":"<ul> <li>Grant minimum permissions needed</li> <li>Use predefined roles when possible</li> <li>Create custom roles for specific needs</li> <li>Avoid primitive roles (Owner, Editor) in production</li> </ul>"},{"location":"gcp/networking/iam-roles/#2-use-groups-not-individual-users","title":"2. Use Groups, Not Individual Users","text":"<pre><code># Good: Grant role to group\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"group:network-admins@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n\n# Avoid: Grant role to individual users\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"user:alice@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre>"},{"location":"gcp/networking/iam-roles/#3-scope-roles-appropriately","title":"3. Scope Roles Appropriately","text":"<p>Organization Level: Broad permissions across all projects <pre><code>gcloud organizations add-iam-policy-binding ORG_ID \\\n  --member=\"group:network-admins@example.com\" \\\n  --role=\"roles/compute.networkViewer\"\n</code></pre></p> <p>Folder Level: Specific business unit or environment <pre><code>gcloud resource-manager folders add-iam-policy-binding FOLDER_ID \\\n  --member=\"group:prod-network-admins@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre></p> <p>Project Level: Individual project permissions <pre><code>gcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"group:dev-team@example.com\" \\\n  --role=\"roles/compute.networkUser\"\n</code></pre></p> <p>Subnet Level (Shared VPC): Granular service project access <pre><code>gcloud compute networks subnets add-iam-policy-binding SUBNET_NAME \\\n  --member=\"serviceAccount:SERVICE_PROJECT_ID@cloudservices.gserviceaccount.com\" \\\n  --role=\"roles/compute.networkUser\" \\\n  --region=REGION\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#4-service-accounts-for-automation","title":"4. Service Accounts for Automation","text":"<p>Pattern: Use dedicated service accounts with minimal permissions</p> <pre><code># Create service account for Terraform\ngcloud iam service-accounts create terraform-network-sa \\\n  --display-name=\"Terraform Network Automation\"\n\n# Grant specific network admin permissions\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"serviceAccount:terraform-network-sa@PROJECT_ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre>"},{"location":"gcp/networking/iam-roles/#5-audit-and-review","title":"5. Audit and Review","text":"<ul> <li>Regularly review IAM bindings</li> <li>Use Cloud Asset Inventory for IAM audits</li> <li>Enable audit logging for IAM changes</li> <li>Implement periodic access reviews</li> <li>Remove unused or stale permissions</li> </ul>"},{"location":"gcp/networking/iam-roles/#6-separation-of-duties","title":"6. Separation of Duties","text":"<p>Example: Separate networking and security management</p> <pre><code>Network Admins Group:\n\n  - roles/compute.networkAdmin (VPC, subnets, routes, VPN)\n\nSecurity Admins Group:\n\n  - roles/compute.securityAdmin (firewall rules, SSL policies)\n\nShared VPC Admins Group:\n\n  - roles/compute.xpnAdmin (Shared VPC management)\n  - roles/compute.networkAdmin (network resources)\n</code></pre>"},{"location":"gcp/networking/iam-roles/#common-iam-patterns","title":"Common IAM Patterns","text":""},{"location":"gcp/networking/iam-roles/#pattern-1-shared-vpc-setup","title":"Pattern 1: Shared VPC Setup","text":"<p>Host Project: <pre><code># Enable Shared VPC (requires xpnAdmin at org/folder level)\ngcloud compute shared-vpc enable HOST_PROJECT_ID\n\n# Grant networkAdmin to network team\ngcloud projects add-iam-policy-binding HOST_PROJECT_ID \\\n  --member=\"group:network-admins@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre></p> <p>Service Project: <pre><code># Attach service project (requires xpnAdmin)\ngcloud compute shared-vpc associated-projects add SERVICE_PROJECT_ID \\\n  --host-project=HOST_PROJECT_ID\n\n# Grant networkUser on specific subnet to service project\ngcloud compute networks subnets add-iam-policy-binding SUBNET_NAME \\\n  --member=\"serviceAccount:SERVICE_PROJECT_NUMBER@cloudservices.gserviceaccount.com\" \\\n  --role=\"roles/compute.networkUser\" \\\n  --region=REGION\n\n# Grant instance admin to application team in service project\ngcloud projects add-iam-policy-binding SERVICE_PROJECT_ID \\\n  --member=\"group:app-team@example.com\" \\\n  --role=\"roles/compute.instanceAdmin\"\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#pattern-2-multi-environment-access-control","title":"Pattern 2: Multi-Environment Access Control","text":"<p>Production: <pre><code># Strict permissions, network changes require approval\ngcloud projects add-iam-policy-binding PROD_PROJECT_ID \\\n  --member=\"group:prod-network-admins@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n\ngcloud projects add-iam-policy-binding PROD_PROJECT_ID \\\n  --member=\"group:developers@example.com\" \\\n  --role=\"roles/compute.networkViewer\"\n</code></pre></p> <p>Development: <pre><code># More permissive for faster iteration\ngcloud projects add-iam-policy-binding DEV_PROJECT_ID \\\n  --member=\"group:developers@example.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#pattern-3-read-only-network-auditor","title":"Pattern 3: Read-Only Network Auditor","text":"<pre><code># Grant read-only access for auditing\ngcloud organizations add-iam-policy-binding ORG_ID \\\n  --member=\"group:network-auditors@example.com\" \\\n  --role=\"roles/compute.networkViewer\"\n\n# Also grant logging viewer for complete audit trail\ngcloud organizations add-iam-policy-binding ORG_ID \\\n  --member=\"group:network-auditors@example.com\" \\\n  --role=\"roles/logging.viewer\"\n</code></pre>"},{"location":"gcp/networking/iam-roles/#troubleshooting-iam-issues","title":"Troubleshooting IAM Issues","text":""},{"location":"gcp/networking/iam-roles/#permission-denied-errors","title":"\u201cPermission Denied\u201d Errors","text":"<p>Symptoms: User cannot create VMs in Shared VPC subnet</p> <p>Common Cause: Missing <code>compute.networkUser</code> role on subnet</p> <p>Solution: <pre><code># Grant networkUser on specific subnet\ngcloud compute networks subnets add-iam-policy-binding SUBNET_NAME \\\n  --member=\"serviceAccount:SERVICE_ACCOUNT@example.com\" \\\n  --role=\"roles/compute.networkUser\" \\\n  --region=REGION\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#cannot-attach-service-project-to-shared-vpc","title":"Cannot Attach Service Project to Shared VPC","text":"<p>Common Cause: Missing <code>compute.xpnAdmin</code> role or granted at project level</p> <p>Solution: <pre><code># Grant xpnAdmin at organization or folder level\ngcloud organizations add-iam-policy-binding ORG_ID \\\n  --member=\"user:admin@example.com\" \\\n  --role=\"roles/compute.xpnAdmin\"\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#service-account-cannot-create-resources","title":"Service Account Cannot Create Resources","text":"<p>Common Cause: Impersonation or missing role on service account</p> <p>Solution: <pre><code># Grant service account user role\ngcloud iam service-accounts add-iam-policy-binding SERVICE_ACCOUNT@PROJECT.iam.gserviceaccount.com \\\n  --member=\"user:admin@example.com\" \\\n  --role=\"roles/iam.serviceAccountUser\"\n\n# OR grant directly to service account\ngcloud projects add-iam-policy-binding PROJECT_ID \\\n  --member=\"serviceAccount:SERVICE_ACCOUNT@PROJECT.iam.gserviceaccount.com\" \\\n  --role=\"roles/compute.networkAdmin\"\n</code></pre></p>"},{"location":"gcp/networking/iam-roles/#security-considerations","title":"Security Considerations","text":""},{"location":"gcp/networking/iam-roles/#1-avoid-over-permissive-roles","title":"1. Avoid Over-Permissive Roles","text":"<p>\u274c Bad: Granting <code>roles/owner</code> for network tasks \u2705 Good: Granting <code>roles/compute.networkAdmin</code></p>"},{"location":"gcp/networking/iam-roles/#2-protect-sensitive-resources","title":"2. Protect Sensitive Resources","text":"<ul> <li>Use organizational policies to enforce controls</li> <li>Require approval for firewall rule changes</li> <li>Implement four-eyes principle for production changes</li> </ul>"},{"location":"gcp/networking/iam-roles/#3-monitor-iam-changes","title":"3. Monitor IAM Changes","text":"<pre><code># Set up log-based alert for IAM policy changes\ngcloud logging sinks create iam-policy-changes \\\n  storage.googleapis.com/iam-audit-logs-bucket \\\n  --log-filter='protoPayload.methodName=\"SetIamPolicy\"'\n</code></pre>"},{"location":"gcp/networking/iam-roles/#4-rotate-service-account-keys","title":"4. Rotate Service Account Keys","text":"<ul> <li>Use short-lived credentials when possible</li> <li>Rotate long-lived keys regularly</li> <li>Use Workload Identity for GKE instead of service account keys</li> </ul>"},{"location":"gcp/networking/iam-roles/#5-conditional-iam-context-aware-access","title":"5. Conditional IAM (Context-Aware Access)","text":"<pre><code># Example: Grant networkAdmin only from corporate network\nbindings:\n\n  - members:\n      - group:network-admins@example.com\n    role: roles/compute.networkAdmin\n    condition:\n      expression: \"request.auth.claims.iss == 'https://accounts.google.com' &amp;&amp; \n                   origin.ip in ['203.0.113.0/24']\"\n      title: \"Allow only from corporate network\"\n</code></pre>"},{"location":"gcp/networking/iam-roles/#related-documentation","title":"Related Documentation","text":"<ul> <li>IAM Overview: https://cloud.google.com/iam/docs</li> <li>Predefined Roles: https://cloud.google.com/iam/docs/understanding-roles</li> <li>Custom Roles: https://cloud.google.com/iam/docs/creating-custom-roles</li> <li>Shared VPC IAM: https://cloud.google.com/vpc/docs/shared-vpc#iam_in_shared_vpc</li> <li>Best Practices: https://cloud.google.com/iam/docs/best-practices</li> </ul>"},{"location":"gcp/networking/load-balancing/","title":"Load Balancing","text":""},{"location":"gcp/networking/load-balancing/#description","title":"Description","text":"<p>Google Cloud Load Balancing is a fully distributed, software-defined managed service that distributes traffic across multiple backend instances. It\u2019s not instance-based or device-based, providing seamless auto-scaling and high availability. GCP offers multiple load balancer types optimized for different use cases.</p>"},{"location":"gcp/networking/load-balancing/#load-balancer-types-overview","title":"Load Balancer Types Overview","text":""},{"location":"gcp/networking/load-balancing/#global-vs-regional","title":"Global vs Regional","text":"<ul> <li>Global: Serve users globally from multiple regions, single anycast IP</li> <li>Regional: Serve users within a single region, useful for internal services</li> </ul>"},{"location":"gcp/networking/load-balancing/#external-vs-internal","title":"External vs Internal","text":"<ul> <li>External: Accept traffic from the internet</li> <li>Internal: Accept traffic only from within VPC or connected networks</li> </ul>"},{"location":"gcp/networking/load-balancing/#layer-4-vs-layer-7","title":"Layer 4 vs Layer 7","text":"<ul> <li>Layer 4 (Network/Transport): TCP/UDP, connection-based routing</li> <li>Layer 7 (Application): HTTP(S), content-based routing, URL mapping</li> </ul>"},{"location":"gcp/networking/load-balancing/#application-load-balancer-layer-7","title":"Application Load Balancer (Layer 7)","text":""},{"location":"gcp/networking/load-balancing/#external-application-load-balancer-global","title":"External Application Load Balancer (Global)","text":"<p>Description: Global Layer 7 load balancer for HTTP(S) traffic with content-based routing.</p> <p>Key Features:</p> <ul> <li>Global load balancing: Single anycast IP serves worldwide</li> <li>SSL/TLS termination: Managed certificates with automatic renewal</li> <li>Content-based routing: URL maps, host rules, path rules</li> <li>Cloud CDN integration: Caching at Google edge locations</li> <li>Cloud Armor: DDoS protection and WAF capabilities</li> <li>Backend types: Instance groups, NEGs (zonal, internet, serverless)</li> <li>HTTP/2 and HTTP/3: Modern protocol support</li> </ul> <p>Limits:</p> Limit Value Backend services per LB 50 URL maps 10 per LB Path matchers per URL map 250 Backends per backend service 50 Maximum request size 32 KB (headers + URL) <p>When to Use:</p> <ul> <li>\u2705 Global web applications with users worldwide</li> <li>\u2705 Need content-based routing (different paths to different backends)</li> <li>\u2705 Require SSL termination and certificate management</li> <li>\u2705 Want Cloud CDN for static content</li> <li>\u2705 Need DDoS protection and WAF</li> </ul> <p>When Not to Use:</p> <ul> <li>\u274c Non-HTTP traffic (use Network Load Balancer)</li> <li>\u274c Internal-only traffic (use Internal Application Load Balancer)</li> <li>\u274c UDP traffic (use Network Load Balancer)</li> </ul>"},{"location":"gcp/networking/load-balancing/#internal-application-load-balancer-regional","title":"Internal Application Load Balancer (Regional)","text":"<p>Description: Regional Layer 7 load balancer for internal HTTP(S) traffic within VPC.</p> <p>Key Features:</p> <ul> <li>Private load balancing: Internal IP addresses only</li> <li>Regional: Serves traffic within a region</li> <li>Cross-region support: Can access backends in other regions</li> <li>Service mesh integration: Works with Traffic Director</li> <li>Shared VPC support: Can be in host or service project</li> </ul> <p>When to Use:</p> <ul> <li>\u2705 Microservices architectures within VPC</li> <li>\u2705 Private APIs and internal applications</li> <li>\u2705 Service mesh deployments (with Traffic Director)</li> <li>\u2705 Multi-tier applications (frontend to backend)</li> </ul>"},{"location":"gcp/networking/load-balancing/#network-load-balancer-layer-4","title":"Network Load Balancer (Layer 4)","text":""},{"location":"gcp/networking/load-balancing/#external-network-load-balancer-regional","title":"External Network Load Balancer (Regional)","text":"<p>Description: Regional Layer 4 load balancer for TCP/UDP traffic, high performance and low latency.</p> <p>Types:</p> <ul> <li>Premium Tier: Anycast IP, global access</li> <li>Standard Tier: Regional IP, regional access</li> </ul> <p>Key Features:</p> <ul> <li>Pass-through: Preserves client IP addresses</li> <li>High throughput: Millions of requests per second</li> <li>UDP support: Gaming, streaming, DNS</li> <li>SSL/TLS: Not terminated (passes through to backends)</li> <li>Session affinity: Client IP, client IP and protocol, client IP-port-proto</li> </ul> <p>Limits:</p> Limit Value Forwarding rules per project 75 (regional) Backend services per LB 50 Backends per backend service 250 <p>When to Use:</p> <ul> <li>\u2705 Non-HTTP(S) protocols (TCP/UDP)</li> <li>\u2705 Need to preserve client IP</li> <li>\u2705 SSL passthrough required (SSL/TLS handled by backend)</li> <li>\u2705 High-performance gaming, streaming applications</li> <li>\u2705 Custom protocols on non-standard ports</li> </ul>"},{"location":"gcp/networking/load-balancing/#internal-network-load-balancer-regional","title":"Internal Network Load Balancer (Regional)","text":"<p>Description: Regional Layer 4 load balancer for internal TCP/UDP traffic within VPC.</p> <p>Types:</p> <ul> <li>Standard: Basic internal load balancing</li> <li>Advanced: Enhanced features, multi-subnet support</li> </ul> <p>Key Features:</p> <ul> <li>Private IPs: Only accessible within VPC</li> <li>High performance: Low latency, high throughput</li> <li>Failover: Automatic with health checks</li> <li>Multi-subnet: Backends can be in different subnets (Advanced)</li> </ul> <p>When to Use:</p> <ul> <li>\u2705 Internal databases, message queues</li> <li>\u2705 Private TCP/UDP services</li> <li>\u2705 High-performance internal applications</li> <li>\u2705 Load balancing for self-managed databases</li> </ul>"},{"location":"gcp/networking/load-balancing/#proxy-network-load-balancer-layer-4","title":"Proxy Network Load Balancer (Layer 4)","text":""},{"location":"gcp/networking/load-balancing/#external-proxy-network-load-balancer-globalregional","title":"External Proxy Network Load Balancer (Global/Regional)","text":"<p>Description: Global or Regional Layer 4 proxy for TCP traffic with SSL termination.</p> <p>Key Features:</p> <ul> <li>TCP proxy: Terminates TCP connections</li> <li>SSL offloading: Terminate SSL at load balancer</li> <li>Global: Single anycast IP, route to nearest backend</li> <li>Long-lived connections: Optimized for persistent connections</li> </ul> <p>When to Use:</p> <ul> <li>\u2705 Non-HTTP TCP traffic that needs SSL termination</li> <li>\u2705 Global applications on custom TCP ports</li> <li>\u2705 Need SSL offloading for TCP applications</li> <li>\u2705 WebSocket connections</li> </ul>"},{"location":"gcp/networking/load-balancing/#internal-proxy-network-load-balancer-regional","title":"Internal Proxy Network Load Balancer (Regional)","text":"<p>Description: Regional Layer 4 proxy for internal TCP traffic.</p> <p>When to Use:</p> <ul> <li>\u2705 Internal TCP applications needing SSL termination</li> <li>\u2705 Private WebSocket services</li> <li>\u2705 Cross-region backend support with internal IPs</li> </ul>"},{"location":"gcp/networking/load-balancing/#decision-matrix","title":"Decision Matrix","text":"<pre><code>                    Traffic Source\n                    \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                       \u2502\n    External                Internal\n        \u2502                       \u2502\n        \u2502                       \u2502\n    HTTP(S)?                HTTP(S)?\n    \u2502       \u2502               \u2502       \u2502\n   Yes      No             Yes      No\n    \u2502       \u2502               \u2502       \u2502\n    \u2502       \u2502               \u2502       \u2502\n    \u2502   TCP/UDP?            \u2502   TCP/UDP?\n    \u2502   \u2502       \u2502           \u2502   \u2502       \u2502\n    \u2502  TCP     UDP          \u2502  TCP     UDP\n    \u2502   \u2502       \u2502           \u2502   \u2502       \u2502\n    \u25bc   \u25bc       \u25bc           \u25bc   \u25bc       \u25bc\n\nExternal    External  Ext.   Internal  Internal  Internal\nApplication Proxy N   Network  App LB   Proxy N   Network\nLB (Global) LB       LB        (Reg)    LB (Reg)  LB (Reg)\n</code></pre>"},{"location":"gcp/networking/load-balancing/#common-architectures","title":"Common Architectures","text":""},{"location":"gcp/networking/load-balancing/#global-multi-region-web-application","title":"Global Multi-Region Web Application","text":"<pre><code>Users (Global)\n    \u2502\n    \u25bc\nExternal Application Load Balancer (Anycast IP)\n    \u2502\n    \u251c\u2500\u2500\u2500 Backend: us-central1 (Instance Group)\n    \u251c\u2500\u2500\u2500 Backend: europe-west1 (Instance Group)\n    \u2514\u2500\u2500\u2500 Backend: asia-east1 (Instance Group)\n\nCloud CDN: Enabled\nCloud Armor: DDoS Protection\nSSL Certificate: Managed by Google\n</code></pre>"},{"location":"gcp/networking/load-balancing/#multi-tier-application-internal","title":"Multi-Tier Application (Internal)","text":"<pre><code>External Application LB \u2500\u2500\u25b6 Frontend Tier (Public)\n                                  \u2502\n                                  \u25bc\n                    Internal Application LB \u2500\u2500\u25b6 API Tier (Private)\n                                                     \u2502\n                                                     \u25bc\n                                       Internal Network LB \u2500\u2500\u25b6 Database Tier\n</code></pre>"},{"location":"gcp/networking/load-balancing/#hybrid-cloud-with-internal-lb","title":"Hybrid Cloud with Internal LB","text":"<pre><code>On-Premises Network\n    \u2502\n    \u25bc (Cloud VPN/Interconnect)\n    \u2502\nInternal Application Load Balancer\n    \u2502\n    \u251c\u2500\u2500\u2500 Backend: GKE Cluster (us-central1)\n    \u2514\u2500\u2500\u2500 Backend: Compute VMs (us-east1)\n</code></pre>"},{"location":"gcp/networking/load-balancing/#key-concepts","title":"Key Concepts","text":""},{"location":"gcp/networking/load-balancing/#backend-services","title":"Backend Services","text":"<ul> <li>Health checks: Determine backend availability</li> <li>Session affinity: Stick users to same backend</li> <li>Connection draining: Graceful shutdown, complete existing connections</li> <li>Timeout: How long to wait for backend response</li> <li>Load balancing mode: RATE, UTILIZATION, or CONNECTION based</li> </ul>"},{"location":"gcp/networking/load-balancing/#backend-types","title":"Backend Types","text":"<ul> <li>Instance groups: Managed or unmanaged VM groups</li> <li>Zonal NEGs: Endpoints in specific zones (GCE VMs, GKE pods)</li> <li>Internet NEGs: External endpoints (on-prem, other clouds)</li> <li>Serverless NEGs: Cloud Run, App Engine, Cloud Functions</li> <li>Hybrid NEGs: PSC-based endpoints</li> </ul>"},{"location":"gcp/networking/load-balancing/#health-checks","title":"Health Checks","text":"<ul> <li>Protocol: HTTP, HTTPS, TCP, SSL, HTTP/2</li> <li>Interval: Time between health checks</li> <li>Timeout: Time to wait for response  </li> <li>Healthy threshold: Consecutive successes to mark healthy</li> <li>Unhealthy threshold: Consecutive failures to mark unhealthy</li> </ul>"},{"location":"gcp/networking/load-balancing/#url-maps-https-load-balancers","title":"URL Maps (HTTP(S) Load Balancers)","text":"<ul> <li>Host rules: Route based on hostname</li> <li>Path matchers: Route based on URL path</li> <li>Path rules: Specific path patterns</li> <li>Default service: Fallback for unmatched requests</li> </ul>"},{"location":"gcp/networking/load-balancing/#features-comparison","title":"Features Comparison","text":"Feature External App LB Internal App LB External Net LB Internal Net LB Global \u2705 \u274c Premium tier \u274c SSL Termination \u2705 \u2705 \u274c \u274c Cloud CDN \u2705 \u274c \u274c \u274c Cloud Armor \u2705 \u274c \u274c \u274c URL Routing \u2705 \u2705 \u274c \u274c WebSocket \u2705 \u2705 Proxy LB Proxy LB UDP \u274c \u274c \u2705 \u2705 Preserve Client IP Custom header Custom header \u2705 \u2705 IPv6 \u2705 \u274c \u2705 \u274c"},{"location":"gcp/networking/load-balancing/#configuration-best-practices","title":"Configuration Best Practices","text":"<ol> <li>Health Checks</li> <li>Set appropriate intervals (not too aggressive)</li> <li>Use dedicated health check endpoints</li> <li>Return 200 OK only when truly healthy</li> <li> <p>Monitor health check failures</p> </li> <li> <p>Backend Configuration</p> </li> <li>Enable connection draining (30-60 seconds)</li> <li>Set reasonable session affinity when needed</li> <li>Configure appropriate timeouts</li> <li> <p>Use multiple backends per region for redundancy</p> </li> <li> <p>Security</p> </li> <li>Enable Cloud Armor for external HTTP(S) load balancers</li> <li>Use managed SSL certificates (auto-renewal)</li> <li>Implement SSL policies (minimum TLS version)</li> <li> <p>Restrict backend access with firewall rules</p> </li> <li> <p>Performance</p> </li> <li>Enable Cloud CDN for cacheable content</li> <li>Use HTTP/2 and HTTP/3</li> <li>Configure appropriate backend timeout values</li> <li> <p>Size backend capacity for peak + 30% headroom</p> </li> <li> <p>Monitoring</p> </li> <li>Set up monitoring for latency, error rates, traffic</li> <li>Alert on health check failures</li> <li>Monitor backend utilization</li> <li>Use Cloud Trace for request tracing</li> </ol>"},{"location":"gcp/networking/load-balancing/#pricing-considerations","title":"Pricing Considerations","text":"<p>Application Load Balancers:</p> <ul> <li>Forwarding rules (per hour)</li> <li>Data processing (per GB)</li> <li>Cloud CDN cache fill and egress (if enabled)</li> </ul> <p>Network Load Balancers:</p> <ul> <li>Forwarding rules (per hour)</li> <li>No data processing charges (passthrough)</li> </ul> <p>General Tips:</p> <ul> <li>Internal load balancers cheaper than external</li> <li>Data processing charges can be significant for HTTP(S) LBs</li> <li>Cloud CDN reduces origin traffic and data processing</li> <li>Consider regional vs global based on user distribution</li> </ul>"},{"location":"gcp/networking/load-balancing/#related-services","title":"Related Services","text":"<ul> <li>Cloud CDN: Content delivery network, integrates with HTTP(S) LB</li> <li>Cloud Armor: DDoS protection and WAF for HTTP(S) LB</li> <li>SSL Certificates: Managed or self-managed certificates</li> <li>Cloud DNS: DNS-based load balancing and failover</li> <li>Traffic Director: Service mesh traffic management</li> <li>Network Endpoint Groups: Advanced backend types</li> </ul>"},{"location":"gcp/networking/shared-vpc/","title":"Shared VPC","text":""},{"location":"gcp/networking/shared-vpc/#description","title":"Description","text":"<p>Shared VPC allows an organization to connect resources from multiple service projects to a common VPC network in a host project. This enables centralized network administration while maintaining project-level billing and resource organization. Network admins maintain control over the network resources while service project admins can create resources that use the shared network.</p> <p>Architecture: Centralized VPC network (host project) with attached service projects consuming the network resources.</p>"},{"location":"gcp/networking/shared-vpc/#key-features","title":"Key Features","text":""},{"location":"gcp/networking/shared-vpc/#organizational","title":"Organizational","text":"<ul> <li>Centralized Network Administration: Network team manages all network resources in one place</li> <li>Separation of Concerns: IAM separation between network admins and resource admins</li> <li>Project-Level Billing: Service projects maintain separate billing despite using shared network</li> <li>Cross-Project Resource Creation: VMs in service projects use subnets from host project</li> </ul>"},{"location":"gcp/networking/shared-vpc/#network-capabilities","title":"Network Capabilities","text":"<ul> <li>Shared Subnets: Service projects can use host project subnets</li> <li>Private IP Address Management: Centralized IP address space planning</li> <li>Firewall Rules: Centralized or delegated firewall rule management</li> <li>VPC Network Peering: Host project can peer with other VPCs, connectivity extends to service projects</li> <li>Hybrid Connectivity: Single point for VPN/Interconnect setup benefiting all service projects</li> </ul>"},{"location":"gcp/networking/shared-vpc/#security-access-control","title":"Security &amp; Access Control","text":"<ul> <li>Subnet-Level IAM: Granular permissions at subnet level</li> <li>Service Project Admins: Limited to resource creation, not network changes</li> <li>Organizational Policy: Can enforce Shared VPC usage across organization</li> <li>Audit Logging: Centralized network change tracking</li> </ul>"},{"location":"gcp/networking/shared-vpc/#important-limits","title":"Important Limits","text":"Limit Value Notes Service projects per host 100 Default, can be increased Host projects per organization No limit Can have multiple host projects Shared VPC Admin role Organization or folder level Cannot be granted at project level Subnet sharing Must explicitly share subnets Subnets not automatically shared VPC Peering Only host project can peer Service projects cannot create peering Cloud VPN/Interconnect Only in host project Service projects cannot create these Network tags Created in service projects But firewall rules in host project can use them"},{"location":"gcp/networking/shared-vpc/#iam-roles","title":"IAM Roles","text":""},{"location":"gcp/networking/shared-vpc/#host-project-roles","title":"Host Project Roles","text":"<ul> <li><code>roles/compute.xpnAdmin</code>: Shared VPC Admin (org/folder level) - enables/disables host projects</li> <li><code>roles/compute.networkAdmin</code>: Network Admin - manages network resources in host project</li> <li><code>roles/compute.securityAdmin</code>: Security Admin - manages firewall rules</li> </ul>"},{"location":"gcp/networking/shared-vpc/#service-project-roles","title":"Service Project Roles","text":"<ul> <li><code>roles/compute.networkUser</code>: Allows creating resources using shared subnets</li> <li><code>roles/compute.instanceAdmin</code>: Create instances but needs networkUser for Shared VPC subnets</li> </ul>"},{"location":"gcp/networking/shared-vpc/#when-to-use","title":"When to Use","text":""},{"location":"gcp/networking/shared-vpc/#use-shared-vpc-when","title":"\u2705 Use Shared VPC When:","text":"<ol> <li>Centralized Network Management</li> <li>Single network team managing infrastructure across multiple teams/projects</li> <li>Standardized network policies and security controls</li> <li> <p>Consistent IP address management across organization</p> </li> <li> <p>Hub and Spoke Architecture</p> </li> <li>Central hub (host project) with multiple spokes (service projects)</li> <li>Shared services (DNS, NTP, monitoring) accessed by all projects</li> <li> <p>Transitive connectivity requirements between spokes</p> </li> <li> <p>Enterprise Organizations</p> </li> <li>Multiple business units or teams with separate projects</li> <li>Compliance requirements for network oversight</li> <li> <p>Cost allocation per team while sharing network infrastructure</p> </li> <li> <p>Hybrid Cloud Deployments</p> </li> <li>Single VPN/Interconnect connection serving multiple projects</li> <li>On-premises integration for all cloud projects</li> <li> <p>Centralized egress/ingress control</p> </li> <li> <p>Multi-Tier Applications</p> </li> <li>Frontend, backend, and database in separate projects</li> <li>Private communication between tiers</li> <li>Different teams managing different tiers</li> </ol>"},{"location":"gcp/networking/shared-vpc/#dont-use-shared-vpc-when","title":"\u274c Don\u2019t Use Shared VPC When:","text":"<ol> <li>Complete Project Isolation Needed</li> <li>Projects must be fully network-isolated</li> <li>Regulatory requirements prevent network sharing</li> <li> <p>Use separate VPCs with VPC Peering if limited connectivity needed</p> </li> <li> <p>Small Organizations with Single Team</p> </li> <li>Overhead of Shared VPC not justified</li> <li>Single project VPC is simpler</li> <li> <p>Team has both network and resource admin responsibilities</p> </li> <li> <p>Cross-Organization Scenarios</p> </li> <li>Shared VPC only works within a single organization</li> <li> <p>Use VPC Peering for cross-organization connectivity</p> </li> <li> <p>Frequently Changing Network Topology</p> </li> <li>Service projects constantly added/removed</li> <li>Network architecture not yet stable</li> <li>Consider starting simple, migrate to Shared VPC later</li> </ol>"},{"location":"gcp/networking/shared-vpc/#common-architectures","title":"Common Architectures","text":""},{"location":"gcp/networking/shared-vpc/#hub-and-spoke-with-shared-vpc","title":"Hub and Spoke with Shared VPC","text":"<pre><code>Host Project (Hub)\n\u251c\u2500\u2500 Shared VPC Network\n\u2502   \u251c\u2500\u2500 Subnet A (us-central1)\n\u2502   \u251c\u2500\u2500 Subnet B (europe-west1)\n\u2502   \u2514\u2500\u2500 Subnet C (asia-east1)\n\u251c\u2500\u2500 Cloud VPN/Interconnect (on-premises)\n\u2514\u2500\u2500 VPC Peering (to partner networks)\n\nService Project 1 (Spoke) - Production\n\u251c\u2500\u2500 Uses Subnet A\n\u2514\u2500\u2500 Compute Engine VMs\n\nService Project 2 (Spoke) - Development  \n\u251c\u2500\u2500 Uses Subnet B\n\u2514\u2500\u2500 GKE Clusters\n\nService Project 3 (Spoke) - Data\n\u251c\u2500\u2500 Uses Subnet C\n\u2514\u2500\u2500 Cloud SQL, BigQuery\n</code></pre>"},{"location":"gcp/networking/shared-vpc/#multi-environment-setup","title":"Multi-Environment Setup","text":"<pre><code>Shared Services Host Project\n\u251c\u2500\u2500 Shared VPC Network\n\u2502   \u251c\u2500\u2500 Monitoring/Logging Subnet\n\u2502   \u251c\u2500\u2500 Artifact Registry Subnet\n\u2502   \u2514\u2500\u2500 DNS Subnet\n\nProduction Host Project\n\u251c\u2500\u2500 Shared VPC Network\n\u2502   \u2514\u2500\u2500 Production Subnets\n\u2514\u2500\u2500 Service Projects: App1, App2, App3\n\nNon-Production Host Project\n\u251c\u2500\u2500 Shared VPC Network\n\u2502   \u2514\u2500\u2500 Dev/Staging Subnets\n\u2514\u2500\u2500 Service Projects: Dev-App1, Dev-App2\n</code></pre>"},{"location":"gcp/networking/shared-vpc/#setup-process","title":"Setup Process","text":"<ol> <li> <p>Enable Host Project <pre><code>gcloud compute shared-vpc enable HOST_PROJECT_ID\n</code></pre></p> </li> <li> <p>Attach Service Project <pre><code>gcloud compute shared-vpc associated-projects add SERVICE_PROJECT_ID \\\n    --host-project=HOST_PROJECT_ID\n</code></pre></p> </li> <li> <p>Grant IAM Permissions <pre><code># Grant network user on specific subnet\ngcloud compute networks subnets add-iam-policy-binding SUBNET_NAME \\\n    --member=serviceAccount:SERVICE_PROJECT_NUMBER@cloudservices.gserviceaccount.com \\\n    --role=roles/compute.networkUser \\\n    --region=REGION\n</code></pre></p> </li> <li> <p>Create Resources in Service Project</p> </li> <li>Resources can now reference host project subnets</li> <li>Use <code>--subnet=projects/HOST_PROJECT/regions/REGION/subnetworks/SUBNET_NAME</code></li> </ol>"},{"location":"gcp/networking/shared-vpc/#configuration-best-practices","title":"Configuration Best Practices","text":"<ol> <li>IP Address Planning</li> <li>Plan comprehensive IP address scheme before implementation</li> <li>Leave room for growth in subnet ranges</li> <li> <p>Document subnet allocation per service project</p> </li> <li> <p>IAM Management</p> </li> <li>Use groups for role assignments, not individual users</li> <li>Grant minimal necessary permissions</li> <li> <p>Use subnet-level IAM for fine-grained control</p> </li> <li> <p>Firewall Strategy</p> </li> <li>Use hierarchical firewall policies for organization-wide rules</li> <li>Delegate specific firewall rules where appropriate</li> <li> <p>Leverage network tags for flexible rule application</p> </li> <li> <p>Monitoring &amp; Logging</p> </li> <li>Enable VPC Flow Logs on shared subnets</li> <li>Set up Cloud Monitoring for network metrics</li> <li> <p>Centralize logging in host project or separate logging project</p> </li> <li> <p>Service Project Management</p> </li> <li>Document which service projects use which subnets</li> <li>Regular audits of attached service projects</li> <li>Establish process for onboarding new service projects</li> </ol>"},{"location":"gcp/networking/shared-vpc/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":"<p>Permission Denied Creating Resources</p> <ul> <li>Verify service project is attached to host project</li> <li>Check IAM permissions on specific subnet</li> <li>Ensure service account has <code>compute.networkUser</code> role</li> </ul> <p>Cannot See Shared Subnets</p> <ul> <li>Confirm subnet is in same region as resource</li> <li>Verify IAM permissions at subnet level</li> <li>Check if using correct subnet reference format</li> </ul> <p>Firewall Rules Not Working</p> <ul> <li>Verify target tags exist on resources in service projects</li> <li>Check if hierarchical firewall policies apply</li> <li>Confirm source/destination ranges include service project IPs</li> </ul>"},{"location":"gcp/networking/shared-vpc/#related-services","title":"Related Services","text":"<ul> <li>VPC Peering: Host project can peer with other VPCs</li> <li>Private Service Connect: Access managed services privately</li> <li>Cloud VPN/Interconnect: Hybrid connectivity through host project</li> <li>Hierarchical Firewall Policies: Organization-wide firewall management</li> <li>VPC Service Controls: Enhanced security perimeter around resources</li> </ul>"},{"location":"gcp/networking/vpc-peering/","title":"VPC Peering","text":""},{"location":"gcp/networking/vpc-peering/#description","title":"Description","text":"<p>VPC Network Peering enables private RFC 1918 connectivity across two VPC networks, allowing resources to communicate using internal IP addresses regardless of whether they belong to the same project or organization. Peering is a decentralized approach where each VPC network remains under its own administrative control.</p> <p>Architecture: Direct connection between two VPC networks creating a private connection path.</p>"},{"location":"gcp/networking/vpc-peering/#key-features","title":"Key Features","text":""},{"location":"gcp/networking/vpc-peering/#connectivity","title":"Connectivity","text":"<ul> <li>Private IP Communication: Resources communicate using internal IPs without traversing the public internet</li> <li>Cross-Project/Organization: Peering works across different projects and organizations</li> <li>Bidirectional: Traffic can flow in both directions once established</li> <li>No Single Point of Failure: Peering is not a physical connection but a logical configuration</li> <li>Transitive Peering: NOT supported - if VPC A peers with B, and B peers with C, A cannot reach C</li> </ul>"},{"location":"gcp/networking/vpc-peering/#performance-security","title":"Performance &amp; Security","text":"<ul> <li>Low Latency: Private Google network backbone</li> <li>No Bandwidth Bottleneck: No aggregated bandwidth limit</li> <li>Firewall Control: Each VPC maintains its own firewall rules</li> <li>No Encryption: Traffic is private but not encrypted (use application-level encryption if needed)</li> </ul>"},{"location":"gcp/networking/vpc-peering/#administrative","title":"Administrative","text":"<ul> <li>Independent Management: Each VPC admin controls their own network</li> <li>Subnet Expansion: Can expand subnet ranges after peering is established</li> <li>Import/Export Custom Routes: Optional custom route exchange</li> </ul>"},{"location":"gcp/networking/vpc-peering/#important-limits","title":"Important Limits","text":"Limit Value Notes Peering connections per VPC 25 Default limit Subnet IP ranges Cannot overlap Critical - overlapping IPs prevent peering Transitive peering Not supported Must create direct peering for each connection Network tags Not shared Tags don\u2019t cross peering boundaries Internal DNS Requires Cloud DNS peering VPC peering doesn\u2019t automatically enable DNS resolution Peering group limit 25 VPCs in a peering group All VPCs that peer to a common VPC"},{"location":"gcp/networking/vpc-peering/#when-to-use","title":"When to Use","text":""},{"location":"gcp/networking/vpc-peering/#use-vpc-peering-when","title":"\u2705 Use VPC Peering When:","text":"<ol> <li>Multi-Project Architecture</li> <li>Different teams manage separate projects but need private connectivity</li> <li>Hub and spoke architectures with limited spoke-to-spoke communication</li> <li> <p>Cost-effective private connectivity between projects</p> </li> <li> <p>Cross-Organization Collaboration</p> </li> <li>Partner organizations need to connect resources privately</li> <li>M&amp;A scenarios where networks need quick integration</li> <li> <p>Service provider connecting to customer VPCs</p> </li> <li> <p>Simple Network Topologies</p> </li> <li>Limited number of VPCs (under 25 per network)</li> <li>No need for transitive routing</li> <li> <p>Each VPC maintains administrative independence</p> </li> <li> <p>Performance-Critical Workloads</p> </li> <li>Low-latency requirements between VPCs</li> <li>High-throughput applications without bandwidth constraints</li> <li>Real-time data processing across projects</li> </ol>"},{"location":"gcp/networking/vpc-peering/#dont-use-vpc-peering-when","title":"\u274c Don\u2019t Use VPC Peering When:","text":"<ol> <li>Centralized Security/Routing Required</li> <li>Use Shared VPC instead for centralized network administration</li> <li> <p>Need unified security policies across all networks</p> </li> <li> <p>Transitive Routing Needed</p> </li> <li>Spoke-to-spoke communication in hub-and-spoke architecture</li> <li> <p>Use Cloud Router with VPN/Interconnect or redesign with Shared VPC</p> </li> <li> <p>Large-Scale Mesh Networks</p> </li> <li>More than 15-20 VPCs needing full mesh connectivity</li> <li>Quota exhaustion becomes challenging to manage</li> <li> <p>Consider Network Connectivity Center or Shared VPC</p> </li> <li> <p>Overlapping IP Ranges</p> </li> <li>Peering is impossible with overlapping subnets</li> <li>Would require NAT or network redesign</li> </ol>"},{"location":"gcp/networking/vpc-peering/#common-use-cases","title":"Common Use Cases","text":"<p>Hub and Spoke (Non-Transitive) <pre><code>Host Project (Hub) \u2190\u2192 Spoke Project 1\n                  \u2190\u2192 Spoke Project 2\n                  \u2190\u2192 Spoke Project 3\n</code></pre> Spokes cannot communicate with each other, only with the hub.</p> <p>Partner Integration <pre><code>Organization A VPC \u2190\u2192 Organization B VPC\n</code></pre> Private connectivity for data sharing, APIs, or service integration.</p> <p>Development/Production Isolation <pre><code>Production VPC \u2190\u2192 Shared Services VPC \u2190\u2192 Development VPC\n</code></pre> Controlled connectivity to shared services (monitoring, logging, artifact registry).</p>"},{"location":"gcp/networking/vpc-peering/#configuration-considerations","title":"Configuration Considerations","text":"<ol> <li>IP Planning: Ensure no subnet overlap before creating peering</li> <li>Route Export/Import: Configure custom route exchange if needed</li> <li>Firewall Rules: Update rules to allow traffic from peered CIDR ranges</li> <li>DNS Setup: Configure Cloud DNS peering for name resolution across VPCs</li> <li>Monitoring: Set up VPC Flow Logs to track inter-VPC traffic</li> <li>IAM Permissions: Requires <code>compute.networks.peer</code> permission on both networks</li> </ol>"},{"location":"gcp/networking/vpc-peering/#related-services","title":"Related Services","text":"<ul> <li>Shared VPC: Alternative for centralized network management</li> <li>Cloud DNS Peering: For DNS resolution across peered VPCs</li> <li>VPC Flow Logs: Monitor traffic between peered networks</li> <li>Cloud Router: For dynamic routing in hybrid connectivity (not directly used with VPC peering)</li> </ul>"},{"location":"general/different_types_of_scaling/","title":"Different Types of Scaling in IT Systems","text":"<p>Scaling is a critical aspect of managing IT systems and applications. As workloads fluctuate, organizations need to ensure that resources are scaled effectively to maintain performance and optimize costs. Scaling strategies can be categorized into various types, each suited to specific use cases. In this article, we\u2019ll explore different types of scaling, including reactive scaling, proactive scaling, predictive scaling, and others.</p>"},{"location":"general/different_types_of_scaling/#reactive-scaling","title":"Reactive Scaling","text":"<p>Reactive scaling, also known as on-demand scaling, adjusts resources in response to observed changes in workload or performance metrics. It is typically triggered by predefined thresholds or alerts.</p> <p>This approach monitors real-time metrics such as CPU usage, memory utilization, or request latency. When these metrics cross predefined thresholds, additional resources are automatically added or removed. While it\u2019s an efficient way to address sudden workload changes, there may be slight delays as the system adjusts.</p> <p>Reactive scaling is commonly used for applications with variable traffic, such as web services, or batch processing systems where workloads are predictable but vary in size.</p>"},{"location":"general/different_types_of_scaling/#proactive-scaling","title":"Proactive Scaling","text":"<p>Proactive scaling involves scheduling resource adjustments based on anticipated workload patterns. This method works well when workloads follow predictable cycles, such as business hours or seasonal traffic.</p> <p>By analyzing historical data or known patterns, proactive scaling schedules resource changes in advance. This ensures resources are provisioned before workload increases occur, reducing the risk of performance bottlenecks. However, it requires a thorough understanding of workload behavior and may result in resource inefficiency if patterns change unexpectedly.</p> <p>Proactive scaling is ideal for scenarios like e-commerce sites during holiday seasons or corporate applications primarily used during business hours.</p>"},{"location":"general/different_types_of_scaling/#predictive-scaling","title":"Predictive Scaling","text":"<p>Predictive scaling leverages machine learning or advanced analytics to forecast future resource needs and adjust resources accordingly. It combines elements of both proactive and reactive scaling to provide a more sophisticated approach.</p> <p>This method analyzes historical data and trends to predict workload fluctuations, enabling the system to provision resources in advance. Predictive scaling minimizes latency while maintaining cost-efficiency. However, its effectiveness relies on accurate predictions, which can be challenging in highly volatile environments.</p> <p>Predictive scaling is well-suited for dynamic environments such as streaming services with varying demand or financial systems experiencing periodic transaction spikes.</p>"},{"location":"general/different_types_of_scaling/#manual-scaling","title":"Manual Scaling","text":"<p>Manual scaling relies on human intervention to adjust resources based on observed or anticipated workload changes. This approach is often used in smaller or less dynamic environments where changes are infrequent.</p> <p>In this method, administrators monitor system performance and manually allocate or deallocate resources as needed. While it provides full control over resource allocation, manual scaling can be time-consuming and is less effective for handling rapid workload fluctuations.</p> <p>Manual scaling is typically employed in development or staging environments and by small businesses with predictable workloads.</p>"},{"location":"general/different_types_of_scaling/#horizontal-vs-vertical-scaling","title":"Horizontal vs. Vertical Scaling","text":"<p>Scaling strategies can also be categorized as horizontal or vertical, depending on how resources are adjusted.</p>"},{"location":"general/different_types_of_scaling/#horizontal-scaling","title":"Horizontal Scaling:","text":"<p>Horizontal scaling involves adding or removing instances of a resource, such as servers or containers. This approach is commonly used in distributed systems and cloud environments, offering high fault tolerance and scalability. Applications need to be designed to support distribution, typically requiring a stateless architecture.</p>"},{"location":"general/different_types_of_scaling/#vertical-scaling","title":"Vertical Scaling:","text":"<p>Vertical scaling increases or decreases the capacity of existing resources, such as adding more CPU or memory to a server. It is simpler to implement for monolithic applications and does not require changes to application architecture. However, it is limited by hardware constraints and can create a single point of failure.</p>"},{"location":"general/different_types_of_scaling/#choosing-the-right-scaling-strategy","title":"Choosing the Right Scaling Strategy","text":"<p>The choice of scaling strategy depends on several factors, including workload predictability, application architecture, and cost considerations:</p> <ol> <li>Use reactive scaling for unpredictable workloads with real-time monitoring needs.</li> <li>Opt for proactive scaling when workloads follow consistent patterns.</li> <li>Implement predictive scaling for dynamic environments where forecasting can improve efficiency.</li> <li>Rely on manual scaling for environments where changes are infrequent and manageable.</li> <li>Combine horizontal and vertical scaling based on your system\u2019s architecture and constraints.</li> </ol> <p>Scaling is a fundamental aspect of modern IT systems. By understanding and applying the right scaling strategies, organizations can ensure optimal performance, cost efficiency, and reliability.</p>"},{"location":"kubernetes/admission_controller/","title":"Admission Controller","text":"<p>An Admission Controller is a component in Kubernetes that intercepts API requests to the Kubernetes API server before the objects are persisted in etcd. Admission controllers can modify, validate, or reject these requests based on custom logic or policies.</p>"},{"location":"kubernetes/admission_controller/#purpose","title":"Purpose","text":"<ul> <li>To enforce policies and best practices for resources created or updated in the Kubernetes cluster.</li> <li>To validate and mutate incoming API requests.</li> </ul>"},{"location":"kubernetes/admission_controller/#how-it-works","title":"How It Works","text":"<ol> <li>A user sends a request to the Kubernetes API server (e.g., create a Pod or Deployment).</li> <li>The request goes through authentication and authorization checks.</li> <li>The request is processed by admission controllers, which:</li> <li>Mutate the request (e.g., add default values or labels).</li> <li>Validate the request against policies.</li> <li>Approve or reject the request based on the outcome.</li> </ol>"},{"location":"kubernetes/admission_controller/#types-of-admission-controllers","title":"Types of Admission Controllers","text":"<ol> <li> <p>Mutating Admission Controllers:</p> </li> <li> <p>Modify the incoming request before it is persisted.</p> </li> <li> <p>Example: Adding default resource limits to Pods.</p> </li> <li> <p>Validating Admission Controllers:</p> </li> <li> <p>Validate the request and either approve or reject it.</p> </li> <li>Example: Ensuring that Pods do not use privileged containers.</li> </ol>"},{"location":"kubernetes/admission_controller/#built-in-admission-controllers","title":"Built-in Admission Controllers","text":"<p>Some common admission controllers in Kubernetes include:</p> <ul> <li>PodSecurity: Implements Pod Security Admission (PSA).</li> <li>NamespaceLifecycle: Ensures that objects are created only in active namespaces.</li> <li>LimitRanger: Enforces resource limits on Pods and containers.</li> <li>ResourceQuota: Ensures that resource quotas are not exceeded in a namespace.</li> </ul>"},{"location":"kubernetes/admission_controller/#custom-admission-controllers","title":"Custom Admission Controllers","text":"<ul> <li>Kubernetes allows you to define Dynamic Admission Controllers using Admission Webhooks.</li> <li>MutatingAdmissionWebhook and ValidatingAdmissionWebhook allow you to create custom logic to process API requests.</li> </ul>"},{"location":"kubernetes/aggregation_layer/","title":"Kubernetes Aggregation Layer","text":"<p>The Kubernetes Aggregation Layer is a feature that allows you to extend the Kubernetes API by integrating custom APIs into the Kubernetes API server. It enables you to provide additional functionality by deploying custom API servers alongside the main Kubernetes API server and exposing them through the same API endpoint (<code>/apis</code>).</p>"},{"location":"kubernetes/aggregation_layer/#purpose","title":"Purpose","text":"<ul> <li>Extend Kubernetes capabilities without modifying the core API server.</li> <li>Enable custom API resources and operations tailored to specific use cases or applications.</li> <li>Provide a unified interface to interact with both native and custom APIs.</li> </ul>"},{"location":"kubernetes/aggregation_layer/#how-it-works","title":"How It Works","text":"<p>The Aggregation Layer allows Kubernetes to route API requests to additional API servers. Here\u2019s how it works:</p> <ol> <li> <p>Custom API Servers:</p> </li> <li> <p>Deploy additional API servers in your cluster to handle specific custom APIs.</p> </li> <li> <p>These servers define their own resources and operations.</p> </li> <li> <p>APIService Objects:</p> </li> <li> <p>Use <code>APIService</code> resources to register custom API servers with the Kubernetes API server.</p> </li> <li> <p>The <code>APIService</code> object specifies how the API server should handle requests for a specific group/version.</p> </li> <li> <p>Routing:</p> </li> <li>When a request is made to the Kubernetes API server for a registered API, the API server proxies the request to the appropriate custom API server.</li> </ol>"},{"location":"kubernetes/aggregation_layer/#example-workflow","title":"Example Workflow","text":""},{"location":"kubernetes/aggregation_layer/#step-1-deploy-a-custom-api-server","title":"Step 1: Deploy a Custom API Server","text":"<ul> <li>Deploy a custom API server in the cluster to handle a specific group/version of APIs.</li> </ul>"},{"location":"kubernetes/aggregation_layer/#step-2-register-the-apiservice","title":"Step 2: Register the APIService","text":"<ul> <li>Create an <code>APIService</code> object to register the custom API server with the Kubernetes API server.</li> </ul>"},{"location":"kubernetes/aggregation_layer/#example-apiservice-yaml","title":"Example <code>APIService</code> YAML:","text":"<pre><code>apiVersion: apiregistration.k8s.io/v1\nkind: APIService\nmetadata:\n  name: v1beta1.custom.example.com\nspec:\n  service:\n    name: custom-api-service\n    namespace: custom-namespace\n  group: custom.example.com\n  version: v1beta1\n  insecureSkipTLSVerify: true\n  groupPriorityMinimum: 1000\n  versionPriority: 10\n</code></pre> <ul> <li><code>group</code>: The API group served by the custom API server.</li> <li><code>version</code>: The API version handled by the custom API server.</li> <li><code>service</code>: Specifies the Kubernetes service that proxies requests to the custom API server.</li> </ul>"},{"location":"kubernetes/aggregation_layer/#step-3-access-the-api","title":"Step 3: Access the API","text":"<ul> <li>After registration, the custom API becomes available through the main Kubernetes API endpoint, e.g.:   <pre><code>https://&lt;kube-apiserver&gt;/apis/custom.example.com/v1beta1\n</code></pre></li> </ul>"},{"location":"kubernetes/aggregation_layer/#key-components","title":"Key Components","text":"<ol> <li> <p>APIService Resource:</p> </li> <li> <p>Registers a custom API with the Kubernetes API server.</p> </li> <li> <p>Specifies routing information and priorities.</p> </li> <li> <p>Custom API Server:</p> </li> <li> <p>Implements and serves custom resources and operations.</p> </li> <li> <p>Typically deployed as a Deployment and exposed via a Kubernetes Service.</p> </li> <li> <p>Proxying:</p> </li> <li>The Kubernetes API server acts as a reverse proxy, forwarding requests to the registered custom API servers.</li> </ol>"},{"location":"kubernetes/aggregation_layer/#use-cases","title":"Use Cases","text":"<ol> <li> <p>Custom Resource APIs:</p> </li> <li> <p>Expose advanced APIs for custom applications, such as machine learning pipelines, workflow management, or CI/CD systems.</p> </li> <li> <p>External Integrations:</p> </li> <li> <p>Integrate external systems into Kubernetes with custom APIs, e.g., managing cloud resources.</p> </li> <li> <p>Enhanced Functionality:</p> </li> <li>Provide functionality that extends Kubernetes\u2019 default behavior, such as advanced metrics aggregation or policy enforcement.</li> </ol>"},{"location":"kubernetes/aggregation_layer/#benefits","title":"Benefits","text":"<ul> <li> <p>Extensibility:</p> </li> <li> <p>Add new APIs without modifying or rebuilding the core Kubernetes API server.</p> </li> <li> <p>Unified Interface:</p> </li> <li> <p>Expose custom APIs alongside Kubernetes\u2019 native APIs for a consistent developer experience.</p> </li> <li> <p>Scalability:</p> </li> <li>Scale custom API servers independently from the core Kubernetes API server.</li> </ul>"},{"location":"kubernetes/aggregation_layer/#security-considerations","title":"Security Considerations","text":"<ol> <li> <p>Authentication and Authorization:</p> </li> <li> <p>Ensure proper authentication and authorization mechanisms for custom APIs.</p> </li> <li> <p>Integrate with Kubernetes RBAC if possible.</p> </li> <li> <p>TLS Encryption:</p> </li> <li> <p>Use secure TLS connections between the Kubernetes API server and custom API servers.</p> </li> <li> <p>Validation:</p> </li> <li>Validate input and responses for custom APIs to prevent misuse.</li> </ol>"},{"location":"kubernetes/aggregation_layer/#comparison-with-crds-custom-resource-definitions","title":"Comparison with CRDs (Custom Resource Definitions)","text":"Feature Aggregation Layer Custom Resource Definitions (CRDs) Purpose Adds custom APIs with new endpoints Extends Kubernetes with new resource types under <code>/apis</code> Complexity Higher (requires custom API servers) Lower (uses built-in Kubernetes mechanisms) Flexibility Fully custom API operations and logic Resource-based CRUD operations Use Case Advanced custom APIs Simple extensions to Kubernetes resources"},{"location":"kubernetes/aggregation_layer/#conclusion","title":"Conclusion","text":"<p>The Kubernetes Aggregation Layer is a powerful feature for extending Kubernetes functionality by adding custom APIs. While it is more complex to implement than CRDs, it provides greater flexibility and control, making it suitable for advanced use cases like integrating external systems or providing custom services. By using the Aggregation Layer, organizations can leverage Kubernetes as a unified platform for both native and extended capabilities.</p>"},{"location":"kubernetes/cilium/","title":"Cilium","text":""},{"location":"kubernetes/cilium/#introduction","title":"Introduction","text":"<p>Cilium is a cloud-native networking, observability, and security solution built on top of eBPF (extended Berkeley Packet Filter). It provides advanced networking capabilities for containerized applications, particularly in Kubernetes environments, while offering enhanced security and observability features.</p>"},{"location":"kubernetes/cilium/#core-components","title":"Core Components","text":""},{"location":"kubernetes/cilium/#1-cilium-agent","title":"1. Cilium Agent","text":"<ul> <li>Role: Primary component running as a DaemonSet on each Kubernetes node</li> <li>Responsibilities:</li> <li>Manages eBPF programs on the node</li> <li>Handles network policy enforcement</li> <li>Maintains local identity and endpoint management</li> <li>Communicates with Cilium Operator and etcd/Kubernetes API</li> <li>Location: Runs in userspace but interacts heavily with kernel space</li> </ul>"},{"location":"kubernetes/cilium/#2-cilium-operator","title":"2. Cilium Operator","text":"<ul> <li>Role: Cluster-wide management component</li> <li>Responsibilities:</li> <li>Manages cluster-wide resources (CiliumNetworkPolicy, CiliumClusterwideNetworkPolicy, Cluster Mesh)</li> <li>Handles IPAM (IP Address Management) coordination</li> <li>Manages CRD lifecycle and validation</li> <li>Coordinates with cloud provider APIs for advanced features</li> <li>Deployment: Typically runs as a Deployment with 1-2 replicas</li> </ul>"},{"location":"kubernetes/cilium/#3-envoy-proxy","title":"3. Envoy Proxy","text":"<ul> <li>Role: Manage L7 traffic</li> <li>Responsibilities:</li> <li>Manage L7 Network Policies</li> <li>Location: Part of Clilum Agent or standalone pod (daemon)</li> </ul>"},{"location":"kubernetes/cilium/#4-cilium-cni-plugin-crd","title":"4. Cilium CNI Plugin (CRD)","text":"<ul> <li>Role: Container Network Interface implementation</li> <li>Responsibilities:</li> <li>Pod network setup and teardown</li> <li>IP address assignment</li> <li>Network namespace configuration</li> <li>Integration with container runtime</li> <li>Location: Binary installed on each node</li> </ul>"},{"location":"kubernetes/cilium/#5-hubble","title":"5. Hubble","text":"<ul> <li>Role: Network observability and security monitoring</li> <li>Components:</li> <li>Hubble Server: Runs alongside Cilium agent, exposes gRPC API and collects flows and visibility data using eBPF</li> <li>Hubble Relay: Cluster-wide aggregation service</li> <li>Hubble UI: Web-based interface for network visualization</li> <li>Hubble CLI: Command-line tool for querying network flows throught thw Hubble relay</li> </ul>"},{"location":"kubernetes/cilium/#6-ebpf-programs","title":"6. eBPF Programs","text":"<ul> <li>Role: Manage L3/L4 traffic</li> <li>Responsibilities:</li> <li>Manage L3/L4 Network Policies</li> <li>Location: Loaded into that node\u2019s kernel</li> </ul>"},{"location":"kubernetes/cilium/#ebpf-foundation","title":"eBPF Foundation","text":""},{"location":"kubernetes/cilium/#what-is-ebpf","title":"What is eBPF?","text":"<ul> <li>Extended Berkeley Packet Filter - a kernel technology</li> <li>Allows running sandboxed programs in kernel space without changing kernel source</li> <li>Provides high-performance, programmable packet processing</li> <li>Enables advanced networking, security, and observability features</li> </ul>"},{"location":"kubernetes/cilium/#ciliums-ebpf-usage","title":"Cilium\u2019s eBPF Usage","text":""},{"location":"kubernetes/cilium/#network-datapath","title":"Network Datapath","text":"<ul> <li>TC (Traffic Control) Programs: Attached to network interfaces for ingress/egress processing</li> <li>XDP (eXpress Data Path) Programs: Ultra-fast packet processing at driver level</li> <li>Socket Operations: Intercept and redirect socket operations</li> <li>Kernel Tracing: Monitor system calls and kernel functions</li> </ul>"},{"location":"kubernetes/cilium/#key-ebpf-maps","title":"Key eBPF Maps","text":"<ul> <li>Identity Map: Maps security identities to numeric IDs</li> <li>Policy Map: Stores network policy decisions</li> <li>Endpoint Map: Tracks local endpoints and their properties</li> <li>Service Map: Load balancing and service discovery information</li> </ul>"},{"location":"kubernetes/cilium/#cilium-features","title":"Cilium Features","text":""},{"location":"kubernetes/cilium/#ipam","title":"IPAM","text":"<p>Two available modes:</p> <ul> <li> <p>Kubernetes Host Scope: kube-controllermanager assign PodCIDR to each nodes. Set the resource Node <pre><code>ipam:\n  mode: \"kubernetes\"\nk8s:\n  requireIPv4PodCIDR: true\n  requireIPv6PodCIDR: true\n</code></pre></p> </li> <li> <p>Cluster Scope (default): Cilium Operator assign PodCIDR. Use the resource CiliumNode <pre><code>ipam:\n  mode: \"cluster-pool\"\nk8s:\n  clusterPoolIPv4PodCIDRList: [\"10.0.0.0/8\"]\n  clusterPoolIPv4MaskSize: 24\n  clusterPoolIPv6PodCIDRList: [\"fd00::/104\"]\n  clusterPoolIPv6MaskSize: 120\n</code></pre></p> </li> </ul> <p>To get all assigned CIDRs:</p> <pre><code>cilium-dbg status --all-addresses\n</code></pre> <p>Do not change IPAM mode on live clusters. Instead, deploy a new cluster with desired IPAM mode and migrate workloads.</p>"},{"location":"kubernetes/cilium/#routing-modes","title":"Routing modes","text":"<p>Cilium supports following routing modes that determine how packets are forwarded between pods across nodes:</p> <ol> <li> <p>Native Routing Uses the host\u2019s existing routing table and network stack <pre><code>routingMode: \"native\"\nipV4NativeRoutingCIDR: \"10.244.0.0/16\"\nipV6NativeRoutingCIDR: \"\"\n</code></pre></p> </li> <li> <p>Tunnel - Encapsulating (Default) Encapsulates pod traffic in VXLAN or Geneve tunnels Overhead: ~50 bytes per packet (VXLAN + UDP + IP headers) <pre><code>routingMode: \"tunnel\"\n\ntunnelProtocol: \"vxlan\" # default\n# tunnelProtocol: \"geneve\"\n\ntunnelPort: 8472 # vxlan\n# tunnelPort: 6081 # geneve\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cilium/#kube-proxy-replacement","title":"Kube-Proxy Replacement","text":"<p>Cilium can completely replace kube-proxy with a more efficient eBPF-based implementation for Kubernetes Service load balancing. Kube-proxy can degrades with large numbers of services/endpoints. eBPF-based has linear scaling regardless of service count. <pre><code>kubeProxyReplacement: false # kube-proxy\n---\nkubeProxyReplacement: true # cilium\nk8sServiceHost: \"host-ip-control-plane\"\nk8sServicePort: \"6443\"\n</code></pre></p> <p>Check current config: <pre><code>cilium-dbg status\n</code></pre></p>"},{"location":"kubernetes/cilium/#cilium-ingress","title":"Cilium Ingress","text":"<p>Cilium provides L7 HTTP/HTTPS ingress capabilities without needing a separate ingress controller. <pre><code>nodePort:\n  enabled: true\ningressController:\n  enabled: true\n  default: true\n  loadBalancerMode: dedicated # or \"shared\"\n</code></pre> Ingress mode:</p> <ul> <li>Dedicated: one loadbalancer for each ingress</li> <li>Shared: one single loadbalancer for all ingress</li> </ul> <p>Ingress components:</p> <ul> <li>GatewayClass: created by Infra team</li> <li>Gateway: created by cluster operator</li> <li>HTTPRoute (TCP, GRPC): created by developer</li> </ul>"},{"location":"kubernetes/cilium/#encryption","title":"Encryption","text":"<p>If enabled, traffic between clusters will be encryted, traffic within cluster not encrypted.</p> <ul> <li>IPSec <pre><code>encryption:\n  enabled: true\n  type: ipsec\n</code></pre></li> <li>WireGuard <pre><code>encryption:\n  enabled: true\n  type: wireguard\n</code></pre></li> </ul> <p>check encryption status: <pre><code>cilium-dbg encryption status\n</code></pre></p>"},{"location":"kubernetes/cilium/#mtls","title":"mTLS","text":"<p>Applied with SPIFFE, implemented by Spire.</p> <ul> <li>A spire-server will be deployed in the cluster</li> <li>A spire-agent in every node</li> </ul> <p>Encryption must be enabled. <pre><code>encryption:\n  enabled: true\n  type: ipsec # or wireguard\n\nauthentication:\n  enabled: true\n  mutual:\n    spire:\n      enabled: true\n      install:\n        enabled: true\n</code></pre></p> <p>In the CiliumNetworkPolicy: <pre><code>apiVersion: \"cilium.io/v2\"\nkind: CiliumNetworkPolicy\nmetadata:\n name: frontend-policy\n namespace: default\nspec:\n endpointSelector:\n   matchLabels:\n     app: frontend\n ingress:\n - fromEndpoints:\n   - matchLabels:\n       app: gateway\n   toPorts:\n   - ports:\n     - port: \"8080\"\n       protocol: TCP\n     authentication: # &lt;---\n       mode: \"required\"\n</code></pre></p>"},{"location":"kubernetes/cilium/#cluster-mesh","title":"Cluster Mesh","text":""},{"location":"kubernetes/cilium/#prerequisites","title":"Prerequisites","text":"<ul> <li>Clusters must have same routing mode</li> <li>Non overlapping Pod CIDRs</li> </ul> <pre><code>cilium clustermesh enable --context $CLUSTER1 # Enable, for every cluster\ncilium clustermesh connect --context $CLUSTER1 --destination-context $CLUSTER2 # connect clusters\ncilium clustermesh status # check status\n</code></pre>"},{"location":"kubernetes/cilium/#kvstoremesh","title":"KVStoreMesh","text":"<p>Cross-cluster networking without requiring a shared key-value store (etcd). Replaces shared etcd with direct cluster-to-cluster communication. Clusters exchange identity and service information directly. No central store: Eliminates shared etcd dependency</p>"},{"location":"kubernetes/cilium/#global-services","title":"Global Services","text":"<p>Global Services enable cross-cluster load balancing, a single service that distributes traffic across pods in multiple clusters. Service exists in multiple clusters with same name/namespace Cilium merges endpoints from all clusters into one global service Traffic is load balanced across all clusters automatically Failover: Automatically excludes unhealthy clusters</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: global-service\n  namespace: default\n  annotations:\n    service.cilium.io/global: \"true\"  # Makes service global (one service for all clusters)\n    service.cilium.io/affinity: \"local\" # Prioritize local clusters (or \"remote\")\n    service.cilium.io/shared: \"false\" # Make service local (one service per cluster)\nspec:\n  type: ClusterIP\n  selector:\n    app: my-app\n  ports:\n  - port: 80\n    targetPort: 8080\n</code></pre>"},{"location":"kubernetes/cilium/#observability-architecture","title":"Observability Architecture","text":""},{"location":"kubernetes/cilium/#hubble","title":"Hubble","text":"<p>To enable: <pre><code>hubble:\n  enabled: true\n\n  relay:\n    enabled: true\n\n  ui:\n    enabled: true\n</code></pre></p> <p>To use hubble CLI: <pre><code>cilium hubble port-forward # start communication\n\nhubble observe --pod pod_name # show in/out traffic for pod\nhubble observe --from-pod pod_name # show out traffic from pod\nhubble observe --to-pod pod_name # show in traffic to pod\n\nhubble observe --to-pod pod_name --port 3000 --protocol http --VERDICT [FORWARDED|DROPPED...] # filter by port, protocol and result\n</code></pre></p> <p>To use hubble UI: <pre><code>cilium hubble ui # start server\n</code></pre></p>"},{"location":"kubernetes/cilium/#bgp-external-networking","title":"BGP &amp; External Networking","text":""},{"location":"kubernetes/cilium/#egress-gateway","title":"Egress gateway","text":"<p>Provides centralized egress traffic control, routing pod traffic through specific gateway nodes with predictable source IPs.</p> <p>To enable: <pre><code>bpf:\n  masquerade: true\n\nkubeProxyReplacement: true\n\negressGateway:\n  enable: true\n</code></pre></p> <p>Configuration: <pre><code>apiVersion: cilium.io/v2\nkind: CiliumEgressGatewayPolicy\nmetadata:\n  name: egress-policy\nspec:\n  selectors:\n  - podSelector:\n      matchLabels:\n        app: frontend\n  destinationCIDRs:\n  - \"10.10.10.0/24\"  # External service subnet\n  gatewayConfig:\n    nodeSelector:\n      matchLabels:\n        egress-gateway: \"true\"  # Designated gateway nodes\n</code></pre></p> <p>Verification: <pre><code>cilium-dbg bpf egress list\n</code></pre></p>"},{"location":"kubernetes/cilium/#loadbalancer-ipam","title":"LoadBalancer IPAM","text":"<p>Automatically assigns IP addresses to Kubernetes LoadBalancer services from predefined pools, eliminating dependency on cloud provider load balancers. Cilium allocates IPs from configured pools to LoadBalancer services.</p> <pre><code>apiVersion: \"cilium.io/v2alpha1\"\nkind: CiliumLoadBalancerIPPool\nmetadata:\n  name: \"main-pool\"\nspec:\n  blocks:\n  - cidr: \"10.0.10.0/24\"\n  serviceSelector:\n    matchLabels:\n      color: red\n</code></pre>"},{"location":"kubernetes/cilium/#bgp","title":"BGP","text":"<p>Enables dynamic route advertisement to network infrastructure, making pod/service IPs reachable from outside the cluster. - Used with routing mode native. - Cilium nodes peer with BGP routers - Advertise routes for pod CIDRs, service IPs, and LoadBalancer IPs - Network infrastructure learns routes and forwards traffic to correct nodes</p> <p>To enable: <pre><code>bgpControlPlane:\n  enabled: true\n</code></pre></p> <p>Configuration: <pre><code>apiVersion: \"cilium.io/v2alpha1\"\nkind: CiliumBGPClusterConfig\nmetadata:\n  name: cilium-bgp\nspec:\n  nodeSelector:\n    matchLabels:\n      bgp: \"true\" # every node must have this label to use bgp\n  bgpInstances:\n  - name: \"instance-64000\"\n    localASN: 64000\n    peers:\n    - name: \"peer-1\"\n      peerASN: 65000\n      peerAddress: \"10.0.0.1\"  # Router switch IP\n      peerConfigRef:\n        name: \"cilium-peer\" # same as CiliumBGPPeerConfig name\n---\napiVersion: \"cilium.io/v2alpha1\"\nkind: CiliumBGPPeerConfig\nmetadata:\n  name: cilium-peer\nspec:\n  timers:\n    holdTimeSeconds: 9\n    keepAliveTimeSeconds: 3\nebgpMultiHop: 5\n  families:\n  - afi: ipv4\n    safi: unicast\n    advertisments:\n      matchLabels:\n        advertise: bgp # must be the same of CiliumBGPAdvertisement labels\n---\napiVersion: \"cilium.io/v2alpha1\"\nkind: CiliumBGPAdvertisement\nmetadata:\n  name: bgp-advertisement\n  labels:\n    advertise: bgp\nspec:\n  advertisements:\n  - advertisementType: PodCIDR\n    attributes:\n      communities:\n        standard: [ \"65000:99\" ]\n      localPreference: 99\n  - advertisementType: Service\n    service:\n      addresses:\n      - ClusterIP\n      - ExternalIP\n      - LoadBalancerIP\n    selector:\n      matchExpressions:\n      - key: type\n        operator: In\n        values: [\"LoadBalancer\"]\n</code></pre></p> <p>Troubleshoot: <pre><code>cilium bgp peers # nodes where bgp is running and all other info\ncilium bgp routes available # routes that the Cilium agent has learned\ncilium bgp routes advertised # routes that the Cilium instances has advertised\n</code></pre></p>"},{"location":"kubernetes/cilium/#l2announcement","title":"L2Announcement","text":"<p>Makes LoadBalancer service IPs reachable by responding to ARP requests on the local network segment, without requiring BGP infrastructure.</p> <p>To enable: <pre><code>kubeProxyReplacement: true\n\nl2announcements:\n  enable: true\n</code></pre></p> <p>Configuration: <pre><code>apiVersion: \"cilium.io/v2alpha1\"\nkind: CiliumL2AnnouncementPolicy\nmetadata:\n  name: \"l2-policy\"\nspec:\n  serviceSelector:\n    matchLabels:\n      app: myapp\n  nodeSelector:\n    matchLabels:\n    - key: node-role.kubernetes.io/control-plane\n      operator: DoesNotExist\n  interfaces:\n  - \"^eth[0-9]+\"  # Network interfaces to announce on\n  externalIPs: true\n  loadBalancerIPs: true\n</code></pre></p>"},{"location":"kubernetes/encryptionconfig/","title":"EncryptionConfig in Kubernetes","text":"<p>EncryptionConfig is a Kubernetes feature that allows you to encrypt sensitive data stored in etcd. Kubernetes uses etcd as its backend storage for cluster data, and while etcd supports encryption at the disk level, EncryptionConfig provides additional protection by encrypting specific Kubernetes resources at the application layer.</p>"},{"location":"kubernetes/encryptionconfig/#why-use-encryptionconfig","title":"Why Use EncryptionConfig?","text":"<ol> <li> <p>Enhanced Security:</p> </li> <li> <p>Protect sensitive data such as Secrets, ConfigMaps, and other resources stored in etcd.</p> </li> <li> <p>Prevent unauthorized access to sensitive information in case etcd backups or snapshots are compromised.</p> </li> <li> <p>Compliance:</p> </li> <li> <p>Helps meet regulatory requirements by encrypting data at rest in etcd.</p> </li> <li> <p>Granular Control:</p> </li> <li>Allows encryption of specific resources or resource types.</li> </ol>"},{"location":"kubernetes/encryptionconfig/#how-it-works","title":"How It Works","text":"<ol> <li> <p>Encryption Providers:</p> </li> <li> <p>Kubernetes uses encryption providers to specify the type of encryption used.</p> </li> <li> <p>Supported providers include:</p> <ul> <li>AES-CBC: Encrypts data using the AES algorithm in Cipher Block Chaining mode.</li> <li>SecretBox: Uses the NaCl SecretBox algorithm for encryption.</li> <li>Identity: No encryption; the data is stored as plaintext.</li> </ul> </li> <li> <p>EncryptionConfig File:</p> </li> <li> <p>An <code>EncryptionConfig</code> file specifies which resources should be encrypted and the encryption method.</p> </li> <li> <p>Decryption on Access:</p> </li> <li>Encrypted data is decrypted automatically when accessed via the Kubernetes API server.</li> </ol>"},{"location":"kubernetes/encryptionconfig/#example-encryptionconfig","title":"Example EncryptionConfig","text":"<p>The following example encrypts Secrets using the AES-CBC encryption provider:</p> <pre><code>apiVersion: apiserver.config.k8s.io/v1\nkind: EncryptionConfiguration\nresources:\n  - resources:\n      - secrets\n    providers:\n      - aescbc:\n          keys:\n            - name: key1\n              secret: &lt;base64-encoded-encryption-key&gt;\n      - identity: {}\n</code></pre>"},{"location":"kubernetes/encryptionconfig/#explanation","title":"Explanation:","text":"<ul> <li><code>resources</code>: Specifies the resource types to encrypt (e.g., Secrets).</li> <li><code>aescbc</code>: Indicates the AES-CBC encryption provider.</li> <li><code>keys</code>: Contains the encryption keys, with the <code>secret</code> field containing a base64-encoded key.</li> <li><code>identity</code>: Falls back to plaintext storage for resources not encrypted by <code>aescbc</code>.</li> </ul>"},{"location":"kubernetes/encryptionconfig/#steps-to-configure-encryptionconfig","title":"Steps to Configure EncryptionConfig","text":""},{"location":"kubernetes/encryptionconfig/#1-create-the-encryptionconfig-file","title":"1. Create the EncryptionConfig File","text":"<ul> <li>Write the <code>EncryptionConfig</code> file as shown above, specifying the resources to encrypt and the encryption providers.</li> </ul>"},{"location":"kubernetes/encryptionconfig/#2-enable-encryption-in-the-api-server","title":"2. Enable Encryption in the API Server","text":"<ul> <li>Update the API server manifest (e.g., <code>/etc/kubernetes/manifests/kube-apiserver.yaml</code>) to include the <code>--encryption-provider-config</code> flag:</li> </ul> <pre><code>- --encryption-provider-config=/path/to/encryption-config.yaml\n</code></pre>"},{"location":"kubernetes/encryptionconfig/#3-restart-the-api-server","title":"3. Restart the API Server","text":"<ul> <li>Restart the API server for the changes to take effect:</li> </ul> <pre><code>sudo systemctl restart kube-apiserver\n</code></pre>"},{"location":"kubernetes/encryptionconfig/#4-migrate-existing-data","title":"4. Migrate Existing Data","text":"<ul> <li>Run the <code>kubectl get</code> and <code>kubectl apply</code> commands to re-encrypt existing resources:</li> </ul> <pre><code>kubectl get secrets --all-namespaces -o yaml | kubectl apply -f -\n</code></pre>"},{"location":"kubernetes/encryptionconfig/#verification","title":"Verification","text":"<p>To confirm that encryption is working:</p> <ol> <li>Inspect the etcd data and verify that encrypted resources are not in plaintext.</li> <li>Use <code>etcdctl</code> to view raw etcd contents:</li> </ol> <pre><code>etcdctl get /registry/secrets/default/my-secret\n</code></pre> <ul> <li>Encrypted data will appear as a ciphered string instead of plaintext values.</li> </ul>"},{"location":"kubernetes/encryptionconfig/#considerations","title":"Considerations","text":"<ol> <li> <p>Key Management:</p> </li> <li> <p>Rotate encryption keys regularly for security.</p> </li> <li> <p>Backup keys securely, as loss of encryption keys may result in data inaccessibility.</p> </li> <li> <p>Resource Overhead:</p> </li> <li> <p>Encryption and decryption introduce additional CPU and memory usage on the API server.</p> </li> <li> <p>Backup Compatibility:</p> </li> <li> <p>Ensure etcd backups include encryption keys to allow data recovery.</p> </li> <li> <p>Fallback to Identity:</p> </li> <li>If decryption fails or a key is lost, resources with <code>identity</code> provider remain accessible as plaintext.</li> </ol>"},{"location":"kubernetes/encryptionconfig/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Encrypting Secrets to secure sensitive information such as API keys, passwords, and certificates.</li> <li>Encrypting ConfigMaps or other sensitive application configurations.</li> <li>Ensuring compliance with data security regulations.</li> </ul>"},{"location":"kubernetes/encryptionconfig/#conclusion","title":"Conclusion","text":"<p>EncryptionConfig is an essential feature for securing sensitive data in Kubernetes clusters. By encrypting data at the application layer, it adds a robust layer of protection against unauthorized access and meets compliance standards. Proper key management and regular testing are critical to maintaining a secure and reliable encryption setup.</p>"},{"location":"kubernetes/endpoint/","title":"Kubernetes Endpoint Resource","text":"<p>In Kubernetes, an Endpoint resource represents the network addresses (IP and port combinations) of the Pods that are associated with a Kubernetes Service. Endpoints enable the Service to route traffic to the appropriate Pods, acting as a bridge between the abstract Service and the concrete Pods that implement it.</p>"},{"location":"kubernetes/endpoint/#how-endpoints-work","title":"How Endpoints Work","text":"<ol> <li> <p>Service-Pod Association:</p> </li> <li> <p>When you create a Service, Kubernetes automatically creates an associated Endpoint resource.</p> </li> <li> <p>The Endpoint contains a list of IP addresses and ports of the Pods that match the Service\u2019s <code>selector</code>.</p> </li> <li> <p>Dynamic Updates:</p> </li> <li> <p>The Endpoint is updated dynamically by the Kubernetes controller as Pods are added, removed, or their status changes.</p> </li> <li> <p>Routing:</p> </li> <li>The Endpoint resource provides the information necessary for the Service to route traffic to the correct Pods.</li> </ol>"},{"location":"kubernetes/endpoint/#structure-of-an-endpoint-resource","title":"Structure of an Endpoint Resource","text":"<p>The <code>Endpoints</code> object in Kubernetes has the following structure:</p> <pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: my-service\n  namespace: default\nsubsets:\n  - addresses:\n      - ip: 10.244.1.5\n      - ip: 10.244.1.6\n    ports:\n      - port: 80\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/endpoint/#key-fields","title":"Key Fields:","text":"<ul> <li><code>addresses</code>:</li> <li>A list of IP addresses representing the Pods associated with the Service.</li> <li><code>ports</code>:</li> <li>A list of port numbers available on the Pods.</li> </ul>"},{"location":"kubernetes/endpoint/#endpoints-vs-endpointslice","title":"Endpoints vs EndpointSlice","text":"<ul> <li> <p>Endpoints:</p> </li> <li> <p>A legacy resource that lists all IP addresses and ports associated with a Service.</p> </li> <li> <p>Can become inefficient for large-scale clusters with many endpoints.</p> </li> <li> <p>EndpointSlice:</p> </li> <li>Introduced in Kubernetes 1.17 as a scalable alternative.</li> <li>Divides endpoints into smaller chunks for better performance and scalability.</li> </ul>"},{"location":"kubernetes/endpoint/#common-use-cases","title":"Common Use Cases","text":"<ol> <li> <p>Service Discovery:</p> </li> <li> <p>Endpoints help Services discover and communicate with the Pods implementing the Service.</p> </li> <li> <p>Debugging Service Issues:</p> </li> <li> <p>You can inspect the Endpoint resource to verify which Pods are associated with a Service.</p> </li> </ol> <pre><code>kubectl get endpoints my-service -o yaml\n</code></pre> <ol> <li>Custom Routing:</li> <li>Applications or custom controllers can use the Endpoint resource for custom traffic routing logic.</li> </ol>"},{"location":"kubernetes/endpoint/#manually-creating-endpoints","title":"Manually Creating Endpoints","text":"<p>In some scenarios (e.g., external services or legacy applications), you may want to create an Endpoint resource manually.</p>"},{"location":"kubernetes/endpoint/#example","title":"Example:","text":"<pre><code>apiVersion: v1\nkind: Endpoints\nmetadata:\n  name: custom-endpoint\nsubsets:\n  - addresses:\n      - ip: 192.168.1.100\n    ports:\n      - port: 8080\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/endpoint/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use EndpointSlices for Scalability:</p> </li> <li> <p>For clusters with large numbers of Services or Pods, enable EndpointSlices for better performance.</p> </li> <li> <p>Avoid Manual Endpoint Management:</p> </li> <li> <p>Let Kubernetes manage Endpoints automatically through Services unless there\u2019s a specific need.</p> </li> <li> <p>Monitor and Debug:</p> </li> <li>Regularly monitor Endpoint resources to ensure Pods are correctly associated with Services.</li> </ol>"},{"location":"kubernetes/endpoint/#troubleshooting-endpoints","title":"Troubleshooting Endpoints","text":"<ol> <li>Check Endpoint Status:</li> </ol> <pre><code>kubectl describe endpoints my-service\n</code></pre> <ol> <li> <p>Verify Service Selectors:</p> </li> <li> <p>Ensure the Service selector matches the labels of the intended Pods.</p> </li> <li> <p>Inspect Pod Readiness:</p> </li> <li>Only Pods in the Ready state are included in the Endpoint resource.</li> </ol>"},{"location":"kubernetes/endpoint/#conclusion","title":"Conclusion","text":"<p>Kubernetes Endpoint resources are crucial for routing traffic within the cluster, providing the linkage between Services and their underlying Pods. While they serve as the backbone for internal service discovery and traffic management, EndpointSlices are the recommended solution for handling large-scale clusters due to their improved scalability and efficiency.</p>"},{"location":"kubernetes/envoy/","title":"What is Envoy?","text":"<p>Envoy is an open-source, high-performance edge and service proxy designed for cloud-native applications. Originally developed by Lyft and now part of the Cloud Native Computing Foundation (CNCF), Envoy is a critical building block for modern service meshes, API gateways, and microservices-based architectures.</p> <p>Envoy acts as a L4/L7 proxy that abstracts networking concerns, enabling reliable, scalable, and observable service-to-service communication.</p>"},{"location":"kubernetes/envoy/#key-features-of-envoy","title":"Key Features of Envoy","text":"<ol> <li> <p>High-Performance Proxy:</p> </li> <li> <p>Envoy is written in C++, ensuring low-latency and high-throughput proxying.</p> </li> <li> <p>Layer 4 (L4) and Layer 7 (L7) Proxy:</p> </li> <li> <p>Supports both transport-level (TCP) and application-level (HTTP/HTTPS) communication.</p> </li> <li> <p>Service Discovery and Load Balancing:</p> </li> <li> <p>Dynamic service discovery and advanced load balancing algorithms (e.g., round-robin, least-request).</p> </li> <li> <p>Observability:</p> </li> <li> <p>Provides detailed metrics, tracing, and logging to monitor service communication.</p> </li> <li> <p>Integrates with tools like Prometheus, Grafana, and Jaeger.</p> </li> <li> <p>Fault Injection and Resilience:</p> </li> <li> <p>Supports retries, circuit breakers, timeouts, and fault injection for improving resilience.</p> </li> <li> <p>mTLS (Mutual TLS):</p> </li> <li> <p>Provides secure communication between services using mutual TLS.</p> </li> <li> <p>Extensibility:</p> </li> <li> <p>Envoy can be extended using filters and works seamlessly with service mesh solutions like Istio.</p> </li> </ol>"},{"location":"kubernetes/envoy/#how-envoy-works","title":"How Envoy Works","text":"<p>Envoy operates as a sidecar proxy alongside application services or as an edge proxy. It intercepts traffic, manages routing, and ensures reliability.</p>"},{"location":"kubernetes/envoy/#1-service-to-service-communication","title":"1. Service-to-Service Communication","text":"<p>Envoy handles requests between services in a microservice architecture, managing load balancing, retries, and failures.</p>"},{"location":"kubernetes/envoy/#2-observability-and-telemetry","title":"2. Observability and Telemetry","text":"<p>Envoy generates telemetry data, including metrics and distributed traces, providing visibility into traffic and performance.</p>"},{"location":"kubernetes/envoy/#3-api-gateway","title":"3. API Gateway","text":"<p>At the edge of a system, Envoy serves as an API gateway, managing external requests, rate limiting, and security.</p>"},{"location":"kubernetes/envoy/#use-cases-for-envoy","title":"Use Cases for Envoy","text":"<ol> <li> <p>Service Mesh:</p> </li> <li> <p>Envoy acts as a sidecar proxy for communication in service meshes like Istio, Consul, and Linkerd.</p> </li> <li> <p>API Gateway:</p> </li> <li> <p>Envoy can manage external API traffic, handle routing, and enforce security policies.</p> </li> <li> <p>Edge Proxy:</p> </li> <li> <p>Envoy can be deployed at the network edge to handle external traffic and load balancing.</p> </li> <li> <p>Observability and Monitoring:</p> </li> <li> <p>Envoy collects and exposes metrics, logs, and traces for performance monitoring.</p> </li> <li> <p>Resilience:</p> </li> <li>Implements features like retries, timeouts, rate limiting, and circuit breakers to ensure system stability.</li> </ol>"},{"location":"kubernetes/envoy/#example-envoy-configuration","title":"Example Envoy Configuration","text":"<p>Here is a sample configuration for routing HTTP requests to a backend service:</p> <pre><code>static_resources:\n  listeners:\n    - name: listener_0\n      address:\n        socket_address: { address: 0.0.0.0, port_value: 8080 }\n      filter_chains:\n        - filters:\n            - name: envoy.filters.network.http_connection_manager\n              typed_config:\n                \"@type\": type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n                codec_type: AUTO\n                stat_prefix: ingress_http\n                route_config:\n                  name: local_route\n                  virtual_hosts:\n                    - name: backend_service\n                      domains: [\"*\"]\n                      routes:\n                        - match: { prefix: \"/\" }\n                          route: { cluster: backend_cluster }\n                http_filters:\n                  - name: envoy.filters.http.router\n\n  clusters:\n    - name: backend_cluster\n      connect_timeout: 0.25s\n      type: LOGICAL_DNS\n      lb_policy: ROUND_ROBIN\n      load_assignment:\n        cluster_name: backend_cluster\n        endpoints:\n          - lb_endpoints:\n              - endpoint:\n                  address:\n                    socket_address: { address: backend, port_value: 80 }\n</code></pre>"},{"location":"kubernetes/envoy/#explanation","title":"Explanation:","text":"<ul> <li>Listeners: Define where Envoy listens for incoming requests.</li> <li>Routes: Specify routing rules for requests.</li> <li>Clusters: Define upstream services where traffic is sent.</li> </ul>"},{"location":"kubernetes/envoy/#why-use-envoy","title":"Why Use Envoy?","text":"<ul> <li>Scalability: Designed for modern, large-scale distributed systems.</li> <li>Extensibility: Highly configurable and supports custom extensions.</li> <li>Observability: Detailed metrics and tracing for full visibility.</li> <li>Resilience: Implements retries, circuit breakers, and load balancing for fault tolerance.</li> <li>Compatibility: Integrates seamlessly with service meshes, cloud-native tools, and Kubernetes.</li> </ul>"},{"location":"kubernetes/envoy/#conclusion","title":"Conclusion","text":"<p>Envoy is a versatile, high-performance proxy that enables reliable, observable, and secure communication in modern cloud-native systems. Whether used as an API gateway, edge proxy, or sidecar proxy in a service mesh, Envoy is a powerful tool for managing microservice architectures and distributed systems.</p>"},{"location":"kubernetes/kubefed/","title":"KubeFed (Kubernetes Federation)","text":"<p>KubeFed is a Kubernetes project that enables federation of multiple Kubernetes clusters. Federation allows you to manage multiple clusters as a single entity, providing centralized control over the resources and configurations across clusters.</p>"},{"location":"kubernetes/kubefed/#key-features-of-kubefed","title":"Key Features of KubeFed","text":"<ol> <li> <p>Multi-Cluster Management:</p> </li> <li> <p>Allows administrators to manage multiple Kubernetes clusters from a single control plane.</p> </li> <li> <p>Synchronizes resources and configurations across clusters.</p> </li> <li> <p>Workload Distribution:</p> </li> <li> <p>Enables workload distribution across clusters for improved availability, fault tolerance, and geographic coverage.</p> </li> <li> <p>Cross-Cluster Resource Sharing:</p> </li> <li> <p>Allows shared resources, such as ConfigMaps and Secrets, to be replicated across clusters.</p> </li> <li> <p>Policy Enforcement:</p> </li> <li>Ensures consistent policies and configurations across all federated clusters.</li> </ol>"},{"location":"kubernetes/kubefed/#use-cases","title":"Use Cases","text":"<ul> <li>Disaster recovery and high availability by distributing workloads across multiple regions.</li> <li>Multi-cloud or hybrid cloud deployments to avoid vendor lock-in.</li> <li>Scaling workloads geographically to reduce latency for end-users.</li> </ul>"},{"location":"kubernetes/kubefed/#how-it-works","title":"How It Works","text":"<ul> <li>Control Plane: A central KubeFed control plane manages multiple clusters.</li> <li>Federated Resources: Resources such as Deployments, Services, or ConfigMaps are created in a federated namespace and propagated to member clusters.</li> </ul>"},{"location":"kubernetes/kubefed/#example-federated-deployment","title":"Example: Federated Deployment","text":"<p>A Deployment managed by KubeFed can run replicas of an application across three clusters (e.g., one in the US, one in Europe, and one in Asia).</p>"},{"location":"kubernetes/kubernetes_components/","title":"Components of Kubernetes","text":"<p>Kubernetes is composed of several key components that work together to orchestrate containerized applications. Below is a list of the core components, grouped into control plane components and node components, along with their descriptions.</p>"},{"location":"kubernetes/kubernetes_components/#control-plane-components","title":"Control Plane Components","text":"<p>The control plane manages the Kubernetes cluster and makes global decisions about scheduling, scaling, and maintaining the cluster\u2019s state.</p>"},{"location":"kubernetes/kubernetes_components/#1-api-server-kube-apiserver","title":"1. API Server (<code>kube-apiserver</code>)","text":"<ul> <li>Description: Acts as the central control plane component, exposing the Kubernetes API. It serves as the primary point of communication for users, administrators, and all cluster components.</li> <li>Key Features:</li> <li>Processes API requests (e.g., <code>kubectl</code> commands).</li> <li>Provides authentication, authorization, and admission control.</li> <li>Persists the cluster\u2019s state to etcd.</li> <li>Example: Handles commands like <code>kubectl apply</code> to create resources.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#2-etcd","title":"2. etcd","text":"<ul> <li>Description: A distributed key-value store used as the primary database for storing all cluster data.</li> <li>Key Features:</li> <li>Stores information about nodes, Pods, ConfigMaps, Secrets, and more.</li> <li>Ensures data consistency across the cluster.</li> <li>Example: Stores the desired state of a Deployment and its associated Pods.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#3-scheduler-kube-scheduler","title":"3. Scheduler (<code>kube-scheduler</code>)","text":"<ul> <li>Description: Determines on which node a Pod should run based on resource requirements, constraints, and available capacity.</li> <li>Key Features:</li> <li>Uses policies and priorities to select the optimal node.</li> <li>Factors in taints, tolerations, node affinity, and Pod affinity/anti-affinity.</li> <li>Example: Assigns a Pod to a node with sufficient memory and CPU.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#4-controller-manager-kube-controller-manager","title":"4. Controller Manager (<code>kube-controller-manager</code>)","text":"<ul> <li>Description: Runs multiple controllers that regulate the cluster\u2019s state by watching the API server and taking action to meet the desired state.</li> <li>Key Controllers:</li> <li>Node Controller: Manages node health and lifecycle.</li> <li>Replication Controller: Ensures the correct number of Pod replicas are running.</li> <li>Service Controller: Maintains network load balancers for services.</li> <li>Endpoint Controller: Updates Endpoints for services.</li> <li>Example: Ensures a Deployment with three replicas always has three Pods running.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#5-cloud-controller-manager","title":"5. Cloud Controller Manager","text":"<ul> <li>Description: Integrates Kubernetes with cloud provider-specific APIs to manage resources like load balancers, storage, and networking.</li> <li>Key Controllers:</li> <li>Node Controller: Manages cloud-based node operations.</li> <li>Route Controller: Configures routes in the cloud for cluster networking.</li> <li>Service Controller: Manages external load balancers.</li> <li>Example: Creates a cloud load balancer for a Kubernetes Service of type <code>LoadBalancer</code>.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#node-components","title":"Node Components","text":"<p>Node components run on each worker node and manage workloads, ensuring that containers operate as specified.</p>"},{"location":"kubernetes/kubernetes_components/#1-kubelet","title":"1. Kubelet","text":"<ul> <li>Description: An agent running on each node that communicates with the API server to ensure containers are running as instructed.</li> <li>Key Features:</li> <li>Manages Pods and their containers.</li> <li>Monitors Pod health and resource usage.</li> <li>Interacts with the container runtime (e.g., Docker, containerd).</li> <li>Example: Starts and stops containers as defined in a Pod spec.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#2-kube-proxy","title":"2. Kube-Proxy","text":"<ul> <li>Description: A network proxy running on each node to manage networking for services.</li> <li>Key Features:</li> <li>Implements Kubernetes Services by forwarding traffic to the correct Pods.</li> <li>Supports protocols like TCP, UDP, and SCTP.</li> <li>Example: Routes external requests to the appropriate backend Pod in a Service.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#3-container-runtime","title":"3. Container Runtime","text":"<ul> <li>Description: The software responsible for running containers on a node.</li> <li>Supported Runtimes:</li> <li>Docker (deprecated as of Kubernetes 1.20+).</li> <li>containerd.</li> <li>CRI-O.</li> <li>Any runtime that implements the Kubernetes Container Runtime Interface (CRI).</li> <li>Example: Pulls a container image from a registry and starts it.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#add-ons","title":"Add-Ons","text":"<p>Add-ons provide additional functionality that is not part of the core Kubernetes components but is essential for a fully functional cluster.</p>"},{"location":"kubernetes/kubernetes_components/#1-coredns","title":"1. CoreDNS","text":"<ul> <li>Description: Provides DNS for Kubernetes services and Pods.</li> <li>Example: Resolves service names to IP addresses (e.g., <code>my-service.default.svc.cluster.local</code>).</li> </ul>"},{"location":"kubernetes/kubernetes_components/#2-dashboard","title":"2. Dashboard","text":"<ul> <li>Description: A web-based user interface for managing and monitoring the cluster.</li> <li>Example: Provides a visual representation of workloads, resources, and cluster status.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#3-metrics-server","title":"3. Metrics Server","text":"<ul> <li>Description: Collects resource usage data (e.g., CPU, memory) for Pods and nodes.</li> <li>Example: Enables horizontal Pod autoscaling based on CPU usage.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#4-ingress-controller","title":"4. Ingress Controller","text":"<ul> <li>Description: Manages HTTP and HTTPS routing to services within the cluster.</li> <li>Example: Routes external traffic to a service using a custom domain (e.g., <code>example.com</code>).</li> </ul>"},{"location":"kubernetes/kubernetes_components/#5-logging-and-monitoring-tools","title":"5. Logging and Monitoring Tools","text":"<ul> <li>Examples:</li> <li>Prometheus/Grafana: Collect and visualize metrics.</li> <li>ELK Stack (Elasticsearch, Logstash, Kibana): Aggregate and analyze logs.</li> </ul>"},{"location":"kubernetes/kubernetes_components/#interaction-of-components","title":"Interaction of Components","text":"<ol> <li>A user submits a request to the API server (e.g., <code>kubectl apply</code>).</li> <li>The API server validates the request and persists the desired state in etcd.</li> <li>The Scheduler assigns the Pod to an appropriate node.</li> <li>The Controller Manager ensures the desired state matches the actual state (e.g., launching Pods, scaling Deployments).</li> <li>The Kubelet on the assigned node pulls the container image, starts the container, and reports status to the API server.</li> <li>Kube-Proxy manages networking so traffic can reach the Pods.</li> </ol>"},{"location":"kubernetes/kubernetes_components/#conclusion","title":"Conclusion","text":"<p>These components work together to manage the lifecycle of applications, maintain the desired state, and ensure scalability and high availability in Kubernetes clusters. Understanding these components is essential for effectively deploying and managing containerized workloads.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/","title":"Kubernetes Serverless Platforms","text":""},{"location":"kubernetes/kubernetes_serverless_platforms/#answer","title":"Answer","text":"<p>Kubernetes serverless platforms are frameworks or tools that extend Kubernetes\u2019 capabilities to support serverless computing. These platforms enable developers to deploy and manage functions or applications that scale automatically based on demand, including scaling to zero when idle. The platforms abstract many of Kubernetes\u2019 complexities, allowing developers to focus on writing code instead of managing infrastructure.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#key-features-of-kubernetes-serverless-platforms","title":"Key Features of Kubernetes Serverless Platforms:","text":"<ol> <li>Auto-Scaling: Automatically scales workloads based on demand.</li> <li>Event-Driven: Supports triggering workloads based on events like HTTP requests, Kafka messages, or scheduled tasks.</li> <li>Scale-to-Zero: Reduces costs by shutting down workloads when they\u2019re not in use.</li> <li>Portability: Most platforms work across different Kubernetes distributions, making them highly portable.</li> </ol> <p>Some of the popular Kubernetes serverless platforms:</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#1-knative","title":"1. Knative","text":"<p>Knative is an open-source Kubernetes-based platform designed for building, deploying, and managing serverless applications. It provides two core components: Knative Serving for deploying stateless services and Knative Eventing for building event-driven architectures.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros","title":"Pros:","text":"<ul> <li>Fully integrates with Kubernetes, leveraging its native features.</li> <li>Supports advanced auto-scaling, including scale-to-zero.</li> <li>Flexible eventing model for complex workflows.</li> <li>Works with containerized workloads, not limited to functions.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons","title":"Cons:","text":"<ul> <li>Can be complex to set up and manage.</li> <li>Requires a strong understanding of Kubernetes to use effectively.</li> <li>Resource-intensive for small-scale deployments.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#2-openfaas","title":"2. OpenFaaS","text":"<p>OpenFaaS (Open Function as a Service) is a lightweight and developer-friendly serverless framework that runs on Kubernetes and Docker Swarm. It focuses on simplicity and portability, allowing developers to deploy functions in any language using templates.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_1","title":"Pros:","text":"<ul> <li>Easy to use with intuitive CLI tools and templates.</li> <li>Language-agnostic, supporting any runtime.</li> <li>Supports Kubernetes and Docker Swarm, making it versatile.</li> <li>Built-in Prometheus integration for monitoring.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_1","title":"Cons:","text":"<ul> <li>Limited eventing capabilities compared to Knative.</li> <li>Lacks native scale-to-zero support (requires external tools).</li> <li>Less suited for large-scale enterprise environments.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#3-kubeless","title":"3. Kubeless","text":"<p>Kubeless is a Kubernetes-native serverless framework that uses Custom Resource Definitions (CRDs) to deploy and manage functions. It is lightweight and integrates closely with Kubernetes\u2019 architecture.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_2","title":"Pros:","text":"<ul> <li>Simple and lightweight; uses Kubernetes-native resources.</li> <li>Event triggers via Kafka, HTTP, or cron jobs.</li> <li>Minimal configuration required for basic use cases.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_2","title":"Cons:","text":"<ul> <li>Limited community support and slower development compared to other platforms.</li> <li>Lacks advanced features like scale-to-zero.</li> <li>Less extensible for complex workflows.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#4-fission","title":"4. Fission","text":"<p>Fission is a fast, Kubernetes-native serverless framework optimized for low-latency function execution. It pre-warms environments to eliminate cold starts and supports multiple languages out of the box.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_3","title":"Pros:","text":"<ul> <li>Extremely fast execution with pre-warmed environments.</li> <li>Simple YAML-based configuration for functions.</li> <li>Supports event-driven triggers like HTTP, Kafka, and cron.</li> <li>Lightweight and easy to install.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_3","title":"Cons:","text":"<ul> <li>Limited scalability for large-scale, complex systems.</li> <li>Fewer integrations compared to Knative.</li> <li>Not as feature-rich for workflows and advanced eventing.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#5-red-hat-openshift-serverless","title":"5. Red Hat OpenShift Serverless","text":"<p>Red Hat OpenShift Serverless is based on Knative and tailored for Red Hat\u2019s OpenShift Kubernetes platform. It offers enterprise-grade serverless capabilities with enhanced security and compliance features.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_4","title":"Pros:","text":"<ul> <li>Enterprise-ready with strong security and compliance.</li> <li>Seamless integration with Red Hat OpenShift.</li> <li>Full support for Knative features (Serving and Eventing).</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_4","title":"Cons:","text":"<ul> <li>Requires OpenShift, limiting portability to non-OpenShift Kubernetes clusters.</li> <li>Higher cost due to the OpenShift licensing model.</li> <li>More complex setup compared to simpler frameworks like OpenFaaS.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#6-apache-openwhisk-self-hosted","title":"6. Apache OpenWhisk (Self-Hosted)","text":"<p>Apache OpenWhisk is an open-source, distributed serverless platform that can run on Kubernetes. It supports event-driven workloads and provides a flexible runtime for functions.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_5","title":"Pros:","text":"<ul> <li>Highly extensible and customizable.</li> <li>Supports multiple event triggers, including HTTP and Kafka.</li> <li>Language-agnostic, supporting various runtimes.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_5","title":"Cons:","text":"<ul> <li>Complex setup and management.</li> <li>Resource-intensive for smaller environments.</li> <li>Limited built-in Kubernetes integrations compared to other platforms.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#7-google-cloud-run-for-anthos","title":"7. Google Cloud Run for Anthos","text":"<p>Google Cloud Run for Anthos extends Knative\u2019s capabilities to hybrid Kubernetes environments. It enables serverless containers to run on Anthos, Google\u2019s hybrid and multi-cloud platform.</p>"},{"location":"kubernetes/kubernetes_serverless_platforms/#pros_6","title":"Pros:","text":"<ul> <li>Based on Knative, providing robust auto-scaling and event-driven capabilities.</li> <li>Seamless integration with Google Cloud services.</li> <li>Ideal for hybrid cloud environments.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#cons_6","title":"Cons:","text":"<ul> <li>Requires Anthos, which adds complexity and cost.</li> <li>Less suitable for non-Google Cloud Kubernetes environments.</li> <li>Limited to containerized workloads.</li> </ul>"},{"location":"kubernetes/kubernetes_serverless_platforms/#conclusion","title":"Conclusion","text":"<p>Kubernetes serverless platforms provide powerful tools for running scalable, event-driven workloads. Choosing the right platform depends on your use case, environment, and skill level. For example:</p> <ul> <li>Use Knative if you need a feature-rich, Kubernetes-native solution with advanced eventing.</li> <li>Choose OpenFaaS or Fission for simplicity and fast deployments.</li> <li>Opt for Red Hat OpenShift Serverless or Google Cloud Run for Anthos for enterprise-grade hybrid cloud solutions.</li> </ul> <p>Understanding the strengths and weaknesses of each platform ensures you select the one that best aligns with your application\u2019s requirements and organizational goals.</p>"},{"location":"kubernetes/observability_tools/","title":"Observability Tools in Kubernetes","text":""},{"location":"kubernetes/observability_tools/#use-case-observability","title":"Use Case: Observability","text":"<p>Observability tools are vital for maintaining the health and performance of Kubernetes clusters. They enable operators to monitor system metrics, identify bottlenecks, and troubleshoot issues effectively. By providing both real-time and historical insights, these tools ensure that workloads remain optimized and reliable, even in dynamic cloud-native environments.</p>"},{"location":"kubernetes/observability_tools/#tools","title":"Tools:","text":""},{"location":"kubernetes/observability_tools/#1-thanos","title":"1. Thanos","text":"<ul> <li>Description: Thanos extends Prometheus by enabling long-term metrics storage, high availability, and cross-cluster queries. It aggregates data from multiple Prometheus instances, allowing operators to view metrics across clusters. With its support for object storage systems like S3 and Azure Blob, Thanos ensures scalable and cost-effective metrics retention.</li> <li>Best For: Large-scale environments requiring unified monitoring across clusters, long-term storage, and robust querying capabilities.</li> </ul>"},{"location":"kubernetes/observability_tools/#2-cortex","title":"2. Cortex","text":"<ul> <li>Description: Cortex is a multi-tenant, horizontally scalable backend for Prometheus designed for cloud-native observability. It enables advanced metrics management by offering isolation for different teams or projects, long-term storage in object stores, and seamless integration with tools like Grafana. Cortex is highly optimized for enterprises running Prometheus-as-a-service.</li> <li>Best For: Organizations needing centralized metrics storage and management with robust multi-tenancy and scalability to support large teams and complex workloads.</li> </ul>"},{"location":"kubernetes/pod_disruption_budget/","title":"PodDisruptionBudget (PDB) in Kubernetes","text":"<p>A PodDisruptionBudget (PDB) is a Kubernetes resource that helps ensure a certain number or percentage of Pods remain available during voluntary disruptions. These disruptions can include node maintenance, cluster scaling, or rolling updates.</p>"},{"location":"kubernetes/pod_disruption_budget/#purpose-of-poddisruptionbudget","title":"Purpose of PodDisruptionBudget","text":"<ul> <li>To protect application availability during planned events.</li> <li>To enforce a minimum number of Pods running or restrict the maximum number of Pods disrupted simultaneously.</li> <li>To balance the needs of system administrators and application reliability.</li> </ul>"},{"location":"kubernetes/pod_disruption_budget/#key-features","title":"Key Features","text":"<ol> <li> <p>Voluntary Disruptions:</p> </li> <li> <p>PDB applies only to voluntary disruptions, such as:</p> <ul> <li>Node draining for maintenance.</li> <li>Rolling updates.</li> <li>Scaling events.</li> </ul> </li> <li> <p>Minimum Availability:</p> </li> <li> <p>Ensures that a certain number of Pods remain available during disruptions.</p> </li> <li> <p>Maximum Disruption:</p> </li> <li> <p>Restricts the maximum number of Pods that can be disrupted simultaneously.</p> </li> <li> <p>Integration with Controllers:</p> </li> <li>Works with Deployments, StatefulSets, ReplicaSets, and other controllers.</li> </ol>"},{"location":"kubernetes/pod_disruption_budget/#how-poddisruptionbudget-works","title":"How PodDisruptionBudget Works","text":"<ul> <li> <p><code>minAvailable</code>:</p> </li> <li> <p>Specifies the minimum number of Pods that must remain available during disruptions.</p> </li> <li> <p><code>maxUnavailable</code>:</p> </li> <li> <p>Specifies the maximum number of Pods that can be disrupted simultaneously.</p> </li> <li> <p>Scope:</p> </li> <li>PDB is applied to a group of Pods matching the specified label selector.</li> </ul>"},{"location":"kubernetes/pod_disruption_budget/#example-poddisruptionbudget","title":"Example PodDisruptionBudget","text":""},{"location":"kubernetes/pod_disruption_budget/#1-minimum-available-pods","title":"1. Minimum Available Pods","text":"<p>This PDB ensures at least 2 Pods are always running during voluntary disruptions.</p> <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: my-app-pdb\n  namespace: my-namespace\nspec:\n  minAvailable: 2\n  selector:\n    matchLabels:\n      app: my-app\n</code></pre>"},{"location":"kubernetes/pod_disruption_budget/#2-maximum-unavailable-pods","title":"2. Maximum Unavailable Pods","text":"<p>This PDB ensures that no more than 1 Pod can be disrupted at any time.</p> <pre><code>apiVersion: policy/v1\nkind: PodDisruptionBudget\nmetadata:\n  name: my-app-pdb\n  namespace: my-namespace\nspec:\n  maxUnavailable: 1\n  selector:\n    matchLabels:\n      app: my-app\n</code></pre>"},{"location":"kubernetes/pod_disruption_budget/#use-cases","title":"Use Cases","text":"<ol> <li> <p>High Availability:</p> </li> <li> <p>Ensures critical applications remain operational during cluster maintenance.</p> </li> <li> <p>Rolling Updates:</p> </li> <li> <p>Controls the pace of Pod evictions to prevent service downtime.</p> </li> <li> <p>Stateful Applications:</p> </li> <li>Protects databases or StatefulSets that require a specific number of Pods for consistency.</li> </ol>"},{"location":"kubernetes/pod_disruption_budget/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Plan for Downtime:</p> </li> <li> <p>Use <code>minAvailable</code> or <code>maxUnavailable</code> based on the application\u2019s availability requirements.</p> </li> <li> <p>Label Pods Consistently:</p> </li> <li> <p>Ensure Pods have appropriate labels to match the PDB\u2019s selector.</p> </li> <li> <p>Combine with Monitoring:</p> </li> <li> <p>Use monitoring tools to track PDB effectiveness during disruptions.</p> </li> <li> <p>Test Scenarios:</p> </li> <li>Simulate node drains and rolling updates to verify PDB behavior.</li> </ol>"},{"location":"kubernetes/pod_disruption_budget/#limitations","title":"Limitations","text":"<ol> <li> <p>Voluntary Disruptions Only:</p> </li> <li> <p>PDB does not apply to involuntary disruptions, such as crashes or node failures.</p> </li> <li> <p>No Guarantee of Scheduling:</p> </li> <li>PDB ensures Pods are not evicted below the threshold but does not guarantee new Pods can be scheduled.</li> </ol>"},{"location":"kubernetes/pod_disruption_budget/#conclusion","title":"Conclusion","text":"<p>PodDisruptionBudget is a vital tool in Kubernetes for ensuring application availability during planned events like maintenance or updates. By setting appropriate thresholds with <code>minAvailable</code> or <code>maxUnavailable</code>, you can balance operational flexibility with application reliability.</p>"},{"location":"kubernetes/pod_priority_and_preemption/","title":"Implementing Pod Priority and Preemption in Kubernetes","text":"<p>Pod Priority and Preemption is a feature in Kubernetes that allows you to assign different levels of importance to Pods. Higher-priority Pods can preempt (evict) lower-priority Pods to make room for critical workloads when cluster resources are scarce.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#steps-to-implement-pod-priority-and-preemption","title":"Steps to Implement Pod Priority and Preemption","text":""},{"location":"kubernetes/pod_priority_and_preemption/#step-1-enable-priority-and-preemption","title":"Step 1: Enable Priority and Preemption","text":"<p>Pod Priority and Preemption are enabled by default in Kubernetes (v1.14+). Ensure it is not disabled in your cluster by checking the <code>--enable-admission-plugins</code> flag on the API server. The <code>Priority</code> admission plugin must be enabled.</p> <pre><code>kubectl get podsecuritypolicy\n# Verify the admission plugins include \"Priority\".\n</code></pre>"},{"location":"kubernetes/pod_priority_and_preemption/#step-2-create-priorityclasses","title":"Step 2: Create PriorityClasses","text":"<p>PriorityClasses define the priority level for Pods. A higher <code>value</code> indicates higher priority.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#example-yaml-for-priorityclasses","title":"Example YAML for PriorityClasses:","text":"<pre><code>apiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: high-priority\nvalue: 1000\nglobalDefault: false\ndescription: \"This priority is for critical Pods.\"\n---\napiVersion: scheduling.k8s.io/v1\nkind: PriorityClass\nmetadata:\n  name: low-priority\nvalue: 500\nglobalDefault: false\ndescription: \"This priority is for less important Pods.\"\n</code></pre> <p>Apply the PriorityClasses:</p> <pre><code>kubectl apply -f priorityclasses.yaml\n</code></pre>"},{"location":"kubernetes/pod_priority_and_preemption/#step-3-assign-priority-to-pods","title":"Step 3: Assign Priority to Pods","text":"<p>Use the <code>priorityClassName</code> field in the Pod specification to assign a priority to your Pods.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#example-high-priority-pod","title":"Example: High-Priority Pod:","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: high-priority-pod\n  namespace: default\nspec:\n  containers:\n    - name: nginx\n      image: nginx\n  priorityClassName: high-priority\n</code></pre>"},{"location":"kubernetes/pod_priority_and_preemption/#example-low-priority-pod","title":"Example: Low-Priority Pod:","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: low-priority-pod\n  namespace: default\nspec:\n  containers:\n    - name: nginx\n      image: nginx\n  priorityClassName: low-priority\n</code></pre> <p>Apply the Pod definitions:</p> <pre><code>kubectl apply -f high-priority-pod.yaml\nkubectl apply -f low-priority-pod.yaml\n</code></pre>"},{"location":"kubernetes/pod_priority_and_preemption/#step-4-test-preemption","title":"Step 4: Test Preemption","text":"<ol> <li>Simulate a resource-scarce scenario by scheduling multiple low-priority Pods to consume available resources.</li> <li>Schedule a high-priority Pod. Kubernetes will preempt (evict) the low-priority Pods if necessary to make room for the high-priority Pod.</li> </ol>"},{"location":"kubernetes/pod_priority_and_preemption/#verify-preemption","title":"Verify Preemption:","text":"<p>Check the status of the evicted Pods:</p> <pre><code>kubectl get pods -o wide\n</code></pre> <p>Evicted Pods will show a status of <code>Evicted</code> or <code>Pending</code>.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#additional-considerations","title":"Additional Considerations","text":"<ol> <li> <p>Preemption Delay:</p> </li> <li> <p>Preemption is not immediate. Kubernetes waits for evicted Pods to terminate before scheduling high-priority Pods.</p> </li> <li> <p>Avoid Overuse of High Priority:</p> </li> <li> <p>Overusing high-priority Pods can lead to instability by preempting essential workloads.</p> </li> <li> <p>Graceful Eviction:</p> </li> <li> <p>Kubernetes respects the <code>terminationGracePeriodSeconds</code> of evicted Pods to allow graceful termination.</p> </li> <li> <p>Default Priority:</p> </li> <li>You can define a <code>globalDefault: true</code> PriorityClass, which will be used for Pods without an explicit <code>priorityClassName</code>.</li> </ol>"},{"location":"kubernetes/pod_priority_and_preemption/#benefits","title":"Benefits","text":"<ul> <li>Ensures critical workloads are prioritized during resource contention.</li> <li>Helps maintain cluster reliability by protecting important services.</li> </ul>"},{"location":"kubernetes/pod_priority_and_preemption/#use-cases","title":"Use Cases","text":"<ul> <li>Assigning higher priority to system Pods (e.g., DNS, monitoring).</li> <li>Ensuring critical workloads are scheduled even in overloaded clusters.</li> <li>Preempting non-essential workloads for disaster recovery operations.</li> </ul> <p>By carefully designing your PriorityClasses and assigning them appropriately, you can efficiently manage resource allocation in your Kubernetes cluster.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#system-cluster-critical-priorityclass","title":"<code>system-cluster-critical</code> PriorityClass","text":"<p><code>system-cluster-critical</code> is a predefined PriorityClass in Kubernetes. It is used for system-critical Pods that are essential for the overall functionality of the cluster. This PriorityClass ensures that critical system Pods have the highest priority and can preempt less critical workloads to maintain cluster health.</p>"},{"location":"kubernetes/pod_priority_and_preemption/#key-features","title":"Key Features","text":"<ol> <li> <p>High Priority:</p> </li> <li> <p><code>system-cluster-critical</code> is one of the highest priority levels in Kubernetes, ensuring that critical system Pods can always run, even under resource contention.</p> </li> <li> <p>Reserved for System Pods:</p> </li> <li> <p>Intended for Pods required for cluster management, such as DNS, network plugins, or monitoring systems.</p> </li> <li> <p>Preemption:</p> </li> <li>Pods with this PriorityClass can preempt lower-priority Pods to free up resources.</li> </ol>"},{"location":"kubernetes/pod_security_admission/","title":"Pod Security Admission (PSA)","text":"<p>Pod Security Admission (PSA) is a Kubernetes feature that enforces security policies at the namespace level to control how Pods are created and managed based on predefined security standards. It is the successor to the deprecated Pod Security Policies (PSPs) and provides a simpler way to apply security controls.</p>"},{"location":"kubernetes/pod_security_admission/#purpose","title":"Purpose","text":"<ul> <li>To enforce security best practices for Kubernetes Pods.</li> <li>To prevent potentially unsafe Pod configurations (e.g., privilege escalation, use of host namespaces).</li> </ul>"},{"location":"kubernetes/pod_security_admission/#how-it-works","title":"How It Works","text":"<ul> <li>PSA evaluates Pod specifications during the admission phase (before the Pod is created) to ensure compliance with the security standards.</li> <li>Security policies are defined by labeling namespaces with one of three predefined security levels:</li> <li>Privileged: Minimal restrictions, suitable for trusted environments.</li> <li>Baseline: Basic restrictions to enforce reasonable security defaults.</li> <li>Restricted: Strong restrictions for high-security environments.</li> </ul>"},{"location":"kubernetes/pod_security_admission/#key-features","title":"Key Features","text":"<ol> <li>Namespace-Level Control:</li> <li>PSA applies policies based on namespace labels, making it simple to manage security across the cluster.</li> <li>Three Modes:</li> <li>Enforce: Rejects Pods that violate the policy.</li> <li>Audit: Logs violations but does not block Pod creation.</li> <li>Warn: Issues warnings to users creating non-compliant Pods.</li> </ol>"},{"location":"kubernetes/pod_security_admission/#example-namespace-labels","title":"Example Namespace Labels","text":"<pre><code>kubectl label namespace dev pod-security.kubernetes.io/enforce=restricted\nkubectl label namespace dev pod-security.kubernetes.io/audit=baseline\nkubectl label namespace dev pod-security.kubernetes.io/warn=privileged\n</code></pre>"},{"location":"kubernetes/submariner/","title":"Submariner","text":"<p>Submariner is a tool that facilitates network connectivity across multiple Kubernetes clusters. It provides secure and seamless communication between Pods and Services across different clusters, even if they are in separate networks.</p>"},{"location":"kubernetes/submariner/#key-features-of-submariner","title":"Key Features of Submariner","text":"<ol> <li> <p>Cross-Cluster Networking:</p> </li> <li> <p>Establishes network connectivity between Kubernetes clusters without requiring them to share the same network.</p> </li> <li> <p>Service Discovery:</p> </li> <li> <p>Enables Pods in one cluster to discover and communicate with Services in another cluster.</p> </li> <li> <p>Secure Communication:</p> </li> <li> <p>Uses IPsec or WireGuard for secure communication between clusters.</p> </li> <li> <p>Load Balancing:</p> </li> <li>Provides efficient load balancing for cross-cluster traffic.</li> </ol>"},{"location":"kubernetes/submariner/#use-cases","title":"Use Cases","text":"<ul> <li>Multi-cluster deployments where clusters are in different networks or regions.</li> <li>Enabling cross-cluster communication for hybrid or multi-cloud setups.</li> <li>Building multi-cluster service meshes for advanced traffic control.</li> </ul>"},{"location":"kubernetes/submariner/#how-it-works","title":"How It Works","text":"<ul> <li>Gateway Nodes: Submariner designates a gateway node in each cluster to handle inter-cluster traffic.</li> <li>Tunnel Creation: Secure tunnels are established between the gateway nodes of participating clusters.</li> <li>Routing: Submariner ensures that Pods and Services can route traffic seamlessly across clusters.</li> </ul>"},{"location":"kubernetes/submariner/#example-service-connectivity","title":"Example: Service Connectivity","text":"<p>A Pod in Cluster A can directly access a Service in Cluster B using the standard Service DNS name, such as <code>my-service.my-namespace.svc.cluster.local</code>.</p>"},{"location":"kubernetes/cka/cri/","title":"CRI","text":""},{"location":"kubernetes/cka/cri/#install-a-container-runtime-interface","title":"Install a container runtime interface","text":""},{"location":"kubernetes/cka/cri/#containerd","title":"Containerd","text":"<p>Install <pre><code>sudo apt update\nsudo apt install -y containerd\n</code></pre></p> <p>Setup <pre><code>sudo mkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n</code></pre></p> <p>Restart <pre><code>sudo systemctl restart containerd\nsudo systemctl enable containerd\n</code></pre></p> <p>Check if Kubernetes is using containerd <pre><code>ps aux | grep kubelet | grep container-runtime\n</code></pre></p> <p>If it\u2019s not using it, set it up: <pre><code>sudo systemctl enable --now containerd\n</code></pre> or: <pre><code>sudo mkdir -p /etc/systemd/system/kubelet.service.d\nsudo tee /etc/systemd/system/kubelet.service.d/10-kubeadm.conf &lt;&lt;EOF\n[Service]\nEnvironment=\"KUBELET_EXTRA_ARGS=--container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock\"\nEOF\n</code></pre></p> <p>Check which CRI is in use: <pre><code>crictl info\n</code></pre></p>"},{"location":"kubernetes/cka/etcd/","title":"ETDC","text":"<p>Backup ETCD database:</p> <ol> <li> <p>Get certicates paths: <pre><code>kubectl get pod etcd-controlplane -n kube-system -o yaml\n</code></pre></p> </li> <li> <p>Create snapshot <pre><code>ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 --cacert=&lt;trusted-ca-file&gt; --cert=&lt;cert-file&gt; --key=&lt;key-file&gt; snapshot save &lt;backup-file-location&gt;\n</code></pre></p> </li> <li> <p>Restore snapshot <pre><code>ETCDCTL_API=3 etcdctl --data-dir &lt;data-dir-location&gt; snapshot restore &lt;backup-file-location&gt;\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cka/helm/","title":"Helm","text":"<p>Some useful commands:</p> <ol> <li> <p>Verify deployed release <pre><code>helm list\n</code></pre></p> </li> <li> <p>Get values used by a release <pre><code>helm get values &lt;release_name&gt; --all\n</code></pre></p> </li> <li> <p>Get available values of a chart <pre><code>helm show values &lt;chart&gt;\n</code></pre></p> </li> <li> <p>Upgrade release (using local chart) <pre><code>helm upgrade --install &lt;release_name&gt; &lt;chart_path&gt;\n</code></pre></p> </li> <li> <p>Upgrade and set custom values <pre><code>helm upgrade --install &lt;release_name&gt; &lt;chart_path&gt; --set key=value\nhelm upgrade --install &lt;release_name&gt; &lt;chart_path&gt; --values &lt;values_file_path&gt;\n</code></pre></p> </li> <li> <p>Add repo <pre><code>helm repo add &lt;repo_name&gt; &lt;repo_url&gt;\n</code></pre></p> </li> <li> <p>Install chart from repo <pre><code>helm install &lt;name&gt; &lt;chart&gt;\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cka/jsonpath/","title":"Jsonpath and custom-columns","text":""},{"location":"kubernetes/cka/jsonpath/#jsonpath","title":"Jsonpath","text":"<p>Print all pods names: <pre><code>kubectl get pods -o jsonpath='{.items[*].metadata.name}'\n</code></pre></p> <p>Loop over multiple objects with <code>range</code> <pre><code>kubectl get pods -o jsonpath='{range .items[*]}{.metadata.name}{\" - \"}{.status.phase}{\"\\n\"}{end}'\n</code></pre></p> <p>Filter with condition: <pre><code>kubectl get pods -o jsonpath='{.items[?(@.status.phase==\"Running\")].metadata.name}'\n</code></pre></p>"},{"location":"kubernetes/cka/jsonpath/#custom-columns","title":"Custom columns","text":"<p>Get name and status in a table like format: <pre><code>kubectl get pods -o custom-columns=\"NAME:.metadata.name,STATUS:.status.phase\"\n</code></pre></p>"},{"location":"kubernetes/cka/kubelet_issues/","title":"Kubelet Issues","text":"<p>Search logs: <pre><code>journalctl -u kubelet --no-pager\ncat /var/log/syslog | grep kubelet\n</code></pre></p> <p>Check status: <pre><code>systemctl status kubelet\n</code></pre></p> <p>Restart: <pre><code>systemctl daemon-reload\nsystemctl restart kubelet\n</code></pre></p> <p>Configuration files: <pre><code>/var/lib/kubelet/\n/etc/kubernetes/kubelet.conf\n/etc/systemd/system/kubelet.service.d/10-kubeadm.conf\n</code></pre></p>"},{"location":"kubernetes/cka/openssl/","title":"OpenSSL commands","text":""},{"location":"kubernetes/cka/openssl/#create-new-user","title":"Create new user","text":"<ol> <li> <p>Generate private key: <pre><code>openssl genrsa -out &lt;private_key_name&gt;.key 2048\n</code></pre></p> </li> <li> <p>Create Certificate Signing Request: <pre><code>openssl req -new -key &lt;private_key_name&gt;.key -subj \"/CN=&lt;user_name&gt;\" -out &lt;user_name&gt;.csr\n</code></pre></p> </li> <li> <p>Create a CSR <pre><code>apiVersion: certificates.k8s.io/v1\nkind: CertificateSigningRequest\nmetadata:\n  name: &lt;user_name&gt;\nspec:\n  groups:\n  - system:authenticated\n  request: $REQUEST\n  signerName: kubernetes.io/kube-apiserver-client\n  usages:\n  - client auth\n</code></pre></p> </li> </ol> <p><code>$REQUEST</code> should contains the encoded .csr file: <pre><code>cat &lt;user_name&gt;.csr | base64 | tr -d '\\n'\n</code></pre></p> <ol> <li> <p>Approve CSR: <pre><code>kubectl certificate approve &lt;user_name&gt;\n</code></pre></p> </li> <li> <p>Save client certificate: <pre><code>k get csr &lt;user_name&gt; -o jsonpath='{.status.certificate}' | base64 -d &gt; &lt;user_name&gt;.crt\n</code></pre></p> </li> <li> <p>Add user to kubeconfig <pre><code>k config set-credentials &lt;user_name&gt; --client-key=&lt;user_name&gt;.key --client-certificate=carlton.crt --embed-certs\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cka/openssl/#check-certificate-content","title":"Check certificate content","text":"<pre><code>openssl x509 -in &lt;certificate_file_name&gt;.crt -text -noout\n</code></pre>"},{"location":"kubernetes/cka/utilities/","title":"Utility commands","text":""},{"location":"kubernetes/cka/utilities/#move-file-from-node-to-node","title":"Move file from node to node","text":"<pre><code>scp /path/to/local-file user@remote-node:/path/to/destination/\n</code></pre>"},{"location":"kubernetes/cka/utilities/#write-logs-to-file","title":"Write logs to file","text":"<pre><code>tail -f /var/log/container.log\n</code></pre>"},{"location":"kubernetes/cka/vpa/","title":"Vertical Pod Autoscaler","text":"<p>Example of VPA manifest: <pre><code>apiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: my-app-vpa\n  namespace: default\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-app\n  updatePolicy:\n    updateMode: \"Auto\" # Options: \"Off\", \"Initial\", \"Auto\", \"Recreate\"\n  resourcePolicy:\n    containerPolicies:\n      - containerName: '*'\n        minAllowed:\n          cpu: 100m\n          memory: 128Mi\n        maxAllowed:\n          cpu: 1\n          memory: 1Gi\n        controlledResources: [\"cpu\", \"memory\"]\n</code></pre></p>"},{"location":"kubernetes/cks/admission_controller_config/","title":"Admission Controller Configuration","text":"<p>This document provides the necessary configuration files for setting up the ImagePolicyWebhook admission controller in Kubernetes. The ImagePolicyWebhook allows you to enforce policies on which container images can be used in your cluster by validating them against an external webhook service.</p>"},{"location":"kubernetes/cks/admission_controller_config/#1-admission-configuration-file","title":"1. Admission Configuration File","text":"<p>Create a file named <code>admission-configuration.yaml</code>:</p> <pre><code>apiVersion: apiserver.config.k8s.io/v1\nkind: AdmissionConfiguration\nplugins:\n- name: ImagePolicyWebhook\n  configuration:\n    imagePolicy:\n      kubeConfigFile: /etc/kubernetes/image-policy-webhook/kubeconfig.yaml\n      allowTTL: 50\n      denyTTL: 50\n      retryBackoff: 500\n      defaultAllow: false\n</code></pre> <p>Save this file to <code>/etc/kubernetes/admission-configuration.yaml</code> on all control plane nodes.</p>"},{"location":"kubernetes/cks/admission_controller_config/#2-webhook-kubeconfig-file","title":"2. Webhook KubeConfig File","text":"<p>Create a file named <code>kubeconfig.yaml</code> with your webhook service configuration:</p> <pre><code>apiVersion: v1\nkind: Config\n# clusters refers to the remote service\nclusters:\n- name: image-policy-webhook\n  cluster:\n    certificate-authority: /etc/kubernetes/image-policy-webhook/ca.crt\n    server: https://image-policy-webhook.example.com/image-policy\n# users refers to the API server's webhook configuration\nusers:\n- name: api-server\n  user:\n    client-certificate: /etc/kubernetes/image-policy-webhook/apiserver-client.crt\n    client-key: /etc/kubernetes/image-policy-webhook/apiserver-client.key\n# kubeconfig files require a context, current-context refers to the context to use\ncurrent-context: webhook\ncontexts:\n- context:\n    cluster: image-policy-webhook\n    user: api-server\n  name: webhook\n</code></pre> <p>Save this file to <code>/etc/kubernetes/image-policy-webhook/kubeconfig.yaml</code> on all control plane nodes.</p>"},{"location":"kubernetes/cks/admission_controller_config/#3-certificate-setup","title":"3. Certificate Setup","text":"<p>You\u2019ll need to set up TLS certificates for secure communication between the API server and your webhook service:</p> <ol> <li> <p>Create a directory for certificates: <pre><code>mkdir -p /etc/kubernetes/image-policy-webhook\n</code></pre></p> </li> <li> <p>Generate a CA certificate (if you don\u2019t have one already): <pre><code>openssl genrsa -out /etc/kubernetes/image-policy-webhook/ca.key 2048\nopenssl req -x509 -new -nodes -key /etc/kubernetes/image-policy-webhook/ca.key \\\n  -subj \"/CN=image-policy-webhook-ca\" \\\n  -days 3650 -out /etc/kubernetes/image-policy-webhook/ca.crt\n</code></pre></p> </li> <li> <p>Generate client certificates for the API server: <pre><code>openssl genrsa -out /etc/kubernetes/image-policy-webhook/apiserver-client.key 2048\nopenssl req -new -key /etc/kubernetes/image-policy-webhook/apiserver-client.key \\\n  -subj \"/CN=api-server\" \\\n  -out /etc/kubernetes/image-policy-webhook/apiserver-client.csr\nopenssl x509 -req -in /etc/kubernetes/image-policy-webhook/apiserver-client.csr \\\n  -CA /etc/kubernetes/image-policy-webhook/ca.crt \\\n  -CAkey /etc/kubernetes/image-policy-webhook/ca.key \\\n  -CAcreateserial \\\n  -days 3650 \\\n  -out /etc/kubernetes/image-policy-webhook/apiserver-client.crt\n</code></pre></p> </li> <li> <p>Set appropriate permissions: <pre><code>chmod 600 /etc/kubernetes/image-policy-webhook/*.key\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cks/admission_controller_config/#4-api-server-configuration","title":"4. API Server Configuration","text":"<p>Enable the ImagePolicyWebhook admission controller in your API server configuration:</p> <p>For kubeadm installations, edit <code>/etc/kubernetes/manifests/kube-apiserver.yaml</code>:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: kube-apiserver\n  namespace: kube-system\nspec:\n  containers:\n  - name: kube-apiserver\n    image: k8s.gcr.io/kube-apiserver:v1.23.0\n    command:\n    - kube-apiserver\n    - --enable-admission-plugins=NodeRestriction,ImagePolicyWebhook\n    - --admission-control-config-file=/etc/kubernetes/admission-configuration.yaml\n    # Other API server flags here...\n    volumeMounts:\n    - mountPath: /etc/kubernetes/admission-configuration.yaml\n      name: admission-configuration\n      readOnly: true\n    - mountPath: /etc/kubernetes/image-policy-webhook\n      name: image-policy-webhook\n      readOnly: true\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/admission-configuration.yaml\n      type: File\n    name: admission-configuration\n  - hostPath:\n      path: /etc/kubernetes/image-policy-webhook\n      type: Directory\n    name: image-policy-webhook\n</code></pre> <p>For non-kubeadm installations, update the API server flags in the appropriate systemd service file:</p> <pre><code>--enable-admission-plugins=NodeRestriction,ImagePolicyWebhook\n--admission-control-config-file=/etc/kubernetes/admission-configuration.yaml\n</code></pre>"},{"location":"kubernetes/cks/admission_controller_config/#5-webhook-service-implementation","title":"5. Webhook Service Implementation","text":"<p>Your webhook service should implement the admission review API and respond with an admission review response. Here\u2019s a sample response format from your webhook service:</p> <pre><code>{\n  \"apiVersion\": \"imagepolicy.k8s.io/v1alpha1\",\n  \"kind\": \"ImageReview\",\n  \"status\": {\n    \"allowed\": true,\n    \"reason\": \"Image is from an allowed registry\"\n  }\n}\n</code></pre> <p>Or to deny an image:</p> <pre><code>{\n  \"apiVersion\": \"imagepolicy.k8s.io/v1alpha1\",\n  \"kind\": \"ImageReview\",\n  \"status\": {\n    \"allowed\": false,\n    \"reason\": \"Image from untrusted registry\"\n  }\n}\n</code></pre>"},{"location":"kubernetes/cks/admission_controller_config/#6-understanding-configuration-options","title":"6. Understanding Configuration Options","text":"<p>The ImagePolicyWebhook configuration has several important options:</p> <ul> <li>kubeConfigFile: Path to the kubeconfig file for connecting to the webhook</li> <li>allowTTL: Duration in seconds to cache \u2018allow\u2019 responses</li> <li>denyTTL: Duration in seconds to cache \u2018deny\u2019 responses</li> <li>retryBackoff: Duration in milliseconds to wait between retries</li> <li>defaultAllow: Whether to allow all images if the webhook service is unavailable</li> <li><code>true</code>: All images are allowed when the webhook is unavailable</li> <li><code>false</code>: All images are denied when the webhook is unavailable (more secure)</li> </ul>"},{"location":"kubernetes/cks/apparmor/","title":"AppArmor Profile Management","text":"<p>AppArmor is a Linux Security Module that allows system administrators to restrict programs\u2019 capabilities with per-program profiles.</p>"},{"location":"kubernetes/cks/apparmor/#verifying-apparmor-status","title":"Verifying AppArmor Status","text":"<p>After installation, verify AppArmor is running:</p> <pre><code>sudo aa-status\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#understanding-apparmor-profiles","title":"Understanding AppArmor Profiles","text":"<p>AppArmor profiles define what system resources a program can access and what actions it can perform. Profiles can be in one of several modes:</p> <ul> <li>enforce: Restricts the program according to the profile and logs violations</li> <li>complain: Does not restrict the program, but logs actions that would be prevented in enforce mode</li> <li>disabled: The profile is loaded but not applied</li> </ul> <p>Profiles are stored in <code>/etc/apparmor.d/</code> and have a specific syntax for defining permissions.</p>"},{"location":"kubernetes/cks/apparmor/#creating-apparmor-profiles","title":"Creating AppArmor Profiles","text":""},{"location":"kubernetes/cks/apparmor/#method-1-using-aa-genprof-recommended-for-beginners","title":"Method 1: Using aa-genprof (Recommended for Beginners)","text":"<ol> <li>Start the profile generation tool:</li> </ol> <pre><code>sudo aa-genprof /path/to/application\n</code></pre> <ol> <li> <p>Run the application to generate typical usage patterns.</p> </li> <li> <p>When done, press \u2018S\u2019 to save the profile.</p> </li> </ol>"},{"location":"kubernetes/cks/apparmor/#method-2-creating-a-profile-manually","title":"Method 2: Creating a Profile Manually","text":"<ol> <li>Create a new file in <code>/etc/apparmor.d/</code> named after your application:</li> </ol> <pre><code>sudo nano /etc/apparmor.d/my.application\n</code></pre> <ol> <li>Add the profile content. Here\u2019s a basic example:</li> </ol> <pre><code>#include &lt;tunables/global&gt;\n\nprofile my.application /path/to/application {\n  #include &lt;abstractions/base&gt;\n\n  # Allow basic functionality\n  /path/to/application mr,\n  /usr/lib/** mr,\n  /lib/** mr,\n\n  # Allow reading of specific files\n  /etc/my-app/** r,\n\n  # Allow writing to specific directories\n  /var/log/my-app/** w,\n}\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#method-3-using-aa-logprof-to-generate-from-logs","title":"Method 3: Using aa-logprof to Generate from Logs","text":"<ol> <li>Set an existing profile to complain mode:</li> </ol> <pre><code>sudo aa-complain /path/to/application\n</code></pre> <ol> <li> <p>Run the application to generate logs.</p> </li> <li> <p>Use aa-logprof to analyze logs and update the profile:</p> </li> </ol> <pre><code>sudo aa-logprof\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#loading-and-enabling-profiles","title":"Loading and Enabling Profiles","text":""},{"location":"kubernetes/cks/apparmor/#loading-a-new-profile","title":"Loading a New Profile","text":"<p>After creating a profile, load it with:</p> <pre><code>sudo apparmor_parser -r /etc/apparmor.d/my.application\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#setting-profile-mode","title":"Setting Profile Mode","text":"<p>Set a profile to enforce mode:</p> <pre><code>sudo aa-enforce /path/to/application\n</code></pre> <p>Set a profile to complain mode:</p> <pre><code>sudo aa-complain /path/to/application\n</code></pre> <p>Disable a profile:</p> <pre><code>sudo ln -s /etc/apparmor.d/my.application /etc/apparmor.d/disable/\nsudo apparmor_parser -R /etc/apparmor.d/my.application\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#managing-profiles","title":"Managing Profiles","text":""},{"location":"kubernetes/cks/apparmor/#listing-profiles","title":"Listing Profiles","text":"<p>List all profiles and their status:</p> <pre><code>sudo aa-status\n</code></pre>"},{"location":"kubernetes/cks/apparmor/#using-apparmor-with-containers","title":"Using AppArmor with Containers","text":"<p>For Kubernetes, you need to:</p> <ol> <li> <p>Create a profile on all worker nodes</p> </li> <li> <p>Load the profile on all nodes:</p> </li> </ol> <pre><code>sudo apparmor_parser -r /etc/apparmor.d/k8s-myprofile\n</code></pre> <ol> <li>Apply the AppArmor profile to your Pod/container using one of two methods:</li> </ol>"},{"location":"kubernetes/cks/apparmor/#method-1-using-annotations-beta-api","title":"Method 1: Using Annotations (Beta API)","text":"<p>The original beta implementation uses annotations:</p> <pre><code>metadata:\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/container-name: localhost/k8s-myprofile\n</code></pre> <p>Where <code>container-name</code> is the name of your container, and <code>k8s-myprofile</code> is your AppArmor profile name.</p>"},{"location":"kubernetes/cks/apparmor/#method-2-using-securitycontext-preferred","title":"Method 2: Using securityContext (Preferred)","text":"<p>The newer, more structured approach uses securityContext:</p> <pre><code># At the container level\nspec:\n  containers:\n  - name: my-container\n    securityContext:\n      appArmorProfile:\n        type: Localhost\n        localhostProfile: k8s-myprofile\n\n# OR at the pod level\nspec:\n  securityContext:\n    appArmorProfile:\n      type: Localhost\n      localhostProfile: k8s-myprofile\n</code></pre> <p>The securityContext approach is recommended for new deployments as it follows Kubernetes conventions for security features and provides better validation.</p>"},{"location":"kubernetes/cks/audit_logging/","title":"Audit Logging","text":"<p>Audit logging in Kubernetes is crucial for security monitoring and compliance. This guide explains how to configure the API server to enable comprehensive audit logging.</p>"},{"location":"kubernetes/cks/audit_logging/#create-an-audit-policy-file","title":"Create an Audit Policy File","text":"<p>First, create an audit policy file that defines what events should be recorded:</p> <pre><code>mkdir -p /etc/kubernetes/audit\n</code></pre> <p>Create the audit policy file at <code>/etc/kubernetes/audit/policy.yaml</code>:</p> <pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  # Log pod changes at RequestResponse level\n  - level: RequestResponse\n    resources:\n    - group: \"\"\n      resources: [\"pods\"]\n\n  # Log persistent volume changes\n  - level: RequestResponse\n    resources:\n    - group: \"\"\n      resources: [\"persistentvolumes\"]\n      verbs: [\"create\", \"delete\", \"update\"]\n\n  # Log auth at Metadata level\n  - level: Metadata\n    resources:\n    - group: \"authentication.k8s.io\"\n      resources: [\"*\"]\n\n  # Log all other resources at the Metadata level\n  - level: Metadata\n    resources:\n    - group: \"\"\n      resources: [\"*\"]\n    - group: \"apps\"\n      resources: [\"*\"]\n    - group: \"rbac.authorization.k8s.io\"\n      resources: [\"*\"]\n\n  # A catch-all rule to log all other events at the Metadata level\n  - level: Metadata\n    omitStages:\n      - \"RequestReceived\"\n</code></pre>"},{"location":"kubernetes/cks/audit_logging/#configure-the-api-server","title":"Configure the API Server","text":"<pre><code>nano /etc/kubernetes/manifests/kube-apiserver.yaml\n</code></pre> <p>Add the audit policy and log path parameters:</p> <pre><code>spec:\n  containers:\n  - command:\n    - kube-apiserver\n    - --audit-policy-file=/etc/kubernetes/audit/policy.yaml\n    - --audit-log-path=/var/log/kubernetes/audit/audit.log\n    - --audit-log-maxage=30\n    - --audit-log-maxbackup=10\n    - --audit-log-maxsize=100\n    # ... other existing parameters\n    volumeMounts:\n    - mountPath: /etc/kubernetes/audit\n      name: audit-config\n      readOnly: true\n    - mountPath: /var/log/kubernetes/audit\n      name: audit-log\n  volumes:\n  - hostPath:\n      path: /etc/kubernetes/audit\n      type: DirectoryOrCreate\n    name: audit-config\n  - hostPath:\n      path: /var/log/kubernetes/audit\n      type: DirectoryOrCreate\n    name: audit-log\n</code></pre>"},{"location":"kubernetes/cks/audit_logging/#audit-log-levels","title":"Audit Log Levels","text":"<p>The policy file uses these audit levels:</p> <ul> <li>None: Don\u2019t log events matching this rule</li> <li>Metadata: Log request metadata but not request or response body</li> <li>Request: Log event metadata and request body</li> <li>RequestResponse: Log event metadata, request and response bodies</li> </ul>"},{"location":"kubernetes/cks/audit_logging/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"kubernetes/cks/audit_logging/#configure-log-backend-format","title":"Configure Log Backend Format","text":"<p>For JSON format (better for processing):</p> <pre><code>--audit-log-format=json\n</code></pre>"},{"location":"kubernetes/cks/audit_logging/#webhook-backend","title":"Webhook Backend","text":"<p>To send audit logs to an external webhook:</p> <pre><code>--audit-webhook-config-file=/etc/kubernetes/audit/webhook-config.yaml\n--audit-webhook-batch-max-size=10000\n--audit-webhook-batch-max-wait=5s\n</code></pre> <p>Example webhook configuration:</p> <pre><code>apiVersion: v1\nkind: Config\nclusters:\n- name: audit-webhook\n  cluster:\n    server: https://audit.example.com/webhook\ncontexts:\n- context:\n    cluster: audit-webhook\n    user: \"\"\n  name: default-context\ncurrent-context: default-context\npreferences: {}\nusers: []\n</code></pre>"},{"location":"kubernetes/cks/cert_auth/","title":"Create User Certificate Authentication","text":"<p>How to create and use client certificates for authenticating users to a Kubernetes cluster. Certificate-based authentication is one of the standard methods for controlling access to your Kubernetes API server.</p>"},{"location":"kubernetes/cks/cert_auth/#prerequisites","title":"Prerequisites","text":"<ul> <li>Access to a running Kubernetes cluster</li> <li><code>kubectl</code> command-line tool installed</li> <li><code>openssl</code> command-line tool installed</li> <li>Admin access to the Kubernetes cluster (to approve certificate signing requests)</li> </ul>"},{"location":"kubernetes/cks/cert_auth/#step-1-create-a-private-key-for-the-user","title":"Step 1: Create a Private Key for the User","text":"<p>First, create a private key for the user using OpenSSL:</p> <pre><code>openssl genrsa -out jane.key 2048\n</code></pre> <p>This command generates a 2048-bit RSA key and saves it to a file named <code>jane.key</code>.</p>"},{"location":"kubernetes/cks/cert_auth/#step-2-create-a-certificate-signing-request-csr","title":"Step 2: Create a Certificate Signing Request (CSR)","text":"<p>Create a certificate signing request using the private key:</p> <pre><code>openssl req -new -key jane.key -out jane.csr -subj \"/CN=jane/O=engineering\"\n</code></pre> <p>In this command: - <code>/CN=jane</code> specifies the username - <code>/O=engineering</code> specifies the group the user belongs to (you can specify multiple groups using multiple <code>/O=</code> entries)</p>"},{"location":"kubernetes/cks/cert_auth/#step-3-encode-the-csr-in-base64","title":"Step 3: Encode the CSR in Base64","text":"<p>Encode the CSR file in base64 format:</p> <pre><code>cat jane.csr | base64 | tr -d '\\n'\n</code></pre> <p>Copy the output for use in the next step.</p>"},{"location":"kubernetes/cks/cert_auth/#step-4-create-a-certificatesigningrequest-object-in-kubernetes","title":"Step 4: Create a CertificateSigningRequest Object in Kubernetes","text":"<p>Create a file named <code>jane-csr.yaml</code> with the following content:</p> <pre><code>apiVersion: certificates.k8s.io/v1\nkind: CertificateSigningRequest\nmetadata:\n  name: jane\nspec:\n  request: &lt;base64-encoded-csr&gt;\n  signerName: kubernetes.io/kube-apiserver-client\n  expirationSeconds: 86400  # 24 hours\n  usages:\n  - client auth\n</code></pre> <p>Replace <code>&lt;base64-encoded-csr&gt;</code> with the output from Step 3.</p> <p>Apply this configuration to your cluster:</p> <pre><code>kubectl apply -f jane-csr.yaml\n</code></pre>"},{"location":"kubernetes/cks/cert_auth/#step-5-approve-the-certificate-signing-request","title":"Step 5: Approve the Certificate Signing Request","text":"<p>As a cluster administrator, approve the CSR:</p> <pre><code>kubectl certificate approve jane\n</code></pre>"},{"location":"kubernetes/cks/cert_auth/#step-6-retrieve-the-signed-certificate","title":"Step 6: Retrieve the Signed Certificate","text":"<p>Retrieve the approved certificate:</p> <pre><code>kubectl get csr jane -o jsonpath='{.status.certificate}' | base64 --decode &gt; jane.crt\n</code></pre> <p>This command extracts the signed certificate from the CSR object and decodes it into a file named <code>jane.crt</code>.</p>"},{"location":"kubernetes/cks/cert_auth/#step-7-create-a-kubeconfig-file-for-the-user","title":"Step 7: Create a kubeconfig File for the User","text":"<p>Now you need to create a kubeconfig file that the user can use for authentication:</p> <pre><code>kubectl config set-credentials jane --client-certificate=&lt;client-cert&gt; --client-key=&lt;client-key&gt; --embed-certs=true\nkubectl config set-context &lt;context-name&gt; --cluster=&lt;cluster-name&gt; --user=jane\nkubectl config use-context jane@&lt;cluster-name&gt;\n</code></pre>"},{"location":"kubernetes/cks/cert_auth/#step-8-set-appropriate-permissions-with-rbac","title":"Step 8: Set Appropriate Permissions with RBAC","text":"<p>The user now has a valid certificate, but they need to be granted permissions to perform actions in the cluster. Create a Role or ClusterRole and a corresponding RoleBinding or ClusterRoleBinding:</p> <p>Example RoleBinding (for namespace-specific access):</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: jane-engineering-rolebinding\n  namespace: development\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: developer\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>Example ClusterRoleBinding (for cluster-wide access):</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: jane-engineering-clusterrolebinding\nsubjects:\n- kind: User\n  name: jane\n  apiGroup: rbac.authorization.k8s.io\n- kind: Group\n  name: engineering\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: view\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>Apply the binding using kubectl:</p> <pre><code>kubectl apply -f jane-rolebinding.yaml\n</code></pre>"},{"location":"kubernetes/cks/cilium/","title":"Cilium","text":"<p>Cilium is an open-source software for providing, securing, and observing network connectivity between container workloads. It\u2019s designed specifically for Kubernetes and leverages a powerful Linux kernel technology called eBPF (extended Berkeley Packet Filter) to deliver its features with high performance and minimal overhead.</p> <p>Cilium operates at Layer \u00be (IP/TCP) as well as Layer 7 (HTTP, gRPC, Kafka), allowing it to secure modern API-driven microservices while also supporting traditional network security approaches.</p>"},{"location":"kubernetes/cks/cilium/#core-concepts","title":"Core Concepts","text":""},{"location":"kubernetes/cks/cilium/#ebpf","title":"eBPF","text":"<p>eBPF is a revolutionary technology that allows programs to run in the Linux kernel without changing kernel source code or loading kernel modules. Cilium leverages eBPF to:</p> <ul> <li>Intercept and control network traffic at the kernel level</li> <li>Apply security policies with minimal performance overhead</li> <li>Provide deep visibility into network and application behavior</li> <li>Dynamically program network flows without service disruption</li> </ul> <p>Unlike traditional networking solutions that use iptables, eBPF programs are JIT-compiled and highly efficient, making Cilium particularly well-suited for large-scale environments.</p>"},{"location":"kubernetes/cks/cilium/#identity-based-security","title":"Identity-Based Security","text":"<p>Cilium introduces the concept of security identities, which are derived from Kubernetes labels. This enables:</p> <ul> <li>Security policies based on service identities rather than IP addresses</li> <li>Persistent security even when pods are rescheduled to different nodes</li> <li>Simplified policy management that aligns with Kubernetes native concepts</li> </ul>"},{"location":"kubernetes/cks/cilium/#network-policy","title":"Network Policy","text":"<p>Cilium extends the Kubernetes NetworkPolicy API with CiliumNetworkPolicy, which adds:</p> <ul> <li>Layer 7 (application protocol) visibility and filtering</li> <li>Support for cluster-wide policies with ClusterwideCiliumNetworkPolicy</li> <li>FQDN/DNS based filtering for external services</li> <li>Deny policies and more advanced rule semantics</li> </ul>"},{"location":"kubernetes/cks/cilium/#key-features","title":"Key Features","text":""},{"location":"kubernetes/cks/cilium/#networking","title":"Networking","text":"<ul> <li>CNI Plugin: Implements the Container Network Interface for Kubernetes</li> <li>Multi-cluster Routing: Connect multiple Kubernetes clusters</li> <li>IPv4/IPv6 Support: Dual-stack networking capabilities</li> <li>VXLAN, Geneve, or Direct Routing: Flexible overlay or native routing options</li> <li>Bandwidth Management: QoS and rate limiting capabilities</li> </ul>"},{"location":"kubernetes/cks/cilium/#security","title":"Security","text":"<ul> <li>Network Policies: Layer 3-4 (IP/ports) filtering</li> <li>Application Policies: Layer 7 filtering for HTTP, gRPC, Kafka, etc.</li> <li>Transparent Encryption: IPsec or WireGuard for node-to-node traffic</li> <li>Service Authorization: Control access to services</li> <li>DNS Security: Filter outbound connections based on DNS names</li> </ul>"},{"location":"kubernetes/cks/cilium/#observability","title":"Observability","text":"<ul> <li>Hubble: Dedicated observability platform built into Cilium</li> <li>Flow Logs: Detailed network flow information</li> <li>Service Maps: Visual representation of service dependencies</li> <li>Policy Verdicts: See which policies accept or deny connections</li> <li>Metrics: Prometheus integration for monitoring</li> </ul>"},{"location":"kubernetes/cks/cilium/#load-balancing","title":"Load Balancing","text":"<ul> <li>Kubernetes Services: Implementation of kube-proxy functionality</li> <li>Direct Server Return (DSR): Optimized load balancing path</li> <li>Session Affinity: Consistent hashing for stable connections</li> <li>Global Services: Services spanning multiple clusters</li> <li>XDP Acceleration: High-performance packet processing</li> </ul>"},{"location":"kubernetes/cks/cilium/#basic-configuration","title":"Basic Configuration","text":""},{"location":"kubernetes/cks/cilium/#network-policies","title":"Network Policies","text":"<p>Cilium extends Kubernetes NetworkPolicy with additional features. Here\u2019s an example of a basic CiliumNetworkPolicy:</p> <pre><code>apiVersion: \"cilium.io/v2\"\nkind: CiliumNetworkPolicy\nmetadata:\n  name: \"allow-web-from-frontend\"\nspec:\n  endpointSelector:\n    matchLabels:\n      app: web\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: frontend\n    toPorts:\n    - ports:\n      - port: \"80\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/api/v1/.*\"\n</code></pre> <p>This policy allows frontend pods to make HTTP GET requests to web pods on port 80, specifically for paths matching <code>/api/v1/.*</code>.</p>"},{"location":"kubernetes/cks/cilium/#service-mesh","title":"Service Mesh","text":"<p>Cilium can be used as a service mesh alternative by enabling the following features:</p> <pre><code>helm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set hubble.enabled=true \\\n  --set hubble.metrics.enabled=\"{dns,drop,tcp,flow,port-distribution,icmp,http}\"\n</code></pre> <p>This provides many service mesh features without a sidecar proxy, including: - Service-to-service communication security - Traffic monitoring and metrics - L7 visibility</p>"},{"location":"kubernetes/cks/cilium/#cluster-mesh","title":"Cluster Mesh","text":"<p>To connect multiple Kubernetes clusters with Cilium:</p> <ol> <li>Enable Cluster Mesh on each cluster:</li> </ol> <pre><code>cilium clustermesh enable\n</code></pre> <ol> <li>Connect the clusters:</li> </ol> <pre><code>cilium clustermesh connect --destination-context=cluster2\n</code></pre>"},{"location":"kubernetes/cks/cilium/#hubble-observability-platform","title":"Hubble: Observability Platform","text":""},{"location":"kubernetes/cks/cilium/#installing-hubble","title":"Installing Hubble","text":"<p>Hubble is Cilium\u2019s observability platform:</p> <pre><code># Enable Hubble with UI\ncilium hubble enable --ui\n\n# Verify Hubble is properly installed\ncilium hubble status\n</code></pre>"},{"location":"kubernetes/cks/cilium/#using-hubble-ui","title":"Using Hubble UI","text":"<p>Access the Hubble UI by port-forwarding:</p> <pre><code>cilium hubble ui\n</code></pre> <p>This will open a browser window with the Hubble UI, displaying: - Service dependency map - Real-time network flows - HTTP, DNS, and TCP metrics - Detailed flow information</p>"},{"location":"kubernetes/cks/cilium/#hubble-cli","title":"Hubble CLI","text":"<p>Hubble CLI provides command-line access to observability data:</p> <pre><code># Install Hubble CLI\nexport HUBBLE_VERSION=$(curl -s https://raw.githubusercontent.com/cilium/hubble/master/stable.txt)\ncurl -L --remote-name-all https://github.com/cilium/hubble/releases/download/$HUBBLE_VERSION/hubble-linux-amd64.tar.gz\nsudo tar xzvfC hubble-linux-amd64.tar.gz /usr/local/bin\n\n# Set up Hubble CLI\ncilium hubble port-forward&amp;\n\n# Observe flows in real-time\nhubble observe --follow\n\n# Filter flows for specific pods\nhubble observe --pod frontend\n\n# Show HTTP metrics\nhubble observe --protocol http\n</code></pre>"},{"location":"kubernetes/cks/cilium/#advanced-features","title":"Advanced Features","text":""},{"location":"kubernetes/cks/cilium/#transparent-encryption","title":"Transparent Encryption","text":"<p>Enable transparent encryption between nodes using IPsec or WireGuard:</p> <pre><code># Using Helm with IPsec\nhelm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set encryption.enabled=true \\\n  --set encryption.type=ipsec\n\n# Using Cilium CLI with WireGuard\ncilium config set encryption.enabled=true\ncilium config set encryption.type=wireguard\n</code></pre>"},{"location":"kubernetes/cks/cilium/#host-firewall","title":"Host Firewall","text":"<p>Protect the Kubernetes nodes themselves with Cilium\u2019s host firewall:</p> <pre><code>helm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set hostFirewall.enabled=true\n</code></pre> <p>Example policy to protect hosts:</p> <pre><code>apiVersion: \"cilium.io/v2\"\nkind: CiliumClusterwideNetworkPolicy\nmetadata:\n  name: \"host-policy\"\nspec:\n  nodeSelector:\n    matchLabels:\n      node-role.kubernetes.io/control-plane: \"\"\n  ingress:\n  - fromEntities:\n    - cluster\n    toPorts:\n    - ports:\n      - port: \"6443\"\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/cilium/#kubernetes-without-kube-proxy","title":"Kubernetes Without kube-proxy","text":"<p>Cilium can replace kube-proxy for better performance:</p> <pre><code>helm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set kubeProxyReplacement=strict \\\n  --set k8sServiceHost=&lt;API_SERVER_IP&gt; \\\n  --set k8sServicePort=&lt;API_SERVER_PORT&gt;\n</code></pre> <p>Benefits include: - eBPF-based service implementation - Lower latency - Better scalability - Support for DSR (Direct Server Return)</p>"},{"location":"kubernetes/cks/cilium/#multi-cluster-connectivity","title":"Multi-Cluster Connectivity","text":"<p>Create global services spanning multiple clusters:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: global-service\n  annotations:\n    service.cilium.io/global: \"true\"\nspec:\n  type: ClusterIP\n  selector:\n    app: web\n  ports:\n  - port: 80\n</code></pre>"},{"location":"kubernetes/cks/cilium/#performance-considerations","title":"Performance Considerations","text":"<p>Cilium is designed for high performance:</p> <ul> <li>eBPF vs iptables: Significant performance improvements, especially at scale</li> <li>Kernel Bypass: XDP acceleration for load balancing</li> <li>Direct Routing: Improved performance compared to overlay networks</li> <li>Hubble Overhead: Minimal when sampling is configured appropriately</li> </ul> <p>Optimizing Cilium for performance:</p> <pre><code># Direct routing for better performance\nhelm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set tunnel=disabled \\\n  --set autoDirectNodeRoutes=true\n\n# Enable XDP acceleration for service load balancing\nhelm upgrade cilium cilium/cilium --namespace kube-system \\\n  --reuse-values \\\n  --set loadBalancer.acceleration=native\n</code></pre>"},{"location":"kubernetes/cks/cilium/#troubleshooting","title":"Troubleshooting","text":"<p>Common troubleshooting commands:</p> <pre><code># Check Cilium status\ncilium status\n\n# Validate Cilium installation\ncilium connectivity test\n\n# Troubleshoot a specific endpoint\ncilium endpoint get &lt;endpoint-id&gt;\n\n# Check Cilium agent logs\nkubectl -n kube-system logs -l k8s-app=cilium\n\n# Restart Cilium on a node\nkubectl -n kube-system delete pod -l k8s-app=cilium -l kubernetes.io/hostname=&lt;node-name&gt;\n\n# Verify network policies\ncilium policy get\n</code></pre>"},{"location":"kubernetes/cks/falco/","title":"Falco","text":"<p>Falco is an open-source, cloud-native runtime security project that detects unexpected behavior, configuration changes, intrusions, and data theft in real-time. Originally created by Sysdig and now a CNCF (Cloud Native Computing Foundation) graduated project, Falco acts as a security camera for your system, alerting you to potentially malicious activity.</p> <p>Key features include: - System call monitoring for process behavior - Container and Kubernetes monitoring - Extensible rule language - Multiple output options (syslog, file, program, HTTP, etc.) - Low performance overhead</p>"},{"location":"kubernetes/cks/falco/#basic-configuration","title":"Basic Configuration","text":""},{"location":"kubernetes/cks/falco/#configuration-file-structure","title":"Configuration File Structure","text":"<p>The main Falco configuration file is typically located at <code>/etc/falco/falco.yaml</code>. Here are the key sections:</p> <pre><code># Rules file(s) or directories\nrules_file:\n  - /etc/falco/falco_rules.yaml\n  - /etc/falco/falco_rules.local.yaml\n  - /etc/falco/rules.d\n\n# Where security notifications should be written\noutput:\n  rate: 1\n  max_burst: 1000\n  enabled: true\n\n# Logging settings\nlog_stderr: true\nlog_syslog: true\nlog_level: info\n\n# Monitoring settings\nsyscall_event_drops:\n  actions:\n    - log\n    - alert\n</code></pre>"},{"location":"kubernetes/cks/falco/#output-methods","title":"Output Methods","text":"<p>Configure various output methods in <code>/etc/falco/falco.yaml</code>:</p>"},{"location":"kubernetes/cks/falco/#standard-output","title":"Standard Output","text":"<pre><code>stdout_output:\n  enabled: true\n</code></pre>"},{"location":"kubernetes/cks/falco/#file-output","title":"File Output","text":"<pre><code>file_output:\n  enabled: true\n  filename: /var/log/falco.log\n  keep_alive: false\n</code></pre>"},{"location":"kubernetes/cks/falco/#syslog-output","title":"Syslog Output","text":"<pre><code>syslog_output:\n  enabled: true\n</code></pre>"},{"location":"kubernetes/cks/falco/#program-output","title":"Program Output","text":"<pre><code>program_output:\n  enabled: true\n  program: \"curl -d @- -X POST https://example.com/falco-alerts\"\n</code></pre>"},{"location":"kubernetes/cks/falco/#http-output","title":"HTTP Output","text":"<pre><code>http_output:\n  enabled: true\n  url: https://alerts.example.com/falco\n  user_agent: falco/5.0.0\n</code></pre>"},{"location":"kubernetes/cks/falco/#working-with-falco-rules","title":"Working with Falco Rules","text":""},{"location":"kubernetes/cks/falco/#rule-anatomy","title":"Rule Anatomy","text":"<p>A typical Falco rule consists of:</p> <ol> <li>Rule definition with a name, description, and priority</li> <li>Condition that triggers the rule</li> <li>Output format for alerts</li> </ol> <p>Example:</p> <pre><code>- rule: Terminal Shell in Container\n  desc: A shell was used as the entrypoint/exec point into a container\n  condition: &gt;\n    container.id != host and\n    proc.name = bash and\n    container\n  output: &gt;\n    Shell executed in a container (user=%user.name %container.info)\n  priority: WARNING\n  tags: [container, shell]\n</code></pre>"},{"location":"kubernetes/cks/falco/#creating-custom-rules","title":"Creating Custom Rules","text":"<p>Create a new file for custom rules:</p> <pre><code>nano /etc/falco/rules.d/custom_rules.yaml\n</code></pre> <p>Add your rules following this structure:</p> <pre><code>- macro: my_custom_macro\n  condition: evt.type=open\n\n- list: my_sensitive_files\n  items: [/etc/shadow, /etc/passwd]\n\n- rule: Read Sensitive Files\n  desc: Detect attempts to read sensitive files\n  condition: &gt;\n    open_read and\n    fd.name in (my_sensitive_files) and\n    not proc.name in (my_trusted_processes)\n  output: &gt;\n    Sensitive file opened for reading (user=%user.name file=%fd.name)\n  priority: WARNING\n  tags: [filesystem]\n</code></pre> <p>After adding rules, restart Falco:</p> <pre><code>systemctl restart falco\n</code></pre>"},{"location":"kubernetes/cks/falco/#testing-rules","title":"Testing Rules","text":"<p>Use <code>falco-tester</code> to validate your rules:</p> <pre><code>falco --validate /etc/falco/falco_rules.yaml\n\n# Test with specific rule file\nfalco -r /etc/falco/rules.d/custom_rules.yaml -V\n</code></pre> <p>To test with real events:</p> <pre><code># Run Falco interactively with your rules\nfalco -r /etc/falco/rules.d/custom_rules.yaml\n\n# In another terminal, perform actions that should trigger rules\ncat /etc/shadow\n</code></pre>"},{"location":"kubernetes/cks/falco/#checking-and-analyzing-logs","title":"Checking and Analyzing Logs","text":""},{"location":"kubernetes/cks/falco/#standard-host-logs","title":"Standard Host Logs","text":""},{"location":"kubernetes/cks/falco/#systemd-journal","title":"Systemd Journal","text":"<pre><code># View real-time logs\njournalctl -u falco -f\n\n# View logs with specific priority\njournalctl -u falco -p warning -f\n\n# View logs from a time period\njournalctl -u falco --since \"2023-04-25 10:00:00\" --until \"2023-04-25 11:00:00\"\n</code></pre>"},{"location":"kubernetes/cks/falco/#log-files","title":"Log Files","text":"<p>If configured to use file output:</p> <pre><code># View the entire log file\ncat /var/log/falco.log\n\n# Follow logs in real-time\ntail -f /var/log/falco.log\n\n# Filter logs by priority\ngrep -i \"critical\\|error\" /var/log/falco.log\n\n# Filter logs by rule name\ngrep \"Terminal Shell in Container\" /var/log/falco.log\n</code></pre>"},{"location":"kubernetes/cks/falco/#syslog","title":"Syslog","text":"<pre><code># Check syslog for Falco events\ngrep falco /var/log/syslog\n</code></pre>"},{"location":"kubernetes/cks/falco/#kubernetes-logs","title":"Kubernetes Logs","text":"<pre><code># List Falco pods\nkubectl get pods -n falco\n\n# Follow logs for a specific pod\nkubectl logs -n falco falco-abcd1234 -f\n\n# Follow logs for all Falco pods\nkubectl logs -n falco -l app=falco -f\n\n# Filter logs by severity\nkubectl logs -n falco -l app=falco | grep -i \"warning\\|error\\|critical\"\n</code></pre>"},{"location":"kubernetes/cks/falco/#log-formats-and-analysis","title":"Log Formats and Analysis","text":""},{"location":"kubernetes/cks/falco/#json-output","title":"JSON Output","text":"<p>Configure JSON output for easier parsing:</p> <pre><code># In falco.yaml\njson_output: true\n</code></pre> <p>Then analyze with tools like <code>jq</code>:</p> <pre><code># Extract specific fields\ncat /var/log/falco.log | jq 'select(.priority == \"CRITICAL\")'\ncat /var/log/falco.log | jq 'select(.rule == \"Terminal Shell in Container\")'\n\n# Count alerts by rule\ncat /var/log/falco.log | jq -r '.rule' | sort | uniq -c | sort -nr\n</code></pre>"},{"location":"kubernetes/cks/falco/#time-based-analysis","title":"Time-Based Analysis","text":"<pre><code># Events in the last hour\ngrep \"$(date -d '1 hour ago' +'%Y-%m-%d %H:')\" /var/log/falco.log\n\n# Create a timeline of events\ncat /var/log/falco.log | jq -r '[.time, .rule, .output] | @tsv' | sort\n</code></pre>"},{"location":"kubernetes/cks/falco/#alert-management","title":"Alert Management","text":"<p>Configure alert throttling to prevent alert fatigue:</p> <pre><code># In falco.yaml\noutputs:\n  rate: 0.03333  # One alert every 30 seconds\n  max_burst: 10   # Allow bursts of up to 10 alerts\n</code></pre>"},{"location":"kubernetes/cks/falco/#advanced-usage","title":"Advanced Usage","text":""},{"location":"kubernetes/cks/falco/#custom-field-extraction","title":"Custom Field Extraction","text":"<p>Define custom fields for use in rules:</p> <pre><code># In a custom rules file\n- required_engine_version: 11\n\n- source: syscall\n\n- list: trusted_users\n  items: [\"root\", \"admin\"]\n\n- rule: Custom Field Example\n  desc: Using custom fields\n  condition: &gt;\n    spawned_process and\n    not user.name in (trusted_users) and\n    proc.args contains \"-i\"\n  output: &gt;\n    Process started with interactive flag (user=%user.name command=%proc.cmdline custom_field=%evt.rawtime)\n  priority: WARNING\n</code></pre>"},{"location":"kubernetes/cks/falco/#lua-support","title":"Lua Support","text":"<p>Enhance rules with Lua functions:</p> <pre><code># Define a Lua function\n- macro: is_suspicious_path\n  condition: &gt;\n    (evt.type=open and fd.name startswith \"/tmp/evil\" and evt.dir=&lt;)\n\n# Use the function in a rule\n- rule: Suspicious File Access\n  desc: Accessing potentially malicious files\n  condition: is_suspicious_path\n  output: Suspicious file accessed (file=%fd.name user=%user.name)\n  priority: WARNING\n</code></pre>"},{"location":"kubernetes/cks/falco/#performance-monitoring","title":"Performance Monitoring","text":"<p>Monitor Falco\u2019s performance impact:</p> <pre><code># Check CPU and memory usage\ntop -p $(pgrep -f falco)\n\n# Check dropped events\ngrep \"Dropped events\" /var/log/falco.log\n\n# Use internal metrics (if enabled)\ncurl http://localhost:8765/metrics\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/","title":"Image Scanning and Security","text":""},{"location":"kubernetes/cks/image_scanning/#introduction","title":"Introduction","text":"<p>As software supply chain attacks increase in frequency and sophistication, organizations are seeking effective ways to secure their software development lifecycle. Two critical components in this effort are Software Bills of Materials (SBOMs) and vulnerability scanning. This guide focuses on Trivy, a powerful open-source scanner, and how it can be used to generate and analyze SBOMs for enhanced security posture.</p>"},{"location":"kubernetes/cks/image_scanning/#understanding-sbom","title":"Understanding SBOM","text":""},{"location":"kubernetes/cks/image_scanning/#what-is-an-sbom","title":"What is an SBOM?","text":"<p>A Software Bill of Materials (SBOM) is a formal, machine-readable inventory of software components and dependencies, information about those components, and their hierarchical relationships. Think of it as a comprehensive ingredient list for software, similar to the nutrition label on food products.</p> <p>An SBOM provides transparency into: - Components: All libraries, modules, and packages included in the software - Versions: Specific versions of each component - Dependencies: Relationships between components - Suppliers: Origin of components - Licensing: License information for each component</p>"},{"location":"kubernetes/cks/image_scanning/#sbom-formats","title":"SBOM Formats","text":"<p>There are several SBOM formats available, with the following being the most widely adopted:</p>"},{"location":"kubernetes/cks/image_scanning/#1-cyclonedx","title":"1. CycloneDX","text":"<p>CycloneDX is a lightweight SBOM specification designed by OWASP for application security contexts and supply chain component analysis.</p> <p>Key characteristics: - Designed specifically for cybersecurity use cases - Supports multiple formats: JSON, XML, Protocol Buffers - Lightweight and focused on security-relevant metadata - Includes vulnerability reporting capabilities - Supports VEX (Vulnerability Exploitability eXchange)</p> <p>Sample CycloneDX JSON (simplified):</p> <pre><code>{\n  \"bomFormat\": \"CycloneDX\",\n  \"specVersion\": \"1.4\",\n  \"serialNumber\": \"urn:uuid:3e671687-395b-41f5-a30f-a58921a69b79\",\n  \"version\": 1,\n  \"components\": [\n    {\n      \"type\": \"library\",\n      \"name\": \"acme-library\",\n      \"version\": \"1.0.0\",\n      \"purl\": \"pkg:npm/acme-library@1.0.0\"\n    }\n  ]\n}\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#2-spdx-software-package-data-exchange","title":"2. SPDX (Software Package Data Exchange)","text":"<p>SPDX is an open standard for communicating software bill of materials information, including components, licenses, copyrights, and security references.</p> <p>Key characteristics: - ISO/IEC 5962:2021 standard - Comprehensive license information - Detailed metadata capabilities - Mature standard with strong industry adoption - Originally focused on license compliance, now expanded for security</p> <p>Sample SPDX JSON (simplified):</p> <pre><code>{\n  \"spdxVersion\": \"SPDX-2.2\",\n  \"dataLicense\": \"CC0-1.0\",\n  \"SPDXID\": \"SPDXRef-DOCUMENT\",\n  \"name\": \"example-project\",\n  \"documentNamespace\": \"http://spdx.org/spdxdocs/example-project\",\n  \"packages\": [\n    {\n      \"name\": \"acme-library\",\n      \"SPDXID\": \"SPDXRef-Package-1\",\n      \"versionInfo\": \"1.0.0\",\n      \"downloadLocation\": \"https://example.com/acme-library-1.0.0.tar.gz\",\n      \"licenseConcluded\": \"MIT\"\n    }\n  ]\n}\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#3-swid-software-identification-tags","title":"3. SWID (Software Identification Tags)","text":"<p>SWID tags provide identification information for software, primarily used for inventory and asset management.</p> <p>Key characteristics: - Standardized by ISO/IEC 19770-2 - Focused on software identification and inventory - Less detailed than CycloneDX or SPDX - Primarily used for IT asset management</p>"},{"location":"kubernetes/cks/image_scanning/#introduction-to-trivy","title":"Introduction to Trivy","text":""},{"location":"kubernetes/cks/image_scanning/#what-is-trivy","title":"What is Trivy?","text":"<p>Trivy is a comprehensive and versatile security scanner developed by Aqua Security. It is designed to find vulnerabilities, misconfigurations, secrets, and generate SBOMs across various targets including containers, filesystems, git repositories, and Kubernetes clusters.</p>"},{"location":"kubernetes/cks/image_scanning/#working-with-trivy","title":"Working with Trivy","text":""},{"location":"kubernetes/cks/image_scanning/#basic-commands","title":"Basic Commands","text":"<p>Trivy has several subcommands for different scanning targets:</p> <ul> <li><code>image</code>: Scan container images</li> <li><code>filesystem</code> (or <code>fs</code>): Scan local filesystem</li> <li><code>repository</code> (or <code>repo</code>): Scan a remote git repository</li> <li><code>kubernetes</code> (or <code>k8s</code>): Scan Kubernetes resources</li> <li><code>config</code>: Scan IaC configuration files</li> <li><code>sbom</code>: Scan SBOM files</li> </ul>"},{"location":"kubernetes/cks/image_scanning/#scanning-container-images","title":"Scanning Container Images","text":""},{"location":"kubernetes/cks/image_scanning/#basic-image-scanning","title":"Basic Image Scanning","text":"<pre><code># Scan an image for vulnerabilities (pull from remote registry)\ntrivy image nginx:latest\n\n# Scan a locally built image\ntrivy image my-local-image:tag\n\n# Scan and filter by severity\ntrivy image --severity HIGH,CRITICAL nginx:latest\n\n# Output results in JSON format\ntrivy image --format json --output results.json nginx:latest\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#advanced-image-scanning-options","title":"Advanced Image Scanning Options","text":"<pre><code># Ignore unfixed vulnerabilities\ntrivy image --ignore-unfixed nginx:latest\n\n# Include package information in the report\ntrivy image --list-all-pkgs nginx:latest\n\n# Scan with custom policy\ntrivy image --policy=./policy/ nginx:latest\n\n# Show dependency tree for vulnerabilities\ntrivy image --dependency-tree nginx:latest\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#scanning-kubernetes-clusters","title":"Scanning Kubernetes Clusters","text":"<pre><code># Scan a Kubernetes cluster (requires kubectl context)\ntrivy k8s --report summary cluster\n\n# Scan a specific namespace\ntrivy k8s --namespace default all\n\n# Scan a specific workload\ntrivy k8s deployment/my-deployment\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#scanning-infrastructure-as-code","title":"Scanning Infrastructure as Code","text":"<pre><code># Scan IaC files for misconfigurations\ntrivy config ./terraform/\n\n# Scan Kubernetes YAML files\ntrivy config ./kubernetes-manifests/\n\n# Scan with custom policies\ntrivy config --policy=./policy/ ./terraform/\n</code></pre>"},{"location":"kubernetes/cks/image_scanning/#generating-sboms-with-trivy","title":"Generating SBOMs with Trivy","text":""},{"location":"kubernetes/cks/image_scanning/#sbom-output-formats","title":"SBOM Output Formats","text":"<p>Trivy can generate SBOMs in the following formats:</p> <ul> <li>CycloneDX: Using <code>--format cyclonedx</code></li> <li>SPDX: Using <code>--format spdx-json</code> or <code>--format spdx</code></li> </ul>"},{"location":"kubernetes/cks/image_scanning/#command-examples","title":"Command Examples","text":""},{"location":"kubernetes/cks/image_scanning/#generate-cyclonedx-sbom-for-a-container-image","title":"Generate CycloneDX SBOM for a Container Image","text":"<pre><code># Generate a CycloneDX SBOM for a container image\ntrivy image --format cyclonedx --output sbom.cdx.json nginx:latest\n\n# Include full dependency tree\ntrivy image --format cyclonedx --output sbom.cdx.json --dependency-tree nginx:latest\n\n# Include package info for all packages\ntrivy image --format cyclonedx --output sbom.cdx.json --list-all-pkgs nginx:latest\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/","title":"mTLS Pod-to-Pod Communication with Istio","text":""},{"location":"kubernetes/cks/istio_mtls/#introduction","title":"Introduction","text":"<p>Mutual TLS (mTLS) is one of the most powerful security features offered by Istio service mesh. Unlike regular TLS where only the server authenticates itself to the client, in mutual TLS both parties verify each other\u2019s identity. </p>"},{"location":"kubernetes/cks/istio_mtls/#understanding-istio-mtls","title":"Understanding Istio mTLS","text":""},{"location":"kubernetes/cks/istio_mtls/#how-mtls-works-in-istio","title":"How mTLS Works in Istio","text":"<p>Istio implements mTLS through its sidecar proxies (Envoy). When a service with an Istio sidecar communicates with another service in the mesh, the following happens:</p> <ol> <li>The client-side sidecar proxy initiates a connection to the server</li> <li>The client-side proxy performs a TLS handshake with the server-side proxy, exchanging certificates</li> <li>The client-side proxy verifies the server\u2019s identity</li> <li>The client and server establish a mutual TLS connection</li> <li>The client proxy forwards the request to the server through the encrypted channel</li> <li>The server-side proxy forwards the request to the application container</li> </ol> <p>This entire process happens transparently to your application.</p>"},{"location":"kubernetes/cks/istio_mtls/#mtls-modes-in-istio","title":"mTLS Modes in Istio","text":"<p>Istio offers three modes for mTLS:</p> <ol> <li>PERMISSIVE: Accepts both plaintext and mTLS traffic (default)</li> <li>STRICT: Only accepts mTLS traffic</li> <li>DISABLED: Only accepts plaintext traffic</li> </ol>"},{"location":"kubernetes/cks/istio_mtls/#implementing-mtls-between-pods","title":"Implementing mTLS Between Pods","text":""},{"location":"kubernetes/cks/istio_mtls/#enable-strict-mtls","title":"Enable Strict mTLS","text":"<p>Enable strict mTLS for the namespaces using PeerAuthentication:</p> <pre><code># save this as peer-authentication.yaml\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: foo\nspec:\n  mtls:\n    mode: STRICT\n---\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: bar\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>Apply the configuration:</p> <pre><code>kubectl apply -f peer-authentication.yaml\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#configure-destination-rules","title":"Configure Destination Rules","text":"<p>Destination rules define how traffic is routed to a service after virtual service routing rules are evaluated.  When you think about Istio\u2019s traffic management, it\u2019s important to understand the sequence:</p> <ul> <li>First, traffic is routed (often using VirtualService)</li> <li>Then, DestinationRule policies are applied to that routed traffic</li> </ul> <p>Create destination rules to enforce mTLS for outbound traffic:</p> <pre><code># save this as destination-rule.yaml\napiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: httpbin-foo\n  namespace: foo\nspec:\n  host: \"httpbin.foo.svc.cluster.local\"\n  trafficPolicy:\n    tls:\n      mode: ISTIO_MUTUAL\n---\napiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: httpbin-bar\n  namespace: bar\nspec:\n  host: \"httpbin.bar.svc.cluster.local\"\n  trafficPolicy:\n    tls:\n      mode: ISTIO_MUTUAL\n</code></pre> <p>Apply the configuration:</p> <pre><code>kubectl apply -f destination-rule.yaml\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#handling-non-mesh-services","title":"Handling Non-Mesh Services","text":"<p>For services outside the mesh or services that don\u2019t support mTLS, you can configure exceptions to the mTLS policy.</p>"},{"location":"kubernetes/cks/istio_mtls/#workload-specific-mtls-policies","title":"Workload-Specific mTLS Policies","text":"<p>Create workload-specific PeerAuthentication policies to override namespace or mesh-wide policies:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: workload-policy\n  namespace: foo\nspec:\n  selector:\n    matchLabels:\n      app: httpbin\n  mtls:\n    mode: PERMISSIVE\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#configure-destination-rules-for-external-services","title":"Configure Destination Rules for External Services","text":"<p>For external services, set up a destination rule to disable mTLS:</p> <pre><code>apiVersion: networking.istio.io/v1beta1\nkind: DestinationRule\nmetadata:\n  name: external-service\nspec:\n  host: external-service.example.com\n  trafficPolicy:\n    tls:\n      mode: DISABLE  # or SIMPLE for regular TLS\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#istio-sidecar-injection","title":"Istio Sidecar Injection","text":"<p>Istio sidecar injection is the process of automatically adding an Envoy proxy container (the \u201csidecar\u201d) to Kubernetes pods. This sidecar proxy is what enables Istio\u2019s service mesh functionality, as it intercepts and manages all network traffic going in and out of your application pods.</p> <p>When you deploy applications in a Kubernetes cluster with Istio, each pod gets its own sidecar proxy that handles all the networking concerns like traffic routing, load balancing, circuit breaking, and implementing security policies.</p>"},{"location":"kubernetes/cks/istio_mtls/#how-sidecar-injection-works","title":"How Sidecar Injection Works","text":"<p>Istio uses a Kubernetes feature called \u201cmutating webhook admission controller\u201d to modify pod specifications at creation time. When the webhook is enabled and a namespace is properly labeled, any new pods created in that namespace will automatically have the Istio sidecar proxy container added to them.</p> <p>The injection can happen in two ways:</p> <ol> <li>Automatic injection: Configured at the namespace level</li> <li>Manual injection: Applied directly to deployments using the <code>istioctl</code> command</li> </ol>"},{"location":"kubernetes/cks/istio_mtls/#how-to-enable-sidecar-injection","title":"How to Enable Sidecar Injection","text":""},{"location":"kubernetes/cks/istio_mtls/#method-1-automatic-injection-namespace-level","title":"Method 1: Automatic Injection (Namespace-Level)","text":"<p>This is the most common approach:</p> <pre><code># Label the namespace to enable automatic injection\nkubectl label namespace &lt;your-namespace&gt; istio-injection=enabled\n</code></pre> <p>Once you apply this label, all new workloads deployed in the namespace will automatically have the Istio sidecar injected. Note that existing workloads won\u2019t be affected\u2014you\u2019ll need to redeploy them to get the sidecar.</p> <p>You can verify the label is applied with:</p> <pre><code>kubectl get namespace &lt;your-namespace&gt; --show-labels\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#method-2-manual-injection-deployment-level","title":"Method 2: Manual Injection (Deployment-Level)","text":"<p>If you prefer to inject sidecars on specific deployments:</p> <pre><code># Manually inject the sidecar into a deployment\nistioctl kube-inject -f your-deployment.yaml | kubectl apply -f -\n</code></pre> <p>This approach modifies the deployment YAML directly, adding the sidecar configuration before applying it to the cluster.</p>"},{"location":"kubernetes/cks/istio_mtls/#how-to-verify-injection-worked","title":"How to Verify Injection Worked","text":"<p>You can verify that a pod has the sidecar injected by checking the READY column:</p> <pre><code>kubectl get pods\n</code></pre> <p>A pod with the sidecar injected will show <code>2/2</code> in the READY column, indicating that there are two containers running (your application and the Istio proxy).</p> <p>You can also describe the pod to see the <code>istio-proxy</code> container:</p> <pre><code>kubectl describe pod &lt;pod-name&gt;\n</code></pre> <p>Or check for the presence of the sidecar container directly:</p> <pre><code>kubectl get pod &lt;pod-name&gt; -o jsonpath='{.spec.containers[*].name}'\n</code></pre>"},{"location":"kubernetes/cks/istio_mtls/#disabling-sidecar-injection","title":"Disabling Sidecar Injection","text":"<p>If you need to exclude a specific workload from injection, you can add an annotation to that workload:</p> <pre><code>metadata:\n  annotations:\n    sidecar.istio.io/inject: \"false\"\n</code></pre> <p>Alternatively, the newer approach uses a label instead of an annotation:</p> <pre><code>metadata:\n  labels:\n    sidecar.istio.io/inject: \"false\"\n</code></pre> <p>This is particularly useful for jobs, CronJobs, or any workload that shouldn\u2019t be part of the service mesh.</p>"},{"location":"kubernetes/cks/k8s_dashboard/","title":"Kubernetes Dashboard","text":"<p>The Kubernetes Dashboard is a web-based UI for Kubernetes clusters that allows users to manage and troubleshoot applications. While convenient, it requires proper security measures to prevent unauthorized access.</p>"},{"location":"kubernetes/cks/k8s_dashboard/#1-use-rbac-role-based-access-control","title":"1. Use RBAC (Role-Based Access Control)","text":"<p>RBAC is critical for limiting dashboard access to authorized users only:</p> <pre><code># Example: Create a restricted dashboard role\napiVersion: rbac.authorization.k8s.io/v1\nkind: Role\nmetadata:\n  name: kubernetes-dashboard-restricted\n  namespace: kubernetes-dashboard\nrules:\n- apiGroups: [\"\"]\n  resources: [\"pods\", \"services\"]\n  verbs: [\"get\", \"list\", \"watch\"]\n</code></pre> <p>Link roles to users with RoleBindings:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: RoleBinding\nmetadata:\n  name: dashboard-user-binding\n  namespace: kubernetes-dashboard\nsubjects:\n- kind: User\n  name: dashboard-user\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: Role\n  name: kubernetes-dashboard-restricted\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>"},{"location":"kubernetes/cks/k8s_dashboard/#2-never-expose-dashboard-publicly","title":"2. Never Expose Dashboard Publicly","text":"<p>Never expose your dashboard directly to the internet. Use secure access methods:</p> <ul> <li> <p>Kubectl Proxy:   <pre><code>kubectl proxy\n# Access at http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/\n</code></pre></p> </li> <li> <p>Port Forwarding:   <pre><code>kubectl port-forward -n kubernetes-dashboard service/kubernetes-dashboard 8443:443\n# Access at https://localhost:8443\n</code></pre></p> </li> </ul>"},{"location":"kubernetes/cks/k8s_dashboard/#3-use-token-authentication","title":"3. Use Token Authentication","text":"<p>Create service accounts with limited permissions for dashboard access:</p> <pre><code>apiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: dashboard-viewer\n  namespace: kubernetes-dashboard\n</code></pre> <p>Bind appropriate roles:</p> <pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: dashboard-viewer\nsubjects:\n- kind: ServiceAccount\n  name: dashboard-viewer\n  namespace: kubernetes-dashboard\nroleRef:\n  kind: ClusterRole\n  name: view\n  apiGroup: rbac.authorization.k8s.io\n</code></pre> <p>Generate and retrieve tokens:</p> <pre><code># For Kubernetes v1.24+\nkubectl create token dashboard-viewer -n kubernetes-dashboard\n\n# For older versions\nkubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep dashboard-viewer | awk '{print $1}')\n</code></pre>"},{"location":"kubernetes/cks/k8s_dashboard/#4-enable-httpstls","title":"4. Enable HTTPS/TLS","text":"<p>Always use HTTPS with valid certificates:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: kubernetes-dashboard\n  namespace: kubernetes-dashboard\nspec:\n  template:\n    spec:\n      containers:\n      - name: kubernetes-dashboard\n        args:\n        - --auto-generate-certificates\n        - --namespace=kubernetes-dashboard\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/","title":"kube-bench","text":""},{"location":"kubernetes/cks/kube_bench/#introduction-to-kube-bench","title":"Introduction to kube-bench","text":"<p>kube-bench is an open-source tool that checks whether Kubernetes is deployed securely by running the checks documented in the CIS Kubernetes Benchmark. The tool helps cluster administrators ensure their Kubernetes deployments meet industry security standards.</p> <p>kube-bench automates security checks against the Center for Internet Security (CIS) Kubernetes Benchmark, which provides guidelines for configuring Kubernetes securely. These benchmarks are widely recognized as security standards for configuring various systems.</p> <p>Key features: - Ability to run checks for multiple Kubernetes components - Support for different Kubernetes versions - Support for various deployment environments - Integration with CI/CD pipelines - Customizable test configurations</p>"},{"location":"kubernetes/cks/kube_bench/#deployment-options","title":"Deployment Options","text":""},{"location":"kubernetes/cks/kube_bench/#running-as-a-kubernetes-job","title":"Running as a Kubernetes Job","text":"<p>A Kubernetes job is a good option for one-time assessments:</p> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata:\n  name: kube-bench\nspec:\n  template:\n    spec:\n      hostPID: true\n      containers:\n        - name: kube-bench\n          image: aquasec/kube-bench:latest\n          securityContext:\n            privileged: true\n          volumeMounts:\n          - name: var-lib-kubelet\n            mountPath: /var/lib/kubelet\n            readOnly: true\n          - name: etc-systemd\n            mountPath: /etc/systemd\n            readOnly: true\n          - name: etc-kubernetes\n            mountPath: /etc/kubernetes\n            readOnly: true\n      restartPolicy: Never\n      volumes:\n      - name: var-lib-kubelet\n        hostPath:\n          path: \"/var/lib/kubelet\"\n      - name: etc-systemd\n        hostPath:\n          path: \"/etc/systemd\"\n      - name: etc-kubernetes\n        hostPath:\n          path: \"/etc/kubernetes\"\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#running-as-a-daemonset","title":"Running as a DaemonSet","text":"<p>To run kube-bench on every node in your cluster, use a DaemonSet:</p> <pre><code>apiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: kube-bench\n  namespace: security\nspec:\n  selector:\n    matchLabels:\n      app: kube-bench\n  template:\n    metadata:\n      labels:\n        app: kube-bench\n    spec:\n      hostPID: true\n      containers:\n      - name: kube-bench\n        image: aquasec/kube-bench:latest\n        command: [\"kube-bench\", \"--json\", \"--logtostderr=true\", \"node\"]\n        securityContext:\n          privileged: true\n        volumeMounts:\n        - name: var-lib-kubelet\n          mountPath: /var/lib/kubelet\n          readOnly: true\n        - name: etc-systemd\n          mountPath: /etc/systemd\n          readOnly: true\n        - name: etc-kubernetes\n          mountPath: /etc/kubernetes\n          readOnly: true\n        - name: output\n          mountPath: /output\n      volumes:\n      - name: var-lib-kubelet\n        hostPath:\n          path: \"/var/lib/kubelet\"\n      - name: etc-systemd\n        hostPath:\n          path: \"/etc/systemd\"\n      - name: etc-kubernetes\n        hostPath:\n          path: \"/etc/kubernetes\"\n      - name: output\n        hostPath:\n          path: \"/tmp/kube-bench\"\n          type: DirectoryOrCreate\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#running-locally-on-nodes","title":"Running Locally on Nodes","text":"<p>For direct execution on a node:</p> <pre><code># If installed as a package\nkube-bench\n\n# Using the binary\n./kube-bench\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#basic-usage","title":"Basic Usage","text":""},{"location":"kubernetes/cks/kube_bench/#running-default-checks","title":"Running Default Checks","text":"<p>To run all checks against your cluster:</p> <pre><code>kube-bench\n</code></pre> <p>This will automatically detect your Kubernetes version and run the appropriate CIS benchmark checks.</p>"},{"location":"kubernetes/cks/kube_bench/#targeting-specific-components","title":"Targeting Specific Components","text":"<p>You can target specific Kubernetes components:</p> <pre><code># Master node checks\nkube-bench run --targets master\n\n# Worker node checks\nkube-bench run --targets node\n\n# etcd node checks\nkube-bench run --targets etcd\n\n# Multiple targets\nkube-bench run --targets master,node\n\n# Control plane components\nkube-bench run --targets control-plane\n\n# Policies\nkube-bench run --targets policies\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"kubernetes/cks/kube_bench/#custom-configuration-files","title":"Custom Configuration Files","text":"<p>You can customize the checks using your own configuration files:</p> <pre><code>kube-bench --config-dir /path/to/custom/configs\n</code></pre> <p>The structure should match the default config structure:</p> <pre><code>/path/to/custom/configs/\n\u251c\u2500\u2500 config.yaml\n\u251c\u2500\u2500 controlplane.yaml\n\u251c\u2500\u2500 etcd.yaml\n\u251c\u2500\u2500 master.yaml\n\u251c\u2500\u2500 node.yaml\n\u2514\u2500\u2500 policies.yaml\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#excluding-specific-tests","title":"Excluding Specific Tests","text":"<p>To exclude certain tests:</p> <pre><code>kube-bench run --targets master --exclude 1.1.2,1.2.1\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#running-specific-test-groups","title":"Running Specific Test Groups","text":"<p>To run only specific test groups or checks:</p> <pre><code># Run only section 1 tests on master\nkube-bench run --targets master --check 1\n\n# Run specific checks\nkube-bench run --targets master --check 1.1.1,1.1.2\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#output-formats","title":"Output Formats","text":""},{"location":"kubernetes/cks/kube_bench/#default-output","title":"Default Output","text":"<p>By default, kube-bench outputs results in a human-readable format:</p> <pre><code>kube-bench\n</code></pre> <p>Example output: <pre><code>[INFO] 1 Master Node Security Configuration\n[INFO] 1.1 Master Node Configuration Files\n[PASS] 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive (Automated)\n[FAIL] 1.1.2 Ensure that the API server pod specification file ownership is set to root:root (Automated)\n</code></pre></p>"},{"location":"kubernetes/cks/kube_bench/#json-output","title":"JSON Output","text":"<p>For programmatic processing, use JSON output:</p> <pre><code>kube-bench --json &gt; kube-bench-results.json\n</code></pre> <p>Example structure: <pre><code>{\n  \"controls\": [\n    {\n      \"id\": \"1\",\n      \"text\": \"Master Node Security Configuration\",\n      \"tests\": [\n        {\n          \"section\": \"1.1\",\n          \"type\": \"manual\",\n          \"pass\": true,\n          \"text\": \"Ensure that the API server pod specification file permissions are set to 644 or more restrictive\"\n        }\n      ]\n    }\n  ]\n}\n</code></pre></p>"},{"location":"kubernetes/cks/kube_bench/#junit-xml-for-cicd","title":"JUnit XML for CI/CD","text":"<p>For CI/CD integration, use JUnit XML format:</p> <pre><code>kube-bench --junit &gt; kube-bench-results.xml\n</code></pre>"},{"location":"kubernetes/cks/kube_bench/#interpreting-results","title":"Interpreting Results","text":""},{"location":"kubernetes/cks/kube_bench/#understanding-severity-levels","title":"Understanding Severity Levels","text":"<p>Results are categorized with these severities:</p> <ul> <li>PASS: The check was successful</li> <li>FAIL: The check failed and needs remediation</li> <li>WARN: The check found something that might need attention</li> <li>INFO: Informational only, no action needed</li> <li>NOTE: Additional information about a test</li> </ul>"},{"location":"kubernetes/cks/kube_bench/#reading-test-output","title":"Reading Test Output","text":"<p>For each check, kube-bench provides:</p> <ol> <li>The CIS benchmark ID (e.g., \u201c1.1.1\u201d)</li> <li>Description of the check</li> <li>Result (PASS/FAIL/WARN/INFO)</li> <li>Remediation suggestions for failed checks</li> </ol>"},{"location":"kubernetes/cks/kube_bench/#remediation-steps","title":"Remediation Steps","text":"<p>For each failed check, kube-bench provides remediation instructions:</p> <pre><code>[FAIL] 1.1.20 Ensure that the Kubernetes PKI directory and file ownership is set to root:root (Automated)\n        [remediation]\n        Run the below command (based on the file location on your system) on the master node.\n        For example,\n        chown -R root:root /etc/kubernetes/pki/\n</code></pre>"},{"location":"kubernetes/cks/opa/","title":"OPA and Gatekeeper","text":""},{"location":"kubernetes/cks/opa/#introduction","title":"Introduction","text":"<p>Open Policy Agent (OPA) is a general-purpose policy engine that enables unified policy enforcement across the entire stack. When combined with Gatekeeper, OPA becomes a powerful tool for enforcing policies in Kubernetes environments. This guide will take you through practical implementations of OPA and Gatekeeper, from basic concepts to advanced use cases, preparing you for real-world scenarios and practical exams.</p>"},{"location":"kubernetes/cks/opa/#understanding-opa-and-gatekeeper","title":"Understanding OPA and Gatekeeper","text":"<p>OPA is a general-purpose policy engine that enables unified policy enforcement across various systems. Gatekeeper is the Kubernetes-native implementation of OPA, providing a way to enforce policies on Kubernetes resources during creation and update operations.</p>"},{"location":"kubernetes/cks/opa/#key-concepts","title":"Key Concepts","text":"<ul> <li>Policy as Code: Define policies in a declarative language (Rego) rather than hardcoding them in applications.</li> <li>Admission Control: Gatekeeper works as a validating admission controller in Kubernetes.</li> <li>Constraint Framework: A system for defining, applying, and monitoring policy compliance.</li> </ul>"},{"location":"kubernetes/cks/opa/#the-relationship-between-opa-and-gatekeeper","title":"The Relationship Between OPA and Gatekeeper","text":"<p>Gatekeeper extends OPA\u2019s capabilities specifically for Kubernetes:</p> <ul> <li>It provides Kubernetes custom resources for defining policies</li> <li>It integrates with the Kubernetes admission controller</li> <li>It enables audit functionality for existing resources</li> </ul>"},{"location":"kubernetes/cks/opa/#installing-gatekeeper","title":"Installing Gatekeeper","text":"<p>Let\u2019s begin with installing Gatekeeper on a Kubernetes cluster:</p>"},{"location":"kubernetes/cks/opa/#using-helm","title":"Using Helm","text":"<pre><code># Add the Gatekeeper Helm repository\nhelm repo add gatekeeper https://open-policy-agent.github.io/gatekeeper/charts\n\n# Update the Helm repositories\nhelm repo update\n\n# Install Gatekeeper\nhelm install gatekeeper gatekeeper/gatekeeper --namespace gatekeeper-system --create-namespace\n</code></pre>"},{"location":"kubernetes/cks/opa/#using-kubectl","title":"Using kubectl","text":"<pre><code>kubectl apply -f https://raw.githubusercontent.com/open-policy-agent/gatekeeper/release-3.11/deploy/gatekeeper.yaml\n</code></pre>"},{"location":"kubernetes/cks/opa/#verify-the-installation","title":"Verify the Installation","text":"<pre><code>kubectl get pods -n gatekeeper-system\n</code></pre> <p>You should see pods like <code>gatekeeper-audit-*</code>, <code>gatekeeper-controller-manager-*</code>, etc., all in a Running state.</p>"},{"location":"kubernetes/cks/opa/#constrainttemplates-and-constraints","title":"ConstraintTemplates and Constraints","text":"<p>Gatekeeper uses two custom resources to define and enforce policies:</p>"},{"location":"kubernetes/cks/opa/#constrainttemplates","title":"ConstraintTemplates","text":"<p>A ConstraintTemplate defines the logic of the policy using Rego and the schema for the Constraint that will implement the policy. Think of it as a reusable policy definition that can be applied in different contexts.</p>"},{"location":"kubernetes/cks/opa/#anatomy-of-a-constrainttemplate","title":"Anatomy of a ConstraintTemplate","text":"<pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequiredlabels  # Name of the template\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequiredLabels  # Kind of the Constraint this template creates\n      validation:\n        # Schema for the `parameters` field in the Constraint\n        openAPIV3Schema:\n          type: object\n          properties:\n            labels:\n              type: array\n              items:\n                type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequiredlabels\n\n        violation[{\"msg\": msg, \"details\": {\"missing_labels\": missing}}] {\n          provided := {label | input.review.object.metadata.labels[label]}\n          required := {label | label := input.parameters.labels[_]}\n          missing := required - provided\n          count(missing) &gt; 0\n          msg := sprintf(\"you must provide labels: %v\", [missing])\n        }\n</code></pre> <p>Let\u2019s break this down:</p> <ol> <li>CRD Specification: Defines the kind name and validation schema for the Constraint.</li> <li>Target: Specifies where the policy will be enforced. For Kubernetes, this is usually <code>admission.k8s.gatekeeper.sh</code>.</li> <li>Rego Policy: The policy logic written in Rego language.</li> </ol>"},{"location":"kubernetes/cks/opa/#constraints","title":"Constraints","text":"<p>A Constraint is an instance of a ConstraintTemplate that enforces the policy defined in the template. It allows you to specify which resources the policy should apply to and provide parameters to customize the policy.</p>"},{"location":"kubernetes/cks/opa/#example-constraint","title":"Example Constraint","text":"<pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequiredLabels  # This must match the kind defined in the ConstraintTemplate\nmetadata:\n  name: require-team-label\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Namespace\"]  # This policy applies to Namespaces\n  parameters:\n    labels: [\"team\"]  # Require 'team' label on all Namespaces\n</code></pre> <p>Let\u2019s break this down:</p> <ol> <li>Kind: Must match the kind defined in the ConstraintTemplate.</li> <li>Match: Defines which resources the Constraint applies to.</li> <li>Parameters: Values passed to the Rego policy in the ConstraintTemplate.</li> </ol>"},{"location":"kubernetes/cks/opa/#practical-examples","title":"Practical Examples","text":"<p>Let\u2019s walk through some practical examples of ConstraintTemplates and Constraints that solve real-world problems:</p>"},{"location":"kubernetes/cks/opa/#example-1-require-specific-labels","title":"Example 1: Require Specific Labels","text":"<p>This example ensures that all Namespaces have required labels:</p> <pre><code># First, create the ConstraintTemplate\napiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequiredlabels\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequiredLabels\n      validation:\n        openAPIV3Schema:\n          type: object\n          properties:\n            labels:\n              type: array\n              items:\n                type: string\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequiredlabels\n\n        violation[{\"msg\": msg, \"details\": {\"missing_labels\": missing}}] {\n          provided := {label | input.review.object.metadata.labels[label]}\n          required := {label | label := input.parameters.labels[_]}\n          missing := required - provided\n          count(missing) &gt; 0\n          msg := sprintf(\"you must provide labels: %v\", [missing])\n        }\n</code></pre> <pre><code># Then, create the Constraint\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequiredLabels\nmetadata:\n  name: ns-must-have-env\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Namespace\"]\n  parameters:\n    labels: [\"environment\"]\n</code></pre> <p>Now, if you try to create a Namespace without the <code>environment</code> label:</p> <pre><code>kubectl create namespace test\n</code></pre> <p>It will fail with an error like:</p> <pre><code>Error from server ([ns-must-have-env] you must provide labels: {\"environment\"}): admission webhook \"validation.gatekeeper.sh\" denied the request: [ns-must-have-env] you must provide labels: {\"environment\"}\n</code></pre>"},{"location":"kubernetes/cks/opa/#example-2-block-latest-image-tags","title":"Example 2: Block Latest Image Tags","text":"<p>This example blocks the use of the <code>:latest</code> tag for container images:</p> <pre><code># ConstraintTemplate\napiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8sblocklatestimages\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sBlockLatestImages\n      validation:\n        openAPIV3Schema:\n          type: object\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8sblocklatestimages\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          endswith(container.image, \":latest\")\n          msg := sprintf(\"container &lt;%v&gt; uses the latest tag\", [container.name])\n        }\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.initContainers[_]\n          endswith(container.image, \":latest\")\n          msg := sprintf(\"initContainer &lt;%v&gt; uses the latest tag\", [container.name])\n        }\n</code></pre> <pre><code># Constraint\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sBlockLatestImages\nmetadata:\n  name: block-latest-images\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\", \"StatefulSet\", \"DaemonSet\"]\n</code></pre>"},{"location":"kubernetes/cks/opa/#example-3-require-resource-limits","title":"Example 3: Require Resource Limits","text":"<p>This example ensures all containers have CPU and memory limits:</p> <pre><code># ConstraintTemplate\napiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8srequirelimits\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sRequireLimits\n      validation:\n        openAPIV3Schema:\n          type: object\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8srequirelimits\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          not container.resources.limits.cpu\n          msg := sprintf(\"container &lt;%v&gt; has no CPU limit\", [container.name])\n        }\n\n        violation[{\"msg\": msg}] {\n          container := input.review.object.spec.containers[_]\n          not container.resources.limits.memory\n          msg := sprintf(\"container &lt;%v&gt; has no memory limit\", [container.name])\n        }\n</code></pre> <pre><code># Constraint\napiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequireLimits\nmetadata:\n  name: require-resource-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n      - apiGroups: [\"apps\"]\n        kinds: [\"Deployment\", \"StatefulSet\"]\n</code></pre>"},{"location":"kubernetes/cks/opa/#advanced-use-cases","title":"Advanced Use Cases","text":""},{"location":"kubernetes/cks/opa/#mutating-admission-control","title":"Mutating Admission Control","text":"<p>While traditionally Gatekeeper has been used for validation, recent versions support mutation as well. Here\u2019s an example of a MutatingWebhook that adds default resource limits:</p> <pre><code>apiVersion: mutations.gatekeeper.sh/v1\nkind: AssignMetadata\nmetadata:\n  name: add-team-label\nspec:\n  match:\n    scope: Namespaced\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Namespace\"]\n  location: \"metadata.labels.team\"\n  parameters:\n    assign:\n      value: \"default-team\"\n</code></pre>"},{"location":"kubernetes/cks/opa/#external-data","title":"External Data","text":"<p>Gatekeeper can use data from external sources through the <code>data.inventory</code> object:</p> <pre><code>apiVersion: templates.gatekeeper.sh/v1\nkind: ConstraintTemplate\nmetadata:\n  name: k8suniqueservices\nspec:\n  crd:\n    spec:\n      names:\n        kind: K8sUniqueServices\n  targets:\n    - target: admission.k8s.gatekeeper.sh\n      rego: |\n        package k8suniqueservices\n\n        violation[{\"msg\": msg}] {\n          input.review.kind.kind == \"Service\"\n          input.review.object.spec.type == \"LoadBalancer\"\n          port := input.review.object.spec.ports[_]\n          existing := data.inventory.namespace[namespace].Service[name]\n          existing.spec.type == \"LoadBalancer\"\n          existing_port := existing.spec.ports[_]\n          port.port == existing_port.port\n          not (input.review.object.metadata.name == existing.metadata.name)\n          msg := sprintf(\"Service port %v already in use by service %v\", [port.port, existing.metadata.name])\n        }\n</code></pre>"},{"location":"kubernetes/cks/opa/#exemptions","title":"Exemptions","text":"<p>You can create exemptions for your policies using the <code>excludedNamespaces</code> field in the Constraint:</p> <pre><code>apiVersion: constraints.gatekeeper.sh/v1beta1\nkind: K8sRequireLimits\nmetadata:\n  name: require-resource-limits\nspec:\n  match:\n    kinds:\n      - apiGroups: [\"\"]\n        kinds: [\"Pod\"]\n    excludedNamespaces: [\"kube-system\", \"gatekeeper-system\"]\n</code></pre>"},{"location":"kubernetes/cks/runtimeclass/","title":"RuntimeClass","text":""},{"location":"kubernetes/cks/runtimeclass/#introduction","title":"Introduction","text":"<p>RuntimeClass is a Kubernetes feature that allows you to select the container runtime configuration used to run a Pod\u2019s containers. It\u2019s particularly valuable in scenarios where you need to provide different levels of isolation, security, or performance for specific workloads.  The RuntimeClass resource is cluster-scoped (non-namespaced) and maps a runtime class name to the corresponding configuration used by the container runtime to run a container.</p>"},{"location":"kubernetes/cks/runtimeclass/#how-runtimeclass-works","title":"How RuntimeClass Works","text":"<p>RuntimeClass leverages the Container Runtime Interface (CRI) to expose different runtime options to Kubernetes. The workflow is:</p> <ol> <li>An administrator configures the CRI implementation on nodes (such as containerd or CRI-O).</li> <li>The administrator creates RuntimeClass objects that reference handlers for these configurations.</li> <li>Users specify a <code>runtimeClassName</code> in their Pod specs.</li> <li>Kubelet uses the referenced RuntimeClass to determine which runtime handler to use for the Pod.</li> </ol>"},{"location":"kubernetes/cks/runtimeclass/#setting-up-runtimeclass","title":"Setting Up RuntimeClass","text":""},{"location":"kubernetes/cks/runtimeclass/#step-1-configure-cri-implementation-on-nodes","title":"Step 1: Configure CRI Implementation on Nodes","text":"<p>The specific configuration depends on your CRI implementation:</p>"},{"location":"kubernetes/cks/runtimeclass/#for-containerd-v12","title":"For containerd (v1.2+)","text":"<p>Edit <code>/etc/containerd/config.toml</code> to define runtime handlers:</p> <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes]\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n    runtime_type = \"io.containerd.runc.v2\"\n    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n      SystemdCgroup = true\n\n  # Example configuration for Kata Containers\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata]\n    runtime_type = \"io.containerd.kata.v2\"\n    [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata.options]\n      ConfigPath = \"/opt/kata/share/defaults/kata-containers/configuration.toml\"\n\n  # Example configuration for gVisor\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.gvisor]\n    runtime_type = \"io.containerd.runsc.v1\"\n</code></pre> <p>After modifying the configuration, restart containerd:</p> <pre><code>sudo systemctl restart containerd\n</code></pre>"},{"location":"kubernetes/cks/runtimeclass/#for-cri-o","title":"For CRI-O","text":"<p>Edit <code>/etc/crio/crio.conf</code> to define runtime handlers:</p> <pre><code>[crio.runtime.runtimes.runc]\nruntime_path = \"/usr/local/bin/runc\"\n\n[crio.runtime.runtimes.kata]\nruntime_path = \"/usr/bin/kata-runtime\"\n\n[crio.runtime.runtimes.runsc]\nruntime_path = \"/usr/local/bin/runsc\"\n</code></pre> <p>After modifying the configuration, restart CRI-O:</p> <pre><code>sudo systemctl restart crio\n</code></pre>"},{"location":"kubernetes/cks/runtimeclass/#step-2-create-runtimeclass-objects","title":"Step 2: Create RuntimeClass Objects","text":"<p>Create RuntimeClass objects to reference your configured handlers:</p> <pre><code># runc-runtimeclass.yaml\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: runc\nhandler: runc\n</code></pre> <pre><code># kata-runtimeclass.yaml\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: kata\nhandler: kata\n</code></pre> <pre><code># gvisor-runtimeclass.yaml\napiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: gvisor\nhandler: gvisor\n</code></pre> <p>Apply the RuntimeClass objects:</p> <pre><code>kubectl apply -f runc-runtimeclass.yaml\nkubectl apply -f kata-runtimeclass.yaml\nkubectl apply -f gvisor-runtimeclass.yaml\n</code></pre> <p>Verify the RuntimeClass objects:</p> <pre><code>kubectl get runtimeclass\n</code></pre>"},{"location":"kubernetes/cks/runtimeclass/#using-runtimeclass-in-pods","title":"Using RuntimeClass in Pods","text":"<p>Once RuntimeClasses are defined, you can use them in your Pod specifications:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-kata\nspec:\n  runtimeClassName: kata\n  containers:\n  - name: nginx\n    image: nginx:latest\n</code></pre> <p>When you create this Pod, the kubelet will use the specified RuntimeClass (in this case, \u201ckata\u201d) to run the Pod\u2019s containers. The kubelet will use the \u201ckata\u201d handler which maps to Kata Containers runtime.</p>"},{"location":"kubernetes/cks/runtimeclass/#scheduling","title":"Scheduling","text":"<p>RuntimeClass also supports scheduling constraints to ensure Pods are scheduled to nodes that support the specified runtime.</p> <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: kata\nhandler: kata\nscheduling:\n  nodeSelector:\n    runtime-kata: \"true\"\n  tolerations:\n  - key: \"runtime-kata\"\n    operator: \"Exists\"\n    effect: \"NoSchedule\"\n</code></pre> <p>With this configuration, Pods using the \u201ckata\u201d RuntimeClass will only be scheduled on nodes with the label <code>runtime-kata: \"true\"</code>, and they will tolerate the NoSchedule taint with the key \u201cruntime-kata\u201d.</p>"},{"location":"kubernetes/cks/runtimeclass/#practical-examples","title":"Practical Examples","text":"<p>This section provides concrete examples for setting up and using various RuntimeClasses.</p>"},{"location":"kubernetes/cks/runtimeclass/#example-1-using-gvisor-for-untrusted-workloads","title":"Example 1: Using gVisor for Untrusted Workloads","text":"<p>gVisor is a container runtime that provides an additional layer of isolation by implementing a user-space kernel. Here\u2019s how to set it up and use it.</p> <ol> <li> <p>Install gVisor on your nodes (commands will vary based on your operating system).</p> </li> <li> <p>Configure containerd:</p> </li> </ol> <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runsc]\n  runtime_type = \"io.containerd.runsc.v1\"\n</code></pre> <ol> <li>Create a RuntimeClass:</li> </ol> <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: gvisor\nhandler: runsc\n</code></pre> <ol> <li>Deploy a Pod that uses gVisor:</li> </ol> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: nginx-gvisor\nspec:\n  runtimeClassName: gvisor\n  containers:\n  - name: nginx\n    image: nginx:latest\n</code></pre>"},{"location":"kubernetes/cks/runtimeclass/#example-2-using-kata-containers-for-hardware-isolation","title":"Example 2: Using Kata Containers for Hardware Isolation","text":"<p>Kata Containers provide stronger isolation by running containers in lightweight VMs.</p> <ol> <li> <p>Install Kata Containers on your nodes.</p> </li> <li> <p>Configure containerd:</p> </li> </ol> <pre><code>[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata-fc]\n  runtime_type = \"io.containerd.kata.v2\"\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.kata-fc.options]\n    ConfigPath = \"/opt/kata/share/defaults/kata-containers/configuration-fc.toml\"\n</code></pre> <ol> <li>Create a RuntimeClass with scheduling and overhead:</li> </ol> <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: kata-fc\nhandler: kata-fc\noverhead:\n  podFixed:\n    memory: \"130Mi\"\n    cpu: \"250m\"\nscheduling:\n  nodeSelector:\n    katacontainers.io/kata-runtime: \"true\"\n</code></pre> <ol> <li>Label nodes that support Kata Containers:</li> </ol> <pre><code>kubectl label nodes worker1 katacontainers.io/kata-runtime=true\n</code></pre> <ol> <li>Deploy a Pod that uses Kata Containers:</li> </ol> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: redis-kata\nspec:\n  runtimeClassName: kata-fc\n  containers:\n  - name: redis\n    image: redis:latest\n</code></pre>"},{"location":"kubernetes/cks/seccomp/","title":"Creating Seccomp Audit Profile","text":""},{"location":"kubernetes/cks/seccomp/#seccomp","title":"Seccomp","text":"<p>Seccomp (secure computing mode) is a Linux kernel feature that allows restricting the system calls that a process can make. In container environments, seccomp profiles provide an additional layer of security by limiting what actions containers can perform at the system call level.</p> <p>Audit mode allows you to log all system calls without blocking any of them, which is useful for: - Understanding what system calls an application requires - Creating baseline profiles for applications - Detecting potential malicious activities - Debugging permission issues</p>"},{"location":"kubernetes/cks/seccomp/#creating-an-audit-seccomp-profile","title":"Creating an Audit Seccomp Profile","text":"<p>Create a JSON file named <code>audit-seccomp.json</code> with the following content:</p> <pre><code>{\n  \"defaultAction\": \"SCMP_ACT_ALLOW\",\n  \"architectures\": [\n    \"SCMP_ARCH_X86_64\",\n    \"SCMP_ARCH_X86\",\n    \"SCMP_ARCH_AARCH64\"\n  ],\n  \"syscalls\": [\n    {\n      \"names\": [\n        \"open\",\n        \"openat\",\n        \"read\",\n        \"write\",\n        \"connect\",\n        \"socket\",\n        \"execve\",\n        \"clone\"\n      ],\n      \"action\": \"SCMP_ACT_LOG\"\n    }\n  ]\n}\n</code></pre> <p>This profile sets the default action to <code>SCMP_ACT_LOG</code>, which logs all system calls without blocking them. The <code>syscalls</code> array of this profile would only log the specified system calls and silently allow the rest. An empty <code>syscalls</code> array means no system calls have special handling - they\u2019re all logged.</p> <ul> <li>defaultAction: The action to take by default (in this case, log but allow all syscalls)</li> <li>architectures: The CPU architectures the profile applies to</li> <li>syscalls: A list of system calls with specific actions (empty in this audit profile)</li> </ul>"},{"location":"kubernetes/cks/seccomp/#installing-the-profile-on-a-worker-node","title":"Installing the Profile on a Worker Node","text":"<pre><code>sudo mkdir -p /var/lib/kubelet/seccomp/profiles\nsudo cp audit-seccomp.json /var/lib/kubelet/seccomp/profiles/\nsudo chmod 644 /var/lib/kubelet/seccomp/profiles/audit-seccomp.json\n</code></pre>"},{"location":"kubernetes/cks/seccomp/#applying-the-profile-to-containers","title":"Applying the Profile to Containers","text":""},{"location":"kubernetes/cks/seccomp/#method-1-using-annotations-older-approach","title":"Method 1: Using annotations (older approach)","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: audit-pod\n  annotations:\n    seccomp.security.alpha.kubernetes.io/pod: \"localhost/audit-seccomp.json\"\nspec:\n  containers:\n  - name: my-container\n    image: nginx\n</code></pre>"},{"location":"kubernetes/cks/seccomp/#method-2-using-securitycontext-recommended","title":"Method 2: Using securityContext (recommended)","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: audit-pod\nspec:\n  securityContext:\n    seccompProfile:\n      type: Localhost\n      localhostProfile: audit-seccomp.json\n  containers:\n  - name: my-container\n    image: nginx\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/","title":"Secure Docker Daemon","text":"<p>The Docker daemon is a critical component that manages and coordinates all Docker operations. Since it often runs with elevated privileges, securing it properly is essential to protect your containerized applications and host systems from potential security threats.</p>"},{"location":"kubernetes/cks/secure_docker_daemon/#understanding-docker-daemon-security-risks","title":"Understanding Docker Daemon Security Risks","text":"<p>Before implementing security measures, it\u2019s important to understand the potential risks:</p> <ol> <li> <p>Privilege Escalation: The Docker daemon typically runs with root privileges, making it a prime target for attackers seeking to gain elevated access to your system.</p> </li> <li> <p>Unauthorized Access: An unsecured Docker daemon can be accessed by unauthorized users, potentially leading to data breaches or system compromise.</p> </li> <li> <p>Container Breakouts: Vulnerabilities in the Docker daemon can lead to container breakouts, where attackers escape container isolation and access the host system.</p> </li> <li> <p>API Exposure: The Docker API, if exposed unsafely, can be exploited for unauthorized operations.</p> </li> </ol>"},{"location":"kubernetes/cks/secure_docker_daemon/#configuring-and-securing-communication-sockets","title":"Configuring and Securing Communication Sockets","text":"<p>Docker daemon can communicate through different types of sockets. Understanding and properly configuring these communication channels is essential for security.</p>"},{"location":"kubernetes/cks/secure_docker_daemon/#1-unix-socket-default-and-recommended","title":"1. Unix Socket (Default and Recommended)","text":"<p>By default, Docker runs through a non-networked UNIX socket. It can also optionally communicate using SSH or a TLS (HTTPS) socket. The Unix socket is located at <code>/var/run/docker.sock</code> and is the most secure option for local communications.</p> <pre><code># The default configuration in daemon.json [/etc/docker/daemon.json] (often doesn't need to be specified)\n{\n  \"hosts\": [\"unix:///var/run/docker.sock\"]\n}\n</code></pre> <p>Unix sockets are more secure than TCP sockets because:</p> <ul> <li>They\u2019re not exposed to the network</li> <li>They use standard Unix file permissions for access control</li> <li>They\u2019re not prone to cross-site request forgery attacks that can happen with TCP sockets</li> </ul>"},{"location":"kubernetes/cks/secure_docker_daemon/#2-tcp-socket-for-remote-access","title":"2. TCP Socket (For Remote Access)","text":"<p>If you need remote access to the Docker daemon, you can configure it to listen on a TCP socket, but this should always be protected with TLS.</p> <p>When using a TCP socket, the Docker daemon provides un-encrypted and un-authenticated direct access to the Docker daemon by default. You should secure the daemon either using the built in HTTPS encrypted socket, or by putting a secure web proxy in front of it.</p> <pre><code># Example daemon.json [/etc/docker/daemon.json] with both Unix socket and secure TCP socket\n{\n  \"hosts\": [\n    \"unix:///var/run/docker.sock\",\n    \"tcp://0.0.0.0:2376\"\n  ],\n  \"tls\": true,\n  \"tlscacert\": \"/path/to/ca.pem\",\n  \"tlscert\": \"/path/to/server-cert.pem\",\n  \"tlskey\": \"/path/to/server-key.pem\",\n  \"tlsverify\": true\n}\n</code></pre> <p>Important:  When using the TCP socket:</p> <ul> <li>Never expose the Docker daemon to the internet without TLS encryption</li> <li>Docker over TLS should run on TCP port 2376 (not 2375, which is unencrypted)</li> <li>Use client certificate authentication</li> <li>Implement proper network firewall rules</li> </ul>"},{"location":"kubernetes/cks/secure_docker_daemon/#3-setting-up-tls-for-docker-daemon","title":"3. Setting Up TLS for Docker Daemon","text":"<p>To set up TLS for secure remote access:</p> <ol> <li>Generate CA, server, and client certificates</li> </ol> <pre><code># Create a CA key and certificate\nopenssl genrsa -out ca-key.pem 4096\nopenssl req -new -x509 -days 365 -key ca-key.pem -sha256 -out ca.pem\n\n# Create a server key and certificate signing request (CSR)\n# Set $HOST to the DNS name or IP of your Docker host\nopenssl genrsa -out server-key.pem 4096\nopenssl req -subj \"/CN=$HOST\" -sha256 -new -key server-key.pem -out server.csr\n\n# Sign the server certificate\n# Include IP addresses and DNS names that will be used to connect to your Docker host\necho \"subjectAltName = DNS:$HOST,IP:127.0.0.1,IP:$PUBLIC_IP\" &gt;&gt; extfile.cnf\necho \"extendedKeyUsage = serverAuth\" &gt;&gt; extfile.cnf\nopenssl x509 -req -days 365 -sha256 -in server.csr -CA ca.pem -CAkey ca-key.pem \\\n  -CAcreateserial -out server-cert.pem -extfile extfile.cnf\n\n# Create a client key and certificate signing request\nopenssl genrsa -out client-key.pem 4096\nopenssl req -subj '/CN=client' -new -key client-key.pem -out client.csr\n\n# Sign the client certificate\necho \"extendedKeyUsage = clientAuth\" &gt; extfile-client.cnf\nopenssl x509 -req -days 365 -sha256 -in client.csr -CA ca.pem -CAkey ca-key.pem \\\n  -CAcreateserial -out client-cert.pem -extfile extfile-client.cnf\n</code></pre> <ol> <li>Configure the Docker daemon to use TLS</li> </ol> <p>Update the <code>/etc/docker/daemon.json</code> (/etc/docker/daemon.json) file:</p> <pre><code>{\n  \"hosts\": [\"unix:///var/run/docker.sock\", \"tcp://0.0.0.0:2376\"],\n  \"tls\": true,\n  \"tlsverify\": true,\n  \"tlscacert\": \"/path/to/ca.pem\",\n  \"tlscert\": \"/path/to/server-cert.pem\",\n  \"tlskey\": \"/path/to/server-key.pem\"\n}\n</code></pre> <ol> <li>Configure your client to use TLS</li> </ol> <p>Replace all instances of $HOST in the following example with the DNS name of your Docker daemon\u2019s host.</p> <pre><code># When connecting, specify the TLS certificates\ndocker --tlsverify \\\n  --tlscacert=ca.pem \\\n  --tlscert=client-cert.pem \\\n  --tlskey=client-key.pem \\\n  -H=$HOST:2376 version\n\n# Or set environment variables\nexport DOCKER_HOST=tcp://$HOST:2376\nexport DOCKER_TLS_VERIFY=1\nexport DOCKER_CERT_PATH=/path/to/client/certificates\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#4-using-systemd-configuration-alternative-method","title":"4. Using systemd Configuration (Alternative Method)","text":"<p>If you\u2019re using systemd, you can also configure the Docker daemon through the service file:</p> <pre><code># Create a systemd override file\nsudo mkdir -p /etc/systemd/system/docker.service.d\nsudo touch /etc/systemd/system/docker.service.d/override.conf\n\n# Edit the override file\nsudo nano /etc/systemd/system/docker.service.d/override.conf\n</code></pre> <p>Add the following content to the <code>override.conf</code> file:</p> <pre><code>[Service]\nExecStart=\nExecStart=/usr/bin/dockerd -H fd:// -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2376 --tlsverify --tlscacert=/path/to/ca.pem --tlscert=/path/to/server-cert.pem --tlskey=/path/to/server-key.pem\n</code></pre> <p>Reload systemd and restart Docker:</p> <pre><code>sudo systemctl daemon-reload\nsudo systemctl restart docker\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#5-verifying-socket-configuration","title":"5. Verifying Socket Configuration","text":"<p>After configuring your Docker daemon, verify that it\u2019s listening on the specified sockets:</p> <pre><code># Check for Unix socket\nls -la /var/run/docker.sock\n\n# Check for TCP socket\nsudo netstat -tulpn | grep dockerd\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#6-listening-on-both-unix-and-tcp-sockets","title":"6. Listening on Both Unix and TCP Sockets","text":"<p>When configuring Docker to listen on both types of sockets, be aware that the \u201chosts\u201d option overrides the Docker default value rather than appends to it. You must specify both the Unix socket and TCP socket in your configuration.</p> <pre><code>{\n  \"hosts\": [\"unix:///var/run/docker.sock\", \"tcp://0.0.0.0:2376\"]\n}\n</code></pre> <p>You can also verify the configuration is working with:</p> <pre><code>sudo netstat -lntp | grep dockerd\n</code></pre> <p>If properly configured, you should see Docker listening on both the Unix socket and the specified TCP port.</p>"},{"location":"kubernetes/cks/secure_docker_daemon/#3-implement-rootless-mode","title":"3. Implement Rootless Mode","text":"<p>Rootless mode allows running the Docker daemon and containers as a non-root user to mitigate potential vulnerabilities in the daemon and the container runtime.</p> <p>Rootless mode ensures that the Docker daemon and containers are running as an unprivileged user, which means that even if an attacker breaks out of the container, they will not have root privileges on the host, which in turn substantially limits the attack surface.</p> <pre><code># Set up rootless mode\ndockerd-rootless-setuptool.sh install\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#4-secure-the-docker-socket","title":"4. Secure the Docker Socket","text":"<p>Docker communicates with a UNIX domain socket called /var/run/docker.sock. This is the main entry point for the Docker API. Anyone who has access to the Docker daemon socket also has unrestricted root access.</p> <p>Best practices for socket security:</p> <ol> <li>Never expose the Docker socket to containers unless absolutely necessary</li> <li>Use proper Unix file permissions to restrict access</li> <li>If socket sharing is required, consider using a proxy like Docker Socket Proxy</li> </ol> <pre><code># Set proper permissions for the Docker socket\nsudo chmod 660 /var/run/docker.sock\nsudo chown root:docker /var/run/docker.sock\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#5-configure-user-namespace-remapping","title":"5. Configure User Namespace Remapping","text":"<p>User namespace remapping is a Docker feature that converts host UIDs to a different unprivileged range inside your containers. This helps to prevent privilege escalation attacks, where a process running in a container gains the same privileges as its UID has on your host.</p> <pre><code># Configure user namespace remapping in daemon.json\n{\n  \"userns-remap\": \"default\"\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#6-restrict-inter-container-communication","title":"6. Restrict Inter-Container Communication","text":"<p>Docker normally allows arbitrary communication between the containers running on your host. Each new container is automatically added to the docker0 bridge network, which allows it to discover and contact its peers. Keeping inter-container communication (ICC) enabled is risky because it could permit a malicious process to launch an attack against neighboring containers.</p> <pre><code># Disable inter-container communication in daemon.json\n{\n  \"icc\": false\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#7-implement-resource-limitations","title":"7. Implement Resource Limitations","text":"<p>Set appropriate resource constraints to prevent denial-of-service attacks:</p> <pre><code># Configure default resource constraints in daemon.json\n{\n  \"default-ulimits\": {\n    \"nofile\": {\n      \"Name\": \"nofile\",\n      \"Hard\": 64000,\n      \"Soft\": 64000\n    }\n  },\n  \"default-shm-size\": \"64M\",\n  \"default-memory-swap\": \"-1\",\n  \"default-memory\": \"1G\",\n  \"default-cpu-shares\": 1024\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#8-enable-content-trust","title":"8. Enable Content Trust","text":"<p>Docker Engine can be configured to run only signed images, enhancing security through image signature verification. This feature, set up in the Docker configuration file (daemon.json), gives you control over enforcing security policies related to image usage.</p> <pre><code># Enable Docker Content Trust in daemon.json\n{\n  \"content-trust\": {\n    \"trust-pinning\": {\n      \"official-library-images\": true\n    }\n  }\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#9-enable-logging-and-monitoring","title":"9. Enable Logging and Monitoring","text":"<p>Collecting Docker daemon logs is instrumental in identifying and responding to security incidents. These logs offer comprehensive insights into Docker\u2019s system-level operations, encompassing critical aspects such as container lifecycle events, network configurations, image management, and incoming API requests.</p> <pre><code># Configure logging in daemon.json\n{\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"log-level\": \"info\"\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#10-use-security-enhanced-systems","title":"10. Use Security Enhanced Systems","text":"<p>Ensuring OS-level security systems are active helps defend against malicious activity originating inside containers and the Docker daemon. Docker supports policies for SELinux, Seccomp, and AppArmor; keeping them enabled ensures sane defaults are applied to your containers, including restrictions for dangerous system calls.</p> <pre><code># Don't disable security-enhanced systems\n# Incorrect configuration (do not use):\n# {\n#   \"selinux-enabled\": false,\n#   \"apparmor-enabled\": false\n# }\n\n# Correct configuration:\n{\n  \"selinux-enabled\": true,\n  \"apparmor-enabled\": true\n}\n</code></pre>"},{"location":"kubernetes/cks/secure_docker_daemon/#comprehensive-etcdockerdaemonjson-example","title":"Comprehensive <code>/etc/docker/daemon.json</code> Example","text":"<p>Here\u2019s a comprehensive example of a secure <code>daemon.json</code> configuration that incorporates many of the best practices:</p> <pre><code>{\n  \"icc\": false,\n  \"log-level\": \"info\",\n  \"iptables\": true,\n  \"live-restore\": true,\n  \"userland-proxy\": false,\n  \"no-new-privileges\": true,\n  \"userns-remap\": \"default\",\n  \"storage-driver\": \"overlay2\",\n  \"default-ulimits\": {\n    \"nofile\": {\n      \"Name\": \"nofile\",\n      \"Hard\": 64000,\n      \"Soft\": 64000\n    }\n  },\n  \"selinux-enabled\": true,\n  \"apparmor-enabled\": true,\n  \"default-runtime\": \"runc\",\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  },\n  \"content-trust\": {\n    \"trust-pinning\": {\n      \"official-library-images\": true\n    }\n  }\n}\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/","title":"Cilium Network Policies Certification Guide","text":""},{"location":"kubernetes/cks/exercises/cilium/#layer-3-network-policies","title":"Layer 3 Network Policies","text":"<p>Layer 3 policies control traffic based on IP addresses and CIDR blocks.</p>"},{"location":"kubernetes/cks/exercises/cilium/#basic-l3-policy-allow-specific-ip-ranges","title":"Basic L3 Policy - Allow Specific IP Ranges","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l3-allow-specific-ips\n  namespace: production\nspec:\n  endpointSelector:\n    matchLabels:\n      app: web-server\n  ingress:\n  - fromCIDR:\n    - \"10.0.1.0/24\"    # Allow from specific subnet\n    - \"192.168.1.100/32\" # Allow from specific IP\n  egress:\n  - toCIDR:\n    - \"10.0.2.0/24\"    # Allow to database subnet\n  - toFQDNs:\n    - matchName: \"api.external-service.com\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l3-policy-block-external-traffic","title":"L3 Policy - Block External Traffic","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l3-block-external\n  namespace: secure-zone\nspec:\n  endpointSelector:\n    matchLabels:\n      security: high\n  ingress:\n  - fromCIDR:\n    - \"10.0.0.0/8\"     # Only allow internal traffic\n    - \"172.16.0.0/12\"\n    - \"192.168.0.0/16\"\n  egress:\n  - toCIDR:\n    - \"10.0.0.0/8\"     # Only allow internal egress\n    - \"172.16.0.0/12\"\n    - \"192.168.0.0/16\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l3-policy-with-node-selection","title":"L3 Policy with Node Selection","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l3-node-based\nspec:\n  endpointSelector:\n    matchLabels:\n      app: monitoring\n  ingress:\n  - fromEntities:\n    - \"host\"           # Allow from node\n  - fromNodes:\n    - matchLabels:\n        node-role: \"worker\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#layer-4-network-policies","title":"Layer 4 Network Policies","text":"<p>Layer 4 policies control traffic based on ports and protocols.</p>"},{"location":"kubernetes/cks/exercises/cilium/#basic-l4-policy-port-specific-access","title":"Basic L4 Policy - Port-specific Access","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l4-web-server-ports\n  namespace: web-app\nspec:\n  endpointSelector:\n    matchLabels:\n      app: nginx\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: frontend\n    toPorts:\n    - ports:\n      - port: \"80\"\n        protocol: TCP\n      - port: \"443\"\n        protocol: TCP\n  - fromEndpoints:\n    - matchLabels:\n        app: monitoring\n    toPorts:\n    - ports:\n      - port: \"9090\"    # Metrics port\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l4-policy-database-access-control","title":"L4 Policy - Database Access Control","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l4-database-access\n  namespace: database\nspec:\n  endpointSelector:\n    matchLabels:\n      app: mysql\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        tier: backend\n    toPorts:\n    - ports:\n      - port: \"3306\"\n        protocol: TCP\n  # Deny all other ingress traffic (implicit)\n  egress:\n  - {} # Allow all egress for database operations\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l4-policy-multi-protocol-support","title":"L4 Policy - Multi-Protocol Support","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l4-multi-protocol\nspec:\n  endpointSelector:\n    matchLabels:\n      app: dns-server\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        role: client\n    toPorts:\n    - ports:\n      - port: \"53\"\n        protocol: TCP\n      - port: \"53\"\n        protocol: UDP\n    - ports:\n      - port: \"853\"      # DNS over TLS\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#icmp-policies","title":"ICMP Policies","text":"<p>ICMP policies control ping, traceroute, and other ICMP traffic.</p>"},{"location":"kubernetes/cks/exercises/cilium/#allow-icmp-for-monitoring","title":"Allow ICMP for Monitoring","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: icmp-monitoring\n  namespace: infrastructure\nspec:\n  endpointSelector:\n    matchLabels:\n      role: server\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: monitoring\n    icmps:\n    - fields:\n      - type: 8          # Echo Request (ping)\n        code: 0\n  - fromEndpoints:\n    - matchLabels:\n        app: network-tools\n    icmps:\n    - fields:\n      - type: 8          # Echo Request\n      - type: 11         # Time Exceeded (traceroute)\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#block-icmp-from-external-sources","title":"Block ICMP from External Sources","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: icmp-block-external\nspec:\n  endpointSelector:\n    matchLabels:\n      exposure: internal\n  ingress:\n  - fromCIDR:\n    - \"10.0.0.0/8\"\n    icmps:\n    - fields:\n      - type: 8          # Allow internal ping\n  # ICMP from external sources blocked (no rule = deny)\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#icmp-troubleshooting-policy","title":"ICMP Troubleshooting Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: icmp-troubleshooting\nspec:\n  endpointSelector:\n    matchLabels:\n      debug: enabled\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        role: admin\n    icmps:\n    - fields:\n      - type: 8          # Echo Request\n      - type: 0          # Echo Reply\n      - type: 3          # Destination Unreachable\n      - type: 11         # Time Exceeded\n      - type: 12         # Parameter Problem\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#layer-7-application-layer-policies","title":"Layer 7 (Application Layer) Policies","text":"<p>Layer 7 policies provide HTTP/gRPC/Kafka protocol-aware filtering.</p>"},{"location":"kubernetes/cks/exercises/cilium/#http-based-l7-policy","title":"HTTP-based L7 Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l7-http-api-access\n  namespace: api-gateway\nspec:\n  endpointSelector:\n    matchLabels:\n      app: api-server\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: frontend\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/api/v1/users\"\n        - method: \"POST\"\n          path: \"/api/v1/users\"\n        - method: \"GET\"\n          path: \"/api/v1/health\"\n  - fromEndpoints:\n    - matchLabels:\n        app: admin-panel\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/api/v1/.*\"    # Regex for any v1 endpoint\n        - method: \"POST\"\n          path: \"/api/v1/.*\"\n        - method: \"PUT\"\n          path: \"/api/v1/.*\"\n        - method: \"DELETE\"\n          path: \"/api/v1/.*\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l7-policy-with-headers","title":"L7 Policy with Headers","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l7-http-headers\nspec:\n  endpointSelector:\n    matchLabels:\n      app: auth-service\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: web-app\n    toPorts:\n    - ports:\n      - port: \"80\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"POST\"\n          path: \"/auth/login\"\n          headers:\n          - \"Content-Type: application/json\"\n        - method: \"GET\"\n          path: \"/auth/verify\"\n          headers:\n          - \"Authorization: Bearer .*\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l7-grpc-policy","title":"L7 gRPC Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l7-grpc-service\nspec:\n  endpointSelector:\n    matchLabels:\n      app: grpc-service\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: grpc-client\n    toPorts:\n    - ports:\n      - port: \"9090\"\n        protocol: TCP\n      rules:\n        grpc:\n        - service: \"user.UserService\"\n          method: \"GetUser\"\n        - service: \"user.UserService\"\n          method: \"ListUsers\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#l7-dns-policy","title":"L7 DNS Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: l7-dns-filtering\nspec:\n  endpointSelector:\n    matchLabels:\n      app: web-crawler\n  egress:\n  - toEndpoints:\n    - matchLabels:\n        k8s:io.kubernetes.pod.namespace: kube-system\n        k8s:app: kube-dns\n    toPorts:\n    - ports:\n      - port: \"53\"\n        protocol: UDP\n      rules:\n        dns:\n        - matchPattern: \"*.example.com\"\n        - matchPattern: \"api.allowed-service.org\"\n        - matchName: \"specific-host.com\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#deny-policies","title":"Deny Policies","text":"<p>Cilium supports explicit deny policies for enhanced security.</p>"},{"location":"kubernetes/cks/exercises/cilium/#explicit-deny-policy","title":"Explicit Deny Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: deny-suspicious-traffic\nspec:\n  endpointSelector:\n    matchLabels:\n      security: strict\n  ingressDeny:\n  - fromCIDR:\n    - \"192.168.100.0/24\"  # Block specific subnet\n  - fromEndpoints:\n    - matchLabels:\n        reputation: suspicious\n  egressDeny:\n  - toPorts:\n    - ports:\n      - port: \"22\"        # Block SSH\n        protocol: TCP\n      - port: \"3389\"      # Block RDP\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#deny-with-l7-rules","title":"Deny with L7 Rules","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: deny-admin-endpoints\nspec:\n  endpointSelector:\n    matchLabels:\n      app: web-server\n  ingressDeny:\n  - fromEndpoints:\n    - matchLabels:\n        role: user\n    toPorts:\n    - ports:\n      - port: \"80\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/admin/.*\"\n        - method: \"POST\"\n          path: \"/admin/.*\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#time-based-deny-advanced","title":"Time-based Deny (Advanced)","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: deny-after-hours\nspec:\n  endpointSelector:\n    matchLabels:\n      access: business-hours\n  ingressDeny:\n  - fromEndpoints:\n    - matchLabels:\n        role: employee\n    toPorts:\n    - ports:\n      - port: \"443\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \".*\"\n          path: \"/.*\"\n          headers:\n          - \"X-Time-Restriction: after-hours\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#allow-policies","title":"Allow Policies","text":"<p>Allow policies explicitly permit traffic and can work with deny policies.</p>"},{"location":"kubernetes/cks/exercises/cilium/#basic-allow-policy","title":"Basic Allow Policy","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: allow-essential-services\nspec:\n  endpointSelector:\n    matchLabels:\n      app: microservice\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        app: gateway\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n  egress:\n  - toEndpoints:\n    - matchLabels:\n        app: database\n    toPorts:\n    - ports:\n      - port: \"5432\"\n        protocol: TCP\n  - toFQDNs:\n    - matchName: \"logging.external.com\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#allow-with-service-mesh-integration","title":"Allow with Service Mesh Integration","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: allow-istio-sidecar\nspec:\n  endpointSelector:\n    matchLabels:\n      app: bookinfo\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        \"k8s:io.kubernetes.pod.namespace\": istio-system\n  - fromEndpoints:\n    - {} # Allow from any pod in same namespace\n    toPorts:\n    - ports:\n      - port: \"15001\"     # Istio proxy\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#advanced-scenarios","title":"Advanced Scenarios","text":""},{"location":"kubernetes/cks/exercises/cilium/#multi-tier-application-security","title":"Multi-tier Application Security","text":"<pre><code># Frontend tier\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: frontend-policy\n  namespace: web-app\nspec:\n  endpointSelector:\n    matchLabels:\n      tier: frontend\n  ingress:\n  - fromCIDR:\n    - \"0.0.0.0/0\"        # Allow from internet\n    toPorts:\n    - ports:\n      - port: \"80\"\n        protocol: TCP\n      - port: \"443\"\n        protocol: TCP\n  egress:\n  - toEndpoints:\n    - matchLabels:\n        tier: backend\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/api/.*\"\n        - method: \"POST\"\n          path: \"/api/.*\"\n\n---\n# Backend tier\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: backend-policy\n  namespace: web-app\nspec:\n  endpointSelector:\n    matchLabels:\n      tier: backend\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        tier: frontend\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n  egress:\n  - toEndpoints:\n    - matchLabels:\n        tier: database\n    toPorts:\n    - ports:\n      - port: \"5432\"\n        protocol: TCP\n\n---\n# Database tier\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: database-policy\n  namespace: web-app\nspec:\n  endpointSelector:\n    matchLabels:\n      tier: database\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        tier: backend\n    toPorts:\n    - ports:\n      - port: \"5432\"\n        protocol: TCP\n  # No egress rules = deny all egress\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#cross-namespace-communication","title":"Cross-Namespace Communication","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumClusterwideNetworkPolicy\nmetadata:\n  name: cross-namespace-api\nspec:\n  endpointSelector:\n    matchLabels:\n      app: shared-api\n  ingress:\n  - fromEndpoints:\n    - matchLabels:\n        \"k8s:io.kubernetes.pod.namespace\": \"frontend\"\n        app: web-app\n    - matchLabels:\n        \"k8s:io.kubernetes.pod.namespace\": \"mobile\"\n        app: mobile-api\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n      rules:\n        http:\n        - method: \"GET\"\n          path: \"/shared/.*\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/cilium/#zero-trust-network","title":"Zero Trust Network","text":"<pre><code>apiVersion: cilium.io/v2\nkind: CiliumClusterwideNetworkPolicy\nmetadata:\n  name: zero-trust-default-deny\nspec:\n  endpointSelector: {}   # Apply to all pods\n  ingressDeny:\n  - fromEntities:\n    - \"all\"\n  egressDeny:\n  - toEntities:\n    - \"all\"\n\n---\n# Explicit allow for essential services\napiVersion: cilium.io/v2\nkind: CiliumNetworkPolicy\nmetadata:\n  name: allow-dns\n  namespace: kube-system\nspec:\n  endpointSelector:\n    matchLabels:\n      k8s-app: kube-dns\n  ingress:\n  - fromEntities:\n    - \"cluster\"\n    toPorts:\n    - ports:\n      - port: \"53\"\n        protocol: UDP\n      - port: \"53\"\n        protocol: TCP\n</code></pre>"},{"location":"kubernetes/cks/exercises/docker-socket-security/","title":"Editing Docker Socket Service File to Change Group Ownership to Root","text":""},{"location":"kubernetes/cks/exercises/docker-socket-security/#problem-statement","title":"Problem Statement","text":"<p>Edit the docker.socket service file to make the group owned by root instead of the default docker group.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#solution","title":"Solution","text":"<p>The Docker socket file (<code>docker.socket</code>) defines permissions for the Docker daemon socket. By default, this socket is owned by root:docker, which allows any user in the docker group to interact with the Docker daemon with essentially root privileges. Changing the group ownership to root restricts Docker access to only the root user, enhancing security.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-1-locate-the-dockersocket-service-file","title":"Step 1: Locate the docker.socket Service File","text":"<p>First, let\u2019s find the exact location of the docker.socket service file:</p> <pre><code>find /lib/systemd/system /usr/lib/systemd/system -name \"docker.socket\"\n</code></pre> <p>This typically returns: <pre><code>/lib/systemd/system/docker.socket\n</code></pre></p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-2-examine-the-current-configuration","title":"Step 2: Examine the Current Configuration","text":"<p>Before making changes, examine the current configuration:</p> <pre><code>cat /lib/systemd/system/docker.socket\n</code></pre> <p>The file should look something like this:</p> <pre><code>[Unit]\nDescription=Docker Socket for the API\n\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n\n[Install]\nWantedBy=sockets.target\n</code></pre> <p>Notice that the <code>SocketGroup</code> is set to <code>docker</code>.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-3-edit-the-dockersocket-file","title":"Step 3: Edit the docker.socket File","text":"<p>Now edit the file to change the group ownership to root:</p> <pre><code>sudo vi /lib/systemd/system/docker.socket\n</code></pre> <p>Modify the <code>SocketGroup</code> line to use root instead of docker:</p> <pre><code>[Unit]\nDescription=Docker Socket for the API\n\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=root\n\n[Install]\nWantedBy=sockets.target\n</code></pre> <p>Save and exit the editor.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-4-reload-the-systemd-daemon","title":"Step 4: Reload the Systemd Daemon","text":"<p>After editing the service file, reload the systemd daemon to recognize the changes:</p> <pre><code>sudo systemctl daemon-reload\n</code></pre>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-5-restart-the-docker-socket-and-service","title":"Step 5: Restart the Docker Socket and Service","text":"<p>Restart both the Docker socket and the Docker service to apply the changes:</p> <pre><code>sudo systemctl restart docker.socket\nsudo systemctl restart docker\n</code></pre>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-6-verify-the-change","title":"Step 6: Verify the Change","text":"<p>Verify that the Docker socket is now owned by root:root:</p> <pre><code>ls -la /var/run/docker.sock\n</code></pre> <p>You should see output similar to this:</p> <pre><code>srw-rw---- 1 root root 0 May 11 10:24 /var/run/docker.sock\n</code></pre> <p>Notice that both the user and group are now \u201croot\u201d instead of \u201croot docker\u201d.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#step-7-test-docker-functionality","title":"Step 7: Test Docker Functionality","text":"<p>Test that Docker still works when accessed with sudo:</p> <pre><code>sudo docker ps\n</code></pre> <p>This should execute successfully and list running containers if any.</p> <p>Try to run Docker as a non-root user:</p> <pre><code>docker ps\n</code></pre> <p>This should fail with a permissions error, confirming that only root can now access Docker.</p>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#security-implications","title":"Security Implications","text":"<ol> <li> <p>Improved Security: Only the root user can now interact with the Docker daemon, reducing the attack surface.</p> </li> <li> <p>Restricted Access: Non-root users (even those in the docker group) can no longer run Docker commands directly.</p> </li> <li> <p>Operational Impact: Any applications or services that rely on docker group access will need to be reconfigured to use sudo or another privilege escalation method.</p> </li> <li> <p>Principle of Least Privilege: This change implements the security principle of granting only the minimum necessary privileges.</p> </li> </ol>"},{"location":"kubernetes/cks/exercises/docker-socket-security/#conclusion","title":"Conclusion","text":"<p>By changing the Docker socket group ownership from <code>docker</code> to <code>root</code>, we\u2019ve significantly enhanced the security of the Docker daemon by restricting access to only the root user. This modification aligns with security best practices for systems where Docker access should be tightly controlled.</p> <p>Remember that after this change, all Docker commands must be executed with sudo or by the root user, which might require adjustments to scripts, CI/CD pipelines, or user workflows that previously relied on docker group membership.</p>"},{"location":"kubernetes/cks/exercises/falco-rule/","title":"Falco Rule to Detect Container Access to /dev/mem","text":""},{"location":"kubernetes/cks/exercises/falco-rule/#problem-statement","title":"Problem Statement","text":"<p>Create a Falco rule to detect which container is accessing the <code>/dev/mem</code> folder. The rule output should include Kubernetes namespace name and pod/container ID information.</p>"},{"location":"kubernetes/cks/exercises/falco-rule/#solution","title":"Solution","text":"<p>Falco is an open-source cloud-native runtime security tool that can detect anomalous behavior in your containers and applications. For this task, we need to create a rule that specifically monitors for container access to the <code>/dev/mem</code> device, which could indicate a privileged container attempting to access physical memory directly (a potential security concern).</p>"},{"location":"kubernetes/cks/exercises/falco-rule/#rule-implementation","title":"Rule Implementation","text":"<pre><code>- rule: Container Accessing /dev/mem\n  desc: Detect attempts by containers to access /dev/mem device\n  condition: &gt;\n    open_read and \n    container and \n    fd.name = \"/dev/mem\" and \n    not falco_privileged_containers\n  output: &gt;\n    Container accessed /dev/mem device \n    (user=%user.name user_uid=%user.uid \n    command=%proc.cmdline %container.info \n    pod=%k8s.pod.name ns=%k8s.ns.name container_id=%container.id image=%container.image.repository)\n  priority: WARNING\n  tags: [container, access, memory, dev, k8s]\n</code></pre>"},{"location":"kubernetes/cks/exercises/falco-rule/#rule-explanation","title":"Rule Explanation","text":"<p>Let\u2019s break down the components of this rule:</p>"},{"location":"kubernetes/cks/exercises/falco-rule/#rule-metadata","title":"Rule Metadata","text":"<ul> <li>rule: Name of the rule - \u201cContainer Accessing /dev/mem\u201d</li> <li>desc: Brief description of what the rule detects</li> <li>priority: Set to WARNING as this is potentially suspicious activity </li> <li>tags: Keywords for organizing and categorizing the rule</li> </ul>"},{"location":"kubernetes/cks/exercises/falco-rule/#condition","title":"Condition","text":"<p>The condition defines when the rule should trigger:</p> <pre><code>open_read and container and fd.name = \"/dev/mem\" and not falco_privileged_containers\n</code></pre> <p>This condition will match when: - An <code>open_read</code> syscall occurs (a file is opened for reading) - The activity happens within a container - The file being accessed is specifically <code>/dev/mem</code> - The container is not already in the list of known privileged containers (to reduce false positives)</p>"},{"location":"kubernetes/cks/exercises/falco-rule/#output","title":"Output","text":"<p>The output specifies what information to include in the alert:</p> <pre><code>Container accessed /dev/mem device (user=%user.name user_uid=%user.uid command=%proc.cmdline %container.info pod=%k8s.pod.name ns=%k8s.ns.name container_id=%container.id image=%container.image.repository)\n</code></pre> <p>This will output: - The username and UID of the process - The command that was run - Container information - Pod name (as required) - Kubernetes namespace (as required) - Container ID (as required) - Container image information</p>"},{"location":"kubernetes/cks/exercises/falco-rule/#testing-the-rule","title":"Testing the Rule","text":"<ol> <li>Save the rule to a file (e.g., <code>dev-mem-access.yaml</code>)</li> <li>Deploy it to your Falco configuration:    <pre><code>sudo cp dev-mem-access.yaml /etc/falco/rules.d/\n</code></pre></li> <li> <p>Restart Falco:    <pre><code>sudo systemctl restart falco\n</code></pre></p> </li> <li> <p>To test the rule, you can run a privileged container that attempts to access <code>/dev/mem</code>:    <pre><code>kubectl run test-pod --image=alpine --overrides='{\"spec\": {\"containers\": [{\"name\": \"test-pod\", \"image\": \"alpine\", \"command\": [\"sh\", \"-c\", \"sleep 3 &amp;&amp; cat /dev/mem 2&gt;/dev/null || echo 'Access attempted'\"], \"securityContext\": {\"privileged\": true}}]}}'\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cks/exercises/falco-rule/#example-alert-output","title":"Example Alert Output","text":"<p>When the rule is triggered, you should see an alert in the Falco logs that looks like:</p> <pre><code>Warning Container Accessing /dev/mem: Container accessed /dev/mem device (user=root user_uid=0 command=cat /dev/mem container=test-pod pod=test-pod-6f7d9c5b9-xv7tj ns=default container_id=e8913b725fd3 image=alpine)\n</code></pre>"},{"location":"kubernetes/cks/exercises/falco-rule/#additional-considerations","title":"Additional Considerations","text":"<ol> <li> <p>This rule might generate false positives in environments where legitimate access to <code>/dev/mem</code> is needed.</p> </li> <li> <p>Consider adding a macro if you have specific containers that legitimately need to access <code>/dev/mem</code>:    <pre><code>- macro: authorized_mem_access_containers\n  condition: (container.name in (authorized-container-1, authorized-container-2))\n</code></pre></p> </li> </ol> <p>Then modify the rule condition:    <pre><code>condition: open_read and container and fd.name = \"/dev/mem\" and not falco_privileged_containers and not authorized_mem_access_containers\n</code></pre></p> <ol> <li>For production environments, you might want to increase the priority to ERROR if this activity is strictly prohibited in your security policies.</li> </ol>"},{"location":"kubernetes/cks/exercises/falco-rule/#conclusion","title":"Conclusion","text":"<p>This Falco rule effectively monitors and alerts on container access to the <code>/dev/mem</code> device with the required Kubernetes namespace and container identification information included in the output.</p>"},{"location":"kubernetes/cks/exercises/hostpath-only/","title":"Creating a Pod with Host Path Access and Falco Detection","text":""},{"location":"kubernetes/cks/exercises/hostpath-only/#problem-statement","title":"Problem Statement","text":"<p>Create a deployment that can read and write to a specific path in the underlying host machine\u2019s filesystem using a normal volume added to the container specs. The solution must ensure that access to any other host paths is denied. After creating the deployment and verifying it works, create Falco rules to detect this activity, identifying which container is performing the actions and displaying the output via journalctl.</p>"},{"location":"kubernetes/cks/exercises/hostpath-only/#solution","title":"Solution","text":""},{"location":"kubernetes/cks/exercises/hostpath-only/#part-1-creating-a-deployment-with-host-path-access","title":"Part 1: Creating a Deployment with Host Path Access","text":"<p>Let\u2019s create a deployment that can access the host filesystem:</p> <pre><code># host-path-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: host-path-access\n  labels:\n    app: host-path-access\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: host-path-access\n  template:\n    metadata:\n      labels:\n        app: host-path-access\n    spec:\n      securityContext:\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n      containers:\n      - name: host-path-container\n        image: ubuntu:20.04\n        command: [\"sleep\", \"infinity\"]\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop: [\"ALL\"]\n          readOnlyRootFilesystem: true\n        volumeMounts:\n        - name: host-volume\n          mountPath: /host-data\n      volumes:\n      - name: host-volume\n        hostPath:\n          path: /opt/app-data  # The specific host path we want to access\n          type: DirectoryOrCreate\n</code></pre> <p>Apply the deployment: <pre><code>kubectl apply -f host-path-deployment.yaml\n</code></pre></p>"},{"location":"kubernetes/cks/exercises/hostpath-only/#part-2-verify-host-path-access","title":"Part 2: Verify Host Path Access","text":"<pre><code># Get the pod name\nPOD_NAME=$(kubectl get pods -l app=host-path-access -o jsonpath='{.items[0].metadata.name}')\n\n# Exec into the pod\nkubectl exec -it $POD_NAME -- bash\n\n# Inside the pod, verify access to the host path\nls -la /host-data\necho \"Test file for host path access\" &gt; /host-data/test.txt\ncat /host-data/test.txt\n\n# Verify we can't write to other locations\necho \"This should fail\" &gt; /etc/test.txt  # Should fail\ntouch /bin/test-file  # Should fail\n\n# Exit the pod\nexit\n</code></pre>"},{"location":"kubernetes/cks/exercises/hostpath-only/#part-3-creating-falco-rules-to-detect-host-path-access","title":"Part 3: Creating Falco Rules to Detect Host Path Access","text":"<p>Now, let\u2019s create Falco rules to detect when containers access this specific host path:</p> <pre><code># host-path-detection.yaml\n- rule: Container Accessing Host Path\n  desc: Detects when a container accesses the specific host path\n  condition: &gt;\n    container \n    and fd.name startswith \"/host-data\"\n    and (evt.type=open or evt.type=openat)\n  output: &gt;\n    Container accessing host path \n    (user=%user.name user_uid=%user.uid command=%proc.cmdline \n    file=%fd.name access_type=%evt.is_open_read,%evt.is_open_write\n    container_id=%container.id container_name=%container.name\n    image=%container.image.repository pod=%k8s.pod.name ns=%k8s.ns.name)\n  priority: INFO\n  tags: [filesystem, access, allowed]\n\n- rule: Container Writing To Host Path\n  desc: Detects when a container writes to the specific host path\n  condition: &gt;\n    container \n    and fd.name startswith \"/host-data\"\n    and (evt.type=open or evt.type=openat)\n    and evt.is_open_write=true\n  output: &gt;\n    Container WRITING to host path \n    (user=%user.name user_uid=%user.uid command=%proc.cmdline \n    file=%fd.name container_id=%container.id container_name=%container.name\n    image=%container.image.repository pod=%k8s.pod.name ns=%k8s.ns.name)\n  priority: INFO\n  tags: [filesystem, modification, allowed]\n\n- rule: Container Accessing Disallowed Path\n  desc: Detects when a container attempts to access any path other than the allowed host path\n  condition: &gt;\n    container \n    and fd.name startswith \"/\"\n    and not fd.name startswith \"/host-data\"\n    and not fd.name in (/proc, /dev, /sys) \n    and (evt.type=open or evt.type=openat)\n    and evt.is_open_write=true\n  output: &gt;\n    Suspicious: Container attempting to write to DISALLOWED path \n    (user=%user.name user_uid=%user.uid command=%proc.cmdline \n    file=%fd.name container_id=%container.id container_name=%container.name\n    image=%container.image.repository pod=%k8s.pod.name ns=%k8s.ns.name)\n  priority: WARNING\n  tags: [filesystem, modification, suspicious]\n</code></pre>"},{"location":"kubernetes/cks/exercises/hostpath-only/#part-4-deploy-the-falco-rules","title":"Part 4: Deploy the Falco Rules","text":"<p>If you\u2019re using Falco as a DaemonSet in Kubernetes:</p> <pre><code># Create a ConfigMap with the rules\nkubectl create configmap falco-hostpath-rules --from-file=host-path-detection.yaml\n\n# Update the Falco DaemonSet to use this ConfigMap\nkubectl -n falco patch daemonset falco --type=json -p='[\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/template/spec/volumes/-\",\n    \"value\": {\n      \"name\": \"hostpath-rules\",\n      \"configMap\": {\n        \"name\": \"falco-hostpath-rules\"\n      }\n    }\n  },\n  {\n    \"op\": \"add\",\n    \"path\": \"/spec/template/spec/containers/0/volumeMounts/-\",\n    \"value\": {\n      \"mountPath\": \"/etc/falco/rules.d/\",\n      \"name\": \"hostpath-rules\"\n    }\n  }\n]'\n</code></pre> <p>If you\u2019re running Falco directly on the host:</p> <pre><code># Copy the rules file to the Falco rules directory\nsudo cp host-path-detection.yaml /etc/falco/rules.d/\n\n# Restart Falco\nsudo systemctl restart falco\n</code></pre>"},{"location":"kubernetes/cks/exercises/hostpath-only/#part-5-monitor-falco-alerts-with-journalctl","title":"Part 5: Monitor Falco Alerts with journalctl","text":"<pre><code># Follow Falco logs in journalctl\nsudo journalctl -fu falco\n</code></pre>"},{"location":"kubernetes/cks/exercises/hostpath-only/#part-6-test-the-falco-detection","title":"Part 6: Test the Falco Detection","text":"<pre><code># Trigger allowed access to host path\nkubectl exec -it $POD_NAME -- bash -c \"echo 'Allowed write to host path' &gt; /host-data/falco-test.txt\"\n\n# Attempt disallowed access\nkubectl exec -it $POD_NAME -- bash -c \"touch /etc/not-allowed.txt || echo 'Access denied as expected'\"\n</code></pre> <p>You should see Falco alerts in the journalctl output that identify which container is accessing the host path.</p>"},{"location":"kubernetes/cks/exercises/hostpath-only/#conclusion","title":"Conclusion","text":"<p>This solution demonstrates:</p> <ol> <li> <p>How to create a deployment that can access a specific host path using a direct hostPath volume</p> </li> <li> <p>How to restrict file system access to only that specific path</p> </li> <li> <p>How to configure Falco rules to:</p> </li> <li>Detect access to the allowed host path</li> <li>Alert on attempts to access disallowed paths</li> <li> <p>Identify which container is performing these actions</p> </li> <li> <p>How to monitor these activities in real-time using journalctl</p> </li> </ol> <p>The solution fulfills the requirements by providing a deployment with access to a specific host path and proper Falco detection configured to monitor this activity.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/","title":"Securing Pod-to-Pod Encryption with mTLS Using Istio and PeerAuthentication","text":""},{"location":"kubernetes/cks/exercises/istio-mtls/#problem-statement","title":"Problem Statement","text":"<p>Implement mutual TLS (mTLS) encryption for pod-to-pod communication within a specific namespace using Istio and the PeerAuthentication resource.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#solution","title":"Solution","text":"<p>Mutual TLS (mTLS) provides strong security for service-to-service communication by ensuring both the client and server verify each other\u2019s identity. Istio\u2019s PeerAuthentication resource makes it easy to enable and enforce mTLS across a namespace. This solution demonstrates how to implement mTLS for all services within a specific namespace.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#prerequisites","title":"Prerequisites","text":"<ol> <li>A Kubernetes cluster with Istio installed</li> <li><code>kubectl</code> configured to interact with your cluster</li> <li>Administrative access to the cluster</li> <li>Istio\u2019s control plane (istiod) running</li> </ol>"},{"location":"kubernetes/cks/exercises/istio-mtls/#step-1-verify-istio-installation","title":"Step 1: Verify Istio Installation","text":"<p>First, let\u2019s verify that Istio is properly installed in your cluster:</p> <pre><code># Check if Istio components are installed and running\nkubectl get pods -n istio-system\n\n# Sample output:\n# NAME                                    READY   STATUS    RESTARTS   AGE\n# istio-ingressgateway-6b9c847cf-m4xb7    1/1     Running   0          24h\n# istiod-5d49996999-8rvdl                 1/1     Running   0          24h\n</code></pre>"},{"location":"kubernetes/cks/exercises/istio-mtls/#step-2-create-or-identify-the-target-namespace","title":"Step 2: Create or Identify the Target Namespace","text":"<p>For this example, let\u2019s create a namespace called <code>secure-apps</code> where we\u2019ll enforce mTLS:</p> <pre><code># Create the namespace\nkubectl create namespace secure-apps\n\n# Label the namespace for Istio injection\nkubectl label namespace secure-apps istio-injection=enabled\n</code></pre> <p>The <code>istio-injection=enabled</code> label ensures that the Istio sidecar proxy is automatically injected into all pods created in this namespace, which is required for mTLS to function.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#step-3-apply-peerauthentication-policy-for-mtls","title":"Step 3: Apply PeerAuthentication Policy for mTLS","text":"<p>Now, let\u2019s create a PeerAuthentication resource that enforces STRICT mTLS for all services in the <code>secure-apps</code> namespace:</p> <pre><code># Save this as mtls-policy.yaml\napiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: default\n  namespace: secure-apps\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>Apply this configuration:</p> <pre><code>kubectl apply -f mtls-policy.yaml\n</code></pre> <p>Let\u2019s understand the important parts of this configuration:</p> <ul> <li><code>kind: PeerAuthentication</code>: Specifies that this is an Istio PeerAuthentication resource</li> <li><code>metadata.namespace: secure-apps</code>: The policy applies to the secure-apps namespace</li> <li><code>mtls.mode: STRICT</code>: Enforces strict mTLS, meaning:</li> <li>All traffic to services in this namespace must use mTLS</li> <li>Plaintext connections will be rejected</li> <li>Communications are encrypted and authenticated</li> </ul>"},{"location":"kubernetes/cks/exercises/istio-mtls/#step-4-verify-mtls-enforcement","title":"Step 4: Verify mTLS Enforcement","text":"<p>Let\u2019s verify that mTLS is properly configured and enforced:</p> <pre><code># Check the PeerAuthentication policy status\nkubectl get peerauthentication -n secure-apps\n\n# Sample output:\n# NAME      MODE     AGE\n# default   STRICT   30s\n</code></pre> <p>For a more detailed verification, deploy test applications in the secure-apps namespace and verify mTLS is working:</p> <pre><code># Deploy a simple application in the secure-apps namespace\nkubectl apply -f - &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: sleep\n  namespace: secure-apps\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: sleep\n  template:\n    metadata:\n      labels:\n        app: sleep\n    spec:\n      containers:\n      - name: sleep\n        image: curlimages/curl\n        command: [\"/bin/sleep\", \"3650d\"]\n        imagePullPolicy: IfNotPresent\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: sleep\n  namespace: secure-apps\nspec:\n  ports:\n  - port: 80\n    name: http\n  selector:\n    app: sleep\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: httpbin\n  namespace: secure-apps\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: httpbin\n  template:\n    metadata:\n      labels:\n        app: httpbin\n    spec:\n      containers:\n      - image: kennethreitz/httpbin\n        imagePullPolicy: IfNotPresent\n        name: httpbin\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: httpbin\n  namespace: secure-apps\nspec:\n  ports:\n  - name: http\n    port: 8000\n    targetPort: 80\n  selector:\n    app: httpbin\nEOF\n</code></pre> <p>Now you can verify mTLS is working by checking the connection from sleep to httpbin:</p> <pre><code># Get the sleep pod name\nSLEEP_POD=$(kubectl get pod -l app=sleep -n secure-apps -o jsonpath={.items..metadata.name})\n\n# Check the TLS stats to verify mTLS is active\nkubectl exec -n secure-apps $SLEEP_POD -c istio-proxy -- curl -s http://localhost:15000/stats | grep tls_inspector\n\n# Try a connection and check if it's using mTLS\nkubectl exec -n secure-apps $SLEEP_POD -c istio-proxy -- curl http://httpbin.secure-apps:8000/headers -s | grep X-Forwarded-Client-Cert\n</code></pre> <p>If the connection is encrypted with mTLS, you\u2019ll see the X-Forwarded-Client-Cert header in the response, which contains the client certificate information.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#step-5-visualize-mtls-with-kiali-optional","title":"Step 5: Visualize mTLS with Kiali (Optional)","text":"<p>If you have Kiali installed as part of your Istio setup, you can visualize the mTLS status:</p> <pre><code># If Kiali is not exposed, you can port-forward to access it\nkubectl port-forward svc/kiali 20001:20001 -n istio-system\n</code></pre> <p>Then open your browser to http://localhost:20001, log in, and navigate to the Graph view. You should see secure (padlock) icons on the connections between services in the secure-apps namespace.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#understanding-mtls-modes","title":"Understanding mTLS Modes","text":"<p>Istio provides different mTLS modes in PeerAuthentication:</p> <ol> <li>STRICT: All connections must use mTLS. Non-mTLS connections are rejected.</li> <li>PERMISSIVE: Both mTLS and plaintext connections are allowed (useful during migration).</li> <li>DISABLE: mTLS is disabled, only plaintext connections are allowed.</li> </ol> <p>For our example, we\u2019ve used STRICT to enforce full encryption.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#fine-tuning-mtls-optional","title":"Fine-tuning mTLS (Optional)","text":"<p>If you need more granular control, you can apply mTLS settings at the service level:</p> <pre><code>apiVersion: security.istio.io/v1beta1\nkind: PeerAuthentication\nmetadata:\n  name: service-specific\n  namespace: secure-apps\nspec:\n  selector:\n    matchLabels:\n      app: httpbin  # This policy applies only to the httpbin service\n  mtls:\n    mode: STRICT\n</code></pre>"},{"location":"kubernetes/cks/exercises/istio-mtls/#conclusion","title":"Conclusion","text":"<p>We\u2019ve successfully configured pod-to-pod encryption using mTLS in the <code>secure-apps</code> namespace with Istio\u2019s PeerAuthentication resource. The configuration ensures that:</p> <ol> <li>All communication between services is encrypted and authenticated</li> <li>Only services with valid certificates can communicate with each other</li> <li>The entire namespace is protected with a single policy</li> </ol> <p>This approach provides strong security for microservices communication without requiring changes to the application code, as Istio\u2019s service mesh handles the TLS negotiation, certificate management, and encryption transparently.</p>"},{"location":"kubernetes/cks/exercises/istio-mtls/#additional-security-considerations","title":"Additional Security Considerations","text":"<ul> <li>Rotation: Istio automatically rotates certificates (default validity is 24 hours)</li> <li>Monitoring: Implement monitoring for failed authentication attempts using Istio telemetry</li> <li>Gradual Rollout: For production environments, consider starting with PERMISSIVE mode, then monitoring, before switching to STRICT mode</li> <li>API Gateway: Consider configuring an AuthorizationPolicy alongside PeerAuthentication for additional security</li> </ul> <p>By implementing mTLS across your namespace, you\u2019ve significantly improved your security posture by ensuring all service-to-service communication is encrypted and authenticated.</p>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/","title":"Enabling Pod-to-Pod Encryption with Istio and Cilium","text":"<p>This document provides solutions for implementing pod-to-pod (P2P) encryption in Kubernetes using two different approaches: Istio service mesh and Cilium network policy engine. Both methods offer robust security for intra-cluster communications.</p>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Solution 1: P2P Encryption with Istio</li> <li>Solution 2: P2P Encryption with Cilium</li> <li>Comparison and Best Practices</li> </ol>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#solution-1-p2p-encryption-with-istio","title":"Solution 1: P2P Encryption with Istio","text":"<p>Istio provides pod-to-pod encryption through mutual TLS (mTLS) authentication, where both the client and server authenticate each other\u2019s identity.</p>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#prerequisites","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster (v1.16+)</li> <li>Istio (v1.9+) installed</li> <li><code>kubectl</code> and <code>istioctl</code> CLI tools</li> </ul>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-1-install-istio-with-mtls-enabled","title":"Step 1: Install Istio with mTLS Enabled","text":"<p>If starting fresh:</p> <pre><code># Download Istio\ncurl -L https://istio.io/downloadIstio | sh -\ncd istio-*\n\n# Install Istio with strict mTLS profile\nistioctl install --set profile=default \\\n  --set meshConfig.enableAutoMtls=true \\\n  --set values.global.mtls.enabled=true\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-2-configure-namespace-for-istio-injection","title":"Step 2: Configure Namespace for Istio Injection","text":"<pre><code># Label the namespace for automatic sidecar injection\nkubectl label namespace default istio-injection=enabled\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-3-define-a-peerauthentication-policy-for-strict-mtls","title":"Step 3: Define a PeerAuthentication Policy for Strict mTLS","text":"<p>Create a file named <code>strict-mtls-policy.yaml</code>:</p> <pre><code>apiVersion: \"security.istio.io/v1beta1\"\nkind: \"PeerAuthentication\"\nmetadata:\n  name: \"default\"\n  namespace: \"istio-system\"  # Apply mesh-wide\nspec:\n  mtls:\n    mode: STRICT\n</code></pre> <p>Apply the policy:</p> <pre><code>kubectl apply -f strict-mtls-policy.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-4-verify-mtls-encryption","title":"Step 4: Verify mTLS Encryption","text":"<p>After deploying some applications, verify that mTLS is working:</p> <pre><code># Check mTLS status\nistioctl x authz check &lt;pod-name&gt;.&lt;namespace&gt;\n\n# View real-time mTLS status in Kiali\nkubectl port-forward -n istio-system svc/kiali 20001:20001\n</code></pre> <p>Visit <code>http://localhost:20001</code> in your browser to visualize secure connections.</p>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-5-debugging-and-validating-mtls","title":"Step 5: Debugging and Validating mTLS","text":"<p>To verify mTLS encryption is actively enforced:</p> <pre><code># Deploy a sample application\nkubectl apply -f samples/bookinfo/platform/kube/bookinfo.yaml\n\n# Create a testing pod\nkubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: Pod\nmetadata:\n  name: sleep\n  labels:\n    app: sleep\nspec:\n  containers:\n  - name: sleep\n    image: curlimages/curl\n    command: [\"/bin/sleep\", \"3650d\"]\nEOF\n\n# Test communication (should succeed with mTLS)\nkubectl exec sleep -- curl -s productpage:9080 | grep -o \"&lt;title&gt;.*&lt;/title&gt;\"\n\n# View TLS certificate information\nkubectl exec -it sleep -- curl -v productpage:9080 | grep \"SSL connection\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#solution-2-p2p-encryption-with-cilium","title":"Solution 2: P2P Encryption with Cilium","text":"<p>Cilium implements transparent encryption using IPsec or WireGuard for pod-to-pod traffic.</p>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Kubernetes cluster</li> <li>Helm (v3+)</li> <li><code>kubectl</code> CLI tool</li> </ul>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-1-install-cilium-with-encryption-enabled","title":"Step 1: Install Cilium with Encryption Enabled","text":""},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#using-ipsec-encryption","title":"Using IPsec Encryption:","text":"<pre><code># Create a secret for IPsec encryption keys\nkubectl create -n kube-system secret generic cilium-ipsec-keys \\\n  --from-literal=keys=\"3 rfc4106(gcm(aes)) $(echo $(dd if=/dev/urandom count=20 bs=1 2&gt; /dev/null | xxd -p -c 64)) 128\"\n\n# Install Cilium with IPsec encryption enabled\nhelm install cilium cilium/cilium --version 1.12.0 \\\n  --namespace kube-system \\\n  --set encryption.enabled=true \\\n  --set encryption.type=ipsec\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#using-wireguard-encryption-alternative","title":"Using WireGuard Encryption (alternative):","text":"<pre><code># Install Cilium with WireGuard encryption enabled\nhelm install cilium cilium/cilium --version 1.12.0 \\\n  --namespace kube-system \\\n  --set encryption.enabled=true \\\n  --set encryption.type=wireguard\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-2-verify-cilium-installation-with-encryption","title":"Step 2: Verify Cilium Installation with Encryption","text":"<pre><code># Check if Cilium is running correctly\nkubectl -n kube-system get pods -l k8s-app=cilium\n\n# Check Cilium status including encryption\nkubectl -n kube-system exec cilium-xxxx -- cilium status | grep Encryption\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-3-create-a-ciliumnetworkpolicy-to-enforce-encryption","title":"Step 3: Create a CiliumNetworkPolicy to Enforce Encryption","text":"<p>Cilium allows selective encryption using CiliumNetworkPolicy. Create a file named <code>encryption-policy.yaml</code>:</p> <pre><code>apiVersion: \"cilium.io/v2\"\nkind: CiliumNetworkPolicy\nmetadata:\n  name: \"encrypt-all-traffic\"\nspec:\n  endpointSelector:\n    matchLabels:\n      app: secure-app\n  egress:\n  - toEndpoints:\n    - matchLabels:\n        app: secure-backend\n    toPorts:\n    - ports:\n      - port: \"8080\"\n        protocol: TCP\n    encrypted: true\n</code></pre> <p>Apply the policy:</p> <pre><code>kubectl apply -f encryption-policy.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#step-4-testing-and-validating-cilium-encryption","title":"Step 4: Testing and Validating Cilium Encryption","text":"<p>Deploy test applications:</p> <pre><code># Deploy a test application\nkubectl apply -f - &lt;&lt;EOF\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: secure-app\nspec:\n  selector:\n    matchLabels:\n      app: secure-app\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: secure-app\n    spec:\n      containers:\n      - name: web\n        image: nginx\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: secure-backend\nspec:\n  selector:\n    matchLabels:\n      app: secure-backend\n  replicas: 2\n  template:\n    metadata:\n      labels:\n        app: secure-backend\n    spec:\n      containers:\n      - name: web\n        image: nginx\nEOF\n</code></pre> <p>Verify encryption:</p> <pre><code># For IPsec encryption, verify ESP packets\nkubectl exec -n kube-system cilium-xxxx -- cilium bpf tunnel list\n\n# For WireGuard encryption, verify WireGuard statistics\nkubectl exec -n kube-system cilium-xxxx -- cilium status --verbose | grep WireGuard\n</code></pre>"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#comparison-and-best-practices","title":"Comparison and Best Practices","text":""},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#istio-mtls-vs-cilium-encryption","title":"Istio mTLS vs. Cilium Encryption","text":"Feature Istio mTLS Cilium Encryption Layer Application (L7) Network (L3) Encryption Method TLS IPsec or WireGuard Performance Impact Moderate Low-Moderate Identity Verification Yes (x509 certs) Limited (IPsec PSK) Selective Encryption Yes (via policies) Yes (via policies) Observability High (detailed metrics) Basic"},{"location":"kubernetes/cks/exercises/p2p-encryption-istio-cilium/#best-practices","title":"Best Practices","text":"<ol> <li>Choose based on requirements:</li> <li>Use Istio for comprehensive service mesh features beyond encryption</li> <li> <p>Use Cilium for network-level security with lower overhead</p> </li> <li> <p>Layered Security:</p> </li> <li>Consider using both solutions for defense in depth</li> <li>Istio for service-to-service authentication</li> <li> <p>Cilium for network-level encryption</p> </li> <li> <p>Key Rotation:</p> </li> <li>For Istio: Configure automated certificate rotation (default: 24h)</li> <li> <p>For Cilium IPsec: Rotate encryption keys periodically</p> </li> <li> <p>Monitoring:</p> </li> <li>For Istio: Use Kiali, Grafana, and Prometheus for visibility</li> <li> <p>For Cilium: Use Hubble for network flow visibility</p> </li> <li> <p>Policy Testing:</p> </li> <li>Test encryption policies in non-production environments first</li> <li>Use Cilium\u2019s dry-run mode or Istio\u2019s permissive mode initially</li> </ol> <p>By implementing either or both of these solutions, you can ensure that pod-to-pod communications within your Kubernetes cluster remain secure and protected from eavesdropping or man-in-the-middle attacks.</p>"},{"location":"kubernetes/cks/exercises/pod-security-standards/","title":"Pod Security Standards (PSS): Overview and Implementation Guide","text":""},{"location":"kubernetes/cks/exercises/pod-security-standards/#introduction-to-pod-security-standards","title":"Introduction to Pod Security Standards","text":"<p>Pod Security Standards (PSS) is a feature in Kubernetes that defines different levels of security for pods. It replaced the deprecated PodSecurityPolicy (PSP) in Kubernetes 1.25. The PSS provides a standardized way to enforce security controls for pods, helping cluster administrators ensure workloads meet specific security requirements without needing to create and manage custom policies.</p>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#pss-profiles","title":"PSS Profiles","text":"<p>PSS defines three security profiles with increasing levels of restriction:</p> <ol> <li> <p>Privileged: Unrestricted policy, providing the widest possible level of permissions. This profile has essentially no restrictions on pod configuration.</p> </li> <li> <p>Baseline: Minimally restrictive policy which prevents known privilege escalations. Allows the default (minimally specified) pod configuration.</p> </li> <li> <p>Restricted: Heavily restricted policy, following current pod hardening best practices. This is the most secure profile, designed to enforce security best practices.</p> </li> </ol>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#pss-implementation-methods","title":"PSS Implementation Methods","text":"<p>There are three ways to implement Pod Security Standards:</p> <ol> <li> <p>Pod Security Admission Controller: Built into Kubernetes since v1.23, it can enforce the standards at the namespace level.</p> </li> <li> <p>Namespace Labels: Used to configure the Pod Security Admission Controller with different modes (enforce, audit, warn).</p> </li> <li> <p>3<sup>rd</sup> Party Solutions: Various tools like OPA/Gatekeeper, Kyverno, etc. can enforce PSS.</p> </li> </ol>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#pss-modes","title":"PSS Modes","text":"<p>Each profile can be applied in one of three modes:</p> <ol> <li>enforce: Policy violations will cause the pod to be rejected</li> <li>audit: Policy violations trigger audit annotations, but are allowed</li> <li>warn: Policy violations trigger user-facing warnings, but are allowed</li> </ol>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#exam-task-example-making-a-deployment-compatible-with-pss-restricted","title":"Exam Task Example: Making a Deployment Compatible with PSS-Restricted","text":""},{"location":"kubernetes/cks/exercises/pod-security-standards/#task-description","title":"Task Description","text":"<p>Create a deployment that is compatible with the Pod Security Standard \u201crestricted\u201d profile in enforce mode. The deployment should run a container that: 1. Reads and writes to a persistent volume 2. Exposes port 8080 3. Runs as a non-root user 4. Meets all the requirements of the restricted profile</p>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#solution","title":"Solution","text":""},{"location":"kubernetes/cks/exercises/pod-security-standards/#step-1-configure-namespace-with-pss","title":"Step 1: Configure Namespace with PSS","text":"<p>First, let\u2019s create a namespace with the restricted profile in enforce mode:</p> <pre><code>kubectl create namespace pss-restricted\nkubectl label --overwrite ns pss-restricted \\\n  pod-security.kubernetes.io/enforce=restricted \\\n  pod-security.kubernetes.io/warn=restricted \\\n  pod-security.kubernetes.io/audit=restricted\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#step-2-create-a-compliant-deployment","title":"Step 2: Create a Compliant Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: pss-restricted-app\n  namespace: pss-restricted\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: pss-restricted-app\n  template:\n    metadata:\n      labels:\n        app: pss-restricted-app\n    spec:\n      # Security Context at Pod level\n      securityContext:\n        runAsNonRoot: true\n        seccompProfile:\n          type: RuntimeDefault\n      containers:\n      - name: app\n        image: nginx:1.21\n        # Container Security Context\n        securityContext:\n          allowPrivilegeEscalation: false\n          capabilities:\n            drop:\n            - ALL\n          runAsUser: 1000\n          runAsGroup: 3000\n          seccompProfile:\n            type: RuntimeDefault\n          readOnlyRootFilesystem: true\n        ports:\n        - containerPort: 8080\n        resources:\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n        volumeMounts:\n        - name: data-volume\n          mountPath: /data\n          readOnly: false\n        - name: tmp-volume\n          mountPath: /tmp\n      volumes:\n      - name: data-volume\n        persistentVolumeClaim:\n          claimName: pss-restricted-pvc\n      - name: tmp-volume\n        emptyDir: {}\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#step-3-create-the-persistent-volume-claim","title":"Step 3: Create the Persistent Volume Claim","text":"<pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: pss-restricted-pvc\n  namespace: pss-restricted\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n  storageClassName: standard\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#step-4-apply-the-configuration","title":"Step 4: Apply the Configuration","text":"<pre><code>kubectl apply -f pss-pvc.yaml\nkubectl apply -f pss-deployment.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#step-5-verify-deployment-status","title":"Step 5: Verify Deployment Status","text":"<pre><code>kubectl get deployment -n pss-restricted\nkubectl describe deployment pss-restricted-app -n pss-restricted\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#key-pss-restricted-requirements-explained","title":"Key PSS Restricted Requirements Explained","text":"<p>When the Pod Security Standard enforces the restricted profile, the following security requirements must be met:</p> <ol> <li>Pod-level Requirements:</li> <li><code>securityContext.runAsNonRoot: true</code>: Ensures pods run as non-root users</li> <li> <p><code>securityContext.seccompProfile.type: RuntimeDefault</code>: Enables default seccomp profile</p> </li> <li> <p>Container-level Requirements:</p> </li> <li><code>securityContext.allowPrivilegeEscalation: false</code>: Prevents privilege escalation</li> <li><code>securityContext.capabilities.drop: [\"ALL\"]</code>: Drops all Linux capabilities</li> <li><code>securityContext.runAsUser</code> and <code>runAsGroup</code>: Explicit non-zero user/group IDs</li> <li><code>securityContext.seccompProfile.type: RuntimeDefault</code>: Enables seccomp at container level</li> <li> <p><code>readOnlyRootFilesystem: true</code>: Makes root filesystem read-only</p> </li> <li> <p>Volume-related Considerations:</p> </li> <li>When a read-only root filesystem is used, you must provide writable volumes for paths like <code>/tmp</code></li> <li> <p>PersistentVolumeClaims are allowed and need appropriate mount paths</p> </li> <li> <p>Prohibited configurations:</p> </li> <li><code>hostPath</code> volumes</li> <li><code>hostNetwork</code>, <code>hostIPC</code>, and <code>hostPID</code> set to true</li> <li><code>privileged</code> containers</li> <li>Adding capabilities beyond a minimal set</li> <li>HostPort usage</li> </ol>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#common-issues-and-troubleshooting","title":"Common Issues and Troubleshooting","text":"<p>When working with PSS in restricted mode, you might encounter the following issues:</p> <ol> <li> <p>Pod Rejection Errors: If a pod is rejected, check the error message from kubectl, which will specify which PSS policy was violated.</p> </li> <li> <p>Runtime Failures: Even if a pod starts, it might fail if it needs to write to locations that are now read-only.</p> </li> <li> <p>Legacy Applications: Older applications often assume root access or specific capabilities, requiring refactoring.</p> </li> </ol>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#troubleshooting-commands","title":"Troubleshooting Commands","text":"<pre><code># Check if pod was rejected due to PSS violations\nkubectl get events -n pss-restricted\n\n# Check audit annotations for violations\nkubectl get pod &lt;pod-name&gt; -n pss-restricted -o yaml | grep \"audit\"\n\n# Check warning events\nkubectl get events -n pss-restricted | grep Warning\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#additional-exam-task-examples","title":"Additional Exam Task Examples","text":""},{"location":"kubernetes/cks/exercises/pod-security-standards/#task-1-configure-a-namespace-for-pss-audit-mode","title":"Task 1: Configure a Namespace for PSS Audit Mode","text":"<p>Create a namespace that audits according to the restricted profile but only enforces the baseline profile.</p> <pre><code>kubectl create namespace mixed-pss\nkubectl label --overwrite ns mixed-pss \\\n  pod-security.kubernetes.io/enforce=baseline \\\n  pod-security.kubernetes.io/audit=restricted \\\n  pod-security.kubernetes.io/warn=restricted\n</code></pre>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#task-2-troubleshoot-a-pod-failing-due-to-pss-restrictions","title":"Task 2: Troubleshoot a Pod Failing Due to PSS Restrictions","text":"<p>Given a pod that is failing to deploy in a namespace with PSS restricted enforcement, identify and fix the issues.</p> <p>Original pod manifest: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: privileged-pod\n  namespace: pss-restricted\nspec:\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - containerPort: 80\n    securityContext:\n      privileged: true  # Violation! \n</code></pre></p> <p>Fixed pod manifest: <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: compliant-pod\n  namespace: pss-restricted\nspec:\n  securityContext:\n    runAsNonRoot: true\n    seccompProfile:\n      type: RuntimeDefault\n  containers:\n  - name: web\n    image: nginx\n    ports:\n    - containerPort: 80\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop:\n        - ALL\n      runAsUser: 101  # nginx user\n      runAsGroup: 101\n      seccompProfile:\n        type: RuntimeDefault\n</code></pre></p>"},{"location":"kubernetes/cks/exercises/pod-security-standards/#conclusion","title":"Conclusion","text":"<p>Pod Security Standards provide a robust framework for securing Kubernetes workloads. Understanding the different profiles and their requirements is essential for creating secure deployments that can run in restricted environments. When working with the restricted profile:</p> <ol> <li>Always specify non-root users</li> <li>Drop ALL capabilities at the container level</li> <li>Prevent privilege escalation</li> <li>Use appropriate seccomp profiles</li> <li>Make root filesystems read-only when possible</li> <li>Use emptyDir volumes for temporary writable storage</li> </ol> <p>By following these practices, you can ensure your workloads are compatible with Kubernetes security best practices and can run in environments with strict security requirements.</p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/","title":"Static Security Analysis","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#dockerfile-security-analysis","title":"Dockerfile Security Analysis","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#key-security-issues-to-look-for","title":"Key Security Issues to Look For","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#1-running-as-root-user","title":"1. Running as Root User","text":"<pre><code># \u274c BAD - Running as root\nFROM ubuntu:20.04\nRUN apt-get update &amp;&amp; apt-get install -y nginx\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n\n# \u2705 GOOD - Non-root user\nFROM ubuntu:20.04\nRUN apt-get update &amp;&amp; apt-get install -y nginx\nRUN useradd -r -s /bin/false nginx-user\nUSER nginx-user\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#2-secrets-in-image-layers","title":"2. Secrets in Image Layers","text":"<pre><code># \u274c BAD - Hardcoded secrets\nFROM node:14\nENV API_KEY=sk-1234567890abcdef\nENV DATABASE_PASSWORD=super-secret-password\nCOPY . /app\n\n# \u2705 GOOD - No secrets in Dockerfile\nFROM node:14\n# Secrets should be passed at runtime via K8s secrets\nCOPY . /app\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#3-unnecessary-packages-and-attack-surface","title":"3. Unnecessary Packages and Attack Surface","text":"<pre><code># \u274c BAD - Full OS with unnecessary packages\nFROM ubuntu:20.04\nRUN apt-get update &amp;&amp; apt-get install -y \\\n    curl wget git vim nano ssh openssh-server\n\n# \u2705 GOOD - Minimal base image\nFROM node:14-alpine\n# Only install what's needed\nRUN apk add --no-cache dumb-init\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#4-improper-file-permissions","title":"4. Improper File Permissions","text":"<pre><code># \u274c BAD - World-writable files\nFROM alpine\nCOPY --chmod=777 app.sh /usr/local/bin/\nCOPY --chmod=666 config.json /etc/\n\n# \u2705 GOOD - Restrictive permissions\nFROM alpine\nCOPY --chmod=755 app.sh /usr/local/bin/\nCOPY --chmod=644 config.json /etc/\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#5-using-latest-tags","title":"5. Using Latest Tags","text":"<pre><code># \u274c BAD - Unpredictable base image\nFROM node:latest\nFROM ubuntu:latest\n\n# \u2705 GOOD - Specific versions\nFROM node:14.21.3-alpine\nFROM ubuntu:20.04\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#kubernetes-manifest-security-analysis","title":"Kubernetes Manifest Security Analysis","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#key-security-issues-to-look-for_1","title":"Key Security Issues to Look For","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#1-missing-security-context","title":"1. Missing Security Context","text":"<pre><code># \u274c BAD - No security context\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: insecure-app\nspec:\n  template:\n    spec:\n      containers:\n      - name: app\n        image: nginx:1.20\n\n# \u2705 GOOD - Proper security context\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: secure-app\nspec:\n  template:\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n        runAsGroup: 1000\n        fsGroup: 1000\n      containers:\n      - name: app\n        image: nginx:1.20\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - ALL\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#2-privileged-containers","title":"2. Privileged Containers","text":"<pre><code># \u274c BAD - Privileged container\ncontainers:\n- name: dangerous-app\n  image: app:1.0\n  securityContext:\n    privileged: true\n\n# \u2705 GOOD - Non-privileged with specific capabilities\ncontainers:\n- name: safe-app\n  image: app:1.0\n  securityContext:\n    privileged: false\n    capabilities:\n      add:\n      - NET_BIND_SERVICE\n      drop:\n      - ALL\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#3-missing-resource-limits","title":"3. Missing Resource Limits","text":"<pre><code># \u274c BAD - No resource limits\ncontainers:\n- name: resource-hog\n  image: app:1.0\n\n# \u2705 GOOD - Resource limits set\ncontainers:\n- name: limited-app\n  image: app:1.0\n  resources:\n    limits:\n      memory: \"512Mi\"\n      cpu: \"500m\"\n    requests:\n      memory: \"256Mi\"\n      cpu: \"250m\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#4-secrets-in-environment-variables","title":"4. Secrets in Environment Variables","text":"<pre><code># \u274c BAD - Secrets in plain text env vars\ncontainers:\n- name: app\n  image: myapp:1.0\n  env:\n  - name: DB_PASSWORD\n    value: \"super-secret-password\"\n  - name: API_KEY\n    value: \"sk-1234567890\"\n\n# \u2705 GOOD - Using Kubernetes secrets\ncontainers:\n- name: app\n  image: myapp:1.0\n  env:\n  - name: DB_PASSWORD\n    valueFrom:\n      secretKeyRef:\n        name: db-secret\n        key: password\n  - name: API_KEY\n    valueFrom:\n      secretKeyRef:\n        name: api-secret\n        key: api-key\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#5-network-policies-missing","title":"5. Network Policies Missing","text":"<pre><code># \u274c BAD - No network restrictions\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\n# No NetworkPolicy defined\n\n# \u2705 GOOD - With NetworkPolicy\napiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: web-app-netpol\nspec:\n  podSelector:\n    matchLabels:\n      app: web-app\n  policyTypes:\n  - Ingress\n  - Egress\n  ingress:\n  - from:\n    - podSelector:\n        matchLabels:\n          app: frontend\n    ports:\n    - protocol: TCP\n      port: 8080\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#tools-for-static-analysis","title":"Tools for Static Analysis","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#1-trivy-recommended-for-exams","title":"1. Trivy (Recommended for exams)","text":"<pre><code># Scan Dockerfile\ntrivy config Dockerfile\n\n# Scan Kubernetes manifests\ntrivy config k8s-manifests/\n\n# Scan specific manifest\ntrivy config deployment.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#2-checkov","title":"2. Checkov","text":"<pre><code># Install\npip install checkov\n\n# Scan Dockerfile\ncheckov -f Dockerfile\n\n# Scan Kubernetes manifests\ncheckov -d k8s-manifests/\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#3-kubesec","title":"3. Kubesec","text":"<pre><code># Online tool\ncurl -sSX POST --data-binary @deployment.yaml https://v2.kubesec.io/scan\n\n# Local installation\nkubesec scan deployment.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#4-kube-score","title":"4. Kube-score","text":"<pre><code># Install\nkubectl krew install score\n\n# Analyze manifest\nkubectl score deployment.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#common-exam-questions","title":"Common Exam Questions","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#question-type-1-identify-security-issues","title":"Question Type 1: \u201cIdentify Security Issues\u201d","text":"<p>Prompt: \u201cAnalyze the following Dockerfile and identify at least 3 security vulnerabilities\u201d</p> <p>Approach: 1. Look for root user usage 2. Check for hardcoded secrets 3. Verify base image tags 4. Check file permissions 5. Look for unnecessary packages</p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#question-type-2-fix-security-issues","title":"Question Type 2: \u201cFix Security Issues\u201d","text":"<p>Prompt: \u201cFix the security issues in the following Kubernetes deployment manifest\u201d</p> <p>Approach: 1. Add securityContext 2. Set resource limits 3. Use secrets instead of plain env vars 4. Ensure non-root execution 5. Add readiness/liveness probes</p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#question-type-3-use-tool-for-analysis","title":"Question Type 3: \u201cUse Tool for Analysis\u201d","text":"<p>Prompt: \u201cUse trivy to scan the provided manifest and fix the HIGH severity issues\u201d</p> <p>Approach: 1. Run trivy scan 2. Identify HIGH severity findings 3. Apply fixes systematically 4. Re-scan to verify</p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#step-by-step-solutions","title":"Step-by-Step Solutions","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#scenario-1-dockerfile-analysis","title":"Scenario 1: Dockerfile Analysis","text":"<p>Given Dockerfile: <pre><code>FROM ubuntu:latest\nRUN apt-get update &amp;&amp; apt-get install -y curl wget git\nENV SECRET_KEY=abc123\nCOPY app.py /app/\nRUN chmod 777 /app/app.py\nCMD [\"python\", \"/app/app.py\"]\n</code></pre></p> <p>Step 1: Identify Issues <pre><code># Run trivy scan\ntrivy config Dockerfile\n</code></pre></p> <p>Step 2: Issues Found - Using <code>latest</code> tag (unpredictable) - Running as root user - Hardcoded secret in ENV - Overly permissive file permissions (777) - Unnecessary packages installed</p> <p>Step 3: Fixed Dockerfile <pre><code>FROM ubuntu:20.04\nRUN apt-get update &amp;&amp; apt-get install -y python3 &amp;&amp; \\\n    apt-get clean &amp;&amp; rm -rf /var/lib/apt/lists/*\nRUN useradd -r -s /bin/false appuser\nCOPY --chown=appuser:appuser --chmod=644 app.py /app/\nUSER appuser\nCMD [\"python3\", \"/app/app.py\"]\n</code></pre></p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#scenario-2-kubernetes-manifest-analysis","title":"Scenario 2: Kubernetes Manifest Analysis","text":"<p>Given Deployment: <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      containers:\n      - name: web\n        image: nginx:latest\n        env:\n        - name: DB_PASSWORD\n          value: \"secretpassword\"\n</code></pre></p> <p>Step 1: Scan with Tools <pre><code>trivy config deployment.yaml\nkubesec scan deployment.yaml\n</code></pre></p> <p>Step 2: Issues Identified - No security context - Using latest tag - Secret in plain text env var - No resource limits - Missing health checks</p> <p>Step 3: Fixed Deployment <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: web-app\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: web-app\n  template:\n    metadata:\n      labels:\n        app: web-app\n    spec:\n      securityContext:\n        runAsNonRoot: true\n        runAsUser: 1000\n        fsGroup: 1000\n      containers:\n      - name: web\n        image: nginx:1.21.6-alpine\n        securityContext:\n          allowPrivilegeEscalation: false\n          readOnlyRootFilesystem: true\n          runAsNonRoot: true\n          capabilities:\n            drop:\n            - ALL\n        env:\n        - name: DB_PASSWORD\n          valueFrom:\n            secretKeyRef:\n              name: db-secret\n              key: password\n        resources:\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n        livenessProbe:\n          httpGet:\n            path: /healthz\n            port: 8080\n          initialDelaySeconds: 30\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 8080\n          initialDelaySeconds: 5\n        volumeMounts:\n        - name: tmp-volume\n          mountPath: /tmp\n        - name: var-cache\n          mountPath: /var/cache/nginx\n      volumes:\n      - name: tmp-volume\n        emptyDir: {}\n      - name: var-cache\n        emptyDir: {}\n</code></pre></p>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#remediation-examples","title":"Remediation Examples","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#security-context-best-practices","title":"Security Context Best Practices","text":"<pre><code># Complete security context example\nsecurityContext:\n  # Pod-level\n  runAsNonRoot: true\n  runAsUser: 1000\n  runAsGroup: 1000\n  fsGroup: 1000\n  seccompProfile:\n    type: RuntimeDefault\n\ncontainers:\n- name: app\n  securityContext:\n    # Container-level\n    allowPrivilegeEscalation: false\n    readOnlyRootFilesystem: true\n    runAsNonRoot: true\n    runAsUser: 1000\n    capabilities:\n      drop:\n      - ALL\n      add:\n      - NET_BIND_SERVICE  # Only if needed\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#resource-management","title":"Resource Management","text":"<pre><code>resources:\n  limits:\n    memory: \"512Mi\"\n    cpu: \"500m\"\n    ephemeral-storage: \"1Gi\"\n  requests:\n    memory: \"256Mi\"\n    cpu: \"250m\"\n    ephemeral-storage: \"500Mi\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#secrets-management","title":"Secrets Management","text":"<pre><code># Create secret first\napiVersion: v1\nkind: Secret\nmetadata:\n  name: app-secrets\ntype: Opaque\ndata:\n  api-key: &lt;base64-encoded-value&gt;\n  db-password: &lt;base64-encoded-value&gt;\n\n# Reference in deployment\nenv:\n- name: API_KEY\n  valueFrom:\n    secretKeyRef:\n      name: app-secrets\n      key: api-key\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#exam-tips","title":"Exam Tips","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#time-management","title":"Time Management","text":"<ol> <li>Quick Scan First: Use automated tools to identify obvious issues</li> <li>Prioritize: Focus on HIGH/CRITICAL severity issues first</li> <li>Systematic Approach: Check each category methodically</li> </ol>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#common-commands-to-remember","title":"Common Commands to Remember","text":"<pre><code># Trivy scanning\ntrivy config .\ntrivy image nginx:latest\n\n# Kubesec analysis\nkubesec scan pod.yaml\n\n# Kubectl dry-run for validation\nkubectl apply --dry-run=client -f manifest.yaml\n\n# Check security context\nkubectl get pod -o jsonpath='{.spec.securityContext}'\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#checklist-for-quick-review","title":"Checklist for Quick Review","text":"<ul> <li>[ ] Non-root user execution</li> <li>[ ] No hardcoded secrets</li> <li>[ ] Specific image tags (not latest)</li> <li>[ ] Resource limits set</li> <li>[ ] Security context configured</li> <li>[ ] Minimal attack surface</li> <li>[ ] Health checks present</li> <li>[ ] Network policies defined</li> </ul>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#practice-exercises","title":"Practice Exercises","text":""},{"location":"kubernetes/cks/exercises/security-static-analysis/#exercise-1-fix-this-dockerfile","title":"Exercise 1: Fix This Dockerfile","text":"<pre><code>FROM node:latest\nRUN apt-get update &amp;&amp; apt-get install -y vim curl wget git\nENV JWT_SECRET=mysecretkey123\nCOPY . /app\nWORKDIR /app\nRUN npm install\nEXPOSE 3000\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"kubernetes/cks/exercises/security-static-analysis/#exercise-2-secure-this-deployment","title":"Exercise 2: Secure This Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: api-server\nspec:\n  template:\n    spec:\n      containers:\n      - name: api\n        image: myapi:latest\n        env:\n        - name: DATABASE_URL\n          value: \"postgres://user:password@db:5432/mydb\"\n        ports:\n        - containerPort: 8080\n</code></pre> <p>Solutions available upon request or can be worked through using the guidelines above.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/","title":"Kubelet Configuration Exam Exercises","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#overview","title":"Overview","text":"<p>This document contains comprehensive exam exercises for modifying and managing Kubelet configuration. Each exercise covers different aspects of Kubelet configuration management, from basic parameter changes to advanced cluster-wide configuration scenarios.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-1-basic-kubelet-configuration-file-management","title":"Exercise 1: Basic Kubelet Configuration File Management","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario","title":"Scenario","text":"<p>You need to modify the Kubelet configuration on a worker node to change basic operational parameters.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks","title":"Tasks","text":"<ol> <li>Locate the current Kubelet configuration file</li> <li>Modify the following parameters:</li> <li>Change the cluster DNS to <code>10.96.0.10</code></li> <li>Set the maximum number of pods per node to 200</li> <li>Enable CPU and Memory manager policies</li> <li>Configure log rotation settings</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#configuration-file-example","title":"Configuration File Example","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\naddress: 0.0.0.0\nport: 10250\nserializeImagePulls: false\nclusterDNS:\n- 10.96.0.10\nclusterDomain: cluster.local\nmaxPods: 200\ncpuManagerPolicy: static\nmemoryManagerPolicy: Static\nlogRotateMaxSize: 100Mi\nlogRotateMaxBackups: 5\nlogRotateMaxAge: 7\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#steps-to-complete","title":"Steps to Complete","text":"<ol> <li> <p>Back up the existing configuration: <pre><code>sudo cp /var/lib/kubelet/config.yaml /var/lib/kubelet/config.yaml.backup\n</code></pre></p> </li> <li> <p>Edit the configuration file: <pre><code>sudo vim /var/lib/kubelet/config.yaml\n</code></pre></p> </li> <li> <p>Restart the Kubelet service: <pre><code>sudo systemctl restart kubelet\n</code></pre></p> </li> <li> <p>Verify the changes: <pre><code>sudo systemctl status kubelet\nkubectl get nodes -o wide\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Kubelet restarts successfully with new configuration</li> <li>Node shows updated capacity and allocatable resources</li> <li>DNS resolution works with the new cluster DNS</li> <li>Pod limit is enforced according to new maxPods setting</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-2-kubeadm-upgrade-node-phase-configuration","title":"Exercise 2: Kubeadm Upgrade Node Phase Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_1","title":"Scenario","text":"<p>Use kubeadm to upgrade the kubelet configuration during a cluster upgrade process.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_1","title":"Tasks","text":"<ol> <li>Perform kubelet configuration upgrade using kubeadm</li> <li>Verify the upgraded configuration</li> <li>Handle any conflicts between old and new configurations</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#pre-upgrade-preparation","title":"Pre-upgrade Preparation","text":"<pre><code># Check current kubelet version\nkubelet --version\n\n# Check current node configuration\nkubectl get node $(hostname) -o yaml | grep kubeletVersion\n\n# Backup current configuration\nsudo cp /var/lib/kubelet/config.yaml /var/lib/kubelet/config.yaml.pre-upgrade\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#kubeadm-upgrade-process","title":"Kubeadm Upgrade Process","text":"<pre><code># Download the new kubelet configuration from the cluster\nsudo kubeadm upgrade node phase kubelet-config\n\n# Restart kubelet to apply the new configuration\nsudo systemctl restart kubelet\n\n# Verify the upgrade\nsudo systemctl status kubelet\nkubectl get nodes\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#post-upgrade-verification","title":"Post-upgrade Verification","text":"<pre><code># Check if kubelet is running with new config\nps aux | grep kubelet\n\n# Verify node readiness\nkubectl describe node $(hostname)\n\n# Check for any configuration differences\ndiff /var/lib/kubelet/config.yaml.pre-upgrade /var/lib/kubelet/config.yaml\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_1","title":"Expected Outcomes","text":"<ul> <li>Kubelet configuration is updated to match cluster version</li> <li>Node remains in Ready state after upgrade</li> <li>No configuration conflicts exist</li> <li>Kubelet version matches the target cluster version</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-3-resource-management-configuration","title":"Exercise 3: Resource Management Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_2","title":"Scenario","text":"<p>Configure Kubelet for optimal resource management in a high-performance computing environment.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_2","title":"Tasks","text":"<ol> <li>Configure CPU Manager with static policy</li> <li>Set up Memory Manager with static policy</li> <li>Configure Topology Manager for NUMA awareness</li> <li>Set up custom resource reservations for system components</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#advanced-resource-configuration","title":"Advanced Resource Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# CPU Management\ncpuManagerPolicy: static\ncpuManagerPolicyOptions:\n  full-pcpus-only: true\ncpuManagerReconcilePeriod: 10s\n\n# Memory Management\nmemoryManagerPolicy: Static\n\n# Topology Management\ntopologyManagerPolicy: single-numa-node\ntopologyManagerScope: pod\n\n# Resource Reservations\nsystemReserved:\n  cpu: 500m\n  memory: 1Gi\n  ephemeral-storage: 2Gi\nkubeReserved:\n  cpu: 500m\n  memory: 1Gi\n  ephemeral-storage: 1Gi\nevictionHard:\n  memory.available: \"100Mi\"\n  nodefs.available: \"10%\"\n  nodefs.inodesFree: \"5%\"\n  imagefs.available: \"15%\"\n\n# Container Runtime\ncontainerRuntimeEndpoint: unix:///var/run/containerd/containerd.sock\nimageServiceEndpoint: unix:///var/run/containerd/containerd.sock\n\n# Feature Gates\nfeatureGates:\n  CPUManager: true\n  MemoryManager: true\n  TopologyManager: true\n  KubeletPodResources: true\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#pre-configuration-setup","title":"Pre-configuration Setup","text":"<pre><code># Clear CPU manager state (if changing policy)\nsudo systemctl stop kubelet\nsudo rm -f /var/lib/kubelet/cpu_manager_state\nsudo rm -f /var/lib/kubelet/memory_manager_state\n\n# Apply the new configuration\nsudo cp new-kubelet-config.yaml /var/lib/kubelet/config.yaml\n\n# Restart kubelet\nsudo systemctl start kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#verification-commands","title":"Verification Commands","text":"<pre><code># Check CPU manager status\nls -la /var/lib/kubelet/cpu_manager_state\ncat /var/lib/kubelet/cpu_manager_state\n\n# Verify resource allocation\nkubectl describe nodes\n\n# Check feature gates\nkubectl get --raw /api/v1/nodes/$(hostname)/proxy/configz | jq '.kubeletconfig.featureGates'\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_2","title":"Expected Outcomes","text":"<ul> <li>CPU Manager allocates exclusive CPU cores to guaranteed pods</li> <li>Memory Manager provides NUMA-local memory allocation</li> <li>Topology Manager ensures NUMA affinity</li> <li>System and Kube reserved resources are properly allocated</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-4-security-and-authentication-configuration","title":"Exercise 4: Security and Authentication Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_3","title":"Scenario","text":"<p>Harden Kubelet security by configuring authentication, authorization, and TLS settings.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_3","title":"Tasks","text":"<ol> <li>Enable Webhook authentication and authorization</li> <li>Configure TLS certificate rotation</li> <li>Set up admission controllers</li> <li>Configure security contexts and AppArmor profiles</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#security-configuration","title":"Security Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# Authentication\nauthentication:\n  anonymous:\n    enabled: false\n  webhook:\n    enabled: true\n    cacheTTL: 30s\n  x509:\n    clientCAFile: /etc/kubernetes/pki/ca.crt\n\n# Authorization\nauthorization:\n  mode: Webhook\n  webhook:\n    cacheAuthorizedTTL: 5m\n    cacheUnauthorizedTTL: 30s\n\n# TLS Configuration\ntlsCertFile: /var/lib/kubelet/pki/kubelet.crt\ntlsPrivateKeyFile: /var/lib/kubelet/pki/kubelet.key\nrotateCertificates: true\nserverTLSBootstrap: true\n\n# Security Settings\nprotectKernelDefaults: true\nmakeIPTablesUtilChains: true\niptablesMasqueradeBit: 14\niptablesDropBit: 15\n\n# Runtime Security\nallowPrivileged: false\nhostNetworkSources: []\nhostPIDSources: []\nhostIPCSources: []\n\n# Admission Controllers\nenableAdmissionPlugins:\n- NamespaceLifecycle\n- LimitRanger\n- ServiceAccount\n- DefaultStorageClass\n- DefaultTolerationSeconds\n- MutatingAdmissionWebhook\n- ValidatingAdmissionWebhook\n- ResourceQuota\n- NodeRestriction\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#configuration-update-steps","title":"Configuration Update Steps","text":"<pre><code># Apply the security configuration\nsudo cp security-kubelet-config.yaml /var/lib/kubelet/config.yaml\n\n# Restart kubelet to apply changes\nsudo systemctl restart kubelet\n\n# Verify security settings are active\nsudo systemctl status kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#security-verification","title":"Security Verification","text":"<pre><code># Test authentication\ncurl -k --cert /var/lib/kubelet/pki/kubelet.crt \\\n     --key /var/lib/kubelet/pki/kubelet.key \\\n     https://localhost:10250/metrics\n\n# Verify certificate rotation\nkubectl get csr | grep kubelet\n\n# Check security settings\nkubectl auth can-i --list --as=system:node:$(hostname)\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_3","title":"Expected Outcomes","text":"<ul> <li>Anonymous access is disabled</li> <li>Webhook authentication and authorization work</li> <li>TLS certificates are properly configured and rotating</li> <li>Security policies are enforced</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-5-logging-and-monitoring-configuration","title":"Exercise 5: Logging and Monitoring Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_4","title":"Scenario","text":"<p>Configure comprehensive logging and monitoring for Kubelet operations.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_4","title":"Tasks","text":"<ol> <li>Configure structured logging</li> <li>Set up log rotation and retention</li> <li>Enable metrics collection</li> <li>Configure event recording and retention</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#logging-and-monitoring-configuration","title":"Logging and Monitoring Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# Logging Configuration\nlogging:\n  format: json\n  flushFrequency: 5s\n  verbosity: 2\n  options:\n    json:\n      infoBufferSize: \"0\"\n\n# Log Rotation\nlogRotateMaxSize: 100Mi\nlogRotateMaxBackups: 5\nlogRotateMaxAge: 7\n\n# Container Log Management\ncontainerLogMaxSize: 50Mi\ncontainerLogMaxFiles: 5\n\n# Event Configuration\neventRecordQPS: 50\neventBurst: 100\neventTTL: 1h\n\n# Metrics\nenableProfilingHandler: true\nenableDebuggingHandlers: true\nmetricsBindAddress: 0.0.0.0:10255\n\n# Health Checks\nhealthzBindAddress: 0.0.0.0:10248\nhealthzPort: 10248\n\n# Node Status\nnodeStatusMaxImages: 50\nnodeStatusUpdateFrequency: 10s\nnodeStatusReportFrequency: 5m\n\n# Runtime Monitoring\nruntimeRequestTimeout: 10m\nimageMinimumGCAge: 2m\nimageGCHighThresholdPercent: 85\nimageGCLowThresholdPercent: 80\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#apply-configuration","title":"Apply Configuration","text":"<pre><code># Update kubelet configuration\nsudo cp logging-kubelet-config.yaml /var/lib/kubelet/config.yaml\n\n# Restart kubelet\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#monitoring-commands","title":"Monitoring Commands","text":"<pre><code># Check Kubelet metrics\ncurl http://localhost:10255/metrics\n\n# Monitor health endpoint\ncurl http://localhost:10248/healthz\n\n# View structured logs\njournalctl -u kubelet -o json-pretty\n\n# Check event logs\nkubectl get events --field-selector involvedObject.kind=Node\n\n# Monitor resource usage\nkubectl top nodes\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_4","title":"Expected Outcomes","text":"<ul> <li>Structured JSON logging is enabled</li> <li>Log rotation works correctly</li> <li>Metrics are accessible and properly formatted</li> <li>Events are recorded and retained appropriately</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-6-container-runtime-configuration","title":"Exercise 6: Container Runtime Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_5","title":"Scenario","text":"<p>Configure Kubelet to work with different container runtimes and optimize container operations.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_5","title":"Tasks","text":"<ol> <li>Configure containerd runtime settings</li> <li>Set up image pull policies and parallel pulls</li> <li>Configure registry authentication</li> <li>Optimize container lifecycle management</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#container-runtime-configuration","title":"Container Runtime Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# Container Runtime\ncontainerRuntimeEndpoint: unix:///var/run/containerd/containerd.sock\nimageServiceEndpoint: unix:///var/run/containerd/containerd.sock\n\n# Image Management\nimageMinimumGCAge: 2m\nimageGCHighThresholdPercent: 85\nimageGCLowThresholdPercent: 80\nserializeImagePulls: false\nmaxParallelImagePulls: 5\n\n# Registry Configuration\nregistryPullQPS: 10\nregistryBurst: 20\n\n# Container Lifecycle\nstreamingConnectionIdleTimeout: 4h\ndockerDisableSharedPID: false\npodPidsLimit: 4096\n\n# Runtime Class Support\nruntimeRequestTimeout: 10m\n\n# Volume Configuration\nvolumePluginDir: /usr/libexec/kubernetes/kubelet-plugins/volume/exec/\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#apply-configuration_1","title":"Apply Configuration","text":"<pre><code># Update configuration\nsudo cp runtime-kubelet-config.yaml /var/lib/kubelet/config.yaml\n\n# Restart kubelet\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#verification-commands_1","title":"Verification Commands","text":"<pre><code># Test runtime connection\nsudo crictl version\n\n# Check image operations\nsudo crictl images\nsudo crictl pull nginx:latest\n\n# Monitor container runtime\nsudo crictl stats\nsudo crictl ps\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_5","title":"Expected Outcomes","text":"<ul> <li>Containerd runtime is properly configured</li> <li>Image pulls work efficiently with parallel downloads</li> <li>Container lifecycle operations are optimized</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-7-node-taints-labels-and-scheduling-configuration","title":"Exercise 7: Node Taints, Labels, and Scheduling Configuration","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_6","title":"Scenario","text":"<p>Configure Kubelet to properly handle node scheduling, taints, and labels for workload placement.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_6","title":"Tasks","text":"<ol> <li>Configure node labels and annotations</li> <li>Set up node taints for specialized workloads</li> <li>Configure scheduling policies</li> <li>Implement node cordoning and draining procedures</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#node-configuration","title":"Node Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# Node Labels\nnodeLabels:\n  node-type: compute\n  hardware: gpu\n  zone: us-west-1a\n  instance-type: m5.xlarge\n\n# Provider Configuration\nproviderID: aws:///us-west-1a/i-1234567890abcdef0\ncloudProvider: aws\n\n# Scheduling Configuration\nmaxPods: 110\npodsPerCore: 0\n\n# Node Status\nnodeStatusUpdateFrequency: 10s\nnodeStatusReportFrequency: 5m\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#apply-configuration-and-node-management","title":"Apply Configuration and Node Management","text":"<pre><code># Apply kubelet configuration\nsudo cp node-kubelet-config.yaml /var/lib/kubelet/config.yaml\nsudo systemctl restart kubelet\n\n# Add node labels\nkubectl label nodes worker-node-1 hardware=gpu\nkubectl label nodes worker-node-1 workload-type=ml\n\n# Add node taints\nkubectl taint nodes worker-node-1 dedicated=gpu:NoSchedule\nkubectl taint nodes worker-node-1 gpu=true:NoExecute\n\n# Configure node annotations\nkubectl annotate nodes worker-node-1 cluster-autoscaler.kubernetes.io/scale-down-disabled=true\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#node-maintenance-commands","title":"Node Maintenance Commands","text":"<pre><code># Cordon node (prevent new pods)\nkubectl cordon worker-node-1\n\n# Drain node (remove existing pods)\nkubectl drain worker-node-1 --ignore-daemonsets --delete-emptydir-data\n\n# Uncordon node (allow scheduling)\nkubectl uncordon worker-node-1\n\n# Check node scheduling status\nkubectl get nodes -o wide\nkubectl describe node worker-node-1\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_6","title":"Expected Outcomes","text":"<ul> <li>Node labels and taints are properly applied</li> <li>Specialized workloads schedule correctly</li> <li>Node maintenance operations work smoothly</li> <li>Scheduling policies are enforced</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-8-performance-tuning-and-optimization","title":"Exercise 8: Performance Tuning and Optimization","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_7","title":"Scenario","text":"<p>Optimize Kubelet configuration for high-performance workloads and large-scale deployments.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_7","title":"Tasks","text":"<ol> <li>Configure for high pod density</li> <li>Optimize garbage collection settings</li> <li>Tune networking and DNS performance</li> <li>Configure for minimal latency</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#high-performance-configuration","title":"High-Performance Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\n# High Density Configuration\nmaxPods: 500\npodsPerCore: 10\n\n# Optimized Frequencies\nnodeStatusUpdateFrequency: 4s\nnodeStatusReportFrequency: 1m\nsyncFrequency: 10s\nfileCheckFrequency: 10s\nhttpCheckFrequency: 10s\n\n# Garbage Collection Optimization\nimageGCHighThresholdPercent: 90\nimageGCLowThresholdPercent: 85\nimageMinimumGCAge: 30s\n\n# Container GC\nminimumGCAge: 30s\nmaxPerPodContainerCount: 2\nmaxContainerCount: 500\n\n# Event Optimization\neventRecordQPS: 100\neventBurst: 200\n\n# DNS Optimization\nclusterDNS:\n- 10.96.0.10\nresolverConfig: /etc/resolv.conf\ndnsPolicy: ClusterFirst\n\n# Runtime Optimization\nserializeImagePulls: false\nmaxParallelImagePulls: 10\nregistryPullQPS: 20\nregistryBurst: 40\n\n# Resource Management\nsystemReserved:\n  cpu: 1000m\n  memory: 2Gi\n  ephemeral-storage: 5Gi\nkubeReserved:\n  cpu: 1000m\n  memory: 2Gi\n  ephemeral-storage: 2Gi\n\n# Security Optimizations\nauthentication:\n  webhook:\n    cacheTTL: 2m\nauthorization:\n  webhook:\n    cacheAuthorizedTTL: 10m\n    cacheUnauthorizedTTL: 1m\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#apply-optimization","title":"Apply Optimization","text":"<pre><code># Apply performance configuration\nsudo cp performance-kubelet-config.yaml /var/lib/kubelet/config.yaml\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Monitor Kubelet performance\nkubectl top nodes\nkubectl get nodes -o custom-columns=NAME:.metadata.name,PODS:.status.capacity.pods,ALLOCATABLE:.status.allocatable.pods\n\n# Check resource usage\ncurl -s localhost:10255/metrics | grep kubelet_\n\n# Monitor garbage collection\njournalctl -u kubelet | grep -i \"garbage collect\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_7","title":"Expected Outcomes","text":"<ul> <li>Increased pod density without performance degradation</li> <li>Optimized resource utilization</li> <li>Reduced latency for pod operations</li> <li>Efficient garbage collection</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-9-kubeadm-integration-and-cluster-wide-updates","title":"Exercise 9: Kubeadm Integration and Cluster-wide Updates","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_8","title":"Scenario","text":"<p>Use kubeadm to manage kubelet configuration updates across the entire cluster during upgrades.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#tasks_8","title":"Tasks","text":"<ol> <li>Prepare cluster for kubelet configuration upgrade</li> <li>Update control plane kubelet configuration</li> <li>Update worker node kubelet configuration</li> <li>Verify cluster-wide configuration consistency</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#control-plane-configuration-update","title":"Control Plane Configuration Update","text":"<pre><code># On control plane node\n# Update kubeadm configuration first\nsudo kubeadm upgrade plan\n\n# Upgrade control plane components\nsudo kubeadm upgrade apply v1.29.0\n\n# Update kubelet configuration\nsudo kubeadm upgrade node phase kubelet-config\n\n# Restart kubelet\nsudo systemctl restart kubelet\n\n# Verify control plane\nkubectl get nodes\nkubectl cluster-info\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#worker-node-configuration-update","title":"Worker Node Configuration Update","text":"<pre><code># On each worker node\n# Download new kubelet configuration\nsudo kubeadm upgrade node phase kubelet-config\n\n# Restart kubelet with new configuration\nsudo systemctl restart kubelet\n\n# Verify node status\nkubectl get nodes\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#custom-configuration-with-kubeadm","title":"Custom Configuration with Kubeadm","text":"<p>Create a kubeadm configuration file for custom kubelet settings:</p> <pre><code># kubeadm-config.yaml\napiVersion: kubeadm.k8s.io/v1beta3\nkind: ClusterConfiguration\nkubernetesVersion: v1.29.0\n---\napiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nmaxPods: 200\ncpuManagerPolicy: static\nsystemReserved:\n  cpu: 500m\n  memory: 1Gi\nkubeReserved:\n  cpu: 500m\n  memory: 1Gi\n---\napiVersion: kubeproxy.config.k8s.io/v1alpha1\nkind: KubeProxyConfiguration\nmode: ipvs\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#apply-custom-configuration","title":"Apply Custom Configuration","text":"<pre><code># Apply the configuration during upgrade\nsudo kubeadm upgrade apply --config=kubeadm-config.yaml v1.29.0\n\n# Update nodes with new configuration\nsudo kubeadm upgrade node phase kubelet-config\n\n# Restart kubelet\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#verification-commands_2","title":"Verification Commands","text":"<pre><code># Check kubelet version across cluster\nkubectl get nodes -o custom-columns=NAME:.metadata.name,VERSION:.status.nodeInfo.kubeletVersion\n\n# Verify configuration consistency\nfor node in $(kubectl get nodes -o name); do\n  echo \"=== $node ===\"\n  kubectl get --raw /api/v1/nodes/${node#node/}/proxy/configz | jq '.kubeletconfig.maxPods'\ndone\n\n# Check cluster health\nkubectl get componentstatuses\nkubectl get nodes -o wide\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_8","title":"Expected Outcomes","text":"<ul> <li>All nodes run the same kubelet version</li> <li>Configuration is consistent across the cluster</li> <li>Cluster remains healthy during updates</li> <li>Custom configurations are properly applied</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#exercise-10-troubleshooting-configuration-issues","title":"Exercise 10: Troubleshooting Configuration Issues","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_9","title":"Scenario","text":"<p>Diagnose and fix various Kubelet configuration problems that may occur in production environments.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#issue-1-kubelet-fails-to-start-after-configuration-change","title":"Issue 1: Kubelet Fails to Start After Configuration Change","text":"<pre><code># Check systemd status\nsudo systemctl status kubelet\n\n# Check logs for errors\njournalctl -u kubelet -n 50\n\n# Validate configuration syntax\nsudo kubelet --config=/var/lib/kubelet/config.yaml --dry-run\n\n# Restore backup configuration if needed\nsudo cp /var/lib/kubelet/config.yaml.backup /var/lib/kubelet/config.yaml\nsudo systemctl restart kubelet\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#issue-2-node-not-ready-after-configuration","title":"Issue 2: Node Not Ready After Configuration","text":"<pre><code># Check node status\nkubectl get nodes\nkubectl describe node $(hostname)\n\n# Check Kubelet logs\njournalctl -u kubelet -f\n\n# Verify container runtime\nsudo systemctl status containerd\nsudo crictl version\n\n# Check certificates\nopenssl x509 -in /var/lib/kubelet/pki/kubelet.crt -text -noout\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#issue-3-resource-manager-policy-conflicts","title":"Issue 3: Resource Manager Policy Conflicts","text":"<pre><code># Reset CPU manager state\nsudo systemctl stop kubelet\nsudo rm -f /var/lib/kubelet/cpu_manager_state\nsudo rm -f /var/lib/kubelet/memory_manager_state\n\n# Apply corrected configuration\nsudo cp fixed-kubelet-config.yaml /var/lib/kubelet/config.yaml\nsudo systemctl start kubelet\n\n# Verify policy is active\ncat /var/lib/kubelet/cpu_manager_state\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#emergency-recovery-procedure","title":"Emergency Recovery Procedure","text":"<pre><code># Complete kubelet reset and reconfiguration\nsudo systemctl stop kubelet\n\n# Reset kubelet configuration to defaults\nsudo kubeadm reset phase cleanup-node\n\n# Rejoin the cluster\nsudo kubeadm join &lt;control-plane-endpoint&gt; --token &lt;token&gt; --discovery-token-ca-cert-hash &lt;hash&gt;\n\n# Verify cluster rejoin\nkubectl get nodes\nkubectl describe node $(hostname)\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_9","title":"Expected Outcomes","text":"<ul> <li>Ability to diagnose configuration issues quickly</li> <li>Successful rollback procedures when needed</li> <li>Proper validation of configuration changes</li> <li>Recovery from various failure scenarios</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#comprehensive-final-exercise-multi-node-configuration-management","title":"Comprehensive Final Exercise: Multi-Node Configuration Management","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#scenario_10","title":"Scenario","text":"<p>Manage kubelet configuration across a heterogeneous cluster with different node types.</p>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#node-specific-configurations","title":"Node-Specific Configurations","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#gpu-node-configuration","title":"GPU Node Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nmaxPods: 100\ncpuManagerPolicy: static\nmemoryManagerPolicy: Static\ntopologyManagerPolicy: single-numa-node\nsystemReserved:\n  cpu: 1000m\n  memory: 4Gi\n  nvidia.com/gpu: 0\nkubeReserved:\n  cpu: 1000m\n  memory: 2Gi\nnodeLabels:\n  accelerator: nvidia-tesla-v100\n  workload-type: ml\nfeatureGates:\n  DevicePlugins: true\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#edge-node-configuration","title":"Edge Node Configuration","text":"<pre><code>apiVersion: kubelet.config.k8s.io/v1beta1\nkind: KubeletConfiguration\nmaxPods: 30\ncpuManagerPolicy: none\nmemoryManagerPolicy: None\nimageGCHighThresholdPercent: 95\nimageGCLowThresholdPercent: 90\nsystemReserved:\n  cpu: 200m\n  memory: 512Mi\nkubeReserved:\n  cpu: 200m\n  memory: 256Mi\nnodeLabels:\n  node-type: edge\n  location: remote\nevictionHard:\n  memory.available: \"50Mi\"\n  nodefs.available: \"5%\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#configuration-deployment-process","title":"Configuration Deployment Process","text":"<pre><code># For GPU nodes\nsudo cp gpu-kubelet-config.yaml /var/lib/kubelet/config.yaml\nsudo systemctl restart kubelet\nkubectl label nodes gpu-node-1 accelerator=nvidia-tesla-v100\nkubectl taint nodes gpu-node-1 dedicated=gpu:NoSchedule\n\n# For edge nodes  \nsudo cp edge-kubelet-config.yaml /var/lib/kubelet/config.yaml\nsudo systemctl restart kubelet\nkubectl label nodes edge-node-1 node-type=edge\nkubectl taint nodes edge-node-1 edge=true:NoSchedule\n\n# Verify configurations\nkubectl get nodes --show-labels\nkubectl describe nodes\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#cluster-wide-validation","title":"Cluster-wide Validation","text":"<pre><code># Check all node configurations\nkubectl get nodes -o custom-columns=NAME:.metadata.name,LABELS:.metadata.labels,TAINTS:.spec.taints\n\n# Verify kubelet versions\nkubectl get nodes -o custom-columns=NAME:.metadata.name,VERSION:.status.nodeInfo.kubeletVersion\n\n# Test workload scheduling\nkubectl apply -f test-workloads.yaml\nkubectl get pods -o wide\n\n# Monitor cluster health\nkubectl get componentstatuses\nkubectl top nodes\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#expected-outcomes_10","title":"Expected Outcomes","text":"<ul> <li>Different node types have appropriate configurations</li> <li>Workloads schedule to correct node types</li> <li>Cluster maintains overall health and stability</li> <li>Configuration changes are applied consistently</li> </ul>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#answer-key-and-validation","title":"Answer Key and Validation","text":""},{"location":"kubernetes/cks/exercises/update-kubelet-config/#general-validation-commands","title":"General Validation Commands","text":"<pre><code># Check kubelet service status\nsudo systemctl status kubelet\n\n# Verify configuration syntax\nsudo kubelet --config=/var/lib/kubelet/config.yaml --dry-run\n\n# Check node readiness\nkubectl get nodes\nkubectl describe node $(hostname)\n\n# Monitor kubelet logs\njournalctl -u kubelet -f\n\n# Verify resource allocation\nkubectl describe node $(hostname) | grep -A 10 \"Allocatable\"\n\n# Check current configuration\nkubectl get --raw /api/v1/nodes/$(hostname)/proxy/configz | jq\n</code></pre>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#common-troubleshooting-steps","title":"Common Troubleshooting Steps","text":"<ol> <li>Always backup configuration before changes</li> <li>Validate YAML syntax before applying</li> <li>Check systemd service status after restart</li> <li>Monitor logs for error messages</li> <li>Verify node remains in Ready state</li> <li>Test pod scheduling functionality</li> </ol>"},{"location":"kubernetes/cks/exercises/update-kubelet-config/#configuration-best-practices","title":"Configuration Best Practices","text":"<ul> <li>Use incremental changes rather than large configuration overhauls</li> <li>Test configurations in development before production</li> <li>Keep backup copies of working configurations</li> <li>Document all configuration changes</li> <li>Use kubeadm for cluster-wide consistency</li> <li>Monitor cluster health after configuration changes</li> </ul>"},{"location":"kubernetes/cks/exercises/use-sbom/","title":"Use SBOM - Finding Images Using Cryptolib","text":""},{"location":"kubernetes/cks/exercises/use-sbom/#problem-statement","title":"Problem Statement","text":"<p>Given 3 container images, identify which one is using cryptolib by using the BOM (Bill of Materials) binary.</p>"},{"location":"kubernetes/cks/exercises/use-sbom/#solution","title":"Solution","text":""},{"location":"kubernetes/cks/exercises/use-sbom/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the <code>bom</code> binary installed:</p> <pre><code># Install if needed\ngo install sigs.k8s.io/bom/cmd/bom@latest\n\n# Or download from releases\ncurl -L -o bom https://github.com/kubernetes-sigs/bom/releases/download/v0.5.1/bom-amd64-linux\nchmod +x bom\nsudo mv bom /usr/local/bin/\n</code></pre>"},{"location":"kubernetes/cks/exercises/use-sbom/#step-1-examine-each-image-directly-with-bom-and-grep-for-cryptolib","title":"Step 1: Examine each image directly with BOM and grep for \u201ccryptolib\u201d","text":"<p>Since the task specifically asks to find which image is using \u201ccryptolib,\u201d we\u2019ll search for this exact term:</p> <pre><code># For this example, let's assume the images are:\n# image1: registry.example.com/app1:latest\n# image2: registry.example.com/app2:latest\n# image3: registry.example.com/app3:latest\n\n# Check image 1\necho \"Checking image 1 for cryptolib:\"\nbom generate -i registry.example.com/app1:latest | grep -i \"cryptolib\"\n\n# Check image 2\necho \"Checking image 2 for cryptolib:\"\nbom generate -i registry.example.com/app2:latest | grep -i \"cryptolib\"\n\n# Check image 3\necho \"Checking image 3 for cryptolib:\"\nbom generate -i registry.example.com/app3:latest | grep -i \"cryptolib\"\n</code></pre>"},{"location":"kubernetes/cks/exercises/use-sbom/#sample-output","title":"Sample Output","text":"<p>The output might look something like this:</p> <pre><code>Checking image 1 for cryptolib:\n[No output - cryptolib not found]\n\nChecking image 2 for cryptolib:\n[No output - cryptolib not found]\n\nChecking image 3 for cryptolib:\nSPDXRef-Package-npm-cryptolib-1.2.3\nname: cryptolib\nPackage: cryptolib\n</code></pre>"},{"location":"kubernetes/cks/exercises/use-sbom/#conclusion","title":"Conclusion","text":"<p>Based on the output, we can determine that Image 3 (registry.example.com/app3:latest) is using cryptolib, as it contains specific references to this library.</p>"},{"location":"kubernetes/cks/exercises/use-sbom/#notes","title":"Notes","text":"<ol> <li> <p>In an exam scenario, it\u2019s important to search for the exact library mentioned in the question.</p> </li> <li> <p>If no results are found with the exact name, you may need to try variations or check for common abbreviations of the library name:    <pre><code>bom generate -i image_name | grep -i -E 'cryptolib|crypto-lib|cryptojs|cryptography'\n</code></pre></p> </li> <li> <p>You can also examine the full SBOM output if the direct search doesn\u2019t provide results:    <pre><code>bom generate -i image_name &gt; sbom.txt\nless sbom.txt  # Then search within the file\n</code></pre></p> </li> <li> <p>The <code>bom</code> tool can generate output in different formats. If you\u2019re having trouble with the default format, try specifying the format explicitly:    <pre><code>bom generate -f spdx -i image_name | grep -i \"cryptolib\"\n</code></pre></p> </li> </ol>"},{"location":"kubernetes/kcsa/compliance_frameworks/","title":"Compliance Frameworks","text":""},{"location":"kubernetes/kcsa/compliance_frameworks/#gdpr-general-data-protection-regulation","title":"GDPR (General Data Protection Regulation)","text":"<p>European Union regulation that establishes strict requirements for processing personal data of EU citizens, including consent, data minimization, breach notifications, and the right to access/erase personal information.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#hipaa-health-insurance-portability-and-accountability-act","title":"HIPAA (Health Insurance Portability and Accountability Act)","text":"<p>US legislation that protects sensitive patient health information by establishing standards for privacy, security, and breach notifications in healthcare.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#pci-dss-payment-card-industry-data-security-standard","title":"PCI DSS (Payment Card Industry Data Security Standard)","text":"<p>Security standard for organizations handling credit card information, requiring secure networks, vulnerability management, access controls, and regular testing.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#nist-national-institute-of-standards-and-technology","title":"NIST (National Institute of Standards and Technology)","text":"<p>US agency that develops cybersecurity frameworks, guidelines, and standards to help organizations assess and improve their security posture across various industries.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#cis-benchmarks","title":"CIS Benchmarks","text":"<p>Industry-standard configuration guidelines developed by the Center for Internet Security that provide best practices for securely configuring operating systems, cloud services, containers, and applications.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#fedramp-federal-risk-and-authorization-management-program","title":"FedRAMP (Federal Risk and Authorization Management Program)","text":"<p>FedRAMP is a US government-wide program that provides a standardized approach to security assessment, authorization, and continuous monitoring for cloud products and services.</p>"},{"location":"kubernetes/kcsa/compliance_frameworks/#microsoft-security-development-lifecycle-sdl","title":"Microsoft Security Development Lifecycle (SDL)","text":"<p>The Microsoft Security Development Lifecycle (SDL) is a software development process that helps developers build more secure software by reducing the number and severity of vulnerabilities while reducing development cost.</p> <p>Key Practices:</p> <ul> <li>Threat Modeling: Structured approach to identifying, quantifying, and addressing security risks</li> <li>Secure Coding Guidelines: Standards for writing code that\u2019s resistant to vulnerabilities</li> <li>Static Application Security Testing (SAST): Automated scanning during development</li> <li>Dynamic Application Security Testing (DAST): Runtime security testing</li> <li>Security Reviews: Formal assessments at critical phases</li> <li>Penetration Testing: Simulated attacks to find vulnerabilities</li> </ul>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/","title":"Compliance and Security frameworks","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#distribute-container-manifest","title":"Distribute - Container manifest","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#kubesec","title":"Kubesec","text":"<p>A security risk analysis tool for Kubernetes resources that scans YAML manifests and Helm charts to identify security misconfigurations, vulnerabilities, and non-compliance with best practices.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#terrascan","title":"Terrascan","text":"<p>An open-source security scanner that detects compliance and security violations across Infrastructure as Code (IaC) tools like Terraform, Kubernetes, Helm, and Dockerfiles to help enforce security best practices.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#distribute-security-tests","title":"Distribute - Security Tests","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#nuclei","title":"Nuclei","text":"<p>A fast, template-based vulnerability scanner that detects security issues across various attack surfaces by using customizable templates for targeted scanning.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#trivy","title":"Trivy","text":"<p>An all-in-one open-source scanner for containers, filesystems, Git repositories, and Kubernetes that detects vulnerabilities, misconfigurations, and secrets.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#snyk","title":"Snyk","text":"<p>A developer security platform that finds, fixes, and monitors vulnerabilities in application code, open source dependencies, containers, and infrastructure as code.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#clair","title":"Clair","text":"<p>An open-source container vulnerability scanner that statically analyzes container images for known security vulnerabilities in application dependencies.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#grype","title":"Grype","text":"<p>A vulnerability scanner for container images and filesystems created by Anchore that provides fast, comprehensive detection of package vulnerabilities.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#sysdig-secure","title":"Sysdig Secure","text":"<p>A cloud-native security platform designed for securing containerized applications, Kubernetes environments, and cloud workloads. It provides comprehensive security capabilities across the entire container lifecycle.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#distribute-signing-and-trust","title":"Distribute - Signing and Trust","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#in-toto","title":"in-toto","text":"<p>A framework that cryptographically ensures software supply chain integrity by tracking each step in the development process with signed metadata to verify the chain hasn\u2019t been compromised.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#notation","title":"Notation","text":"<p>A CNCF project for signing and verifying OCI container images and artifacts with a pluggable signature verification architecture.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#tuf-the-update-framework","title":"TUF (The Update Framework):","text":"<p>A secure framework for software updates that protects against various attacks by using multiple layers of signing keys and metadata verification.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#sigstore","title":"Sigstore","text":"<p>An open-source project providing free tools for code signing, transparency, and verification to secure software supply chains without managing private keys.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#deploy-pre-flight-checks","title":"Deploy - Pre-flight checks","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#gatekeeper","title":"Gatekeeper","text":"<p>A Kubernetes admission controller using Open Policy Agent (OPA) that enforces configurable policies to validate, mutate, or reject resources before they\u2019re admitted to the cluster.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#kyverno","title":"Kyverno","text":"<p>A policy engine designed specifically for Kubernetes that can validate, mutate, and generate resources using policy as code without requiring a new language, providing native YAML/JSON support.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#distribution-response-investigation","title":"Distribution - Response &amp; Investigation","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#wazuh","title":"Wazuh","text":"<p>An open-source security monitoring platform that provides threat detection, integrity monitoring, and compliance capabilities through log analysis, file integrity checking, and security alerts.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#snort","title":"Snort","text":"<p>A widely-used open-source network intrusion detection and prevention system (IDPS) that performs real-time traffic analysis and packet logging to detect and prevent network attacks.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#zeek","title":"Zeek","text":"<p>A powerful network security monitoring tool that analyzes network traffic to identify suspicious activity by generating high-level logs about network behavior rather than just matching signatures.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#runtime-orchestration","title":"Runtime - Orchestration","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#kube-bench","title":"kube-bench","text":"<p>An open-source tool that checks whether Kubernetes deployments align with CIS Kubernetes Benchmark security recommendations by automatically testing control plane and worker nodes for best practices.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#trivy_1","title":"Trivy","text":"<p>An all-in-one vulnerability scanner for containers, filesystems, Git repositories, and Kubernetes that detects vulnerabilities, misconfigurations, and secrets.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#falco","title":"Falco","text":"<p>A cloud-native runtime security tool that detects abnormal behavior and security threats in real-time by monitoring Linux system calls, container activities, and Kubernetes events.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#spiffe","title":"SPIFFE","text":"<p>A set of open-source standards for securely identifying and authenticating services to each other across heterogeneous environments using platform-agnostic, cryptographic identities.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#runtime-storage","title":"Runtime - Storage","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#rook","title":"Rook","text":"<p>A cloud-native storage orchestrator for Kubernetes that automates deployment, bootstrapping, configuration, scaling, and recovery of storage services like Ceph.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#ceph","title":"Ceph","text":"<p>A highly scalable, distributed storage system providing object, block, and file storage in a unified platform designed for high performance, reliability, and no single point of failure.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#gluster","title":"Gluster","text":"<p>An open-source distributed file system that can scale to several petabytes, handles thousands of clients, and is suitable for data-intensive workloads like cloud storage and media streaming.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#runtime-access","title":"Runtime - Access","text":""},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#keycloak","title":"Keycloak","text":"<p>An open-source identity and access management solution that provides single sign-on, identity federation, social login, and user management with support for standard protocols like OAuth 2.0 and SAML.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#teleport","title":"Teleport","text":"<p>A security gateway for accessing Kubernetes clusters, servers, and applications that unifies access controls with certificate-based authentication, session recording, and audit logging.</p>"},{"location":"kubernetes/kcsa/compliance_security_frameworks_tools/#vault","title":"Vault","text":"<p>HashiCorp\u2019s secrets management tool that securely stores and tightly controls access to tokens, passwords, certificates, and encryption keys with dynamic secrets generation, data encryption, and leasing/renewal capabilities.</p>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/","title":"Kubernetes Auditing Policy","text":"<p>Kubernetes auditing provides a security-relevant chronological set of records documenting the sequence of activities that have affected the system. The audit policy defines what events should be recorded and what data they should include.</p>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/#audit-policy-configuration","title":"Audit Policy Configuration","text":"<p>Kubernetes audit policies are defined in YAML format. The policy specifies rules that determine what events should be recorded and the level of detail.</p>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/#audit-levels","title":"Audit Levels","text":"<p>Kubernetes supports these audit levels, from least to most verbose:</p> <ul> <li>None: Don\u2019t log events matching this rule</li> <li>Metadata: Log request metadata (user, timestamp, resource, verb) but not request or response body</li> <li>Request: Log event metadata and request body but not response body</li> <li>RequestResponse: Log event metadata, request and response bodies</li> </ul>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/#example-audit-policy","title":"Example Audit Policy","text":"<pre><code>apiVersion: audit.k8s.io/v1\nkind: Policy\nrules:\n  # Log pod changes at RequestResponse level\n  - level: RequestResponse\n    resources:\n    - group: \"\"\n      resources: [\"pods\"]\n\n  # Log \"configmaps\" and \"secrets\" at Metadata level\n  - level: Metadata\n    resources:\n    - group: \"\"\n      resources: [\"configmaps\", \"secrets\"]\n\n  # Don't log requests to certain non-resource URL paths\n  - level: None\n    nonResourceURLs:\n    - /api*\n    - /version\n    - /healthz\n\n  # Log everything else at Metadata level\n  - level: Metadata\n</code></pre>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/#implementing-audit-logging","title":"Implementing Audit Logging","text":"<p>To enable audit logging in Kubernetes, you need to:</p> <ol> <li> <p>Configure the API server with audit policy file:    <pre><code>--audit-policy-file=/etc/kubernetes/audit-policy.yaml\n</code></pre></p> </li> <li> <p>Specify the log backend:</p> </li> <li>Log to file:      <pre><code>--audit-log-path=/var/log/kubernetes/audit.log\n--audit-log-maxage=30\n--audit-log-maxbackup=10\n</code></pre></li> <li>Or log to webhook:      <pre><code>--audit-webhook-config-file=/etc/kubernetes/audit-webhook.yaml\n</code></pre></li> </ol>"},{"location":"kubernetes/kcsa/kubernetes_auditing_policy/#best-practices","title":"Best Practices","text":"<ol> <li>Focus on sensitive operations: Privilege escalation, auth failures, resource deletion</li> <li>Be selective: Logging everything at RequestResponse level causes significant overhead</li> <li>Consider log storage and rotation: Audit logs can grow very large</li> <li>Monitor audit logs: Integrate with security monitoring tools like SIEM systems</li> <li>Implement a graduated approach: Log sensitive operations at RequestResponse level, less sensitive at Metadata</li> </ol> <p>Properly configured audit logging is critical for security incident detection, forensic investigations, and compliance in Kubernetes clusters.</p>"},{"location":"kubernetes/kcsa/linux_tools/","title":"AppArmor","text":"<p>AppArmor (Application Armor) is a Linux security module that provides mandatory access control (MAC) for processes. It restricts programs\u2019 capabilities by enforcing security policies that limit what actions applications can perform.</p> <pre><code># Check AppArmor status\nsudo aa-status\n\n# List all profiles and their modes\nsudo apparmor_status\n\n# Get version information\nsudo apparmor_parser -V\n\n# Load a profile\nsudo apparmor_parser -r /etc/apparmor.d/profile_name\n\n# Set a profile to enforce mode\nsudo aa-enforce /path/to/binary\n\n# Set a profile to complain mode\nsudo aa-complain /path/to/binary\n\n# Check profile syntax\nsudo apparmor_parser -p /etc/apparmor.d/profile_name\n</code></pre>"},{"location":"kubernetes/kcsa/linux_tools/#kubernetes-apparmor-integration","title":"Kubernetes AppArmor Integration","text":"<p>Kubernetes supports AppArmor profiles through annotations on pods. This allows you to apply different security profiles to different pods based on their specific security requirements.</p>"},{"location":"kubernetes/kcsa/linux_tools/#implementation-details","title":"Implementation Details","text":"<ul> <li>Pod Annotations: AppArmor profiles are specified using annotations on the pod specification</li> <li>Node Requirements: AppArmor must be installed on each worker node</li> <li>Profile Loading: Profiles must be loaded on each node before pods can use them</li> </ul> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: secure-nginx\n  annotations:\n    container.apparmor.security.beta.kubernetes.io/nginx: runtime/default\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n</code></pre>"},{"location":"kubernetes/kcsa/security_context/","title":"Security Context","text":""},{"location":"kubernetes/kcsa/security_context/#examples","title":"Examples","text":"<pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: mixed-security-context\nspec:\n  securityContext:\n    runAsUser: 1000\n    runAsGroup: 3000\n    fsGroup: 2000  # file system group ownership for volumes mounted in a Pod\n    supplementalGroups: [1001, 1002]  # adds secondary group IDs to the processes running in all containers of a Pod\n    seLinuxOptions:  # SELinux (Security-Enhanced Linux) parameters for containers and pods. SELinux provides mandatory access controls by enforcing security policies that restrict what processes can do\n      level: \"s0:c123,c456\"\n    seccompProfile: # apply seccomp (secure computing mode) profiles to restrict the system calls that containers can make to the Linux kernel\n      type: RuntimeDefault\n  containers:\n  - name: first-container\n    image: nginx\n    securityContext:\n      allowPrivilegeEscalation: false\n      capabilities:\n        drop: [\"ALL\"]\n  - name: second-container\n    image: busybox\n    command: [\"sh\", \"-c\", \"sleep 3600\"]\n    securityContext:\n      runAsUser: 2000  # Overrides the Pod-level setting\n      capabilities:\n        add: [\"NET_ADMIN\"]\n</code></pre>"},{"location":"kubernetes/kcsa/threat_modeling_frameworks/","title":"Threat Modeling Framework","text":"<p>Threat modeling for Kubernetes involves a structured approach to identifying, categorizing, and mitigating potential security threats.</p>"},{"location":"kubernetes/kcsa/threat_modeling_frameworks/#stride","title":"STRIDE","text":"<p>STRIDE is a commonly used threat modeling framework that can be effectively applied to Kubernetes:</p> <ul> <li>Spoofing: Unauthorized access using stolen credentials or impersonating legitimate Kubernetes components</li> <li>Tampering: Unauthorized modification of Kubernetes resources, configurations, or container images</li> <li>Repudiation: Lack of audit trails for actions performed in the cluster</li> <li>Information Disclosure: Unauthorized access to sensitive data in pods, secrets, or ConfigMaps</li> <li>Denial of Service: Attacks that make Kubernetes services unavailable</li> <li>Elevation of Privilege: Gaining higher levels of access than intended</li> </ul>"},{"location":"kubernetes/kcsa/threat_modeling_frameworks/#mitre-attck-framework","title":"MITRE ATT&amp;CK Framework","text":"<p>MITRE ATT&amp;CK (Adversarial Tactics, Techniques, and Common Knowledge) is a globally accessible knowledge base of adversary tactics and techniques based on real-world observations. It\u2019s a comprehensive framework that systematically documents cyber adversary behavior.</p>"},{"location":"kubernetes/kcsa/threat_modeling_frameworks/#tactical-categories","title":"Tactical Categories","text":"<ul> <li>Initial Access: Methods attackers use to first enter a network or system, such as phishing emails, exploiting vulnerabilities in public-facing applications, or using stolen credentials.</li> <li>Execution: Techniques for running malicious code on a compromised system, including command-line interfaces, scripts, or scheduled tasks to execute the attacker\u2019s code.</li> <li>Persistence: Methods to maintain access to systems despite reboots or credential changes, including backdoors, registry modifications, or startup scripts that ensure attackers can return.</li> <li>Privilege Escalation: Techniques to gain higher-level permissions, such as exploiting vulnerabilities or manipulating access tokens to obtain administrative rights needed for further attack activities.</li> <li>Defense Evasion: Methods to avoid detection, including disabling security tools, clearing logs, encrypting malicious payloads, or disguising malicious activity as legitimate processes.</li> </ul>"},{"location":"kubernetes/kcsa/virtualizers/","title":"Virtualization Technologies","text":""},{"location":"kubernetes/kcsa/virtualizers/#gvisor","title":"gVisor","text":"<p>gVisor is an application kernel developed by Google that provides an additional security layer for containers by intercepting and handling system calls.</p>"},{"location":"kubernetes/kcsa/virtualizers/#key-characteristics","title":"Key Characteristics:","text":"<ul> <li>Acts as a security sandbox between containers and the host kernel</li> <li>Implements a substantial portion of the Linux system call interface in userspace</li> <li>Written primarily in Go</li> <li>Creates an application kernel that mediates access between the container and host</li> </ul>"},{"location":"kubernetes/kcsa/virtualizers/#how-it-works","title":"How it Works:","text":"<ul> <li>Intercepts system calls from containerized applications</li> <li>Implements its own network and filesystem interfaces</li> <li>Provides compatibility with standard container runtimes via OCI integration (runsc)</li> <li>Significantly reduces the attack surface exposed to containers</li> </ul>"},{"location":"kubernetes/kcsa/virtualizers/#use-cases","title":"Use Cases:","text":"<ul> <li>Multi-tenant container deployments</li> <li>Running untrusted or third-party code</li> <li>Enhancing security of web-facing containerized applications</li> </ul> <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: gvisor\nhandler: runsc\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: gvisor-pod\nspec:\n  runtimeClassName: gvisor\n  containers:\n  - name: nginx\n    image: nginx\n</code></pre>"},{"location":"kubernetes/kcsa/virtualizers/#firecracker","title":"Firecracker","text":"<p>Firecracker is a lightweight virtualization technology developed by AWS that powers AWS Lambda and Fargate services.</p>"},{"location":"kubernetes/kcsa/virtualizers/#key-characteristics_1","title":"Key Characteristics:","text":"<ul> <li>Micro-VM technology combining VM security with container-like performance</li> <li>Minimalist VMM (Virtual Machine Monitor) built on KVM</li> <li>Written in Rust for memory safety</li> <li>Creates lightweight VMs in milliseconds</li> </ul>"},{"location":"kubernetes/kcsa/virtualizers/#how-it-works_1","title":"How it Works:","text":"<ul> <li>Launches micro-VMs with minimal memory footprint (~5MB per instance)</li> <li>Provides a minimal device model (virtio-net, virtio-block, serial console)</li> <li>Uses a RESTful API to manage VM lifecycle</li> <li>Each workload runs in a separate VM with true hardware-based isolation</li> </ul>"},{"location":"kubernetes/kcsa/virtualizers/#use-cases_1","title":"Use Cases:","text":"<ul> <li>Serverless computing platforms</li> <li>Container-as-a-service offerings</li> <li>Secure isolation of workloads</li> <li>High-density computing environments</li> </ul> <pre><code>apiVersion: node.k8s.io/v1\nkind: RuntimeClass\nmetadata:\n  name: kata-fc\nhandler: kata-fc\n---\napiVersion: v1\nkind: Pod\nmetadata:\n  name: firecracker-pod\nspec:\n  runtimeClassName: kata-fc\n  containers:\n  - name: nginx\n    image: nginx\n</code></pre>"},{"location":"kubernetes/open_standards/cni_components/","title":"Networking Tools in Kubernetes","text":""},{"location":"kubernetes/open_standards/cni_components/#container-network-interface-cni","title":"Container Network Interface (CNI)","text":""},{"location":"kubernetes/open_standards/cni_components/#use-case-networking","title":"Use Case: Networking","text":"<p>Networking tools in Kubernetes play a critical role in ensuring seamless communication within the cluster and with external systems. They provide the backbone for pod-to-pod connectivity, service discovery, load balancing, and traffic routing. Beyond connectivity, these tools enforce security policies, optimize traffic flow, and maintain the reliability and scalability of modern distributed applications.</p>"},{"location":"kubernetes/open_standards/cni_components/#tools","title":"Tools:","text":""},{"location":"kubernetes/open_standards/cni_components/#1-contour","title":"1. Contour","text":"<ul> <li>Description: Contour is a Kubernetes-native ingress controller that uses the Envoy proxy to manage HTTP/HTTPS traffic effectively. It supports real-time configuration updates, enabling zero-downtime changes to routing rules. With advanced features like rate limiting, path rewrites, and secure gRPC support, Contour ensures robust and scalable traffic management.</li> <li>Best For: Teams that need a powerful, flexible ingress solution for managing complex traffic patterns and integrating seamlessly with modern application architectures.</li> </ul>"},{"location":"kubernetes/open_standards/cni_components/#2-calico","title":"2. Calico","text":"<ul> <li>Description: Calico is a robust Kubernetes networking and security solution designed for large-scale clusters. It provides advanced networking capabilities, such as encrypted traffic between pods, fine-grained network policies, and support for multiple networking backends like BGP and VXLAN. Its high scalability makes it a top choice for enterprises seeking enhanced security and performance.</li> <li>Best For: Large-scale Kubernetes deployments requiring comprehensive security policies and flexible networking configurations.</li> </ul>"},{"location":"kubernetes/open_standards/cni_components/#3-kube-router","title":"3. Kube-router","text":"<ul> <li>Description: Kube-router simplifies Kubernetes networking by consolidating routing, network policy enforcement, and service proxying into a single lightweight component. By leveraging IP routing instead of overlays, it minimizes latency and maximizes throughput, making it a preferred choice for performance-critical environments.</li> <li>Best For: Scenarios demanding high-performance networking and minimal overhead, particularly for latency-sensitive applications.</li> </ul>"},{"location":"kubernetes/open_standards/cni_components/#4-metallb","title":"4. MetalLB","text":"<ul> <li>Description: MetalLB is a load balancer designed specifically for bare-metal Kubernetes clusters. It integrates seamlessly with existing network infrastructure, offering cloud-like load balancing features via Layer 2 (local network) or Layer 3 (BGP). MetalLB simplifies external traffic routing, making bare-metal clusters operationally similar to cloud-based environments.</li> <li>Best For: Organizations operating bare-metal Kubernetes clusters that require external traffic handling without native cloud provider integrations.</li> </ul>"},{"location":"kubernetes/open_standards/cni_components/#5-flannel","title":"5. Flannel","text":"<ul> <li>Description: Flannel is a straightforward CNI plugin that provides basic pod networking through an overlay network. With support for multiple backends, it offers flexibility for a variety of cluster setups. Flannel is lightweight, easy to configure, and is often the go-to choice for small-to-medium Kubernetes environments.</li> <li>Best For: Environments prioritizing simplicity and ease of deployment over advanced networking capabilities.</li> </ul>"},{"location":"kubernetes/open_standards/cni_components/#6-weave","title":"6. Weave","text":"<ul> <li>Description: Weave Net offers a versatile networking solution that emphasizes simplicity and security. It includes built-in traffic encryption, multi-cloud support, and automatic service discovery. Weave makes it easy to set up hybrid and multi-cloud Kubernetes environments with minimal configuration, ensuring secure communication across all nodes and regions.</li> <li>Best For: Organizations operating in multi-cloud or hybrid environments that require secure and reliable pod networking.</li> </ul>"},{"location":"kubernetes/open_standards/cpi_components/","title":"Cloud Provider Interface (CPI)","text":"<p>The Cloud Provider Interface (CPI) is a Kubernetes standard that allows Kubernetes clusters to integrate with cloud providers for managing cloud-specific infrastructure. It enables provisioning of resources like nodes, load balancers, and persistent storage by abstracting cloud platform details.</p> <p>Below is an example of integrating a Kubernetes cluster with a Cloud Provider Interface (CPI) for managing a Load Balancer on a cloud provider.</p>"},{"location":"kubernetes/open_standards/cpi_components/#example-use-case-exposing-a-service-using-cloud-load-balancer","title":"Example Use Case: Exposing a Service Using Cloud Load Balancer","text":"<p>This example demonstrates how the Cloud Provider Interface enables Kubernetes to provision a cloud-based load balancer to expose a service.</p>"},{"location":"kubernetes/open_standards/cpi_components/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>A Kubernetes cluster running on a supported cloud provider (AWS, GCP, Azure).</li> <li>The Cloud Controller Manager for the cloud provider must be deployed and configured.</li> </ul>"},{"location":"kubernetes/open_standards/cpi_components/#2-deployment-and-service-configuration","title":"2. Deployment and Service Configuration","text":""},{"location":"kubernetes/open_standards/cpi_components/#sample-deployment","title":"Sample Deployment","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:latest\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"kubernetes/open_standards/cpi_components/#service-with-load-balancer","title":"Service with Load Balancer","text":"<p>The following service definition provisions a cloud load balancer using the CPI:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-service\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\" # AWS-specific annotation (optional)\nspec:\n  type: LoadBalancer\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/open_standards/cpi_components/#explanation","title":"Explanation:","text":"<ul> <li>Type: LoadBalancer: Tells Kubernetes to provision an external cloud load balancer.</li> <li>Annotations: Optional cloud-specific configurations (e.g., specifying the load balancer type in AWS).</li> <li>Selector: Targets pods labeled with <code>app: nginx</code>.</li> </ul>"},{"location":"kubernetes/open_standards/cpi_components/#3-how-it-works","title":"3. How It Works","text":"<ol> <li>When the service is created with <code>type: LoadBalancer</code>, the CPI Cloud Controller Manager interacts with the cloud provider\u2019s API.</li> <li>A cloud load balancer (e.g., AWS Elastic Load Balancer, Azure Load Balancer, or GCP Load Balancer) is provisioned automatically.</li> <li>The load balancer routes external traffic to the Kubernetes service, which forwards requests to the backend pods.</li> </ol>"},{"location":"kubernetes/open_standards/cpi_components/#4-verifying-the-load-balancer","title":"4. Verifying the Load Balancer","text":"<p>After creating the service, run the following command to verify the provisioned load balancer:</p> <pre><code>kubectl get services\n</code></pre> <p>Output Example:</p> <pre><code>NAME            TYPE           CLUSTER-IP     EXTERNAL-IP       PORT(S)        AGE\nnginx-service   LoadBalancer   10.0.0.1       a1b2c3d4e5.elb.amazonaws.com   80:30080/TCP   5m\n</code></pre> <ul> <li>EXTERNAL-IP: Shows the address of the provisioned cloud load balancer.</li> <li>Traffic sent to this external IP will be forwarded to the service and its backend pods.</li> </ul>"},{"location":"kubernetes/open_standards/cpi_components/#supported-cloud-providers","title":"Supported Cloud Providers","text":"Cloud Provider CPI Implementation Features AWS AWS Cloud Controller Manager Load balancers, EBS storage, node management GCP GCE Cloud Controller Manager Load balancers, PD storage, node scaling Azure Azure Cloud Controller Manager Load balancers, Disk storage, scaling"},{"location":"kubernetes/open_standards/cpi_components/#conclusion","title":"Conclusion","text":"<p>The Cloud Provider Interface (CPI) allows Kubernetes to integrate seamlessly with cloud providers for provisioning cloud infrastructure like load balancers, persistent volumes, and nodes. By defining a Service with <code>type: LoadBalancer</code>, Kubernetes leverages the CPI to interact with the cloud provider\u2019s API and automatically provision a load balancer for external traffic.</p>"},{"location":"kubernetes/open_standards/csi_components/","title":"Container Storage Interface (CSI)","text":"<p>The Container Storage Interface (CSI) is a Kubernetes open standard that enables storage providers to expose their storage systems to Kubernetes in a consistent and portable way. CSI standardizes how storage volumes are provisioned, mounted, and managed, regardless of the underlying storage infrastructure.</p> <p>Here are some prominent examples of CSI-compliant implementations:</p>"},{"location":"kubernetes/open_standards/csi_components/#1-amazon-elastic-block-store-ebs-csi-driver","title":"1. Amazon Elastic Block Store (EBS) CSI Driver","text":"<ul> <li>Description:   The Amazon EBS CSI driver enables Kubernetes to manage Amazon Elastic Block Store (EBS) volumes as persistent storage. It allows dynamic provisioning and management of EBS volumes for Kubernetes workloads.</li> <li>Key Features:</li> <li>Supports dynamic provisioning of EBS volumes.</li> <li>Enables mounting and attaching EBS volumes to Kubernetes pods.</li> <li>Provides support for resizing and snapshotting volumes.</li> <li>Example Usage:   <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: ebs-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: gp2\n</code></pre></li> <li>Use Case:   Applications running on Kubernetes that require block storage on AWS.</li> </ul>"},{"location":"kubernetes/open_standards/csi_components/#2-google-persistent-disk-csi-driver","title":"2. Google Persistent Disk CSI Driver","text":"<ul> <li>Description:   The Google Persistent Disk (PD) CSI driver allows Kubernetes to manage Google Cloud Persistent Disks as persistent volumes. It supports both standard and SSD-backed persistent disks.</li> <li>Key Features:</li> <li>Supports dynamic provisioning, resizing, and snapshots of persistent disks.</li> <li>Provides multi-read access for specific disk types.</li> <li>Example Usage:   <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: gcp-pd-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: standard\n</code></pre></li> <li>Use Case:   Applications requiring persistent block storage on Google Cloud.</li> </ul>"},{"location":"kubernetes/open_standards/csi_components/#3-azure-disk-csi-driver","title":"3. Azure Disk CSI Driver","text":"<ul> <li>Description:   The Azure Disk CSI driver allows Kubernetes clusters to dynamically provision and manage Azure Managed Disks as persistent storage.</li> <li>Key Features:</li> <li>Supports dynamic provisioning, resizing, and snapshotting of Azure Disks.</li> <li>Integrates seamlessly with Azure Kubernetes Service (AKS).</li> <li>Example Usage:   <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: azure-disk-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 8Gi\n  storageClassName: managed-premium\n</code></pre></li> <li>Use Case:   Applications running on Kubernetes clusters deployed in Azure.</li> </ul>"},{"location":"kubernetes/open_standards/csi_components/#4-ceph-rbd-csi-driver","title":"4. Ceph RBD CSI Driver","text":"<ul> <li>Description:   Ceph RBD (RADOS Block Device) CSI driver integrates Ceph block storage with Kubernetes. It provides scalable, distributed block storage for Kubernetes clusters.</li> <li>Key Features:</li> <li>Supports dynamic provisioning and resizing of block storage.</li> <li>Integrates with on-premises and hybrid Ceph clusters.</li> <li>Example Usage:   <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: ceph-rbd-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n  storageClassName: ceph-rbd\n</code></pre></li> <li>Use Case:   Organizations using Ceph for on-premises distributed storage.</li> </ul>"},{"location":"kubernetes/open_standards/csi_components/#5-portworx-csi-driver","title":"5. Portworx CSI Driver","text":"<ul> <li>Description:   Portworx provides a cloud-native storage solution for Kubernetes that integrates seamlessly using the CSI standard. It supports high availability, snapshots, backups, and multi-cloud capabilities.</li> <li>Key Features:</li> <li>Supports dynamic provisioning, replication, and snapshots.</li> <li>Provides data resilience, encryption, and backup.</li> <li>Example Usage:   <pre><code>apiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: portworx-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n  storageClassName: portworx-sc\n</code></pre></li> <li>Use Case:   Kubernetes workloads that require highly available and resilient storage.</li> </ul>"},{"location":"kubernetes/open_standards/csi_components/#comparison-of-csi-drivers","title":"Comparison of CSI Drivers","text":"Storage Driver Cloud Provider Features Best For Amazon EBS CSI Driver AWS Block storage, snapshots, resizing Kubernetes clusters on AWS Google PD CSI Driver Google Cloud Block storage, dynamic provisioning Kubernetes clusters on GCP Azure Disk CSI Driver Azure Managed Disks, dynamic provisioning Kubernetes clusters on Azure Ceph RBD CSI Driver On-Premises/Hybrid Distributed block storage, scalability On-premises or hybrid Kubernetes setups Portworx CSI Driver Multi-Cloud Resilience, replication, snapshots High-availability storage solutions"},{"location":"kubernetes/open_standards/csi_components/#conclusion","title":"Conclusion","text":"<p>The Container Storage Interface (CSI) provides a consistent and extensible way for Kubernetes to interact with different storage systems, both cloud-based and on-premises. Examples like Amazon EBS, Google Persistent Disk, Azure Disk, Ceph RBD, and Portworx demonstrate how CSI enables dynamic provisioning, scalability, and flexibility for Kubernetes workloads. By adhering to CSI standards, Kubernetes ensures that storage solutions are portable and interoperable across environments.</p>"},{"location":"kubernetes/open_standards/open_standards/","title":"Kubernetes \u2014 Open Standards (OCI, CRI, CNI, CSI, SMI, CPI)","text":"<p>Kubernetes embraces open standards to ensure interoperability, portability, and extensibility across platforms, tools, and environments. These standards allow Kubernetes to remain vendor-neutral, modular, and highly extensible, enabling organizations to build, deploy, and manage applications seamlessly in cloud-native ecosystems.</p>"},{"location":"kubernetes/open_standards/open_standards/#1-open-container-initiative-oci","title":"1. Open Container Initiative (OCI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description","title":"Description","text":"<p>The Open Container Initiative (OCI) is a set of open standards for container runtimes, image formats, and distribution. OCI ensures consistent and interoperable container technology, allowing containers to run uniformly across platforms and tools.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-components","title":"Key Components:","text":"<ul> <li> <p>OCI Runtime Specification: <code>runtime-spec</code> specifies the configuration, execution environment, and lifecycle of containers.   This outlines how to run a \u201cfilesystem bundle\u201d that is unpacked on disk. At a high-level, an OCI implementation would download an OCI Image and then unpack that image into an OCI Runtime filesystem bundle.</p> </li> <li> <p>OCI Image Specification: <code>image-spec</code> defines how to build and package container images.   The goal of this specification is to enable the creation of interoperable tools for building, transporting, and preparing a container image to run.</p> </li> <li> <p>OCI Distribution Specification: The <code>Distribution-Spec</code> provides a standard for the distribution of content in general and container images in particular. It is a most recent addition to the OCI project.   Container registries, implementing the distribution-spec, provide reliable, highly scalable, secured storage services for container images.   Customers either use a cloud provider implementation, vendor implementations, or instance the open source implementation of distribution.</p> </li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters","title":"Why It Matters:","text":"<ul> <li>Prevents vendor lock-in for container ecosystems.</li> <li>Ensures container runtime and image portability across environments.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#2-container-runtime-interface-cri","title":"2. Container Runtime Interface (CRI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description_1","title":"Description","text":"<p>The Container Runtime Interface (CRI) is a Kubernetes API standard that allows Kubernetes to interact with different container runtimes. It abstracts the runtime layer, enabling flexibility and plug-and-play runtimes.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-features","title":"Key Features:","text":"<ul> <li>Provides a gRPC API between Kubernetes kubelet and container runtimes.</li> <li>Supports various runtimes like containerd, CRI-O, and Docker (via <code>shim</code>).</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters_1","title":"Why It Matters:","text":"<ul> <li>Decouples Kubernetes from a specific container runtime.</li> <li>Enhances flexibility and choice in runtime solutions.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#3-container-network-interface-cni","title":"3. Container Network Interface (CNI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description_2","title":"Description","text":"<p>The Container Network Interface (CNI) standard defines how networking is configured for containers. CNI plugins allow Kubernetes to manage pod networking dynamically and flexibly.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-features_1","title":"Key Features:","text":"<ul> <li>Provides a standard API to configure networking for containers.</li> <li>Supports advanced features like Network Policies for traffic control.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#examples","title":"Examples:","text":"<ul> <li>Calico: Network security and policy enforcement.</li> <li>Flannel: Simple overlay network.</li> <li>Weave: Multi-cloud and encrypted pod networking.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters_2","title":"Why It Matters:","text":"<ul> <li>Ensures interoperability across different networking plugins.</li> <li>Simplifies the configuration and management of container networking.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#4-container-storage-interface-csi","title":"4. Container Storage Interface (CSI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description_3","title":"Description","text":"<p>The Container Storage Interface (CSI) standardizes how storage providers integrate their solutions with Kubernetes. It enables dynamic provisioning and management of storage volumes.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-features_2","title":"Key Features:","text":"<ul> <li>Provides APIs for creating, attaching, and mounting storage volumes.</li> <li>Works with both on-premises and cloud storage providers.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#examples_1","title":"Examples:","text":"<ul> <li>Amazon EBS: Elastic Block Store.</li> <li>Google Persistent Disk: Cloud-native block storage.</li> <li>Ceph: Open-source storage solution.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters_3","title":"Why It Matters:","text":"<ul> <li>Decouples Kubernetes from specific storage implementations.</li> <li>Enables storage portability and dynamic provisioning.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#5-service-mesh-interface-smi","title":"5. Service Mesh Interface (SMI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description_4","title":"Description","text":"<p>The Service Mesh Interface (SMI) is an open standard for service mesh interoperability in Kubernetes. It provides a set of common APIs for traffic management, security, and observability.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-features_3","title":"Key Features:","text":"<ul> <li>Traffic Policies: Route, split, and retry traffic between services.</li> <li>Observability: Collect metrics, logs, and traces for service communication.</li> <li>Security: Implements mutual TLS (mTLS) for secure inter-service communication.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#examples_2","title":"Examples:","text":"<ul> <li>Istio: Feature-rich service mesh for Kubernetes.</li> <li>Linkerd: Lightweight and simple service mesh.</li> <li>Consul: Service discovery and mesh.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters_4","title":"Why It Matters:","text":"<ul> <li>Provides a unified API for service mesh implementations.</li> <li>Simplifies the adoption and management of service mesh tools.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#6-cloud-provider-interface-cpi","title":"6. Cloud Provider Interface (CPI)","text":""},{"location":"kubernetes/open_standards/open_standards/#description_5","title":"Description","text":"<p>The Cloud Provider Interface (CPI) standardizes the integration of Kubernetes with cloud providers, enabling Kubernetes to manage cloud-specific resources like storage, load balancers, and nodes.</p>"},{"location":"kubernetes/open_standards/open_standards/#key-features_4","title":"Key Features:","text":"<ul> <li>Provides APIs for cloud infrastructure provisioning.</li> <li>Supports operations like load balancer setup, persistent volume management, and scaling.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#examples_3","title":"Examples:","text":"<ul> <li>AWS Cloud Controller Manager: Manages AWS resources.</li> <li>Azure Cloud Controller Manager: Integrates Kubernetes with Azure.</li> <li>GCP Cloud Controller Manager: Supports Google Cloud resources.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#why-it-matters_5","title":"Why It Matters:","text":"<ul> <li>Enables Kubernetes to operate seamlessly across multiple cloud providers.</li> <li>Ensures abstraction of cloud-specific infrastructure.</li> </ul>"},{"location":"kubernetes/open_standards/open_standards/#conclusion","title":"Conclusion","text":"<p>Kubernetes relies on open standards like OCI, CRI, CNI, CSI, SMI, and CPI to remain modular, extensible, and vendor-neutral. These standards ensure that Kubernetes can integrate with diverse runtime, networking, storage, and service mesh solutions while offering consistent behavior and flexibility across cloud-native environments. By embracing these standards, Kubernetes empowers organizations to build and scale resilient, portable, and future-proof applications.</p>"},{"location":"kubernetes/open_standards/SMI/description/","title":"Service Mesh Interface (SMI)","text":"<p>The Service Mesh Interface (SMI) is an open standard for managing service-to-service communication in Kubernetes. It provides a consistent and portable way to integrate service meshes like Linkerd, Istio, and Consul Connect into Kubernetes clusters. SMI standardizes APIs for traffic management, observability, and security.</p> <p>Below is an example demonstrating SMI Traffic Split, one of the core SMI capabilities.</p>"},{"location":"kubernetes/open_standards/SMI/description/#traffic-split-example","title":"Traffic Split Example","text":""},{"location":"kubernetes/open_standards/SMI/description/#use-case","title":"Use Case:","text":"<p>A gradual rollout (canary release) of a new version of a microservice while splitting traffic between two versions.</p>"},{"location":"kubernetes/open_standards/SMI/description/#1-prerequisites","title":"1. Prerequisites:","text":"<ul> <li>A Kubernetes cluster with a service mesh like Linkerd or Istio installed.</li> <li>Two deployments of the same service:</li> <li><code>v1</code> for the current stable version.</li> <li><code>v2</code> for the new version being tested.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/description/#2-deployments-and-services","title":"2. Deployments and Services","text":""},{"location":"kubernetes/open_standards/SMI/description/#deployment-for-v1","title":"Deployment for v1:","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend-v1\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: backend\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: backend\n        version: v1\n    spec:\n      containers:\n        - name: backend\n          image: my-backend:v1\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"kubernetes/open_standards/SMI/description/#deployment-for-v2","title":"Deployment for v2:","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: backend-v2\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: backend\n      version: v2\n  template:\n    metadata:\n      labels:\n        app: backend\n        version: v2\n    spec:\n      containers:\n        - name: backend\n          image: my-backend:v2\n          ports:\n            - containerPort: 80\n</code></pre>"},{"location":"kubernetes/open_standards/SMI/description/#service-definition","title":"Service Definition:","text":"<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: backend-service\nspec:\n  selector:\n    app: backend\n  ports:\n    - port: 80\n      targetPort: 80\n</code></pre>"},{"location":"kubernetes/open_standards/SMI/description/#3-smi-traffic-split","title":"3. SMI Traffic Split","text":"<p>The following Traffic Split definition directs 90% of the traffic to version <code>v1</code> of the backend and 10% of the traffic to version <code>v2</code>. As confidence in <code>v2</code> grows, the weights can be adjusted gradually.</p> <pre><code>apiVersion: split.smi-spec.io/v1alpha2\nkind: TrafficSplit\nmetadata:\n  name: backend-traffic-split\nspec:\n  service: backend-service\n  backends:\n    - service: backend-v1\n      weight: 90\n    - service: backend-v2\n      weight: 10\n</code></pre>"},{"location":"kubernetes/open_standards/SMI/description/#explanation","title":"Explanation:","text":"<ul> <li>service: Refers to the Kubernetes service (<code>backend-service</code>) that acts as the main entry point.</li> <li>backends: Defines the traffic distribution between the two versions (<code>backend-v1</code> and <code>backend-v2</code>) using weights.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/description/#4-observability","title":"4. Observability","text":"<p>With SMI observability tools integrated into your service mesh (like Linkerd), you can monitor:</p> <ul> <li>Traffic metrics between <code>v1</code> and <code>v2</code>.</li> <li>Response times and error rates.</li> </ul> <p>Example using Linkerd CLI:</p> <pre><code>linkerd stat traffic-split backend-traffic-split\n</code></pre>"},{"location":"kubernetes/open_standards/SMI/description/#conclusion","title":"Conclusion","text":"<p>The SMI Traffic Split API provides a standardized way to manage traffic between different versions of a service. It simplifies gradual rollouts, canary releases, and A/B testing in Kubernetes clusters, ensuring smooth service mesh interoperability regardless of the underlying implementation (Linkerd, Istio, Consul Connect).</p>"},{"location":"kubernetes/open_standards/SMI/istio/","title":"Istio: A Service Mesh for Kubernetes","text":"<p>Istio is an open-source service mesh that provides a way to control and secure service-to-service communication in modern application architectures, such as microservices. It adds observability, traffic management, and security features to applications without requiring changes to the application code.</p>"},{"location":"kubernetes/open_standards/SMI/istio/#key-features-of-istio","title":"Key Features of Istio","text":"<ol> <li> <p>Traffic Management:</p> </li> <li> <p>Provides fine-grained control over traffic routing and load balancing.</p> </li> <li> <p>Supports blue-green and canary deployments.</p> </li> <li> <p>Security:</p> </li> <li> <p>Implements strong identity-based authentication and authorization using mutual TLS (mTLS).</p> </li> <li> <p>Encrypts service-to-service communication.</p> </li> <li> <p>Observability:</p> </li> <li> <p>Offers telemetry, distributed tracing, and monitoring for all services in the mesh.</p> </li> <li> <p>Fault Tolerance:</p> </li> <li>Provides retries, timeouts, and circuit breakers to make applications more resilient.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/istio/#istio-components","title":"Istio Components","text":""},{"location":"kubernetes/open_standards/SMI/istio/#1-envoy-proxy","title":"1. Envoy Proxy","text":"<ul> <li>Description: A lightweight proxy deployed as a sidecar alongside each service.</li> <li>Responsibilities:</li> <li>Intercepts and manages all inbound and outbound traffic for the service.</li> <li>Handles traffic routing, telemetry, and enforcing security policies.</li> <li>Key Features:</li> <li>Protocol support for HTTP, gRPC, WebSocket, and TCP.</li> <li>Built-in observability and traffic control.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#2-istiod-control-plane","title":"2. Istiod (Control Plane)","text":"<ul> <li>Description: The central control plane component that manages the service mesh configuration.</li> <li>Responsibilities:</li> <li>Configures and manages the Envoy proxies.</li> <li>Maintains the service registry and tracks service discovery.</li> <li>Manages authentication, authorization, and telemetry configuration.</li> <li>Key Features:</li> <li>Centralized control for all traffic and security policies.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#3-gateway","title":"3. Gateway","text":"<ul> <li>Description: Manages ingress and egress traffic for services inside the mesh.</li> <li>Ingress Gateway:</li> <li>Routes external traffic into the mesh.</li> <li>Acts as a reverse proxy for services in the mesh.</li> <li>Egress Gateway:</li> <li>Routes traffic from services in the mesh to external services.</li> <li>Provides control over outbound traffic policies.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#4-pilot","title":"4. Pilot","text":"<ul> <li>Description: A component of the control plane that provides service discovery and traffic management.</li> <li>Responsibilities:</li> <li>Configures Envoy proxies for routing, retries, and load balancing.</li> <li>Supports advanced traffic management strategies like canary and blue-green deployments.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#5-mixer-deprecated-in-istio-15","title":"5. Mixer (Deprecated in Istio 1.5+)","text":"<ul> <li>Description: Previously responsible for telemetry and policy enforcement.</li> <li>Replacement: Functionality moved to Envoy and Istiod for better performance and integration.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#6-citadel","title":"6. Citadel","text":"<ul> <li>Description: Manages service identities and certificates in the mesh.</li> <li>Responsibilities:</li> <li>Issues and rotates certificates for secure mTLS communication.</li> <li>Ensures secure service-to-service authentication.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#7-telemetry","title":"7. Telemetry","text":"<ul> <li>Description: Collects metrics, logs, and traces for services in the mesh.</li> <li>Responsibilities:</li> <li>Enables observability through integration with tools like Prometheus, Grafana, and Jaeger.</li> <li>Provides detailed insights into service behavior and performance.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/istio/#how-istio-works","title":"How Istio Works","text":"<ol> <li> <p>Traffic Interception:</p> </li> <li> <p>Envoy sidecars intercept all traffic between services and apply traffic management and security policies.</p> </li> <li> <p>Control Plane Management:</p> </li> <li> <p>Istiod configures Envoy proxies based on the desired state defined by operators.</p> </li> <li> <p>Telemetry Collection:</p> </li> <li> <p>Envoy collects metrics and traces, sending them to monitoring systems like Prometheus or Jaeger.</p> </li> <li> <p>Authentication and Authorization:</p> </li> <li>Citadel and Envoy enforce mTLS and role-based access control (RBAC) policies.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/istio/#conclusion","title":"Conclusion","text":"<p>Istio is a powerful service mesh that simplifies traffic management, enhances observability, and strengthens security for microservices. By abstracting complex networking tasks and automating policies, Istio enables developers to focus on building applications while ensuring reliability and security across the entire system.</p>"},{"location":"kubernetes/open_standards/SMI/linkerd/","title":"Linkerd: An Overview","text":"<p>Linkerd is an open-source service mesh for Kubernetes and other containerized environments. It provides a lightweight, secure, and reliable platform for managing communication between microservices in a distributed system.</p>"},{"location":"kubernetes/open_standards/SMI/linkerd/#key-features-of-linkerd","title":"Key Features of Linkerd","text":"<ol> <li> <p>Traffic Management:</p> </li> <li> <p>Handles routing, load balancing, retries, and failovers.</p> </li> <li> <p>Ensures reliable communication between microservices.</p> </li> <li> <p>Security:</p> </li> <li> <p>Provides mutual TLS (mTLS) for encrypting service-to-service communication.</p> </li> <li> <p>Automates certificate management and rotation.</p> </li> <li> <p>Observability:</p> </li> <li> <p>Offers fine-grained telemetry, including metrics, logs, and distributed tracing.</p> </li> <li> <p>Integrates with tools like Prometheus and Grafana for visualization.</p> </li> <li> <p>Lightweight Design:</p> </li> <li> <p>Designed to be minimal and performant, with a focus on operational simplicity.</p> </li> <li> <p>Uses a sidecar proxy model but maintains a small resource footprint compared to other service meshes.</p> </li> <li> <p>Kubernetes-Native:</p> </li> <li>Integrates seamlessly with Kubernetes, using native constructs like Custom Resource Definitions (CRDs).</li> <li>Automatically injects sidecars into Pods for service mesh functionality.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/linkerd/#how-linkerd-works","title":"How Linkerd Works","text":"<ol> <li> <p>Sidecar Proxy:</p> </li> <li> <p>A lightweight proxy is injected as a sidecar container alongside application containers in each Pod.</p> </li> <li> <p>The proxy intercepts and manages all inbound and outbound traffic for the application.</p> </li> <li> <p>Control Plane:</p> </li> <li> <p>Manages the configuration, policy enforcement, and telemetry collection for the mesh.</p> </li> <li> <p>Components include:</p> <ul> <li>Proxy Injector: Injects the Linkerd sidecar proxy into Pods.</li> <li>Destination Controller: Manages service discovery and routing.</li> <li>Identity Service: Issues and validates mTLS certificates.</li> </ul> </li> <li> <p>Data Plane:</p> </li> <li>Comprises the sidecar proxies that handle the actual service-to-service traffic.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/linkerd/#benefits-of-linkerd","title":"Benefits of Linkerd","text":"<ol> <li> <p>Improved Reliability:</p> </li> <li> <p>Automatically retries failed requests and implements failover mechanisms.</p> </li> <li> <p>Enhanced Security:</p> </li> <li> <p>Ensures all traffic between services is encrypted and authenticated using mTLS.</p> </li> <li> <p>Better Observability:</p> </li> <li> <p>Provides detailed metrics such as request success rates, latencies, and throughput.</p> </li> <li> <p>Simplicity:</p> </li> <li> <p>Easy to install and operate, with minimal configuration compared to other service meshes.</p> </li> <li> <p>Resource Efficiency:</p> </li> <li>Lightweight and performant, making it suitable for resource-constrained environments.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/linkerd/#use-cases-for-linkerd","title":"Use Cases for Linkerd","text":"<ol> <li> <p>Microservices Observability:</p> </li> <li> <p>Gain visibility into service communication, performance, and failures.</p> </li> <li> <p>Zero-Trust Security:</p> </li> <li> <p>Encrypt all service-to-service communication and enforce strict authentication.</p> </li> <li> <p>Traffic Control:</p> </li> <li> <p>Implement fine-grained routing, retries, and failovers for resilient applications.</p> </li> <li> <p>Kubernetes-Native Applications:</p> </li> <li>Manage communication between microservices running in a Kubernetes cluster.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/linkerd/#comparison-linkerd-vs-istio","title":"Comparison: Linkerd vs. Istio","text":"Feature Linkerd Istio Complexity Simple and lightweight Feature-rich but more complex Performance High, with minimal resource usage Moderate, requires more resources Ease of Use Quick setup and minimal configuration Requires extensive configuration Observability Focuses on metrics and simplicity Advanced telemetry and tracing Security Built-in mTLS Built-in mTLS and more policies"},{"location":"kubernetes/open_standards/SMI/linkerd/#installation-example","title":"Installation Example","text":"<p>Install Linkerd using the CLI:</p> <ol> <li>Install the CLI:</li> </ol> <pre><code>curl -sL https://run.linkerd.io/install | sh\nexport PATH=$PATH:$HOME/.linkerd2/bin\n</code></pre> <ol> <li>Validate the Cluster:</li> </ol> <pre><code>linkerd check --pre\n</code></pre> <ol> <li>Install Linkerd:</li> </ol> <pre><code>linkerd install | kubectl apply -f -\n</code></pre> <ol> <li>Inject Sidecars:    Inject Linkerd into your application Pods:</li> </ol> <pre><code>kubectl get deploy -o yaml | linkerd inject - | kubectl apply -f -\n</code></pre> <ol> <li>Access the Dashboard:    Launch the Linkerd dashboard to monitor your services:    <pre><code>linkerd dashboard\n</code></pre></li> </ol>"},{"location":"kubernetes/open_standards/SMI/linkerd/#conclusion","title":"Conclusion","text":"<p>Linkerd is a lightweight and Kubernetes-native service mesh that simplifies the management of service-to-service communication. Its focus on simplicity, security, and observability makes it an excellent choice for organizations looking to enhance their microservices architecture with minimal overhead.</p>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/","title":"What is a Service Mesh?","text":"<p>A service mesh is a dedicated infrastructure layer designed to manage service-to-service communication in modern, distributed application architectures such as microservices. It provides features like traffic management, service discovery, security, observability, and resilience without requiring changes to the application code.</p>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#key-features-of-a-service-mesh","title":"Key Features of a Service Mesh","text":"<ol> <li> <p>Traffic Management:</p> </li> <li> <p>Provides fine-grained control over traffic between services, including load balancing, traffic shaping, retries, and timeouts.</p> </li> <li> <p>Service Discovery:</p> </li> <li> <p>Automatically detects and tracks service instances to ensure efficient routing of requests.</p> </li> <li> <p>Security:</p> </li> <li> <p>Enables secure communication between services using mutual TLS (mTLS) for authentication and encryption.</p> </li> <li> <p>Observability:</p> </li> <li> <p>Provides metrics, logs, and distributed tracing for visibility into service interactions and performance.</p> </li> <li> <p>Resilience:</p> </li> <li>Implements circuit breaking, rate limiting, and fault injection to improve system reliability.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#how-a-service-mesh-works","title":"How a Service Mesh Works","text":"<p>A service mesh typically uses a data plane and a control plane:</p> <ol> <li> <p>Data Plane:</p> </li> <li> <p>Composed of lightweight proxies (e.g., Envoy) deployed alongside application services (as sidecars) to handle service-to-service communication.</p> </li> <li> <p>Control Plane:</p> </li> <li>Centralized management layer that configures and monitors the proxies, enforcing policies and collecting telemetry data.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#benefits-of-using-a-service-mesh","title":"Benefits of Using a Service Mesh","text":"<ol> <li> <p>Simplifies Microservices Management:</p> </li> <li> <p>Decouples service communication logic from application code.</p> </li> <li> <p>Enhances Security:</p> </li> <li> <p>Automates encryption and authentication between services.</p> </li> <li> <p>Improves Reliability:</p> </li> <li> <p>Provides advanced traffic control and error-handling mechanisms.</p> </li> <li> <p>Increases Observability:</p> </li> <li>Offers deep insights into inter-service communication with metrics and tracing.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#challenges-of-a-service-mesh","title":"Challenges of a Service Mesh","text":"<ol> <li> <p>Complexity:</p> </li> <li> <p>Adds operational overhead and learning curve for implementation and management.</p> </li> <li> <p>Performance Overhead:</p> </li> <li> <p>Proxy sidecars introduce additional latency and resource consumption.</p> </li> <li> <p>Cost:</p> </li> <li>Higher infrastructure and operational costs due to additional components.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#popular-service-mesh-solutions","title":"Popular Service Mesh Solutions","text":"<ol> <li> <p>Istio:</p> </li> <li> <p>A feature-rich and widely adopted service mesh offering advanced traffic management, mTLS, and observability.</p> </li> <li> <p>Linkerd:</p> </li> <li> <p>A lightweight, simpler alternative to Istio, focusing on ease of use and minimal resource usage.</p> </li> <li> <p>Consul:</p> </li> <li> <p>A service mesh integrated with Consul\u2019s service discovery and configuration management capabilities.</p> </li> <li> <p>AWS App Mesh:</p> </li> <li>A cloud-native service mesh for managing microservices on AWS.</li> </ol>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#when-to-use-a-service-mesh","title":"When to Use a Service Mesh","text":"<ul> <li>Large-scale microservices architectures requiring secure, reliable communication.</li> <li>Applications needing advanced observability and traffic control.</li> <li>Scenarios where managing service communication in application code becomes unmanageable.</li> </ul>"},{"location":"kubernetes/open_standards/SMI/what_is_a_service_mesh/#when-not-to-use-a-service-mesh","title":"When Not to Use a Service Mesh","text":"<ul> <li>Small-scale applications or monoliths with limited service communication.</li> <li>Environments where the added complexity outweighs the benefits.</li> </ul>"},{"location":"linux/network/bridge-bonding/","title":"Configure Bridge and Bonding Devices","text":""},{"location":"linux/network/bridge-bonding/#overview","title":"Overview","text":"<p>This guide covers network bridge configuration (for virtualization and container networking) and network bonding/teaming (for redundancy and load balancing) in Linux.</p>"},{"location":"linux/network/bridge-bonding/#network-bridges","title":"Network Bridges","text":""},{"location":"linux/network/bridge-bonding/#bridge-concepts","title":"Bridge Concepts","text":"<p>A network bridge connects two or more network segments, operating at Layer 2 (Data Link layer). Common uses: - Virtual machine networking - Container networking (Docker, LXC) - Connecting physical and virtual networks - Network segmentation</p> <p>Key Points: - Bridges forward traffic based on MAC addresses - All bridge members share the same broadcast domain - Bridge itself can have an IP address - Used extensively in virtualization (KVM, VirtualBox, etc.)</p>"},{"location":"linux/network/bridge-bonding/#creating-network-bridges","title":"Creating Network Bridges","text":""},{"location":"linux/network/bridge-bonding/#method-1-using-ip-command-temporary","title":"Method 1: Using <code>ip</code> Command (Temporary)","text":"<pre><code># Create bridge interface\nip link add name br0 type bridge\n\n# Bring bridge up\nip link set br0 up\n\n# Add interfaces to bridge\nip link set eth0 master br0\nip link set eth1 master br0\n\n# Assign IP to bridge\nip addr add 192.168.1.100/24 dev br0\n\n# View bridge\nip link show master br0    # Show bridge members\nbridge link show           # Show bridge ports\n\n# Remove interface from bridge\nip link set eth0 nomaster\n\n# Delete bridge\nip link set br0 down\nip link delete br0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#method-2-using-brctl-command-legacy","title":"Method 2: Using <code>brctl</code> Command (Legacy)","text":"<pre><code># Install bridge-utils\ndnf install bridge-utils\n\n# Create bridge\nbrctl addbr br0\n\n# Add interfaces to bridge\nbrctl addif br0 eth0\nbrctl addif br0 eth1\n\n# Remove interface\nbrctl delif br0 eth0\n\n# Show bridge information\nbrctl show\nbrctl showmacs br0      # Show MAC addresses\nbrctl showstp br0       # Show STP info\n\n# Delete bridge\nbrctl delbr br0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#method-3-networkmanager-persistent","title":"Method 3: NetworkManager (Persistent)","text":"<pre><code># Create bridge connection\nnmcli connection add type bridge \\\n    con-name br0 \\\n    ifname br0\n\n# Configure bridge IP\nnmcli connection modify br0 \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.gateway 192.168.1.1 \\\n    ipv4.dns 8.8.8.8 \\\n    ipv4.method manual\n\n# Add slave interfaces\nnmcli connection add type bridge-slave \\\n    con-name br0-slave-eth0 \\\n    ifname eth0 \\\n    master br0\n\nnmcli connection add type bridge-slave \\\n    con-name br0-slave-eth1 \\\n    ifname eth1 \\\n    master br0\n\n# Activate bridge\nnmcli connection up br0\nnmcli connection up br0-slave-eth0\nnmcli connection up br0-slave-eth1\n\n# View configuration\nnmcli connection show br0\nnmcli device status\n\n# Modify bridge properties\nnmcli connection modify br0 bridge.stp yes\nnmcli connection modify br0 bridge.priority 32768\nnmcli connection modify br0 bridge.forward-delay 15\nnmcli connection modify br0 bridge.hello-time 2\nnmcli connection modify br0 bridge.max-age 20\n\n# Delete bridge\nnmcli connection delete br0\nnmcli connection delete br0-slave-eth0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#method-4-configuration-files-rhelcentos","title":"Method 4: Configuration Files (RHEL/CentOS)","text":"<p>Bridge interface: <code>/etc/sysconfig/network-scripts/ifcfg-br0</code> <pre><code>DEVICE=br0\nTYPE=Bridge\nBOOTPROTO=none\nONBOOT=yes\nIPADDR=192.168.1.100\nPREFIX=24\nGATEWAY=192.168.1.1\nDNS1=8.8.8.8\nSTP=yes\nDELAY=0\n</code></pre></p> <p>Bridge member: <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code> <pre><code>DEVICE=eth0\nTYPE=Ethernet\nBOOTPROTO=none\nONBOOT=yes\nBRIDGE=br0\n</code></pre></p> <p>Restart network: <pre><code>systemctl restart NetworkManager\n# or\nnmcli connection reload\nnmcli connection up br0\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#method-5-netplan-ubuntudebian","title":"Method 5: Netplan (Ubuntu/Debian)","text":"<p>Edit: <code>/etc/netplan/01-netcfg.yaml</code></p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp4: no\n    eth1:\n      dhcp4: no\n  bridges:\n    br0:\n      interfaces:\n        - eth0\n        - eth1\n      dhcp4: no\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n      parameters:\n        stp: true\n        forward-delay: 4\n</code></pre> <p>Apply: <pre><code>netplan try\nnetplan apply\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#bridge-management-and-monitoring","title":"Bridge Management and Monitoring","text":""},{"location":"linux/network/bridge-bonding/#view-bridge-information","title":"View Bridge Information","text":"<pre><code># Using ip command\nip link show type bridge\nbridge link show\n\n# Show FDB (forwarding database)\nbridge fdb show\nbridge fdb show br br0\n\n# Show VLAN info\nbridge vlan show\n\n# Using brctl\nbrctl show\nbrctl showmacs br0\nbrctl showstp br0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#bridge-parameters","title":"Bridge Parameters","text":""},{"location":"linux/network/bridge-bonding/#spanning-tree-protocol-stp","title":"Spanning Tree Protocol (STP)","text":"<pre><code># Enable/disable STP (prevents loops)\nip link set br0 type bridge stp_state 1  # Enable\nip link set br0 type bridge stp_state 0  # Disable\n\n# Using brctl\nbrctl stp br0 on\nbrctl stp br0 off\n\n# Set bridge priority (lower = higher priority)\nip link set br0 type bridge priority 32768\nbrctl setbridgeprio br0 32768\n\n# Set forward delay\nip link set br0 type bridge forward_delay 1500  # 15 seconds\nbrctl setfd br0 15\n\n# Set hello time\nip link set br0 type bridge hello_time 200  # 2 seconds\nbrctl sethello br0 2\n\n# Set max age\nip link set br0 type bridge max_age 2000  # 20 seconds\nbrctl setmaxage br0 20\n\n# View STP info\nbridge -d link show\n</code></pre>"},{"location":"linux/network/bridge-bonding/#port-parameters","title":"Port Parameters","text":"<pre><code># Set port priority\nbridge link set dev eth0 priority 10\n\n# Set port path cost\nbridge link set dev eth0 cost 100\n\n# Disable learning on port\nbridge link set dev eth0 learning off\n\n# Disable flooding on port\nbridge link set dev eth0 flood off\n</code></pre>"},{"location":"linux/network/bridge-bonding/#network-bonding-link-aggregation","title":"Network Bonding (Link Aggregation)","text":""},{"location":"linux/network/bridge-bonding/#bonding-concepts","title":"Bonding Concepts","text":"<p>Network bonding (also called NIC teaming) combines multiple network interfaces into a single logical interface for: - Redundancy: Failover if one link fails - Load balancing: Distribute traffic across links - Increased bandwidth: Aggregate throughput (mode-dependent)</p>"},{"location":"linux/network/bridge-bonding/#bonding-modes","title":"Bonding Modes","text":"<p>Mode 0 (balance-rr): Round-robin load balancing - Packets transmitted sequentially on each slave - Provides load balancing and fault tolerance - Requires switch support (EtherChannel/LACP)</p> <p>Mode 1 (active-backup): Active-backup - One slave active, others standby - Provides fault tolerance only - No switch configuration needed - Most compatible</p> <p>Mode 2 (balance-xor): XOR load balancing - Traffic distributed by source/destination MAC/IP - Provides load balancing and fault tolerance - May require switch configuration</p> <p>Mode 3 (broadcast): Broadcast - All traffic transmitted on all slaves - Provides fault tolerance - Rarely used</p> <p>Mode 4 (802.3ad): IEEE 802.3ad LACP - Dynamic link aggregation - Requires switch support for LACP - Provides load balancing and fault tolerance - Recommended for most use cases</p> <p>Mode 5 (balance-tlb): Adaptive transmit load balancing - Outgoing traffic balanced, incoming on one interface - No switch configuration needed - Provides load balancing and fault tolerance</p> <p>Mode 6 (balance-alb): Adaptive load balancing - Both TX and RX load balancing - No switch configuration needed - Requires ethtool support</p>"},{"location":"linux/network/bridge-bonding/#creating-network-bonds","title":"Creating Network Bonds","text":""},{"location":"linux/network/bridge-bonding/#method-1-using-ip-command-temporary_1","title":"Method 1: Using <code>ip</code> Command (Temporary)","text":"<pre><code># Load bonding module\nmodprobe bonding\n\n# Create bond interface\nip link add bond0 type bond mode active-backup\n\n# Set bonding mode (if not set during creation)\nip link set bond0 type bond mode 802.3ad\n\n# Add slaves\nip link set eth0 master bond0\nip link set eth1 master bond0\n\n# Bring interfaces up\nip link set eth0 up\nip link set eth1 up\nip link set bond0 up\n\n# Assign IP\nip addr add 192.168.1.100/24 dev bond0\n\n# View bond info\ncat /proc/net/bonding/bond0\nip link show bond0\n\n# Remove slave\nip link set eth0 nomaster\n\n# Delete bond\nip link set bond0 down\nip link delete bond0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#method-2-networkmanager-persistent","title":"Method 2: NetworkManager (Persistent)","text":"<pre><code># Create bond connection\nnmcli connection add type bond \\\n    con-name bond0 \\\n    ifname bond0 \\\n    mode active-backup\n\n# Alternative modes:\n# mode balance-rr (0)\n# mode active-backup (1)\n# mode balance-xor (2)\n# mode broadcast (3)\n# mode 802.3ad (4)\n# mode balance-tlb (5)\n# mode balance-alb (6)\n\n# Configure IP\nnmcli connection modify bond0 \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.gateway 192.168.1.1 \\\n    ipv4.dns 8.8.8.8 \\\n    ipv4.method manual\n\n# Add slave interfaces\nnmcli connection add type ethernet \\\n    con-name bond0-slave-eth0 \\\n    ifname eth0 \\\n    master bond0\n\nnmcli connection add type ethernet \\\n    con-name bond0-slave-eth1 \\\n    ifname eth1 \\\n    master bond0\n\n# Activate\nnmcli connection up bond0\nnmcli connection up bond0-slave-eth0\nnmcli connection up bond0-slave-eth1\n\n# View configuration\nnmcli connection show bond0\nnmcli device status\n\n# Modify bonding parameters\nnmcli connection modify bond0 \\\n    bond.options \"mode=802.3ad,miimon=100,lacp_rate=fast\"\n\n# Common bonding options:\n# miimon=100               # Link monitoring interval (ms)\n# downdelay=200            # Delay before disabling slave\n# updelay=200              # Delay before enabling slave\n# lacp_rate=fast           # LACP rate (slow/fast)\n# xmit_hash_policy=layer3+4  # Hash policy for mode 2/4\n# primary=eth0             # Primary interface for mode 1\n# arp_interval=250         # ARP monitoring interval\n# arp_ip_target=192.168.1.1  # ARP target IP\n\n# Delete bond\nnmcli connection delete bond0\nnmcli connection delete bond0-slave-eth0\nnmcli connection delete bond0-slave-eth1\n</code></pre>"},{"location":"linux/network/bridge-bonding/#method-3-configuration-files-rhelcentos","title":"Method 3: Configuration Files (RHEL/CentOS)","text":"<p>Bond interface: <code>/etc/sysconfig/network-scripts/ifcfg-bond0</code> <pre><code>DEVICE=bond0\nTYPE=Bond\nBONDING_MASTER=yes\nBOOTPROTO=none\nONBOOT=yes\nIPADDR=192.168.1.100\nPREFIX=24\nGATEWAY=192.168.1.1\nDNS1=8.8.8.8\nBONDING_OPTS=\"mode=active-backup miimon=100\"\n</code></pre></p> <p>Slave interface: <code>/etc/sysconfig/network-scripts/ifcfg-eth0</code> <pre><code>DEVICE=eth0\nTYPE=Ethernet\nBOOTPROTO=none\nONBOOT=yes\nMASTER=bond0\nSLAVE=yes\n</code></pre></p> <p>Slave interface: <code>/etc/sysconfig/network-scripts/ifcfg-eth1</code> <pre><code>DEVICE=eth1\nTYPE=Ethernet\nBOOTPROTO=none\nONBOOT=yes\nMASTER=bond0\nSLAVE=yes\n</code></pre></p> <p>Load bonding module: <code>/etc/modprobe.d/bonding.conf</code> <pre><code>alias bond0 bonding\noptions bonding mode=1 miimon=100\n</code></pre></p> <p>Restart network: <pre><code>systemctl restart NetworkManager\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#method-4-netplan-ubuntudebian","title":"Method 4: Netplan (Ubuntu/Debian)","text":"<p>Edit: <code>/etc/netplan/01-netcfg.yaml</code></p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp4: no\n    eth1:\n      dhcp4: no\n  bonds:\n    bond0:\n      interfaces:\n        - eth0\n        - eth1\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n      parameters:\n        mode: active-backup\n        mii-monitor-interval: 100\n        # or for 802.3ad:\n        # mode: 802.3ad\n        # lacp-rate: fast\n        # transmit-hash-policy: layer3+4\n</code></pre> <p>Apply: <pre><code>netplan apply\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#bonding-configuration-options","title":"Bonding Configuration Options","text":""},{"location":"linux/network/bridge-bonding/#common-bonding-parameters","title":"Common Bonding Parameters","text":"<pre><code># Bonding modes\nmode=0              # balance-rr\nmode=1              # active-backup\nmode=2              # balance-xor\nmode=4              # 802.3ad\nmode=5              # balance-tlb\nmode=6              # balance-alb\n\n# Link monitoring\nmiimon=100          # MII link monitoring interval (ms)\narp_interval=250    # ARP monitoring interval (ms)\narp_ip_target=192.168.1.1  # Target for ARP monitoring\n\n# Failover/failback timing\ndowndelay=200       # Delay before marking slave down (ms)\nupdelay=200         # Delay before marking slave up (ms)\n\n# Mode-specific options\nprimary=eth0        # Primary interface (mode 1)\nlacp_rate=fast      # LACP heartbeat rate (slow=30s, fast=1s)\nxmit_hash_policy=layer3+4  # Hash policy (mode 2/4)\n# Options: layer2, layer3+4, layer2+3, encap2+3, encap3+4\n\n# Advanced\nfail_over_mac=none  # MAC address handling\nall_slaves_active=0 # Deliver packets to all slaves\n</code></pre>"},{"location":"linux/network/bridge-bonding/#set-bonding-options","title":"Set Bonding Options","text":"<pre><code># Using NetworkManager\nnmcli connection modify bond0 \\\n    bond.options \"mode=802.3ad,miimon=100,lacp_rate=fast,xmit_hash_policy=layer3+4\"\n\n# Using sysfs (temporary)\necho \"fast\" &gt; /sys/class/net/bond0/bonding/lacp_rate\necho \"layer3+4\" &gt; /sys/class/net/bond0/bonding/xmit_hash_policy\n</code></pre>"},{"location":"linux/network/bridge-bonding/#monitoring-bonds-and-bridges","title":"Monitoring Bonds and Bridges","text":""},{"location":"linux/network/bridge-bonding/#monitor-bonding-status","title":"Monitor Bonding Status","text":"<pre><code># View bond status\ncat /proc/net/bonding/bond0\n\n# View brief status\nip link show bond0\n\n# Using nmcli\nnmcli device show bond0\n\n# Check slave status\ncat /sys/class/net/bond0/bonding/slaves\ncat /sys/class/net/bond0/bonding/active_slave\n\n# Monitor in real-time\nwatch -n 1 'cat /proc/net/bonding/bond0'\n</code></pre>"},{"location":"linux/network/bridge-bonding/#monitor-bridge-status","title":"Monitor Bridge Status","text":"<pre><code># View bridge\nbridge link show\nip link show master br0\n\n# View MAC address table\nbridge fdb show\nbridge fdb show br br0\n\n# View statistics\nip -s link show br0\n\n# Monitor in real-time\nwatch -n 1 'bridge link show'\n</code></pre>"},{"location":"linux/network/bridge-bonding/#network-teaming-alternative-to-bonding","title":"Network Teaming (Alternative to Bonding)","text":""},{"location":"linux/network/bridge-bonding/#teaming-vs-bonding","title":"Teaming vs Bonding","text":"<ul> <li>teamd: Modern alternative to bonding</li> <li>More flexible and feature-rich</li> <li>Better performance monitoring</li> <li>JSON configuration</li> <li>Active-backup, load balancing, LACP support</li> </ul>"},{"location":"linux/network/bridge-bonding/#create-team-with-networkmanager","title":"Create Team with NetworkManager","text":"<pre><code># Create team\nnmcli connection add type team \\\n    con-name team0 \\\n    ifname team0 \\\n    config '{\"runner\": {\"name\": \"activebackup\"}}'\n\n# Alternative runners:\n# \"roundrobin\"\n# \"activebackup\"\n# \"loadbalance\"\n# \"broadcast\"\n# \"lacp\"\n\n# Configure IP\nnmcli connection modify team0 \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.gateway 192.168.1.1 \\\n    ipv4.method manual\n\n# Add team ports\nnmcli connection add type team-slave \\\n    con-name team0-port1 \\\n    ifname eth0 \\\n    master team0\n\nnmcli connection add type team-slave \\\n    con-name team0-port2 \\\n    ifname eth1 \\\n    master team0\n\n# Activate\nnmcli connection up team0\n\n# View team status\nteamdctl team0 state\n</code></pre>"},{"location":"linux/network/bridge-bonding/#team-configuration-examples","title":"Team Configuration Examples","text":"<p>Active-Backup: <pre><code>{\n    \"runner\": {\n        \"name\": \"activebackup\"\n    },\n    \"link_watch\": {\n        \"name\": \"ethtool\"\n    }\n}\n</code></pre></p> <p>LACP: <pre><code>{\n    \"runner\": {\n        \"name\": \"lacp\",\n        \"active\": true,\n        \"fast_rate\": true,\n        \"tx_hash\": [\"eth\", \"ipv4\", \"ipv6\"]\n    },\n    \"link_watch\": {\n        \"name\": \"ethtool\"\n    }\n}\n</code></pre></p> <p>Load Balance: <pre><code>{\n    \"runner\": {\n        \"name\": \"loadbalance\",\n        \"tx_hash\": [\"eth\", \"ipv4\", \"ipv6\"]\n    },\n    \"link_watch\": {\n        \"name\": \"ethtool\"\n    }\n}\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#vlan-with-bridges-and-bonds","title":"VLAN with Bridges and Bonds","text":""},{"location":"linux/network/bridge-bonding/#bridge-with-vlan","title":"Bridge with VLAN","text":"<pre><code># Create VLAN interface\nip link add link eth0 name eth0.100 type vlan id 100\n\n# Add to bridge\nip link set eth0.100 master br0\n\n# Or using NetworkManager\nnmcli connection add type vlan \\\n    con-name vlan100 \\\n    ifname eth0.100 \\\n    dev eth0 \\\n    id 100 \\\n    master br0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#bond-with-vlan","title":"Bond with VLAN","text":"<pre><code># Create VLAN on bond\nip link add link bond0 name bond0.100 type vlan id 100\n\n# Configure VLAN\nip addr add 192.168.100.1/24 dev bond0.100\nip link set bond0.100 up\n\n# Using NetworkManager\nnmcli connection add type vlan \\\n    con-name vlan100 \\\n    ifname bond0.100 \\\n    dev bond0 \\\n    id 100\n</code></pre>"},{"location":"linux/network/bridge-bonding/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/network/bridge-bonding/#bridge-troubleshooting","title":"Bridge Troubleshooting","text":"<pre><code># Check bridge exists and is up\nip link show br0\nbrctl show\n\n# Check interfaces in bridge\nbridge link show\nip link show master br0\n\n# Check MAC address table\nbridge fdb show\n\n# Check STP status\nbrctl showstp br0\n\n# Verify IP configuration\nip addr show br0\n\n# Check for errors\nip -s link show br0\n\n# Test connectivity\nping -I br0 192.168.1.1\n</code></pre>"},{"location":"linux/network/bridge-bonding/#bond-troubleshooting","title":"Bond Troubleshooting","text":"<pre><code># Check bond status\ncat /proc/net/bonding/bond0\n\n# Verify mode\ncat /sys/class/net/bond0/bonding/mode\n\n# Check active slave\ncat /sys/class/net/bond0/bonding/active_slave\n\n# Check all slaves\ncat /sys/class/net/bond0/bonding/slaves\n\n# Check MII status\ncat /sys/class/net/bond0/bonding/mii_status\n\n# View statistics\nip -s link show bond0\n\n# Check slave status individually\nethtool eth0\nethtool eth1\n\n# Test failover (for testing only)\nip link set eth0 down\ncat /proc/net/bonding/bond0\nip link set eth0 up\n</code></pre>"},{"location":"linux/network/bridge-bonding/#common-issues","title":"Common Issues","text":"<p>Bridge not forwarding traffic: <pre><code># Enable forwarding\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\n\n# Check iptables\niptables -L FORWARD\n\n# Disable netfilter on bridge (if needed)\necho 0 &gt; /proc/sys/net/bridge/bridge-nf-call-iptables\n</code></pre></p> <p>Bond slaves not activating: <pre><code># Check interfaces are up\nip link set eth0 up\nip link set eth1 up\n\n# Verify no IP on slaves\nip addr flush dev eth0\nip addr flush dev eth1\n\n# Check for conflicting configurations\nnmcli connection show\n</code></pre></p> <p>LACP not negotiating: <pre><code># Verify switch configuration\n# Check LACP is enabled on switch\n# Verify correct mode (802.3ad)\ncat /proc/net/bonding/bond0 | grep -A 10 \"802.3ad\"\n\n# Check LACP rate\ncat /sys/class/net/bond0/bonding/lacp_rate\n</code></pre></p>"},{"location":"linux/network/bridge-bonding/#practical-examples","title":"Practical Examples","text":""},{"location":"linux/network/bridge-bonding/#example-1-kvm-bridge","title":"Example 1: KVM Bridge","text":"<pre><code># Create bridge for KVM VMs\nnmcli connection add type bridge \\\n    con-name br0 \\\n    ifname br0 \\\n    ipv4.method disabled \\\n    ipv6.method disabled\n\nnmcli connection add type bridge-slave \\\n    con-name br0-port1 \\\n    ifname eth0 \\\n    master br0\n\nnmcli connection up br0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#example-2-redundant-server-network","title":"Example 2: Redundant Server Network","text":"<pre><code># Active-backup bond with two NICs\nnmcli connection add type bond \\\n    con-name bond0 \\\n    ifname bond0 \\\n    mode active-backup \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.gateway 192.168.1.1 \\\n    ipv4.method manual\n\nnmcli connection add type ethernet \\\n    slave-type bond \\\n    con-name bond0-eth0 \\\n    ifname eth0 \\\n    master bond0\n\nnmcli connection add type ethernet \\\n    slave-type bond \\\n    con-name bond0-eth1 \\\n    ifname eth1 \\\n    master bond0\n\nnmcli connection modify bond0 \\\n    bond.options \"mode=active-backup,miimon=100,primary=eth0\"\n\nnmcli connection up bond0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#example-3-lacp-bond-for-high-bandwidth","title":"Example 3: LACP Bond for High Bandwidth","text":"<pre><code># 802.3ad LACP bond\nnmcli connection add type bond \\\n    con-name bond0 \\\n    ifname bond0 \\\n    mode 802.3ad \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.method manual\n\nnmcli connection modify bond0 \\\n    bond.options \"mode=802.3ad,miimon=100,lacp_rate=fast,xmit_hash_policy=layer3+4\"\n\nnmcli connection add type ethernet \\\n    slave-type bond \\\n    ifname eth0 \\\n    master bond0\n\nnmcli connection add type ethernet \\\n    slave-type bond \\\n    ifname eth1 \\\n    master bond0\n\nnmcli connection up bond0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/network/bridge-bonding/#bridge-commands","title":"Bridge Commands","text":"<pre><code>ip link add br0 type bridge                    # Create bridge\nip link set eth0 master br0                    # Add interface\nbridge link show                               # Show bridge ports\nbrctl show                                     # Show bridges\nip link delete br0                             # Delete bridge\n</code></pre>"},{"location":"linux/network/bridge-bonding/#bond-commands","title":"Bond Commands","text":"<pre><code>ip link add bond0 type bond mode active-backup # Create bond\nip link set eth0 master bond0                  # Add slave\ncat /proc/net/bonding/bond0                    # Show status\nip link delete bond0                           # Delete bond\n</code></pre>"},{"location":"linux/network/bridge-bonding/#networkmanager","title":"NetworkManager","text":"<pre><code>nmcli connection add type bridge con-name br0 ifname br0\nnmcli connection add type bridge-slave ifname eth0 master br0\nnmcli connection add type bond con-name bond0 mode active-backup\nnmcli connection add type ethernet master bond0 ifname eth0\n</code></pre>"},{"location":"linux/network/bridge-bonding/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know how to create bridges and bonds with NetworkManager</li> <li>Understand different bonding modes and when to use each</li> <li>Be familiar with both temporary (<code>ip</code>) and persistent (nmcli/files) configuration</li> <li>Know how to troubleshoot bond and bridge issues</li> <li>Understand LACP requirements and configuration</li> <li>Practice viewing status with <code>/proc/net/bonding/</code> and <code>bridge</code> commands</li> <li>Know the difference between bonding and teaming</li> <li>Understand when bridges are needed (VMs, containers)</li> <li>Be comfortable with both RHEL and Ubuntu configurations</li> <li>Know how to verify link status and failover behavior</li> </ul>"},{"location":"linux/network/ipv4-ipv6-hostname/","title":"Configure IPv4 and IPv6 Networking and Hostname Resolution","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#overview","title":"Overview","text":"<p>This guide covers essential commands and configurations for managing network interfaces, IP addressing (both IPv4 and IPv6), and hostname resolution in Linux systems.</p>"},{"location":"linux/network/ipv4-ipv6-hostname/#network-interface-management","title":"Network Interface Management","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#ip-command","title":"<code>ip</code> Command","text":"<p>The modern standard for network configuration in Linux, replacing older tools like <code>ifconfig</code>.</p>"},{"location":"linux/network/ipv4-ipv6-hostname/#display-network-interfaces","title":"Display Network Interfaces","text":"<pre><code># Show all network interfaces\nip link show\n\n# Show specific interface\nip link show eth0\n\n# Show interface statistics\nip -s link show eth0\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#enabledisable-interfaces","title":"Enable/Disable Interfaces","text":"<pre><code># Bring interface up\nip link set eth0 up\n\n# Bring interface down\nip link set eth0 down\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#ipv4-configuration","title":"IPv4 Configuration","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#viewing-ipv4-addresses","title":"Viewing IPv4 Addresses","text":"<pre><code># Show all IPv4 addresses\nip -4 addr show\n\n# Show IPv4 for specific interface\nip addr show eth0\n\n# Brief output\nip -br addr show\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#addingremoving-ipv4-addresses","title":"Adding/Removing IPv4 Addresses","text":"<pre><code># Add IPv4 address\nip addr add 192.168.1.100/24 dev eth0\n\n# Add with broadcast\nip addr add 192.168.1.100/24 broadcast 192.168.1.255 dev eth0\n\n# Remove IPv4 address\nip addr del 192.168.1.100/24 dev eth0\n\n# Flush all addresses from interface\nip addr flush dev eth0\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#default-gateway","title":"Default Gateway","text":"<pre><code># Show routing table\nip route show\n\n# Add default gateway\nip route add default via 192.168.1.1\n\n# Delete default gateway\nip route del default via 192.168.1.1\n\n# Add route to specific network\nip route add 10.0.0.0/8 via 192.168.1.254\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#ipv6-configuration","title":"IPv6 Configuration","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#viewing-ipv6-addresses","title":"Viewing IPv6 Addresses","text":"<pre><code># Show all IPv6 addresses\nip -6 addr show\n\n# Show IPv6 only for specific interface\nip -6 addr show eth0\n\n# Show IPv6 routing table\nip -6 route show\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#addingremoving-ipv6-addresses","title":"Adding/Removing IPv6 Addresses","text":"<pre><code># Add IPv6 address\nip -6 addr add 2001:db8::1/64 dev eth0\n\n# Remove IPv6 address\nip -6 addr del 2001:db8::1/64 dev eth0\n\n# Add IPv6 default gateway\nip -6 route add default via 2001:db8::ff\n\n# Delete IPv6 default gateway\nip -6 route del default via 2001:db8::ff\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#ipv6-link-local-addresses","title":"IPv6 Link-Local Addresses","text":"<pre><code># View link-local addresses (fe80::/10)\nip -6 addr show scope link\n\n# Ping using link-local (must specify interface)\nping6 fe80::a00:27ff:fe4e:66a1%eth0\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#network-configuration-files","title":"Network Configuration Files","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#networkmanager-rhelcentosfedora","title":"NetworkManager (RHEL/CentOS/Fedora)","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#using-nmcli-command","title":"Using <code>nmcli</code> Command","text":"<pre><code># Show all connections\nnmcli connection show\n\n# Show active connections\nnmcli connection show --active\n\n# Show device status\nnmcli device status\n\n# Create new connection with static IPv4\nnmcli connection add \\\n    type ethernet \\\n    con-name eth0-static \\\n    ifname eth0 \\\n    ipv4.addresses 192.168.1.100/24 \\\n    ipv4.gateway 192.168.1.1 \\\n    ipv4.dns \"8.8.8.8 8.8.4.4\" \\\n    ipv4.method manual\n\n# Create DHCP connection\nnmcli connection add \\\n    type ethernet \\\n    con-name eth0-dhcp \\\n    ifname eth0 \\\n    ipv4.method auto\n\n# Modify existing connection\nnmcli connection modify eth0-static ipv4.addresses 192.168.1.101/24\n\n# Add secondary IP address\nnmcli connection modify eth0-static +ipv4.addresses 192.168.1.102/24\n\n# Configure IPv6\nnmcli connection modify eth0-static \\\n    ipv6.addresses 2001:db8::100/64 \\\n    ipv6.gateway 2001:db8::1 \\\n    ipv6.method manual\n\n# Enable/disable IPv6\nnmcli connection modify eth0-static ipv6.method auto\nnmcli connection modify eth0-static ipv6.method ignore\n\n# Activate connection\nnmcli connection up eth0-static\n\n# Deactivate connection\nnmcli connection down eth0-static\n\n# Delete connection\nnmcli connection delete eth0-static\n\n# Reload configuration\nnmcli connection reload\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#configuration-files-rhelcentos","title":"Configuration Files (RHEL/CentOS)","text":"<p>Location: <code>/etc/sysconfig/network-scripts/ifcfg-&lt;interface&gt;</code></p> <p>Example static IPv4 configuration: <pre><code># /etc/sysconfig/network-scripts/ifcfg-eth0\nTYPE=Ethernet\nBOOTPROTO=none\nNAME=eth0\nDEVICE=eth0\nONBOOT=yes\nIPADDR=192.168.1.100\nPREFIX=24\nGATEWAY=192.168.1.1\nDNS1=8.8.8.8\nDNS2=8.8.4.4\n</code></pre></p> <p>Example DHCP configuration: <pre><code>TYPE=Ethernet\nBOOTPROTO=dhcp\nNAME=eth0\nDEVICE=eth0\nONBOOT=yes\n</code></pre></p> <p>Example IPv6 configuration: <pre><code>IPV6INIT=yes\nIPV6ADDR=2001:db8::100/64\nIPV6_DEFAULTGW=2001:db8::1\n</code></pre></p>"},{"location":"linux/network/ipv4-ipv6-hostname/#netplan-ubuntudebian","title":"Netplan (Ubuntu/Debian)","text":"<p>Location: <code>/etc/netplan/*.yaml</code></p> <p>Example static configuration: <pre><code># /etc/netplan/01-netcfg.yaml\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 192.168.1.100/24\n        - 2001:db8::100/64\n      gateway4: 192.168.1.1\n      gateway6: 2001:db8::1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n          - 2001:4860:4860::8888\n</code></pre></p> <p>Example DHCP configuration: <pre><code>network:\n  version: 2\n  ethernets:\n    eth0:\n      dhcp4: true\n      dhcp6: true\n</code></pre></p> <p>Apply Netplan configuration: <pre><code># Test configuration\nnetplan try\n\n# Apply configuration\nnetplan apply\n\n# Generate backend configuration\nnetplan generate\n</code></pre></p>"},{"location":"linux/network/ipv4-ipv6-hostname/#hostname-configuration","title":"Hostname Configuration","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#viewing-hostname","title":"Viewing Hostname","text":"<pre><code># Show hostname\nhostname\n\n# Show FQDN (Fully Qualified Domain Name)\nhostname -f\n\n# Show short hostname\nhostname -s\n\n# Show all hostname information\nhostnamectl\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#setting-hostname","title":"Setting Hostname","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#using-hostnamectl-systemd-systems","title":"Using <code>hostnamectl</code> (systemd systems)","text":"<pre><code># Set hostname\nhostnamectl set-hostname server1.example.com\n\n# Set static hostname only\nhostnamectl set-hostname server1 --static\n\n# Set pretty hostname (descriptive name)\nhostnamectl set-hostname \"Production Web Server\" --pretty\n\n# Set transient hostname (temporary)\nhostnamectl set-hostname temp-host --transient\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#manual-configuration-files","title":"Manual Configuration Files","text":"<pre><code># RHEL/CentOS/Fedora\necho \"server1.example.com\" &gt; /etc/hostname\n\n# Also update /etc/hosts\necho \"192.168.1.100 server1.example.com server1\" &gt;&gt; /etc/hosts\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#dns-and-name-resolution","title":"DNS and Name Resolution","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#dns-configuration-file","title":"DNS Configuration File","text":"<p>Location: <code>/etc/resolv.conf</code></p> <pre><code># Configure DNS servers\nnameserver 8.8.8.8\nnameserver 8.8.4.4\nnameserver 2001:4860:4860::8888\n\n# Search domains\nsearch example.com local.domain\n\n# Options\noptions timeout:2\noptions attempts:3\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#etchosts-file","title":"<code>/etc/hosts</code> File","text":"<p>Static hostname to IP mapping:</p> <pre><code># IPv4\n127.0.0.1       localhost localhost.localdomain\n192.168.1.100   server1.example.com server1\n192.168.1.101   server2.example.com server2\n\n# IPv6\n::1             localhost localhost.localdomain\n2001:db8::100   server1.example.com server1\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#etcnsswitchconf","title":"<code>/etc/nsswitch.conf</code>","text":"<p>Controls the order of name resolution sources:</p> <pre><code># Important line for hostname resolution\nhosts: files dns myhostname\n\n# This means: check /etc/hosts first, then DNS, then systemd hostname\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#dns-testing-commands","title":"DNS Testing Commands","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#nslookup","title":"<code>nslookup</code>","text":"<pre><code># Query DNS for domain\nnslookup example.com\n\n# Query specific DNS server\nnslookup example.com 8.8.8.8\n\n# Reverse lookup\nnslookup 8.8.8.8\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#dig","title":"<code>dig</code>","text":"<pre><code># Basic query\ndig example.com\n\n# Query specific record type\ndig example.com A      # IPv4\ndig example.com AAAA   # IPv6\ndig example.com MX     # Mail exchange\ndig example.com NS     # Name servers\n\n# Query specific DNS server\ndig @8.8.8.8 example.com\n\n# Short output\ndig +short example.com\n\n# Reverse lookup\ndig -x 8.8.8.8\n\n# Trace DNS resolution path\ndig +trace example.com\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#host","title":"<code>host</code>","text":"<pre><code># Simple lookup\nhost example.com\n\n# Reverse lookup\nhost 8.8.8.8\n\n# Query specific record type\nhost -t MX example.com\nhost -t AAAA example.com\n\n# Use specific DNS server\nhost example.com 8.8.8.8\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#getent","title":"<code>getent</code>","text":"<pre><code># Query using system resolution (respects /etc/nsswitch.conf)\ngetent hosts example.com\n\n# This uses the configured resolution order (files, DNS, etc.)\ngetent ahosts example.com  # All addresses\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#network-manager-text-ui","title":"Network Manager Text UI","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#nmtui","title":"<code>nmtui</code>","text":"<p>Interactive text-based interface for NetworkManager:</p> <pre><code># Launch network configuration UI\nnmtui\n\n# Directly launch specific function\nnmtui edit       # Edit connection\nnmtui connect    # Activate connection\nnmtui hostname   # Set hostname\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#systemd-network-configuration","title":"SystemD Network Configuration","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#systemd-networkd","title":"<code>systemd-networkd</code>","text":"<p>Alternative to NetworkManager on systemd systems.</p> <p>Configuration files: <code>/etc/systemd/network/*.network</code></p> <p>Example configuration: <pre><code># /etc/systemd/network/20-wired.network\n[Match]\nName=eth0\n\n[Network]\nAddress=192.168.1.100/24\nGateway=192.168.1.1\nDNS=8.8.8.8\nDNS=8.8.4.4\n</code></pre></p> <p>Enable and start: <pre><code>systemctl enable systemd-networkd\nsystemctl start systemd-networkd\nsystemctl status systemd-networkd\n</code></pre></p>"},{"location":"linux/network/ipv4-ipv6-hostname/#useful-network-information-commands","title":"Useful Network Information Commands","text":""},{"location":"linux/network/ipv4-ipv6-hostname/#show-network-configuration-summary","title":"Show Network Configuration Summary","text":"<pre><code># Modern way\nip addr show\n\n# Show only IPv4\nip -4 addr\n\n# Show only IPv6\nip -6 addr\n\n# Show with colors\nip -c addr\n\n# Brief output\nip -br addr show\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#check-connectivity","title":"Check Connectivity","text":"<pre><code># Ping IPv4\nping -c 4 192.168.1.1\n\n# Ping IPv6\nping6 -c 4 2001:db8::1\n\n# Ping with specific interface\nping -I eth0 192.168.1.1\n</code></pre>"},{"location":"linux/network/ipv4-ipv6-hostname/#persistent-vs-temporary-configuration","title":"Persistent vs Temporary Configuration","text":"<p>Temporary (runtime only): <pre><code>ip addr add 192.168.1.100/24 dev eth0\n# Lost after reboot\n</code></pre></p> <p>Persistent (survives reboot): - Use <code>nmcli</code> commands - Edit configuration files in <code>/etc/sysconfig/network-scripts/</code> (RHEL) - Edit Netplan files <code>/etc/netplan/</code> (Ubuntu) - Use <code>systemd-networkd</code> configuration files</p>"},{"location":"linux/network/ipv4-ipv6-hostname/#common-troubleshooting-steps","title":"Common Troubleshooting Steps","text":"<ol> <li> <p>Check interface status: <pre><code>ip link show\nip addr show\n</code></pre></p> </li> <li> <p>Check routing: <pre><code>ip route show\nip -6 route show\n</code></pre></p> </li> <li> <p>Test connectivity: <pre><code>ping -c 4 8.8.8.8\nping6 -c 4 2001:4860:4860::8888\n</code></pre></p> </li> <li> <p>Check DNS resolution: <pre><code>dig example.com\nnslookup example.com\ngetent hosts example.com\n</code></pre></p> </li> <li> <p>Verify configuration files: <pre><code>cat /etc/resolv.conf\ncat /etc/hosts\ncat /etc/nsswitch.conf\n</code></pre></p> </li> <li> <p>Check NetworkManager/networkd status: <pre><code>systemctl status NetworkManager\nsystemctl status systemd-networkd\n</code></pre></p> </li> </ol>"},{"location":"linux/network/ipv4-ipv6-hostname/#key-exam-tips","title":"Key Exam Tips","text":"<ul> <li>Know both temporary (<code>ip</code> commands) and persistent (config files, <code>nmcli</code>) methods</li> <li>Understand IPv4 and IPv6 addressing and configuration</li> <li>Be comfortable with CIDR notation (e.g., /24, /64)</li> <li>Practice DNS configuration and testing</li> <li>Understand the hostname resolution order in <code>/etc/nsswitch.conf</code></li> <li>Know how to configure both DHCP and static IP addresses</li> <li>Remember to restart/reload network services after configuration changes</li> </ul>"},{"location":"linux/network/monitor-troubleshoot-networking/","title":"Monitor and Troubleshoot Networking","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#overview","title":"Overview","text":"<p>This guide covers essential tools and techniques for monitoring network performance, diagnosing connectivity issues, and troubleshooting network problems in Linux.</p>"},{"location":"linux/network/monitor-troubleshoot-networking/#basic-connectivity-testing","title":"Basic Connectivity Testing","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#ping-command","title":"<code>ping</code> Command","text":"<p>Tests basic connectivity using ICMP Echo Request/Reply.</p> <pre><code># Basic ping\nping 8.8.8.8\n\n# Ping with count\nping -c 4 google.com\n\n# Ping with specific interval (default 1 second)\nping -i 2 192.168.1.1\n\n# Ping with specific packet size\nping -s 1000 google.com\n\n# Ping with timeout\nping -W 2 192.168.1.1\n\n# Ping IPv6\nping6 2001:4860:4860::8888\nping6 -c 4 google.com\n\n# Flood ping (requires root)\nping -f 192.168.1.1\n\n# Don't fragment packets\nping -M do -s 1472 192.168.1.1\n</code></pre> <p>Options explained: - <code>-c</code>: Count (number of packets) - <code>-i</code>: Interval between packets - <code>-s</code>: Packet size - <code>-W</code>: Timeout - <code>-f</code>: Flood mode - <code>-M</code>: MTU discovery strategy</p>"},{"location":"linux/network/monitor-troubleshoot-networking/#network-interface-monitoring","title":"Network Interface Monitoring","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#ip-command","title":"<code>ip</code> Command","text":"<pre><code># Show all interfaces with statistics\nip -s link show\n\n# Show specific interface statistics\nip -s -s link show eth0\n\n# Show interface errors\nip -s link show eth0 | grep -E \"RX|TX|errors|dropped\"\n\n# Monitor in real-time\nwatch -n 1 'ip -s link show eth0'\n\n# Show ARP cache\nip neighbour show\nip neigh show\n\n# Flush ARP cache\nip neighbour flush all\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#ifconfig-legacy-but-still-useful","title":"<code>ifconfig</code> (Legacy, but still useful)","text":"<pre><code># Show all interfaces\nifconfig -a\n\n# Show specific interface\nifconfig eth0\n\n# Show statistics\nifconfig eth0 | grep -E \"RX|TX\"\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#interface-statistics-files","title":"Interface Statistics Files","text":"<pre><code># View interface statistics via /sys\ncat /sys/class/net/eth0/statistics/rx_packets\ncat /sys/class/net/eth0/statistics/tx_packets\ncat /sys/class/net/eth0/statistics/rx_errors\ncat /sys/class/net/eth0/statistics/tx_errors\ncat /sys/class/net/eth0/statistics/collisions\n\n# View all statistics for interface\nls /sys/class/net/eth0/statistics/\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#routing-and-network-path","title":"Routing and Network Path","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#ip-route-command","title":"<code>ip route</code> Command","text":"<pre><code># Show routing table\nip route show\n\n# Show IPv6 routing table\nip -6 route show\n\n# Show routing table with details\nip route show table all\n\n# Show route to specific destination\nip route get 8.8.8.8\nip route get 2001:4860:4860::8888\n\n# Show routing cache (deprecated in newer kernels)\nip route show cache\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#traceroute-command","title":"<code>traceroute</code> Command","text":"<p>Shows the path packets take to reach destination.</p> <pre><code># Basic traceroute\ntraceroute google.com\n\n# Traceroute with no DNS resolution\ntraceroute -n 8.8.8.8\n\n# Traceroute using ICMP instead of UDP\ntraceroute -I google.com\n\n# Traceroute using TCP SYN\ntraceroute -T -p 80 google.com\n\n# Set maximum hops\ntraceroute -m 20 google.com\n\n# Set number of queries per hop\ntraceroute -q 3 google.com\n\n# IPv6 traceroute\ntraceroute6 google.com\n\n# MTU path discovery\ntraceroute --mtu google.com\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#tracepath-command","title":"<code>tracepath</code> Command","text":"<p>Similar to traceroute but doesn\u2019t require root privileges.</p> <pre><code># Basic tracepath\ntracepath google.com\n\n# IPv6 tracepath\ntracepath6 google.com\n\n# Set initial packet length\ntracepath -l 1400 google.com\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#mtr-command","title":"<code>mtr</code> Command","text":"<p>Combines ping and traceroute functionality with real-time updates.</p> <pre><code># Interactive mode\nmtr google.com\n\n# Report mode (non-interactive)\nmtr -r -c 10 google.com\n\n# No DNS resolution\nmtr -n google.com\n\n# Show both hostnames and IP addresses\nmtr -b google.com\n\n# Wide report mode\nmtr -w google.com\n\n# CSV output\nmtr --csv google.com\n\n# JSON output\nmtr --json google.com\n\n# Set packet size\nmtr -s 1000 google.com\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#port-and-service-connectivity","title":"Port and Service Connectivity","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#telnet-command","title":"<code>telnet</code> Command","text":"<p>Test TCP connectivity to specific ports.</p> <pre><code># Test HTTP port\ntelnet google.com 80\n\n# Test HTTPS port\ntelnet google.com 443\n\n# Test SSH port\ntelnet 192.168.1.100 22\n\n# Exit telnet: Ctrl+] then type 'quit'\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#nc-netcat-command","title":"<code>nc</code> (netcat) Command","text":"<p>Swiss Army knife for network testing.</p> <pre><code># Test TCP connection\nnc -vz google.com 80\n\n# Test UDP connection\nnc -vzu 8.8.8.8 53\n\n# Scan range of ports\nnc -vz google.com 80-443\n\n# Listen on a port\nnc -l 8080\n\n# Connect and send data\necho \"GET / HTTP/1.0\" | nc google.com 80\n\n# Transfer file\n# On receiver:\nnc -l 9999 &gt; received_file\n# On sender:\nnc receiver_ip 9999 &lt; file_to_send\n\n# Port scanning\nnc -zv 192.168.1.1 20-80\n\n# Test with timeout\nnc -w 3 -vz google.com 80\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#nmap-command","title":"<code>nmap</code> Command","text":"<p>Powerful network scanning and port discovery tool.</p> <pre><code># Scan single host\nnmap 192.168.1.1\n\n# Scan with service detection\nnmap -sV 192.168.1.1\n\n# Scan specific ports\nnmap -p 22,80,443 192.168.1.1\n\n# Scan port range\nnmap -p 1-1000 192.168.1.1\n\n# Scan all ports\nnmap -p- 192.168.1.1\n\n# Fast scan (top 100 ports)\nnmap -F 192.168.1.1\n\n# Scan subnet\nnmap 192.168.1.0/24\n\n# OS detection\nnmap -O 192.168.1.1\n\n# Aggressive scan\nnmap -A 192.168.1.1\n\n# TCP SYN scan (stealth)\nnmap -sS 192.168.1.1\n\n# UDP scan\nnmap -sU 192.168.1.1\n\n# Save output\nnmap -oN output.txt 192.168.1.1\nnmap -oX output.xml 192.168.1.1\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#network-statistics-and-connections","title":"Network Statistics and Connections","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#ss-command-socket-statistics","title":"<code>ss</code> Command (Socket Statistics)","text":"<p>Modern replacement for netstat, showing socket information.</p> <pre><code># Show all sockets\nss -a\n\n# Show listening TCP sockets\nss -lt\n\n# Show listening UDP sockets\nss -lu\n\n# Show all TCP connections\nss -t\n\n# Show all UDP connections\nss -u\n\n# Show process using socket\nss -p\n\n# Show summary statistics\nss -s\n\n# Show sockets with numeric ports\nss -n\n\n# Combine options\nss -tulpn\n\n# Show TCP sockets in listening state\nss -tln\n\n# Show established connections\nss -t state established\n\n# Show connections to specific port\nss -tn sport = :80\nss -tn dport = :443\n\n# Show connections to specific IP\nss dst 192.168.1.100\n\n# Show socket memory usage\nss -m\n\n# Show timer information\nss -o\n\n# Extended socket info\nss -e\n\n# Show both IPv4 and IPv6\nss -46tulpn\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#netstat-command-legacy","title":"<code>netstat</code> Command (Legacy)","text":"<pre><code># Show all listening ports\nnetstat -tuln\n\n# Show all connections with process\nnetstat -tulpn\n\n# Show routing table\nnetstat -r\n\n# Show interface statistics\nnetstat -i\n\n# Show network statistics\nnetstat -s\n\n# Continuous monitoring\nnetstat -c\n\n# Show only TCP\nnetstat -t\n\n# Show only UDP\nnetstat -u\n\n# Show listening sockets\nnetstat -l\n\n# Show all (listening and non-listening)\nnetstat -a\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#packet-capture-and-analysis","title":"Packet Capture and Analysis","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#tcpdump-command","title":"<code>tcpdump</code> Command","text":"<p>Capture and analyze network packets.</p> <pre><code># Capture on specific interface\ntcpdump -i eth0\n\n# Capture specific number of packets\ntcpdump -c 100 -i eth0\n\n# Capture and save to file\ntcpdump -i eth0 -w capture.pcap\n\n# Read from file\ntcpdump -r capture.pcap\n\n# Capture with verbose output\ntcpdump -v -i eth0\ntcpdump -vv -i eth0\ntcpdump -vvv -i eth0\n\n# Show packet contents in hex and ASCII\ntcpdump -X -i eth0\n\n# Capture specific host\ntcpdump -i eth0 host 192.168.1.100\n\n# Capture specific port\ntcpdump -i eth0 port 80\n\n# Capture specific protocol\ntcpdump -i eth0 icmp\ntcpdump -i eth0 tcp\ntcpdump -i eth0 udp\n\n# Capture source or destination\ntcpdump -i eth0 src 192.168.1.100\ntcpdump -i eth0 dst 192.168.1.100\n\n# Capture network range\ntcpdump -i eth0 net 192.168.1.0/24\n\n# Complex filters\ntcpdump -i eth0 'tcp port 80 and src 192.168.1.100'\ntcpdump -i eth0 'tcp[tcpflags] &amp; tcp-syn != 0'\n\n# Capture DNS queries\ntcpdump -i eth0 -n port 53\n\n# Capture HTTP traffic\ntcpdump -i eth0 -A 'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)'\n\n# Don't resolve hostnames\ntcpdump -n -i eth0\n\n# Don't resolve hostnames or ports\ntcpdump -nn -i eth0\n\n# Capture on all interfaces\ntcpdump -i any\n\n# Set snapshot length\ntcpdump -s 0 -i eth0  # Full packet\ntcpdump -s 96 -i eth0 # First 96 bytes\n\n# Rotate capture files\ntcpdump -i eth0 -w capture.pcap -C 100 -W 5\n</code></pre> <p>Common filters: - <code>host X</code>: Traffic to/from host X - <code>src X</code>: Traffic from X - <code>dst X</code>: Traffic to X - <code>net X</code>: Traffic to/from network X - <code>port X</code>: Traffic on port X - <code>portrange X-Y</code>: Traffic on port range - <code>less/greater X</code>: Packet size less/greater than X - <code>tcp/udp/icmp</code>: Specific protocol</p>"},{"location":"linux/network/monitor-troubleshoot-networking/#dns-troubleshooting","title":"DNS Troubleshooting","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#dig-command","title":"<code>dig</code> Command","text":"<pre><code># Basic query\ndig example.com\n\n# Query specific record type\ndig example.com A\ndig example.com AAAA\ndig example.com MX\ndig example.com NS\ndig example.com TXT\ndig example.com SOA\n\n# Query specific DNS server\ndig @8.8.8.8 example.com\n\n# Short answer only\ndig +short example.com\n\n# Reverse DNS lookup\ndig -x 8.8.8.8\n\n# Trace DNS resolution\ndig +trace example.com\n\n# Show query time\ndig example.com +stats\n\n# Show all information\ndig example.com ANY\n\n# Disable recursion\ndig +norecurse example.com\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#nslookup-command","title":"<code>nslookup</code> Command","text":"<pre><code># Basic query\nnslookup example.com\n\n# Query specific server\nnslookup example.com 8.8.8.8\n\n# Reverse lookup\nnslookup 8.8.8.8\n\n# Interactive mode\nnslookup\n&gt; server 8.8.8.8\n&gt; set type=MX\n&gt; example.com\n&gt; exit\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#host-command","title":"<code>host</code> Command","text":"<pre><code># Basic lookup\nhost example.com\n\n# Specific record type\nhost -t A example.com\nhost -t MX example.com\nhost -t NS example.com\n\n# Reverse lookup\nhost 8.8.8.8\n\n# Verbose output\nhost -v example.com\n\n# Query specific server\nhost example.com 8.8.8.8\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#network-performance-testing","title":"Network Performance Testing","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#iperf3-command","title":"<code>iperf3</code> Command","text":"<p>Network bandwidth testing tool.</p> <p>Server side: <pre><code># Start server\niperf3 -s\n\n# Start server on specific port\niperf3 -s -p 5201\n\n# Server with JSON output\niperf3 -s -J\n</code></pre></p> <p>Client side: <pre><code># Basic test\niperf3 -c server_ip\n\n# Test with specific duration\niperf3 -c server_ip -t 30\n\n# Test with specific bandwidth\niperf3 -c server_ip -b 100M\n\n# Reverse mode (server sends)\niperf3 -c server_ip -R\n\n# Bidirectional test\niperf3 -c server_ip --bidir\n\n# UDP test\niperf3 -c server_ip -u\n\n# Parallel streams\niperf3 -c server_ip -P 4\n\n# JSON output\niperf3 -c server_ip -J\n\n# Test specific port\niperf3 -c server_ip -p 5201\n</code></pre></p>"},{"location":"linux/network/monitor-troubleshoot-networking/#curl-command-for-http-testing","title":"<code>curl</code> Command for HTTP Testing","text":"<pre><code># Basic request with timing\ncurl -w \"@-\" -o /dev/null -s https://example.com &lt;&lt; 'EOF'\n    time_namelookup:  %{time_namelookup}\\n\n       time_connect:  %{time_connect}\\n\n    time_appconnect:  %{time_appconnect}\\n\n   time_pretransfer:  %{time_pretransfer}\\n\n      time_redirect:  %{time_redirect}\\n\n time_starttransfer:  %{time_starttransfer}\\n\n                    ----------\\n\n         time_total:  %{time_total}\\n\nEOF\n\n# Test connection speed\ncurl -o /dev/null https://example.com/file\n\n# Show only headers\ncurl -I https://example.com\n\n# Follow redirects with timing\ncurl -L -w \"Total time: %{time_total}s\\n\" https://example.com\n\n# Test with specific timeout\ncurl --connect-timeout 5 https://example.com\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#log-analysis-for-network-issues","title":"Log Analysis for Network Issues","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#system-logs","title":"System Logs","text":"<pre><code># General system logs\njournalctl -xe\n\n# Network-related logs\njournalctl -u NetworkManager\njournalctl -u systemd-networkd\njournalctl -u chronyd\n\n# Follow logs in real-time\njournalctl -f\n\n# Show kernel messages\ndmesg | grep -i eth\ndmesg | grep -i network\ndmesg | tail -50\n\n# Traditional log files\ntail -f /var/log/messages\ntail -f /var/log/syslog\ngrep -i network /var/log/messages\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#connection-tracking","title":"Connection Tracking","text":"<pre><code># Show connection tracking table (conntrack)\nconntrack -L\n\n# Show statistics\nconntrack -S\n\n# Monitor new connections\nconntrack -E\n\n# Count connections\nconntrack -C\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#bandwidth-monitoring","title":"Bandwidth Monitoring","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#iftop-command","title":"<code>iftop</code> Command","text":"<p>Real-time bandwidth monitoring per connection.</p> <pre><code># Monitor specific interface\niftop -i eth0\n\n# Don't resolve hostnames\niftop -n\n\n# Don't resolve port numbers\niftop -N\n\n# Show ports\niftop -P\n\n# Text mode (no curses)\niftop -t\n\n# Filter by network\niftop -F 192.168.1.0/24\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#nethogs-command","title":"<code>nethogs</code> Command","text":"<p>Bandwidth usage per process.</p> <pre><code># Monitor all interfaces\nnethogs\n\n# Monitor specific interface\nnethogs eth0\n\n# Don't resolve hostnames\nnethogs -v 0\n\n# Trace mode (no curses)\nnethogs -t\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#vnstat-command","title":"<code>vnstat</code> Command","text":"<p>Network traffic logger and monitor.</p> <pre><code># Show statistics for all interfaces\nvnstat\n\n# Show specific interface\nvnstat -i eth0\n\n# Live monitoring\nvnstat -l -i eth0\n\n# Show hourly stats\nvnstat -h -i eth0\n\n# Show daily stats\nvnstat -d -i eth0\n\n# Show monthly stats\nvnstat -m -i eth0\n\n# Show top days\nvnstat -t -i eth0\n\n# JSON output\nvnstat --json\n\n# Initialize database for interface\nvnstat -u -i eth0\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#bmon-command","title":"<code>bmon</code> Command","text":"<p>Bandwidth monitoring with graphical output.</p> <pre><code># Monitor all interfaces\nbmon\n\n# Monitor specific interface\nbmon -p eth0\n\n# Set update interval\nbmon -r 1\n\n# Show bits instead of bytes\nbmon -b\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#network-file-systems-monitoring","title":"Network File Systems Monitoring","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#nfsstat-command","title":"<code>nfsstat</code> Command","text":"<pre><code># Show NFS statistics\nnfsstat\n\n# Show client statistics\nnfsstat -c\n\n# Show server statistics\nnfsstat -s\n\n# Show all statistics\nnfsstat -a\n\n# Show statistics with timestamps\nwatch -n 5 nfsstat\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#showmount-command","title":"<code>showmount</code> Command","text":"<pre><code># Show NFS exports\nshowmount -e nfs_server\n\n# Show mounted directories\nshowmount -d nfs_server\n\n# Show all mount points\nshowmount -a nfs_server\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#wireless-network-monitoring","title":"Wireless Network Monitoring","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#iwconfig-command","title":"<code>iwconfig</code> Command","text":"<pre><code># Show wireless interfaces\niwconfig\n\n# Show specific interface\niwconfig wlan0\n\n# Set wireless parameters\niwconfig wlan0 essid \"NetworkName\"\niwconfig wlan0 key s:password\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#iw-command-modern","title":"<code>iw</code> Command (Modern)","text":"<pre><code># Show wireless devices\niw dev\n\n# Show wireless info\niw dev wlan0 info\n\n# Scan for networks\niw dev wlan0 scan\n\n# Show link status\niw dev wlan0 link\n\n# Show station info\niw dev wlan0 station dump\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#troubleshooting-workflow","title":"Troubleshooting Workflow","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#step-by-step-network-troubleshooting","title":"Step-by-Step Network Troubleshooting","text":"<ol> <li> <p>Check Physical Layer <pre><code># Check if interface is up\nip link show eth0\n\n# Check cable connection\nethtool eth0 | grep \"Link detected\"\n</code></pre></p> </li> <li> <p>Check IP Configuration <pre><code># Verify IP address\nip addr show eth0\n\n# Check for DHCP lease (if using DHCP)\ndhclient -v eth0\n</code></pre></p> </li> <li> <p>Check Local Connectivity <pre><code># Ping gateway\nping -c 4 192.168.1.1\n\n# Check ARP resolution\nip neigh show\n</code></pre></p> </li> <li> <p>Check DNS Resolution <pre><code># Test DNS\ndig google.com\nnslookup google.com\n\n# Check resolv.conf\ncat /etc/resolv.conf\n</code></pre></p> </li> <li> <p>Check Routing <pre><code># Verify default gateway\nip route show\n\n# Test route to destination\nip route get 8.8.8.8\n\n# Traceroute to destination\ntraceroute 8.8.8.8\n</code></pre></p> </li> <li> <p>Check Remote Connectivity <pre><code># Ping external host\nping -c 4 8.8.8.8\n\n# Test specific service\nnc -vz google.com 443\n</code></pre></p> </li> <li> <p>Check Firewall Rules <pre><code># Check firewall status\nfirewall-cmd --list-all\niptables -L -n -v\n</code></pre></p> </li> <li> <p>Check Services and Ports <pre><code># Check listening ports\nss -tulpn\n\n# Check specific service\nsystemctl status NetworkManager\n</code></pre></p> </li> </ol>"},{"location":"linux/network/monitor-troubleshoot-networking/#common-network-issues-and-solutions","title":"Common Network Issues and Solutions","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#issue-no-network-connectivity","title":"Issue: No Network Connectivity","text":"<pre><code># Check interface status\nip link show\n\n# Bring interface up\nip link set eth0 up\n\n# Restart NetworkManager\nsystemctl restart NetworkManager\n\n# Check for DHCP\ndhclient -v eth0\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#issue-dns-not-resolving","title":"Issue: DNS Not Resolving","text":"<pre><code># Check DNS servers\ncat /etc/resolv.conf\n\n# Test DNS manually\ndig @8.8.8.8 google.com\n\n# Flush DNS cache (systemd-resolved)\nresolvectl flush-caches\n\n# Restart DNS service\nsystemctl restart systemd-resolved\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#issue-slow-network-performance","title":"Issue: Slow Network Performance","text":"<pre><code># Check interface errors\nip -s link show eth0\n\n# Check bandwidth usage\niftop -i eth0\n\n# Check MTU\nip link show eth0 | grep mtu\n\n# Test bandwidth\niperf3 -c server_ip\n\n# Check for packet loss\nping -c 100 8.8.8.8 | grep loss\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#issue-intermittent-connectivity","title":"Issue: Intermittent Connectivity","text":"<pre><code># Monitor in real-time\nmtr google.com\n\n# Check for errors\ndmesg | grep -i eth\n\n# Monitor connections\nwatch -n 1 'ss -s'\n\n# Check logs\njournalctl -u NetworkManager -f\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#performance-metrics-to-monitor","title":"Performance Metrics to Monitor","text":"<ol> <li>Bandwidth: Current usage vs. available capacity</li> <li>Latency: Round-trip time (ping)</li> <li>Packet Loss: Percentage of lost packets</li> <li>Throughput: Actual data transfer rate</li> <li>Connection Count: Number of active connections</li> <li>Errors: Interface errors, collisions, drops</li> <li>DNS Resolution Time: Time to resolve hostnames</li> <li>MTU: Maximum transmission unit issues</li> </ol>"},{"location":"linux/network/monitor-troubleshoot-networking/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"linux/network/monitor-troubleshoot-networking/#connectivity","title":"Connectivity","text":"<pre><code>ping -c 4 8.8.8.8             # Test connectivity\ntraceroute google.com         # Trace route\nmtr google.com                # Combined ping/traceroute\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#interfaces-and-routing","title":"Interfaces and Routing","text":"<pre><code>ip addr show                  # Show IP addresses\nip link show                  # Show interfaces\nip route show                 # Show routing table\nip route get 8.8.8.8         # Show route to destination\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#connections-and-ports","title":"Connections and Ports","text":"<pre><code>ss -tulpn                     # Show listening ports\nss -t state established       # Show established TCP\nnc -vz host 80                # Test port connectivity\nnmap -p 80,443 host           # Scan specific ports\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#performance-and-monitoring","title":"Performance and Monitoring","text":"<pre><code>iftop -i eth0                 # Real-time bandwidth\nnethogs                       # Bandwidth per process\nvnstat -l -i eth0             # Live traffic stats\niperf3 -c server              # Bandwidth test\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#packet-analysis","title":"Packet Analysis","text":"<pre><code>tcpdump -i eth0 port 80       # Capture HTTP traffic\ntcpdump -nn -i eth0           # Capture without DNS lookup\ntcpdump -r file.pcap          # Read capture file\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#dns","title":"DNS","text":"<pre><code>dig google.com                # DNS query\nnslookup google.com           # Simple DNS lookup\nhost google.com               # Quick DNS lookup\n</code></pre>"},{"location":"linux/network/monitor-troubleshoot-networking/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know the difference between <code>ss</code> and <code>netstat</code> (prefer <code>ss</code>)</li> <li>Practice using <code>tcpdump</code> with various filters</li> <li>Understand how to read <code>mtr</code> output</li> <li>Be comfortable with both <code>ip</code> and legacy commands</li> <li>Know how to test connectivity at each OSI layer</li> <li>Practice troubleshooting methodology systematically</li> <li>Understand common port numbers (22, 80, 443, 53, etc.)</li> <li>Know how to interpret network statistics and errors</li> <li>Be able to identify bottlenecks and performance issues</li> <li>Practice reading and analyzing packet captures</li> </ul>"},{"location":"linux/network/openssh-configuration/","title":"Configure OpenSSH Server and Client","text":""},{"location":"linux/network/openssh-configuration/#overview","title":"Overview","text":"<p>This guide covers configuration, management, and security best practices for OpenSSH server (sshd) and client (ssh) on Linux systems.</p>"},{"location":"linux/network/openssh-configuration/#ssh-basics","title":"SSH Basics","text":"<p>SSH (Secure Shell) provides encrypted network communication for: - Remote command execution - Secure file transfer (SCP, SFTP) - Port forwarding and tunneling - X11 forwarding for GUI applications</p> <p>Default port: 22/TCP</p>"},{"location":"linux/network/openssh-configuration/#installation","title":"Installation","text":""},{"location":"linux/network/openssh-configuration/#install-openssh","title":"Install OpenSSH","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install openssh-server openssh-clients\n\n# Ubuntu/Debian\napt install openssh-server openssh-client\n\n# Check if installed\nrpm -qa | grep openssh          # RHEL\ndpkg -l | grep openssh          # Debian\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-server-sshd-configuration","title":"SSH Server (sshd) Configuration","text":""},{"location":"linux/network/openssh-configuration/#service-management","title":"Service Management","text":"<pre><code># Start SSH service\nsystemctl start sshd\n\n# Stop SSH service\nsystemctl stop sshd\n\n# Restart SSH service\nsystemctl restart sshd\n\n# Reload configuration (no connection drop)\nsystemctl reload sshd\n\n# Enable at boot\nsystemctl enable sshd\n\n# Check status\nsystemctl status sshd\n\n# Check if enabled\nsystemctl is-enabled sshd\n\n# View SSH service logs\njournalctl -u sshd\njournalctl -u sshd -f          # Follow logs\n</code></pre>"},{"location":"linux/network/openssh-configuration/#main-configuration-file","title":"Main Configuration File","text":"<p>Location: <code>/etc/ssh/sshd_config</code></p> <p>Important Configuration Directives:</p> <pre><code># Port and address binding\nPort 22                        # Change default port\n#Port 2222                     # Custom port\nListenAddress 0.0.0.0          # Listen on all IPv4\nListenAddress ::               # Listen on all IPv6\n#ListenAddress 192.168.1.100   # Specific IP only\n\n# Protocol version\nProtocol 2                     # Only use SSH protocol 2\n\n# Host keys\nHostKey /etc/ssh/ssh_host_rsa_key\nHostKey /etc/ssh/ssh_host_ecdsa_key\nHostKey /etc/ssh/ssh_host_ed25519_key\n\n# Logging\nSyslogFacility AUTH\nLogLevel INFO                  # QUIET, FATAL, ERROR, INFO, VERBOSE, DEBUG\n\n# Authentication\nPermitRootLogin no             # Disable root login (RECOMMENDED)\n#PermitRootLogin prohibit-password  # Allow only key-based root login\n#PermitRootLogin yes            # Allow all root login (NOT RECOMMENDED)\n\nPubkeyAuthentication yes       # Enable public key authentication\nPasswordAuthentication yes     # Enable password authentication\nPermitEmptyPasswords no        # Disable empty passwords\nChallengeResponseAuthentication no\n\n# PAM authentication\nUsePAM yes\n\n# Kerberos authentication\nKerberosAuthentication no\nKerberosOrLocalPasswd yes\n\n# GSSAPI authentication\nGSSAPIAuthentication no\n\n# Connection settings\nX11Forwarding yes              # Enable X11 forwarding\nX11UseLocalhost yes\nPrintMotd no                   # Don't print /etc/motd\nPrintLastLog yes\nTCPKeepAlive yes\nClientAliveInterval 300        # Send keepalive every 300 seconds\nClientAliveCountMax 3          # Disconnect after 3 failed keepalives\n\n# Login settings\nMaxAuthTries 3                 # Maximum authentication attempts\nMaxSessions 10                 # Maximum sessions per connection\nLoginGraceTime 60              # Time to authenticate (seconds)\n\n# Subsystem\nSubsystem sftp /usr/libexec/openssh/sftp-server\n\n# User/Group restrictions\nAllowUsers user1 user2         # Only these users can connect\n#DenyUsers baduser             # These users cannot connect\nAllowGroups sshusers           # Only members of these groups\n#DenyGroups restricted         # Members cannot connect\n\n# Banner\nBanner /etc/ssh/banner         # Display banner before login\n</code></pre>"},{"location":"linux/network/openssh-configuration/#example-secure-configuration","title":"Example: Secure Configuration","text":"<pre><code># /etc/ssh/sshd_config - Hardened configuration\nPort 2222\nProtocol 2\nListenAddress 0.0.0.0\n\n# Encryption\nCiphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com\nMACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com\nKexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group-exchange-sha256\n\n# Authentication\nPermitRootLogin no\nPubkeyAuthentication yes\nPasswordAuthentication no\nPermitEmptyPasswords no\nChallengeResponseAuthentication no\nUsePAM yes\n\n# Access control\nAllowGroups sshusers\nMaxAuthTries 3\nMaxSessions 5\nLoginGraceTime 30\n\n# Connection security\nClientAliveInterval 300\nClientAliveCountMax 2\nX11Forwarding no\nPrintMotd no\nTCPKeepAlive yes\n\n# Logging\nLogLevel VERBOSE\nSyslogFacility AUTH\n</code></pre>"},{"location":"linux/network/openssh-configuration/#test-configuration","title":"Test Configuration","text":"<pre><code># Test configuration syntax\nsshd -t\n\n# Test with specific config file\nsshd -t -f /etc/ssh/sshd_config\n\n# Test and show configuration\nsshd -T\n\n# Show configuration for specific user\nsshd -T -C user=john\n</code></pre>"},{"location":"linux/network/openssh-configuration/#reload-configuration","title":"Reload Configuration","text":"<pre><code># Reload without dropping connections\nsystemctl reload sshd\n\n# Or send HUP signal\nkill -HUP $(cat /var/run/sshd.pid)\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-client-configuration","title":"SSH Client Configuration","text":""},{"location":"linux/network/openssh-configuration/#per-user-configuration","title":"Per-User Configuration","text":"<p>Location: <code>~/.ssh/config</code></p> <pre><code># Global defaults\nHost *\n    ServerAliveInterval 60\n    ServerAliveCountMax 3\n    Compression yes\n    ForwardAgent no\n\n# Specific host\nHost webserver\n    HostName web.example.com\n    User admin\n    Port 2222\n    IdentityFile ~/.ssh/web_rsa\n\nHost db\n    HostName 192.168.1.100\n    User dbadmin\n    Port 22\n    IdentityFile ~/.ssh/db_key\n    ForwardAgent yes\n\n# Pattern matching\nHost *.example.com\n    User john\n    IdentityFile ~/.ssh/example_rsa\n\n# Jump host (bastion)\nHost internal-server\n    HostName 10.0.1.100\n    User admin\n    ProxyJump bastion.example.com\n\n# Multiple jump hosts\nHost deep-server\n    HostName 10.0.2.100\n    ProxyJump bastion1.example.com,bastion2.example.com\n</code></pre>"},{"location":"linux/network/openssh-configuration/#system-wide-configuration","title":"System-Wide Configuration","text":"<p>Location: <code>/etc/ssh/ssh_config</code></p>"},{"location":"linux/network/openssh-configuration/#ssh-key-management","title":"SSH Key Management","text":""},{"location":"linux/network/openssh-configuration/#generate-ssh-key-pairs","title":"Generate SSH Key Pairs","text":"<pre><code># Generate RSA key (default, 3072 bits)\nssh-keygen\n\n# Generate RSA with specific bits\nssh-keygen -t rsa -b 4096 -C \"user@email.com\"\n\n# Generate Ed25519 key (recommended, more secure)\nssh-keygen -t ed25519 -C \"user@email.com\"\n\n# Generate ECDSA key\nssh-keygen -t ecdsa -b 521\n\n# Specify file location\nssh-keygen -t ed25519 -f ~/.ssh/custom_key\n\n# Generate without passphrase (not recommended)\nssh-keygen -t ed25519 -N \"\"\n\n# Change passphrase of existing key\nssh-keygen -p -f ~/.ssh/id_ed25519\n</code></pre>"},{"location":"linux/network/openssh-configuration/#key-files","title":"Key Files","text":"<pre><code>~/.ssh/id_rsa          # Private key (RSA)\n~/.ssh/id_rsa.pub      # Public key (RSA)\n~/.ssh/id_ed25519      # Private key (Ed25519)\n~/.ssh/id_ed25519.pub  # Public key (Ed25519)\n~/.ssh/authorized_keys # Authorized public keys\n~/.ssh/known_hosts     # Known host fingerprints\n~/.ssh/config          # Client configuration\n</code></pre>"},{"location":"linux/network/openssh-configuration/#deploy-public-key","title":"Deploy Public Key","text":"<pre><code># Method 1: Using ssh-copy-id (recommended)\nssh-copy-id user@remote-host\nssh-copy-id -i ~/.ssh/id_ed25519.pub user@remote-host\nssh-copy-id -p 2222 user@remote-host\n\n# Method 2: Manual copy\ncat ~/.ssh/id_ed25519.pub | ssh user@remote-host \"mkdir -p ~/.ssh &amp;&amp; cat &gt;&gt; ~/.ssh/authorized_keys\"\n\n# Method 3: Direct append\nssh user@remote-host \"echo '$(cat ~/.ssh/id_ed25519.pub)' &gt;&gt; ~/.ssh/authorized_keys\"\n\n# Method 4: SCP\nscp ~/.ssh/id_ed25519.pub user@remote-host:~/key.pub\nssh user@remote-host \"mkdir -p ~/.ssh &amp;&amp; cat ~/key.pub &gt;&gt; ~/.ssh/authorized_keys &amp;&amp; rm ~/key.pub\"\n</code></pre>"},{"location":"linux/network/openssh-configuration/#correct-permissions","title":"Correct Permissions","text":"<pre><code># On remote server\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/authorized_keys\nchmod 600 ~/.ssh/id_*\nchmod 644 ~/.ssh/id_*.pub\nchmod 644 ~/.ssh/known_hosts\nchmod 600 ~/.ssh/config\n\n# Fix all at once\nchmod 700 ~/.ssh &amp;&amp; chmod 600 ~/.ssh/* &amp;&amp; chmod 644 ~/.ssh/*.pub\n</code></pre>"},{"location":"linux/network/openssh-configuration/#manage-authorized-keys","title":"Manage Authorized Keys","text":"<pre><code># Add key to authorized_keys\necho \"ssh-ed25519 AAAA...\" &gt;&gt; ~/.ssh/authorized_keys\n\n# View authorized keys\ncat ~/.ssh/authorized_keys\n\n# Remove specific key (edit file)\nvim ~/.ssh/authorized_keys\n\n# Limit key usage (prepend to key in authorized_keys)\nfrom=\"192.168.1.0/24\" ssh-ed25519 AAAA...\ncommand=\"/usr/local/bin/backup.sh\" ssh-ed25519 AAAA...\nno-port-forwarding,no-X11-forwarding ssh-ed25519 AAAA...\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-agent","title":"SSH Agent","text":"<pre><code># Start SSH agent\neval $(ssh-agent)\n\n# Add key to agent\nssh-add ~/.ssh/id_ed25519\n\n# Add with timeout (seconds)\nssh-add -t 3600 ~/.ssh/id_ed25519\n\n# List loaded keys\nssh-add -l\n\n# List loaded keys with full public key\nssh-add -L\n\n# Remove specific key\nssh-add -d ~/.ssh/id_ed25519\n\n# Remove all keys\nssh-add -D\n\n# Kill agent\nssh-agent -k\n</code></pre>"},{"location":"linux/network/openssh-configuration/#connecting-with-ssh","title":"Connecting with SSH","text":""},{"location":"linux/network/openssh-configuration/#basic-connection","title":"Basic Connection","text":"<pre><code># Connect to host\nssh user@hostname\n\n# Connect to specific port\nssh -p 2222 user@hostname\n\n# Connect using specific key\nssh -i ~/.ssh/custom_key user@hostname\n\n# Connect with verbose output\nssh -v user@hostname          # Level 1\nssh -vv user@hostname         # Level 2\nssh -vvv user@hostname        # Level 3 (most verbose)\n\n# Connect and execute command\nssh user@hostname \"ls -la /tmp\"\n\n# Connect and execute multiple commands\nssh user@hostname \"uptime; df -h; free -m\"\n\n# Using config alias\nssh webserver                 # Uses ~/.ssh/config\n</code></pre>"},{"location":"linux/network/openssh-configuration/#advanced-connection-options","title":"Advanced Connection Options","text":"<pre><code># Disable strict host key checking (use carefully)\nssh -o StrictHostKeyChecking=no user@hostname\n\n# Specify cipher\nssh -c aes256-gcm@openssh.com user@hostname\n\n# Enable compression\nssh -C user@hostname\n\n# Allocate pseudo-TTY\nssh -t user@hostname\n\n# No pseudo-TTY\nssh -T user@hostname\n\n# Run in background\nssh -f user@hostname \"sleep 10; command\"\n\n# Keep connection alive\nssh -o ServerAliveInterval=60 user@hostname\n\n# X11 forwarding\nssh -X user@hostname\nssh -Y user@hostname          # Trusted X11 forwarding\n</code></pre>"},{"location":"linux/network/openssh-configuration/#jump-hosts-bastion","title":"Jump Hosts (Bastion)","text":"<pre><code># Connect through jump host\nssh -J jump-host user@target-host\n\n# Multiple jump hosts\nssh -J jump1,jump2 user@target\n\n# Alternative syntax\nssh -o ProxyJump=jump-host user@target\n\n# With different users\nssh -J jumpuser@jump-host targetuser@target\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-tunneling-and-port-forwarding","title":"SSH Tunneling and Port Forwarding","text":""},{"location":"linux/network/openssh-configuration/#local-port-forwarding","title":"Local Port Forwarding","text":"<p>Forward local port to remote destination.</p> <pre><code># Basic syntax: ssh -L local_port:destination:destination_port user@ssh_server\n\n# Forward local port 8080 to remote localhost:80\nssh -L 8080:localhost:80 user@remote-host\n\n# Access remote database locally\nssh -L 3306:localhost:3306 user@database-server\n# Now connect to localhost:3306 locally\n\n# Forward to third host through SSH server\nssh -L 8080:internal-web:80 user@gateway\n\n# Multiple port forwards\nssh -L 8080:web:80 -L 3306:db:3306 user@gateway\n\n# Bind to specific interface\nssh -L 192.168.1.100:8080:localhost:80 user@remote\n</code></pre>"},{"location":"linux/network/openssh-configuration/#remote-port-forwarding","title":"Remote Port Forwarding","text":"<p>Forward remote port to local destination.</p> <pre><code># Basic syntax: ssh -R remote_port:destination:destination_port user@ssh_server\n\n# Expose local web server to remote\nssh -R 8080:localhost:80 user@remote-host\n# Remote host can access your local web server on port 8080\n\n# Allow remote server to forward to internal network\nssh -R 3306:database:3306 user@remote\n\n# Bind to all remote interfaces (requires GatewayPorts yes in sshd_config)\nssh -R 0.0.0.0:8080:localhost:80 user@remote\n</code></pre>"},{"location":"linux/network/openssh-configuration/#dynamic-port-forwarding-socks-proxy","title":"Dynamic Port Forwarding (SOCKS Proxy)","text":"<p>Create a SOCKS proxy for all traffic.</p> <pre><code># Create SOCKS proxy on local port 1080\nssh -D 1080 user@remote-host\n\n# Use specific bind address\nssh -D 127.0.0.1:1080 user@remote\n\n# Configure browser or application to use SOCKS proxy:\n# Host: localhost, Port: 1080, SOCKS v5\n\n# Test SOCKS proxy\ncurl --socks5 localhost:1080 http://example.com\n</code></pre>"},{"location":"linux/network/openssh-configuration/#combined-tunneling","title":"Combined Tunneling","text":"<pre><code># Local + Dynamic forwarding\nssh -L 8080:web:80 -D 1080 user@gateway\n\n# Background with no shell\nssh -fNL 8080:localhost:80 user@remote\n\n# Options explained:\n# -f: Background\n# -N: No command execution\n# -L: Local forward\n# -R: Remote forward\n# -D: Dynamic forward\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-tunnel-as-daemon","title":"SSH Tunnel as Daemon","text":"<pre><code># Create persistent tunnel\nssh -fNL 8080:localhost:80 user@remote\n\n# With auto-reconnect in cron\n*/5 * * * * pgrep -f \"ssh -fNL\" || ssh -fNL 8080:localhost:80 user@remote\n\n# Using autossh (better for persistent tunnels)\nautossh -M 0 -fNL 8080:localhost:80 user@remote\n</code></pre>"},{"location":"linux/network/openssh-configuration/#file-transfer-with-ssh","title":"File Transfer with SSH","text":""},{"location":"linux/network/openssh-configuration/#scp-secure-copy","title":"SCP (Secure Copy)","text":"<pre><code># Copy file to remote\nscp file.txt user@remote:/path/to/destination\n\n# Copy file from remote\nscp user@remote:/path/to/file.txt /local/destination\n\n# Copy directory recursively\nscp -r /local/dir user@remote:/remote/dir\n\n# Copy with specific port\nscp -P 2222 file.txt user@remote:/path\n\n# Copy with compression\nscp -C large_file.txt user@remote:/path\n\n# Preserve permissions and timestamps\nscp -p file.txt user@remote:/path\n\n# Copy between two remote hosts\nscp user1@remote1:/file user2@remote2:/path\n\n# Limit bandwidth (in Kbps)\nscp -l 1000 large_file user@remote:/path\n\n# Verbose output\nscp -v file.txt user@remote:/path\n</code></pre>"},{"location":"linux/network/openssh-configuration/#sftp-ssh-file-transfer-protocol","title":"SFTP (SSH File Transfer Protocol)","text":"<pre><code># Connect to SFTP server\nsftp user@remote-host\n\n# Connect with specific port\nsftp -P 2222 user@remote\n\n# SFTP interactive commands\nsftp&gt; ls                      # List remote directory\nsftp&gt; lls                     # List local directory\nsftp&gt; pwd                     # Print remote working directory\nsftp&gt; lpwd                    # Print local working directory\nsftp&gt; cd /remote/path         # Change remote directory\nsftp&gt; lcd /local/path         # Change local directory\nsftp&gt; get file.txt            # Download file\nsftp&gt; get -r directory/       # Download directory\nsftp&gt; put file.txt            # Upload file\nsftp&gt; put -r directory/       # Upload directory\nsftp&gt; mkdir newdir            # Create remote directory\nsftp&gt; rmdir directory         # Remove remote directory\nsftp&gt; rm file.txt             # Delete remote file\nsftp&gt; rename old.txt new.txt  # Rename remote file\nsftp&gt; chmod 755 script.sh     # Change permissions\nsftp&gt; exit                    # Quit\n\n# Batch mode with command file\necho \"get file.txt\" | sftp user@remote\n\n# Execute single command\nsftp user@remote &lt;&lt;&lt; \"get /remote/file.txt\"\n</code></pre>"},{"location":"linux/network/openssh-configuration/#rsync-over-ssh","title":"rsync over SSH","text":"<pre><code># Basic sync\nrsync -avz /local/path/ user@remote:/remote/path/\n\n# Sync with specific SSH port\nrsync -avz -e \"ssh -p 2222\" /local/ user@remote:/remote/\n\n# Sync with progress\nrsync -avz --progress /local/ user@remote:/remote/\n\n# Dry run (test without changes)\nrsync -avz --dry-run /local/ user@remote:/remote/\n\n# Delete files in destination not in source\nrsync -avz --delete /local/ user@remote:/remote/\n\n# Exclude files\nrsync -avz --exclude='*.log' /local/ user@remote:/remote/\n\n# Options explained:\n# -a: Archive mode (preserves permissions, times, etc.)\n# -v: Verbose\n# -z: Compress\n# -e: Specify SSH command\n</code></pre>"},{"location":"linux/network/openssh-configuration/#ssh-security-best-practices","title":"SSH Security Best Practices","text":""},{"location":"linux/network/openssh-configuration/#1-disable-root-login","title":"1. Disable Root Login","text":"<pre><code># In /etc/ssh/sshd_config\nPermitRootLogin no\n</code></pre>"},{"location":"linux/network/openssh-configuration/#2-use-key-based-authentication","title":"2. Use Key-Based Authentication","text":"<pre><code># Generate strong key\nssh-keygen -t ed25519 -C \"user@email.com\"\n\n# Disable password authentication after deploying keys\nPasswordAuthentication no\n</code></pre>"},{"location":"linux/network/openssh-configuration/#3-change-default-port","title":"3. Change Default Port","text":"<pre><code># In /etc/ssh/sshd_config\nPort 2222\n\n# Update firewall\nfirewall-cmd --permanent --add-port=2222/tcp\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/network/openssh-configuration/#4-limit-user-access","title":"4. Limit User Access","text":"<pre><code># In /etc/ssh/sshd_config\nAllowUsers john jane admin\n# Or use groups\nAllowGroups sshusers\n</code></pre>"},{"location":"linux/network/openssh-configuration/#5-use-fail2ban","title":"5. Use fail2ban","text":"<pre><code># Install fail2ban\ndnf install fail2ban\n\n# Configure for SSH\n# /etc/fail2ban/jail.local\n[sshd]\nenabled = true\nport = ssh\nfilter = sshd\nlogpath = /var/log/secure\nmaxretry = 3\nbantime = 3600\n</code></pre>"},{"location":"linux/network/openssh-configuration/#6-two-factor-authentication","title":"6. Two-Factor Authentication","text":"<pre><code># Install Google Authenticator PAM module\ndnf install google-authenticator\n\n# Configure PAM\n# Add to /etc/pam.d/sshd\nauth required pam_google_authenticator.so\n\n# Configure sshd_config\nChallengeResponseAuthentication yes\nAuthenticationMethods publickey,keyboard-interactive\n</code></pre>"},{"location":"linux/network/openssh-configuration/#7-restrict-ssh-protocol","title":"7. Restrict SSH Protocol","text":"<pre><code># Only use protocol 2\nProtocol 2\n</code></pre>"},{"location":"linux/network/openssh-configuration/#8-set-login-grace-time","title":"8. Set Login Grace Time","text":"<pre><code># Limit time to authenticate\nLoginGraceTime 30\n</code></pre>"},{"location":"linux/network/openssh-configuration/#9-use-tcp-wrappers","title":"9. Use TCP Wrappers","text":"<pre><code># /etc/hosts.allow\nsshd: 192.168.1.0/24\n\n# /etc/hosts.deny\nsshd: ALL\n</code></pre>"},{"location":"linux/network/openssh-configuration/#10-configure-idle-timeout","title":"10. Configure Idle Timeout","text":"<pre><code># In /etc/ssh/sshd_config\nClientAliveInterval 300\nClientAliveCountMax 2\n</code></pre>"},{"location":"linux/network/openssh-configuration/#troubleshooting-ssh","title":"Troubleshooting SSH","text":""},{"location":"linux/network/openssh-configuration/#check-ssh-service","title":"Check SSH Service","text":"<pre><code># Service status\nsystemctl status sshd\n\n# Check if listening\nss -tlnp | grep ssh\nnetstat -tlnp | grep ssh\n\n# Test configuration\nsshd -t\n\n# View logs\njournalctl -u sshd -f\ntail -f /var/log/secure    # RHEL\ntail -f /var/log/auth.log  # Ubuntu\n</code></pre>"},{"location":"linux/network/openssh-configuration/#verbose-connection-testing","title":"Verbose Connection Testing","text":"<pre><code># Client-side debugging\nssh -vvv user@host\n\n# Look for:\n# - Key exchange\n# - Authentication attempts\n# - Cipher negotiation\n# - Connection errors\n</code></pre>"},{"location":"linux/network/openssh-configuration/#common-issues","title":"Common Issues","text":""},{"location":"linux/network/openssh-configuration/#connection-refused","title":"Connection Refused","text":"<pre><code># Check if service running\nsystemctl status sshd\n\n# Check firewall\nfirewall-cmd --list-all\niptables -L -n\n\n# Check if listening on correct interface\nss -tlnp | grep :22\n</code></pre>"},{"location":"linux/network/openssh-configuration/#permission-denied-publickey","title":"Permission Denied (publickey)","text":"<pre><code># Check key permissions\nls -la ~/.ssh/\n\n# Should be:\n# 700 for ~/.ssh/\n# 600 for private keys\n# 644 for public keys\n\n# Check server logs\ntail -f /var/log/secure\n\n# Verify key is in authorized_keys\ncat ~/.ssh/authorized_keys\n\n# Test with password (if enabled)\nssh -o PubkeyAuthentication=no user@host\n</code></pre>"},{"location":"linux/network/openssh-configuration/#host-key-verification-failed","title":"Host Key Verification Failed","text":"<pre><code># Remove old key\nssh-keygen -R hostname\n\n# Or edit known_hosts\nvim ~/.ssh/known_hosts\n\n# Accept new key\nssh -o StrictHostKeyChecking=no user@host\n</code></pre>"},{"location":"linux/network/openssh-configuration/#too-many-authentication-failures","title":"Too Many Authentication Failures","text":"<pre><code># Limit keys offered\nssh -o IdentitiesOnly=yes -i ~/.ssh/specific_key user@host\n\n# Or configure in ~/.ssh/config\nHost problem-host\n    IdentitiesOnly yes\n    IdentityFile ~/.ssh/specific_key\n</code></pre>"},{"location":"linux/network/openssh-configuration/#firewall-configuration","title":"Firewall Configuration","text":""},{"location":"linux/network/openssh-configuration/#firewalld","title":"firewalld","text":"<pre><code># Allow SSH\nfirewall-cmd --permanent --add-service=ssh\nfirewall-cmd --reload\n\n# Allow custom SSH port\nfirewall-cmd --permanent --add-port=2222/tcp\nfirewall-cmd --reload\n\n# Allow from specific source\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" accept'\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/network/openssh-configuration/#iptables","title":"iptables","text":"<pre><code># Allow SSH\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\n\n# Allow from specific source\niptables -A INPUT -p tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT\n\n# Save rules\niptables-save &gt; /etc/sysconfig/iptables\n</code></pre>"},{"location":"linux/network/openssh-configuration/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"linux/network/openssh-configuration/#service-management_1","title":"Service Management","text":"<pre><code>systemctl start/stop/restart sshd    # Manage service\nsystemctl enable sshd                 # Enable at boot\nsshd -t                               # Test configuration\n</code></pre>"},{"location":"linux/network/openssh-configuration/#key-management","title":"Key Management","text":"<pre><code>ssh-keygen -t ed25519                 # Generate key\nssh-copy-id user@host                 # Deploy key\nssh-add                               # Add to agent\n</code></pre>"},{"location":"linux/network/openssh-configuration/#connecting","title":"Connecting","text":"<pre><code>ssh user@host                         # Basic connection\nssh -p 2222 user@host                 # Custom port\nssh -i key user@host                  # Specific key\nssh -J jump user@target               # Jump host\n</code></pre>"},{"location":"linux/network/openssh-configuration/#port-forwarding","title":"Port Forwarding","text":"<pre><code>ssh -L 8080:dest:80 user@host        # Local forward\nssh -R 8080:dest:80 user@host        # Remote forward\nssh -D 1080 user@host                 # SOCKS proxy\n</code></pre>"},{"location":"linux/network/openssh-configuration/#file-transfer","title":"File Transfer","text":"<pre><code>scp file user@host:/path              # Copy file\nsftp user@host                        # Interactive transfer\nrsync -avz /src/ user@host:/dst/     # Sync directories\n</code></pre>"},{"location":"linux/network/openssh-configuration/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know both server (<code>sshd_config</code>) and client (<code>ssh_config</code>) configuration</li> <li>Understand key-based authentication setup and troubleshooting</li> <li>Practice port forwarding scenarios (local, remote, dynamic)</li> <li>Know how to secure SSH (disable root, change port, keys only)</li> <li>Understand file permissions for SSH directories and files</li> <li>Be comfortable with <code>ssh-keygen</code>, <code>ssh-copy-id</code>, and <code>ssh-agent</code></li> <li>Know how to test SSH configuration without breaking access</li> <li>Practice troubleshooting with verbose output (<code>-vvv</code>)</li> <li>Understand TCP wrappers and firewall configuration for SSH</li> <li>Know the difference between SCP, SFTP, and rsync</li> </ul>"},{"location":"linux/network/packet-filtering-nat/","title":"Configure Packet Filtering, Port Redirection, and NAT","text":""},{"location":"linux/network/packet-filtering-nat/#overview","title":"Overview","text":"<p>This guide covers firewall configuration using firewalld and iptables, including packet filtering, port forwarding (redirection), and Network Address Translation (NAT) in Linux.</p>"},{"location":"linux/network/packet-filtering-nat/#firewall-concepts","title":"Firewall Concepts","text":""},{"location":"linux/network/packet-filtering-nat/#key-terms","title":"Key Terms","text":"<ul> <li>Packet Filtering: Controlling network traffic based on rules</li> <li>Stateful Firewall: Tracks connection state</li> <li>Stateless Firewall: Examines packets individually</li> <li>NAT: Network Address Translation (translates IP addresses)</li> <li>Port Forwarding: Redirects traffic from one port to another</li> <li>Masquerading: Dynamic source NAT (SNAT) for outbound traffic</li> <li>DNAT: Destination NAT (port forwarding, load balancing)</li> <li>SNAT: Source NAT (masquerading, explicit source translation)</li> </ul>"},{"location":"linux/network/packet-filtering-nat/#netfilteriptables-tables","title":"Netfilter/iptables Tables","text":"<ul> <li>filter: Default table for packet filtering (INPUT, OUTPUT, FORWARD)</li> <li>nat: Network address translation (PREROUTING, POSTROUTING, OUTPUT)</li> <li>mangle: Packet alteration (all chains)</li> <li>raw: Connection tracking exemption (PREROUTING, OUTPUT)</li> </ul>"},{"location":"linux/network/packet-filtering-nat/#iptables-chains","title":"iptables Chains","text":"<ul> <li>INPUT: Incoming packets destined for local system</li> <li>OUTPUT: Outgoing packets from local system</li> <li>FORWARD: Packets being routed through the system</li> <li>PREROUTING: Packets before routing decision (DNAT)</li> <li>POSTROUTING: Packets after routing decision (SNAT/Masquerading)</li> </ul>"},{"location":"linux/network/packet-filtering-nat/#firewalld-modern-firewall-management","title":"firewalld (Modern Firewall Management)","text":""},{"location":"linux/network/packet-filtering-nat/#overview_1","title":"Overview","text":"<p>firewalld is a dynamic firewall daemon that uses zones and services for easier management.</p>"},{"location":"linux/network/packet-filtering-nat/#installation-and-service-management","title":"Installation and Service Management","text":"<pre><code># Install firewalld\ndnf install firewalld\n\n# Start service\nsystemctl start firewalld\n\n# Enable at boot\nsystemctl enable firewalld\n\n# Check status\nsystemctl status firewalld\nfirewall-cmd --state\n\n# Stop firewall\nsystemctl stop firewalld\n\n# Disable at boot\nsystemctl disable firewalld\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#zones-concept","title":"Zones Concept","text":"<p>Zones define trust levels for network connections.</p> <pre><code># List all zones\nfirewall-cmd --get-zones\n\n# List active zones\nfirewall-cmd --get-active-zones\n\n# Get default zone\nfirewall-cmd --get-default-zone\n\n# Set default zone\nfirewall-cmd --set-default-zone=public\n\n# List configuration for zone\nfirewall-cmd --zone=public --list-all\n\n# List configuration for all zones\nfirewall-cmd --list-all-zones\n</code></pre> <p>Common zones: - drop: Drop all incoming, allow outgoing - block: Reject all incoming, allow outgoing - public: Public networks (default) - external: External networks with masquerading - dmz: DMZ (limited access) - work: Work networks - home: Home networks - internal: Internal networks - trusted: Trust all connections</p>"},{"location":"linux/network/packet-filtering-nat/#basic-firewall-cmd-operations","title":"Basic firewall-cmd Operations","text":""},{"location":"linux/network/packet-filtering-nat/#view-current-configuration","title":"View Current Configuration","text":"<pre><code># Show all settings\nfirewall-cmd --list-all\n\n# Show settings for specific zone\nfirewall-cmd --zone=public --list-all\n\n# List services\nfirewall-cmd --list-services\n\n# List ports\nfirewall-cmd --list-ports\n\n# List rich rules\nfirewall-cmd --list-rich-rules\n\n# List all\nfirewall-cmd --list-all-zones\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#runtime-vs-permanent-changes","title":"Runtime vs Permanent Changes","text":"<pre><code># Runtime change (lost on reload/reboot)\nfirewall-cmd --add-service=http\n\n# Permanent change (survives reload/reboot)\nfirewall-cmd --permanent --add-service=http\n\n# Apply both runtime and permanent\nfirewall-cmd --add-service=http\nfirewall-cmd --permanent --add-service=http\n\n# Reload to apply permanent changes\nfirewall-cmd --reload\n\n# Complete restart\nfirewall-cmd --complete-reload\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#managing-services","title":"Managing Services","text":""},{"location":"linux/network/packet-filtering-nat/#predefined-services","title":"Predefined Services","text":"<pre><code># List available services\nfirewall-cmd --get-services\n\n# Add service\nfirewall-cmd --permanent --add-service=http\nfirewall-cmd --permanent --add-service=https\nfirewall-cmd --permanent --add-service=ssh\n\n# Add multiple services\nfirewall-cmd --permanent --add-service={http,https,ssh}\n\n# Remove service\nfirewall-cmd --permanent --remove-service=http\n\n# Query service\nfirewall-cmd --query-service=http\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#custom-services","title":"Custom Services","text":"<p>Service definitions: <code>/etc/firewalld/services/</code></p> <pre><code># Create custom service file\n# /etc/firewalld/services/myapp.xml\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;service&gt;\n  &lt;short&gt;MyApp&lt;/short&gt;\n  &lt;description&gt;My Application Service&lt;/description&gt;\n  &lt;port protocol=\"tcp\" port=\"8080\"/&gt;\n  &lt;port protocol=\"udp\" port=\"8080\"/&gt;\n&lt;/service&gt;\n\n# Reload firewalld\nfirewall-cmd --reload\n\n# Add custom service\nfirewall-cmd --permanent --add-service=myapp\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#managing-ports","title":"Managing Ports","text":"<pre><code># Add single port\nfirewall-cmd --permanent --add-port=8080/tcp\n\n# Add port range\nfirewall-cmd --permanent --add-port=8000-8100/tcp\n\n# Add multiple ports\nfirewall-cmd --permanent --add-port={80/tcp,443/tcp,8080/tcp}\n\n# Remove port\nfirewall-cmd --permanent --remove-port=8080/tcp\n\n# Query port\nfirewall-cmd --query-port=8080/tcp\n\n# Add UDP port\nfirewall-cmd --permanent --add-port=53/udp\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#source-based-filtering","title":"Source-Based Filtering","text":"<pre><code># Allow traffic from specific source\nfirewall-cmd --permanent --add-source=192.168.1.0/24\n\n# Add source to specific zone\nfirewall-cmd --permanent --zone=trusted --add-source=10.0.0.0/8\n\n# Remove source\nfirewall-cmd --permanent --remove-source=192.168.1.100\n\n# Query source\nfirewall-cmd --query-source=192.168.1.0/24\n\n# Change zone for interface\nfirewall-cmd --zone=public --change-interface=eth0\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#rich-rules","title":"Rich Rules","text":"<p>More complex firewall rules with additional options.</p> <pre><code># Allow SSH from specific IP\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.100\" service name=\"ssh\" accept'\n\n# Allow HTTP from subnet\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"http\" accept'\n\n# Reject traffic from IP\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"10.0.0.5\" reject'\n\n# Drop traffic from IP\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"10.0.0.5\" drop'\n\n# Log accepted packets\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"ssh\" log prefix=\"SSH-ACCESS\" level=\"info\" accept'\n\n# Rate limiting (prevent DoS)\nfirewall-cmd --permanent --add-rich-rule='rule service name=\"ssh\" accept limit value=\"3/m\"'\n\n# Port-based rule\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" port port=\"8080\" protocol=\"tcp\" accept'\n\n# Time-based rule (not commonly supported)\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" service name=\"http\" accept'\n\n# Remove rich rule\nfirewall-cmd --permanent --remove-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.100\" service name=\"ssh\" accept'\n\n# List rich rules\nfirewall-cmd --list-rich-rules\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#port-forwarding-port-redirection","title":"Port Forwarding (Port Redirection)","text":""},{"location":"linux/network/packet-filtering-nat/#local-port-forwarding","title":"Local Port Forwarding","text":"<pre><code># Forward port 80 to 8080 on same system\nfirewall-cmd --permanent --add-forward-port=port=80:proto=tcp:toport=8080\n\n# Forward to different host\nfirewall-cmd --permanent --add-forward-port=port=80:proto=tcp:toaddr=192.168.1.100:toport=8080\n\n# Forward with source filtering\nfirewall-cmd --permanent --zone=public --add-rich-rule='rule family=\"ipv4\" source address=\"192.168.1.0/24\" forward-port port=\"80\" protocol=\"tcp\" to-port=\"8080\"'\n\n# Remove port forward\nfirewall-cmd --permanent --remove-forward-port=port=80:proto=tcp:toport=8080\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#masquerading-nat","title":"Masquerading (NAT)","text":"<pre><code># Enable masquerading (SNAT for outbound traffic)\nfirewall-cmd --permanent --zone=public --add-masquerade\n\n# Disable masquerading\nfirewall-cmd --permanent --zone=public --remove-masquerade\n\n# Query masquerading\nfirewall-cmd --zone=public --query-masquerade\n\n# Common use case: Internet gateway\n# External interface (public zone) with masquerading enabled\nfirewall-cmd --permanent --zone=public --add-interface=eth0\nfirewall-cmd --permanent --zone=public --add-masquerade\n\n# Internal interface (internal zone)\nfirewall-cmd --permanent --zone=internal --add-interface=eth1\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#direct-rules","title":"Direct Rules","text":"<p>Raw iptables rules within firewalld.</p> <pre><code># Add direct rule\nfirewall-cmd --permanent --direct --add-rule ipv4 filter INPUT 0 -p tcp --dport 9000 -j ACCEPT\n\n# Remove direct rule\nfirewall-cmd --permanent --direct --remove-rule ipv4 filter INPUT 0 -p tcp --dport 9000 -j ACCEPT\n\n# List direct rules\nfirewall-cmd --direct --get-all-rules\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#interface-management","title":"Interface Management","text":"<pre><code># Add interface to zone\nfirewall-cmd --permanent --zone=public --add-interface=eth0\n\n# Change interface zone\nfirewall-cmd --zone=internal --change-interface=eth1\n\n# Remove interface from zone\nfirewall-cmd --permanent --zone=public --remove-interface=eth0\n\n# Query interface\nfirewall-cmd --get-zone-of-interface=eth0\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#panic-mode","title":"Panic Mode","text":"<p>Emergency mode that blocks all traffic.</p> <pre><code># Enable panic mode\nfirewall-cmd --panic-on\n\n# Disable panic mode\nfirewall-cmd --panic-off\n\n# Query panic mode\nfirewall-cmd --query-panic\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#iptables-traditional-firewall","title":"iptables (Traditional Firewall)","text":""},{"location":"linux/network/packet-filtering-nat/#installation","title":"Installation","text":"<pre><code># Install iptables\ndnf install iptables iptables-services\n\n# Stop firewalld (conflicts with iptables)\nsystemctl stop firewalld\nsystemctl disable firewalld\nsystemctl mask firewalld\n\n# Enable iptables\nsystemctl start iptables\nsystemctl enable iptables\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#basic-iptables-syntax","title":"Basic iptables Syntax","text":"<pre><code>iptables [-t table] COMMAND CHAIN PARAMETERS -j TARGET\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#viewing-rules","title":"Viewing Rules","text":"<pre><code># List all rules\niptables -L\n\n# List with line numbers\niptables -L --line-numbers\n\n# List with verbose output\niptables -L -v\n\n# List with numeric output (no DNS)\niptables -L -n\n\n# List specific chain\niptables -L INPUT\n\n# List specific table\niptables -t nat -L\n\n# List all with packet counts\niptables -L -v -n\n\n# Show rules as commands\niptables-save\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#basic-packet-filtering","title":"Basic Packet Filtering","text":""},{"location":"linux/network/packet-filtering-nat/#allowdeny-traffic","title":"Allow/Deny Traffic","text":"<pre><code># Accept all incoming HTTP\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\n\n# Accept all incoming HTTPS\niptables -A INPUT -p tcp --dport 443 -j ACCEPT\n\n# Accept SSH\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\n\n# Accept from specific IP\niptables -A INPUT -s 192.168.1.100 -j ACCEPT\n\n# Accept from subnet\niptables -A INPUT -s 192.168.1.0/24 -j ACCEPT\n\n# Drop from specific IP\niptables -A INPUT -s 10.0.0.5 -j DROP\n\n# Reject from specific IP\niptables -A INPUT -s 10.0.0.5 -j REJECT\n\n# Accept on specific interface\niptables -A INPUT -i eth0 -p tcp --dport 80 -j ACCEPT\n\n# Accept established connections\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n# Accept loopback\niptables -A INPUT -i lo -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#default-policies","title":"Default Policies","text":"<pre><code># Set default policies\niptables -P INPUT DROP\niptables -P FORWARD DROP\niptables -P OUTPUT ACCEPT\n\n# View policies\niptables -L | grep policy\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#common-rule-patterns","title":"Common Rule Patterns","text":"<pre><code># Allow SSH with rate limiting\niptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set\niptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 60 --hitcount 4 -j DROP\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\n\n# Allow ICMP (ping)\niptables -A INPUT -p icmp --icmp-type echo-request -j ACCEPT\n\n# Allow DNS\niptables -A INPUT -p udp --dport 53 -j ACCEPT\niptables -A INPUT -p tcp --dport 53 -j ACCEPT\n\n# Allow established and related\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n# Log dropped packets\niptables -A INPUT -j LOG --log-prefix \"IPTABLES-DROPPED: \" --log-level 4\niptables -A INPUT -j DROP\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#deleting-rules","title":"Deleting Rules","text":"<pre><code># Delete by specification\niptables -D INPUT -p tcp --dport 80 -j ACCEPT\n\n# Delete by line number\niptables -D INPUT 5\n\n# Delete all rules in chain\niptables -F INPUT\n\n# Delete all rules in all chains\niptables -F\n\n# Delete all rules in specific table\niptables -t nat -F\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#inserting-rules","title":"Inserting Rules","text":"<pre><code># Insert at specific position\niptables -I INPUT 1 -p tcp --dport 22 -j ACCEPT\n\n# Replace rule at position\niptables -R INPUT 1 -p tcp --dport 2222 -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#nat-with-iptables","title":"NAT with iptables","text":""},{"location":"linux/network/packet-filtering-nat/#masquerading-snat","title":"Masquerading (SNAT)","text":"<pre><code># Enable IP forwarding (required for NAT)\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\n\n# Make permanent\necho \"net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf\nsysctl -p\n\n# Masquerade outgoing traffic\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n\n# Masquerade specific subnet\niptables -t nat -A POSTROUTING -s 192.168.1.0/24 -o eth0 -j MASQUERADE\n\n# SNAT (explicit source translation)\niptables -t nat -A POSTROUTING -o eth0 -j SNAT --to-source 203.0.113.5\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#dnat-port-forwarding","title":"DNAT (Port Forwarding)","text":"<pre><code># Forward external port to internal server\niptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:80\n\n# Forward to different port\niptables -t nat -A PREROUTING -p tcp --dport 8080 -j DNAT --to-destination 192.168.1.100:80\n\n# Forward with source restriction\niptables -t nat -A PREROUTING -s 10.0.0.0/8 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:80\n\n# Port range forwarding\niptables -t nat -A PREROUTING -p tcp --dport 8000:8100 -j DNAT --to-destination 192.168.1.100\n\n# Allow forwarded traffic\niptables -A FORWARD -p tcp -d 192.168.1.100 --dport 80 -j ACCEPT\niptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#complete-nat-router-example","title":"Complete NAT Router Example","text":"<pre><code># Enable IP forwarding\nsysctl -w net.ipv4.ip_forward=1\n\n# INPUT chain (for router itself)\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\niptables -A INPUT -j DROP\n\n# FORWARD chain (for routed traffic)\niptables -A FORWARD -i eth1 -o eth0 -j ACCEPT\niptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A FORWARD -j DROP\n\n# NAT (masquerade internal network)\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\n\n# Port forwarding (external 80 to internal 192.168.1.100:80)\niptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:80\niptables -A FORWARD -p tcp -d 192.168.1.100 --dport 80 -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#advanced-iptables-features","title":"Advanced iptables Features","text":""},{"location":"linux/network/packet-filtering-nat/#connection-tracking","title":"Connection Tracking","text":"<pre><code># Match connection states\niptables -A INPUT -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -m state --state INVALID -j DROP\n\n# Match conntrack states\niptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#rate-limiting","title":"Rate Limiting","text":"<pre><code># Limit new connections\niptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT\n\n# Limit ICMP\niptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/second -j ACCEPT\n\n# Recent module for rate limiting\niptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH\niptables -A INPUT -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 60 --hitcount 4 --rttl --name SSH -j DROP\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#multiple-ports","title":"Multiple Ports","text":"<pre><code># Match multiple ports\niptables -A INPUT -p tcp -m multiport --dports 80,443,8080 -j ACCEPT\n\n# Match port ranges\niptables -A INPUT -p tcp --dport 8000:8100 -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#mac-address-filtering","title":"MAC Address Filtering","text":"<pre><code># Allow specific MAC address\niptables -A INPUT -m mac --mac-source 00:11:22:33:44:55 -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#time-based-rules","title":"Time-Based Rules","text":"<pre><code># Allow during specific hours\niptables -A INPUT -p tcp --dport 80 -m time --timestart 09:00 --timestop 18:00 -j ACCEPT\n\n# Allow on specific days\niptables -A INPUT -p tcp --dport 80 -m time --weekdays Mon,Tue,Wed,Thu,Fri -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#string-matching","title":"String Matching","text":"<pre><code># Block packets containing string\niptables -A FORWARD -m string --string \"badstring\" --algo bm -j DROP\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#saving-and-restoring-rules","title":"Saving and Restoring Rules","text":"<pre><code># Save rules\niptables-save &gt; /etc/sysconfig/iptables\n\n# Restore rules\niptables-restore &lt; /etc/sysconfig/iptables\n\n# Save via service (RHEL/CentOS)\nservice iptables save\n\n# Persistent rules across reboots\nsystemctl enable iptables\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#nftables-modern-replacement-for-iptables","title":"nftables (Modern Replacement for iptables)","text":""},{"location":"linux/network/packet-filtering-nat/#overview_2","title":"Overview","text":"<p>nftables is the modern successor to iptables, offering better performance and syntax.</p>"},{"location":"linux/network/packet-filtering-nat/#installation_1","title":"Installation","text":"<pre><code># Install nftables\ndnf install nftables\n\n# Enable service\nsystemctl enable nftables\nsystemctl start nftables\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#basic-commands","title":"Basic Commands","text":"<pre><code># List ruleset\nnft list ruleset\n\n# Add table\nnft add table inet filter\n\n# Add chain\nnft add chain inet filter input { type filter hook input priority 0 \\; }\n\n# Add rule\nnft add rule inet filter input tcp dport 22 accept\n\n# Delete rule by handle\nnft -a list ruleset  # Show handles\nnft delete rule inet filter input handle 5\n\n# Flush rules\nnft flush ruleset\n\n# Save configuration\nnft list ruleset &gt; /etc/nftables.conf\n\n# Load configuration\nnft -f /etc/nftables.conf\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#ip-forwarding-and-routing","title":"IP Forwarding and Routing","text":""},{"location":"linux/network/packet-filtering-nat/#enable-ip-forwarding","title":"Enable IP Forwarding","text":"<pre><code># Temporary\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\n\n# Check status\ncat /proc/sys/net/ipv4/ip_forward\n\n# Permanent\necho \"net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf\nsysctl -p\n\n# For IPv6\necho \"net.ipv6.conf.all.forwarding = 1\" &gt;&gt; /etc/sysctl.conf\nsysctl -p\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#connection-tracking_1","title":"Connection Tracking","text":"<pre><code># View connection tracking table\nconntrack -L\n\n# Count connections\nconntrack -C\n\n# Delete specific connection\nconntrack -D -p tcp --dport 80\n\n# View statistics\ncat /proc/net/nf_conntrack\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#common-firewall-scenarios","title":"Common Firewall Scenarios","text":""},{"location":"linux/network/packet-filtering-nat/#scenario-1-basic-web-server","title":"Scenario 1: Basic Web Server","text":"<pre><code># Using firewalld\nfirewall-cmd --permanent --add-service=http\nfirewall-cmd --permanent --add-service=https\nfirewall-cmd --permanent --add-service=ssh\nfirewall-cmd --reload\n\n# Using iptables\niptables -A INPUT -i lo -j ACCEPT\niptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\niptables -A INPUT -p tcp --dport 22 -j ACCEPT\niptables -A INPUT -p tcp --dport 80 -j ACCEPT\niptables -A INPUT -p tcp --dport 443 -j ACCEPT\niptables -A INPUT -j DROP\niptables-save &gt; /etc/sysconfig/iptables\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#scenario-2-nat-gateway","title":"Scenario 2: NAT Gateway","text":"<pre><code># Enable forwarding\nsysctl -w net.ipv4.ip_forward=1\n\n# Using firewalld\nfirewall-cmd --permanent --zone=external --add-interface=eth0\nfirewall-cmd --permanent --zone=external --add-masquerade\nfirewall-cmd --permanent --zone=internal --add-interface=eth1\nfirewall-cmd --reload\n\n# Using iptables\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\niptables -A FORWARD -i eth1 -o eth0 -j ACCEPT\niptables -A FORWARD -m state --state ESTABLISHED,RELATED -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#scenario-3-port-forwarding-dmz","title":"Scenario 3: Port Forwarding (DMZ)","text":"<pre><code># Forward external 80 to DMZ server\n# Using firewalld\nfirewall-cmd --permanent --zone=public --add-forward-port=port=80:proto=tcp:toaddr=192.168.1.100:toport=80\nfirewall-cmd --reload\n\n# Using iptables\niptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:80\niptables -A FORWARD -p tcp -d 192.168.1.100 --dport 80 -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#scenario-4-restrict-ssh-access","title":"Scenario 4: Restrict SSH Access","text":"<pre><code># Allow SSH only from specific network\n# Using firewalld\nfirewall-cmd --permanent --remove-service=ssh\nfirewall-cmd --permanent --add-rich-rule='rule family=\"ipv4\" source address=\"10.0.0.0/8\" service name=\"ssh\" accept'\nfirewall-cmd --reload\n\n# Using iptables\niptables -A INPUT -p tcp -s 10.0.0.0/8 --dport 22 -j ACCEPT\niptables -A INPUT -p tcp --dport 22 -j DROP\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/network/packet-filtering-nat/#debug-firewalld","title":"Debug firewalld","text":"<pre><code># Check service status\nfirewall-cmd --state\nsystemctl status firewalld\n\n# View logs\njournalctl -u firewalld -f\n\n# Test rules\nfirewall-cmd --direct --get-all-rules\nfirewall-cmd --list-all\n\n# Reload\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#debug-iptables","title":"Debug iptables","text":"<pre><code># View packet counts\niptables -L -v -n\n\n# Watch packets in real-time\nwatch -n 1 'iptables -L -v -n'\n\n# Enable logging\niptables -A INPUT -j LOG --log-prefix \"IPTABLES: \"\ntail -f /var/log/messages\n\n# Trace packets\niptables -t raw -A PREROUTING -p tcp --dport 80 -j TRACE\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#test-connectivity","title":"Test Connectivity","text":"<pre><code># Test from external\ntelnet server_ip 80\nnc -vz server_ip 80\n\n# Test locally\ncurl localhost:80\nss -tlnp | grep :80\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/network/packet-filtering-nat/#firewalld","title":"firewalld","text":"<pre><code>firewall-cmd --list-all                                    # View configuration\nfirewall-cmd --permanent --add-service=http                # Add service\nfirewall-cmd --permanent --add-port=8080/tcp               # Add port\nfirewall-cmd --permanent --add-source=192.168.1.0/24       # Add source\nfirewall-cmd --permanent --add-masquerade                  # Enable NAT\nfirewall-cmd --permanent --add-forward-port=port=80:proto=tcp:toport=8080  # Port forward\nfirewall-cmd --reload                                      # Apply changes\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#iptables","title":"iptables","text":"<pre><code>iptables -L -n -v                                         # List rules\niptables -A INPUT -p tcp --dport 80 -j ACCEPT            # Add rule\niptables -D INPUT 5                                       # Delete rule\niptables -F                                               # Flush all\niptables-save &gt; /etc/sysconfig/iptables                  # Save rules\niptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE     # Masquerade\niptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to 192.168.1.100  # Port forward\n</code></pre>"},{"location":"linux/network/packet-filtering-nat/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know both firewalld and iptables basics</li> <li>Understand the difference between runtime and permanent changes</li> <li>Practice NAT and port forwarding scenarios</li> <li>Remember to enable IP forwarding for routing/NAT</li> <li>Know how to troubleshoot with logs and packet counts</li> <li>Understand firewalld zones concept</li> <li>Be comfortable with rich rules in firewalld</li> <li>Know the iptables table/chain structure</li> <li>Practice saving and restoring firewall rules</li> <li>Understand connection tracking and stateful filtering</li> </ul>"},{"location":"linux/network/reverse-proxy-load-balancer/","title":"Implement Reverse Proxies and Load Balancers","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#overview","title":"Overview","text":"<p>This guide covers implementation of reverse proxies and load balancers using HAProxy, Nginx, and Apache in Linux systems.</p>"},{"location":"linux/network/reverse-proxy-load-balancer/#concepts","title":"Concepts","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#reverse-proxy","title":"Reverse Proxy","text":"<p>A reverse proxy sits in front of web servers and forwards client requests to those servers. Benefits: - SSL/TLS termination - Caching - Compression - Security (hide backend servers) - Single entry point</p>"},{"location":"linux/network/reverse-proxy-load-balancer/#load-balancer","title":"Load Balancer","text":"<p>A load balancer distributes incoming traffic across multiple servers. Benefits: - High availability - Scalability - Redundancy - Performance optimization</p>"},{"location":"linux/network/reverse-proxy-load-balancer/#key-terms","title":"Key Terms","text":"<ul> <li>Frontend: Entry point that receives client requests</li> <li>Backend: Pool of servers that handle requests</li> <li>Health Check: Monitoring to verify server availability</li> <li>Session Persistence: Maintaining user session on same server (sticky sessions)</li> <li>Load Balancing Algorithm: Method to distribute traffic</li> </ul>"},{"location":"linux/network/reverse-proxy-load-balancer/#load-balancing-algorithms","title":"Load Balancing Algorithms","text":"<ul> <li>Round Robin: Sequential distribution</li> <li>Least Connections: Server with fewest active connections</li> <li>IP Hash: Based on client IP address</li> <li>Weighted: Servers have different capacities</li> <li>Least Response Time: Fastest responding server</li> </ul>"},{"location":"linux/network/reverse-proxy-load-balancer/#haproxy-high-availability-proxy","title":"HAProxy (High Availability Proxy)","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#overview_1","title":"Overview","text":"<p>HAProxy is a popular open-source load balancer and proxy server for TCP and HTTP-based applications.</p>"},{"location":"linux/network/reverse-proxy-load-balancer/#installation","title":"Installation","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install haproxy\n\n# Ubuntu/Debian\napt install haproxy\n\n# Start service\nsystemctl start haproxy\nsystemctl enable haproxy\n\n# Check status\nsystemctl status haproxy\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#configuration-file","title":"Configuration File","text":"<p>Location: <code>/etc/haproxy/haproxy.cfg</code></p>"},{"location":"linux/network/reverse-proxy-load-balancer/#basic-haproxy-configuration-structure","title":"Basic HAProxy Configuration Structure","text":"<pre><code># Global settings\nglobal\n    # Process management\n    # Logging\n    # Performance tuning\n\n# Default settings for all sections\ndefaults\n    # Timeouts\n    # Mode (tcp/http)\n    # Options\n\n# Frontend - entry point\nfrontend &lt;name&gt;\n    # Bind address and port\n    # ACLs\n    # Backend selection\n\n# Backend - server pool\nbackend &lt;name&gt;\n    # Load balancing algorithm\n    # Health checks\n    # Server definitions\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#simple-http-load-balancer-example","title":"Simple HTTP Load Balancer Example","text":"<pre><code># /etc/haproxy/haproxy.cfg\n\nglobal\n    log /dev/log local0\n    log /dev/log local1 notice\n    chroot /var/lib/haproxy\n    stats socket /run/haproxy/admin.sock mode 660 level admin\n    stats timeout 30s\n    user haproxy\n    group haproxy\n    daemon\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend http_front\n    bind *:80\n    stats uri /haproxy?stats\n    default_backend http_back\n\nbackend http_back\n    balance roundrobin\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n    server web3 192.168.1.12:80 check\n</code></pre> <p>Test and reload: <pre><code># Test configuration\nhaproxy -c -f /etc/haproxy/haproxy.cfg\n\n# Reload without dropping connections\nsystemctl reload haproxy\n\n# Restart\nsystemctl restart haproxy\n</code></pre></p>"},{"location":"linux/network/reverse-proxy-load-balancer/#advanced-haproxy-configuration","title":"Advanced HAProxy Configuration","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#ssltls-termination","title":"SSL/TLS Termination","text":"<pre><code>frontend https_front\n    bind *:443 ssl crt /etc/haproxy/certs/cert.pem\n    bind *:80\n    redirect scheme https code 301 if !{ ssl_fc }\n    default_backend web_back\n\nbackend web_back\n    balance roundrobin\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#health-checks","title":"Health Checks","text":"<pre><code>backend web_back\n    balance roundrobin\n    option httpchk GET /health\n    http-check expect status 200\n\n    server web1 192.168.1.10:80 check inter 2000 rise 2 fall 3\n    server web2 192.168.1.11:80 check inter 2000 rise 2 fall 3\n\n# Parameters:\n# check      - Enable health checks\n# inter 2000 - Check interval (2 seconds)\n# rise 2     - Consider server up after 2 successful checks\n# fall 3     - Consider server down after 3 failed checks\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#load-balancing-algorithms_1","title":"Load Balancing Algorithms","text":"<pre><code>backend web_back\n    # Round robin (default)\n    balance roundrobin\n\n    # Or least connections\n    # balance leastconn\n\n    # Or source IP hash\n    # balance source\n\n    # Or URI hash\n    # balance uri\n\n    # Or URL parameter hash\n    # balance url_param userid\n\n    server web1 192.168.1.10:80 check\n    server web2 192.168.1.11:80 check\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#weighted-load-balancing","title":"Weighted Load Balancing","text":"<pre><code>backend web_back\n    balance roundrobin\n    server web1 192.168.1.10:80 check weight 100\n    server web2 192.168.1.11:80 check weight 50\n    server web3 192.168.1.12:80 check weight 150\n    # web3 gets 1.5x more traffic than web1\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#session-persistence-sticky-sessions","title":"Session Persistence (Sticky Sessions)","text":"<pre><code>backend web_back\n    balance roundrobin\n    # Cookie-based persistence\n    cookie SERVERID insert indirect nocache\n    server web1 192.168.1.10:80 check cookie web1\n    server web2 192.168.1.11:80 check cookie web2\n\n    # Or source IP based\n    # stick-table type ip size 200k expire 30m\n    # stick on src\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#acls-access-control-lists","title":"ACLs (Access Control Lists)","text":"<pre><code>frontend http_front\n    bind *:80\n\n    # Define ACLs\n    acl is_api path_beg /api\n    acl is_admin path_beg /admin\n    acl is_static path_end .jpg .png .css .js\n    acl allowed_ips src 192.168.1.0/24 10.0.0.0/8\n\n    # Use ACLs\n    use_backend api_back if is_api\n    use_backend admin_back if is_admin allowed_ips\n    use_backend static_back if is_static\n    default_backend web_back\n\nbackend api_back\n    server api1 192.168.1.20:8080 check\n\nbackend admin_back\n    server admin1 192.168.1.30:8080 check\n\nbackend static_back\n    server static1 192.168.1.40:80 check\n\nbackend web_back\n    server web1 192.168.1.10:80 check\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#http-headers-manipulation","title":"HTTP Headers Manipulation","text":"<pre><code>frontend http_front\n    bind *:80\n    # Add headers\n    http-request add-header X-Forwarded-Proto https\n    http-request set-header X-Client-IP %[src]\n    default_backend web_back\n\nbackend web_back\n    # Add backend headers\n    http-request add-header X-Backend-Server %[srv_name]\n    # Remove headers\n    http-response del-header Server\n    server web1 192.168.1.10:80 check\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#rate-limiting","title":"Rate Limiting","text":"<pre><code>frontend http_front\n    bind *:80\n    # Track client requests\n    stick-table type ip size 100k expire 30s store http_req_rate(10s)\n    http-request track-sc0 src\n    # Deny if more than 100 requests in 10 seconds\n    http-request deny if { sc_http_req_rate(0) gt 100 }\n    default_backend web_back\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#haproxy-statistics-page","title":"HAProxy Statistics Page","text":"<pre><code>frontend http_front\n    bind *:80\n    # Enable stats\n    stats enable\n    stats uri /haproxy-stats\n    stats auth admin:password\n    stats refresh 30s\n    default_backend web_back\n</code></pre> <p>Access: http://your-server/haproxy-stats</p>"},{"location":"linux/network/reverse-proxy-load-balancer/#haproxy-runtime-api","title":"HAProxy Runtime API","text":"<pre><code># Connect to admin socket\necho \"show stat\" | socat stdio /run/haproxy/admin.sock\n\n# Show servers\necho \"show servers state\" | socat stdio /run/haproxy/admin.sock\n\n# Disable server\necho \"disable server web_back/web1\" | socat stdio /run/haproxy/admin.sock\n\n# Enable server\necho \"enable server web_back/web1\" | socat stdio /run/haproxy/admin.sock\n\n# Set server weight\necho \"set weight web_back/web1 50\" | socat stdio /run/haproxy/admin.sock\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#nginx-as-reverse-proxy-and-load-balancer","title":"Nginx as Reverse Proxy and Load Balancer","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#installation_1","title":"Installation","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install nginx\n\n# Ubuntu/Debian\napt install nginx\n\n# Start service\nsystemctl start nginx\nsystemctl enable nginx\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#basic-reverse-proxy-configuration","title":"Basic Reverse Proxy Configuration","text":"<pre><code># /etc/nginx/nginx.conf or /etc/nginx/conf.d/proxy.conf\n\nhttp {\n    upstream backend {\n        server 192.168.1.10:80;\n        server 192.168.1.11:80;\n        server 192.168.1.12:80;\n    }\n\n    server {\n        listen 80;\n        server_name example.com;\n\n        location / {\n            proxy_pass http://backend;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n        }\n    }\n}\n</code></pre> <p>Test and reload: <pre><code># Test configuration\nnginx -t\n\n# Reload\nsystemctl reload nginx\n\n# Restart\nsystemctl restart nginx\n</code></pre></p>"},{"location":"linux/network/reverse-proxy-load-balancer/#load-balancing-methods","title":"Load Balancing Methods","text":"<pre><code># Round robin (default)\nupstream backend {\n    server 192.168.1.10:80;\n    server 192.168.1.11:80;\n}\n\n# Least connections\nupstream backend {\n    least_conn;\n    server 192.168.1.10:80;\n    server 192.168.1.11:80;\n}\n\n# IP hash (session persistence)\nupstream backend {\n    ip_hash;\n    server 192.168.1.10:80;\n    server 192.168.1.11:80;\n}\n\n# Weighted load balancing\nupstream backend {\n    server 192.168.1.10:80 weight=3;\n    server 192.168.1.11:80 weight=1;\n    server 192.168.1.12:80 weight=2;\n}\n\n# Hash-based (generic)\nupstream backend {\n    hash $request_uri consistent;\n    server 192.168.1.10:80;\n    server 192.168.1.11:80;\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#health-checks_1","title":"Health Checks","text":"<pre><code>upstream backend {\n    server 192.168.1.10:80 max_fails=3 fail_timeout=30s;\n    server 192.168.1.11:80 max_fails=3 fail_timeout=30s;\n    server 192.168.1.12:80 backup;  # Backup server\n}\n\n# max_fails: Number of failed attempts before marking down\n# fail_timeout: Time to consider server down\n# backup: Only used when other servers are down\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#ssltls-termination_1","title":"SSL/TLS Termination","text":"<pre><code>server {\n    listen 443 ssl http2;\n    server_name example.com;\n\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers HIGH:!aNULL:!MD5;\n\n    location / {\n        proxy_pass http://backend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n\n# Redirect HTTP to HTTPS\nserver {\n    listen 80;\n    server_name example.com;\n    return 301 https://$server_name$request_uri;\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#caching","title":"Caching","text":"<pre><code># Define cache path\nproxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m max_size=1g inactive=60m;\n\nserver {\n    listen 80;\n\n    location / {\n        proxy_cache my_cache;\n        proxy_cache_valid 200 60m;\n        proxy_cache_valid 404 10m;\n        proxy_cache_key \"$scheme$request_method$host$request_uri\";\n        add_header X-Cache-Status $upstream_cache_status;\n\n        proxy_pass http://backend;\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>http {\n    # Rate limiting\n    limit_req_zone $binary_remote_addr zone=mylimit:10m rate=10r/s;\n\n    # Connection limiting\n    limit_conn_zone $binary_remote_addr zone=addr:10m;\n\n    upstream backend {\n        least_conn;\n        server 192.168.1.10:80 weight=3 max_fails=2 fail_timeout=30s;\n        server 192.168.1.11:80 weight=2 max_fails=2 fail_timeout=30s;\n        server 192.168.1.12:80 backup;\n\n        # Keepalive connections\n        keepalive 32;\n    }\n\n    server {\n        listen 80;\n        server_name example.com;\n\n        # Apply rate limit\n        location / {\n            limit_req zone=mylimit burst=20 nodelay;\n            limit_conn addr 10;\n\n            proxy_pass http://backend;\n            proxy_http_version 1.1;\n            proxy_set_header Connection \"\";\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n\n            # Timeouts\n            proxy_connect_timeout 60s;\n            proxy_send_timeout 60s;\n            proxy_read_timeout 60s;\n        }\n\n        # Static content (bypass backend)\n        location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ {\n            root /var/www/static;\n            expires 30d;\n            access_log off;\n        }\n\n        # Health check endpoint\n        location /health {\n            access_log off;\n            return 200 \"healthy\\n\";\n        }\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#apache-as-reverse-proxy","title":"Apache as Reverse Proxy","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#installation-and-modules","title":"Installation and Modules","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install httpd\n\n# Enable proxy modules\n# Modules are typically enabled by default or in:\n# /etc/httpd/conf.modules.d/00-proxy.conf\n\n# Required modules:\n# mod_proxy\n# mod_proxy_http\n# mod_proxy_balancer\n# mod_lbmethod_byrequests\n\n# Ubuntu/Debian\napt install apache2\na2enmod proxy\na2enmod proxy_http\na2enmod proxy_balancer\na2enmod lbmethod_byrequests\n\nsystemctl restart httpd  # or apache2\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#basic-reverse-proxy","title":"Basic Reverse Proxy","text":"<pre><code># /etc/httpd/conf.d/proxy.conf\n\n&lt;VirtualHost *:80&gt;\n    ServerName example.com\n\n    ProxyPreserveHost On\n    ProxyPass / http://192.168.1.10/\n    ProxyPassReverse / http://192.168.1.10/\n\n    # Logging\n    ErrorLog /var/log/httpd/proxy_error.log\n    CustomLog /var/log/httpd/proxy_access.log combined\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#load-balancer-configuration","title":"Load Balancer Configuration","text":"<pre><code>&lt;VirtualHost *:80&gt;\n    ServerName example.com\n\n    # Load balancer\n    &lt;Proxy balancer://mycluster&gt;\n        BalancerMember http://192.168.1.10:80\n        BalancerMember http://192.168.1.11:80\n        BalancerMember http://192.168.1.12:80\n\n        # Load balancing method\n        ProxySet lbmethod=byrequests\n        # Options: byrequests, bytraffic, bybusyness\n    &lt;/Proxy&gt;\n\n    ProxyPreserveHost On\n    ProxyPass / balancer://mycluster/\n    ProxyPassReverse / balancer://mycluster/\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#advanced-apache-load-balancer","title":"Advanced Apache Load Balancer","text":"<pre><code>&lt;VirtualHost *:80&gt;\n    ServerName example.com\n\n    &lt;Proxy balancer://mycluster&gt;\n        # Server definitions with parameters\n        BalancerMember http://192.168.1.10:80 loadfactor=3 route=node1\n        BalancerMember http://192.168.1.11:80 loadfactor=2 route=node2\n        BalancerMember http://192.168.1.12:80 loadfactor=1 status=+H\n        # status=+H means hot standby (backup)\n\n        # Health check (requires mod_proxy_hcheck)\n        # ProxySet lbmethod=bybusyness\n\n        # Session stickiness\n        ProxySet stickysession=ROUTEID\n    &lt;/Proxy&gt;\n\n    # Headers\n    RequestHeader set X-Forwarded-Proto \"http\"\n    RequestHeader set X-Forwarded-Port \"80\"\n\n    ProxyPass / balancer://mycluster/\n    ProxyPassReverse / balancer://mycluster/\n\n    # Manager interface\n    &lt;Location /balancer-manager&gt;\n        SetHandler balancer-manager\n        Require ip 192.168.1.0/24\n    &lt;/Location&gt;\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#ssl-termination","title":"SSL Termination","text":"<pre><code>&lt;VirtualHost *:443&gt;\n    ServerName example.com\n\n    SSLEngine on\n    SSLCertificateFile /etc/pki/tls/certs/cert.pem\n    SSLCertificateKeyFile /etc/pki/tls/private/key.pem\n\n    &lt;Proxy balancer://mycluster&gt;\n        BalancerMember http://192.168.1.10:80\n        BalancerMember http://192.168.1.11:80\n    &lt;/Proxy&gt;\n\n    RequestHeader set X-Forwarded-Proto \"https\"\n    ProxyPreserveHost On\n    ProxyPass / balancer://mycluster/\n    ProxyPassReverse / balancer://mycluster/\n&lt;/VirtualHost&gt;\n\n# HTTP to HTTPS redirect\n&lt;VirtualHost *:80&gt;\n    ServerName example.com\n    Redirect permanent / https://example.com/\n&lt;/VirtualHost&gt;\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#comparison-haproxy-vs-nginx-vs-apache","title":"Comparison: HAProxy vs Nginx vs Apache","text":"Feature HAProxy Nginx Apache Primary Use Load balancing Web server + proxy Web server + proxy Performance Excellent Excellent Good Configuration Moderate complexity Moderate Complex Layer 4 LB Yes Yes (stream) Limited Layer 7 LB Yes Yes Yes Health Checks Advanced Basic+ Basic SSL Termination Yes Yes Yes Statistics Built-in Third-party mod_status Hot Reload Yes Yes Limited Ease of Use Moderate Good Moderate"},{"location":"linux/network/reverse-proxy-load-balancer/#common-scenarios","title":"Common Scenarios","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#scenario-1-web-application-load-balancer","title":"Scenario 1: Web Application Load Balancer","text":"<pre><code># Nginx configuration\nhttp {\n    upstream webapp {\n        least_conn;\n        server 192.168.1.10:8080 weight=2;\n        server 192.168.1.11:8080 weight=2;\n        server 192.168.1.12:8080 weight=1;\n\n        keepalive 32;\n    }\n\n    server {\n        listen 80;\n        server_name app.example.com;\n\n        location / {\n            proxy_pass http://webapp;\n            proxy_http_version 1.1;\n            proxy_set_header Connection \"\";\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#scenario-2-api-gateway-with-rate-limiting","title":"Scenario 2: API Gateway with Rate Limiting","text":"<pre><code>http {\n    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;\n\n    upstream api_backend {\n        server 192.168.1.20:3000;\n        server 192.168.1.21:3000;\n    }\n\n    server {\n        listen 80;\n        server_name api.example.com;\n\n        location /api/ {\n            limit_req zone=api_limit burst=50 nodelay;\n\n            proxy_pass http://api_backend;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#scenario-3-high-availability-setup-with-health-checks","title":"Scenario 3: High Availability Setup with Health Checks","text":"<pre><code># HAProxy configuration\nfrontend http_front\n    bind *:80\n    default_backend web_servers\n\nbackend web_servers\n    balance leastconn\n    option httpchk GET /health HTTP/1.1\\r\\nHost:\\ example.com\n    http-check expect status 200\n\n    server web1 192.168.1.10:80 check inter 5s fall 3 rise 2\n    server web2 192.168.1.11:80 check inter 5s fall 3 rise 2\n    server web3 192.168.1.12:80 check inter 5s fall 3 rise 2 backup\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#scenario-4-ssl-offloading","title":"Scenario 4: SSL Offloading","text":"<pre><code>server {\n    listen 443 ssl http2;\n    server_name secure.example.com;\n\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n\n    location / {\n        proxy_pass http://backend;\n        proxy_set_header X-Forwarded-Proto https;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#haproxy-stats","title":"HAProxy Stats","text":"<pre><code># Via stats page\nfrontend http_front\n    stats enable\n    stats uri /stats\n    stats auth admin:password\n\n# Via socket\necho \"show stat\" | socat stdio /run/haproxy/admin.sock\n\n# Show info\necho \"show info\" | socat stdio /run/haproxy/admin.sock\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#nginx-status","title":"Nginx Status","text":"<pre><code>server {\n    listen 80;\n\n    location /nginx_status {\n        stub_status on;\n        access_log off;\n        allow 127.0.0.1;\n        deny all;\n    }\n}\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#logs","title":"Logs","text":"<pre><code># HAProxy logs\ntail -f /var/log/haproxy.log\n\n# Nginx logs\ntail -f /var/log/nginx/access.log\ntail -f /var/log/nginx/error.log\n\n# Apache logs\ntail -f /var/log/httpd/access_log\ntail -f /var/log/httpd/error_log\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#check-configuration","title":"Check Configuration","text":"<pre><code># HAProxy\nhaproxy -c -f /etc/haproxy/haproxy.cfg\n\n# Nginx\nnginx -t\n\n# Apache\napachectl configtest\nhttpd -t\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#test-backend-connectivity","title":"Test Backend Connectivity","text":"<pre><code># From load balancer\ncurl -I http://192.168.1.10/\ntelnet 192.168.1.10 80\nnc -vz 192.168.1.10 80\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#debug-issues","title":"Debug Issues","text":"<pre><code># Check if service is running\nsystemctl status haproxy\nsystemctl status nginx\nsystemctl status httpd\n\n# Check listening ports\nss -tlnp | grep haproxy\nss -tlnp | grep nginx\n\n# View connections\nss -tn | grep :80\n\n# Check logs\njournalctl -u haproxy -f\njournalctl -u nginx -f\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#common-issues","title":"Common Issues","text":"<p>Backend servers not responding: <pre><code># Check health\ncurl http://backend-ip/health\n\n# Verify firewall\nfirewall-cmd --list-all\n\n# Check backend logs\n</code></pre></p> <p>SSL certificate errors: <pre><code># Verify certificate\nopenssl x509 -in /path/to/cert.pem -text -noout\n\n# Test SSL\nopenssl s_client -connect example.com:443\n</code></pre></p>"},{"location":"linux/network/reverse-proxy-load-balancer/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/network/reverse-proxy-load-balancer/#haproxy","title":"HAProxy","text":"<pre><code>haproxy -c -f /etc/haproxy/haproxy.cfg    # Test config\nsystemctl reload haproxy                   # Reload\necho \"show stat\" | socat stdio /run/haproxy/admin.sock  # Stats\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#nginx","title":"Nginx","text":"<pre><code>nginx -t                                   # Test config\nsystemctl reload nginx                     # Reload\ncurl http://localhost/nginx_status         # Status\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#apache","title":"Apache","text":"<pre><code>apachectl configtest                       # Test config\nsystemctl reload httpd                     # Reload\ncurl http://localhost/server-status        # Status\n</code></pre>"},{"location":"linux/network/reverse-proxy-load-balancer/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know how to configure basic reverse proxy with Nginx or HAProxy</li> <li>Understand load balancing algorithms (round-robin, least-conn, etc.)</li> <li>Be familiar with health checks configuration</li> <li>Know how to implement SSL termination</li> <li>Understand session persistence mechanisms</li> <li>Practice testing configurations before applying</li> <li>Know how to view statistics and monitor</li> <li>Be comfortable with ACLs and routing rules</li> <li>Understand the difference between Layer 4 and Layer 7 load balancing</li> <li>Know how to troubleshoot backend connectivity issues</li> <li>Practice configuring multiple backends with different weights</li> <li>Understand when to use each solution (HAProxy vs Nginx vs Apache)</li> </ul>"},{"location":"linux/network/static-routing/","title":"Configure Static Routing","text":""},{"location":"linux/network/static-routing/#overview","title":"Overview","text":"<p>This guide covers static routing configuration, route management, policy-based routing, and advanced routing concepts in Linux.</p>"},{"location":"linux/network/static-routing/#routing-concepts","title":"Routing Concepts","text":""},{"location":"linux/network/static-routing/#key-terms","title":"Key Terms","text":"<ul> <li>Routing: Process of forwarding packets between networks</li> <li>Static Route: Manually configured route (doesn\u2019t change automatically)</li> <li>Dynamic Route: Automatically learned route (via routing protocols)</li> <li>Default Gateway: Route used when no specific route matches</li> <li>Metric: Cost or priority of a route (lower is preferred)</li> <li>Next Hop: Next router/gateway to forward packets</li> <li>Administrative Distance: Route preference (lower is preferred)</li> <li>Policy Routing: Routing based on source, not just destination</li> </ul>"},{"location":"linux/network/static-routing/#routing-table-components","title":"Routing Table Components","text":"<ul> <li>Destination: Target network</li> <li>Gateway: Next hop IP address</li> <li>Genmask/Prefix: Network mask</li> <li>Interface: Outgoing network interface</li> <li>Metric: Route priority</li> </ul>"},{"location":"linux/network/static-routing/#viewing-routing-tables","title":"Viewing Routing Tables","text":""},{"location":"linux/network/static-routing/#using-ip-route-command","title":"Using <code>ip route</code> Command","text":"<pre><code># Show routing table\nip route show\nip route list\nip r\n\n# Show with details\nip route show table all\n\n# Show specific table\nip route show table main\nip route show table local\n\n# Show IPv6 routes\nip -6 route show\n\n# Show route to specific destination\nip route get 8.8.8.8\nip route get 192.168.1.100\n\n# Show cached routes (deprecated in newer kernels)\nip route show cache\n</code></pre>"},{"location":"linux/network/static-routing/#using-route-command-legacy","title":"Using <code>route</code> Command (Legacy)","text":"<pre><code># Show routing table\nroute -n\n\n# Show with hostname resolution\nroute\n\n# Show IPv6 routes\nroute -A inet6 -n\n</code></pre>"},{"location":"linux/network/static-routing/#using-netstat-command","title":"Using <code>netstat</code> Command","text":"<pre><code># Show routing table\nnetstat -r\nnetstat -rn\n\n# Show IPv6 routes\nnetstat -rn -A inet6\n</code></pre>"},{"location":"linux/network/static-routing/#routing-table-files","title":"Routing Table Files","text":"<pre><code># View kernel routing table\ncat /proc/net/route\n\n# View IPv6 routing table\ncat /proc/net/ipv6_route\n\n# Format: destination, gateway, netmask, flags, metric, ref, use, interface\n</code></pre>"},{"location":"linux/network/static-routing/#managing-static-routes","title":"Managing Static Routes","text":""},{"location":"linux/network/static-routing/#using-ip-route-command_1","title":"Using <code>ip route</code> Command","text":""},{"location":"linux/network/static-routing/#add-routes","title":"Add Routes","text":"<pre><code># Add route to network via gateway\nip route add 10.0.0.0/8 via 192.168.1.1\n\n# Add route via specific interface\nip route add 10.0.0.0/8 dev eth1\n\n# Add route with both gateway and interface\nip route add 10.0.0.0/8 via 192.168.1.1 dev eth0\n\n# Add default gateway\nip route add default via 192.168.1.1\nip route add 0.0.0.0/0 via 192.168.1.1\n\n# Add route with metric\nip route add 10.0.0.0/8 via 192.168.1.1 metric 100\n\n# Add host route (single IP)\nip route add 10.0.0.5/32 via 192.168.1.1\n\n# Add IPv6 route\nip -6 route add 2001:db8::/32 via 2001:db8::1\n\n# Add IPv6 default gateway\nip -6 route add default via 2001:db8::1\n</code></pre>"},{"location":"linux/network/static-routing/#delete-routes","title":"Delete Routes","text":"<pre><code># Delete specific route\nip route del 10.0.0.0/8 via 192.168.1.1\n\n# Delete default gateway\nip route del default\n\n# Delete IPv6 route\nip -6 route del 2001:db8::/32\n</code></pre>"},{"location":"linux/network/static-routing/#replace-routes","title":"Replace Routes","text":"<pre><code># Replace existing route\nip route replace 10.0.0.0/8 via 192.168.1.2\n\n# Replace default gateway\nip route replace default via 192.168.1.254\n</code></pre>"},{"location":"linux/network/static-routing/#flush-routes","title":"Flush Routes","text":"<pre><code># Flush all routes\nip route flush table main\n\n# Flush routes to specific network\nip route flush 10.0.0.0/8\n\n# Flush cached routes\nip route flush cache\n</code></pre>"},{"location":"linux/network/static-routing/#using-route-command-legacy_1","title":"Using <code>route</code> Command (Legacy)","text":"<pre><code># Add route\nroute add -net 10.0.0.0/8 gw 192.168.1.1\n\n# Add default gateway\nroute add default gw 192.168.1.1\n\n# Add host route\nroute add -host 10.0.0.5 gw 192.168.1.1\n\n# Delete route\nroute del -net 10.0.0.0/8\n\n# Delete default gateway\nroute del default\n\n# Add route via interface\nroute add -net 10.0.0.0/8 dev eth1\n</code></pre>"},{"location":"linux/network/static-routing/#persistent-static-routes","title":"Persistent Static Routes","text":""},{"location":"linux/network/static-routing/#rhelcentosfedora","title":"RHEL/CentOS/Fedora","text":""},{"location":"linux/network/static-routing/#method-1-network-scripts","title":"Method 1: Network Scripts","text":"<p>Create route files: <code>/etc/sysconfig/network-scripts/route-&lt;interface&gt;</code></p> <pre><code># /etc/sysconfig/network-scripts/route-eth0\n10.0.0.0/8 via 192.168.1.1\n172.16.0.0/12 via 192.168.1.1 dev eth0\ndefault via 192.168.1.254\n\n# Format:\n# network/prefix via gateway [dev interface] [metric N]\n</code></pre> <p>Alternative format: <pre><code># /etc/sysconfig/network-scripts/route-eth0\nADDRESS0=10.0.0.0\nNETMASK0=255.0.0.0\nGATEWAY0=192.168.1.1\n\nADDRESS1=172.16.0.0\nNETMASK1=255.240.0.0\nGATEWAY1=192.168.1.1\n</code></pre></p>"},{"location":"linux/network/static-routing/#method-2-networkmanager","title":"Method 2: NetworkManager","text":"<p>Using <code>nmcli</code>: <pre><code># Add static route to connection\nnmcli connection modify eth0 +ipv4.routes \"10.0.0.0/8 192.168.1.1\"\n\n# Add multiple routes\nnmcli connection modify eth0 +ipv4.routes \"10.0.0.0/8 192.168.1.1, 172.16.0.0/12 192.168.1.1\"\n\n# Add route with metric\nnmcli connection modify eth0 +ipv4.routes \"10.0.0.0/8 192.168.1.1 100\"\n\n# Remove route\nnmcli connection modify eth0 -ipv4.routes \"10.0.0.0/8 192.168.1.1\"\n\n# View routes\nnmcli connection show eth0 | grep ipv4.routes\n\n# Apply changes\nnmcli connection up eth0\n\n# IPv6 routes\nnmcli connection modify eth0 +ipv6.routes \"2001:db8::/32 2001:db8::1\"\n</code></pre></p>"},{"location":"linux/network/static-routing/#method-3-networkmanager-configuration-files","title":"Method 3: NetworkManager Configuration Files","text":"<p>Edit: <code>/etc/NetworkManager/system-connections/&lt;connection&gt;.nmconnection</code></p> <pre><code>[ipv4]\nmethod=manual\naddress1=192.168.1.100/24,192.168.1.1\nroute1=10.0.0.0/8,192.168.1.1\nroute2=172.16.0.0/12,192.168.1.1,100\ndns=8.8.8.8;8.8.4.4;\n\n[ipv6]\nmethod=manual\naddress1=2001:db8::100/64,2001:db8::1\nroute1=2001:db8:1::/48,2001:db8::1\n</code></pre> <p>Reload NetworkManager: <pre><code>nmcli connection reload\nnmcli connection up eth0\n</code></pre></p>"},{"location":"linux/network/static-routing/#ubuntudebian-netplan","title":"Ubuntu/Debian (Netplan)","text":"<p>Edit: <code>/etc/netplan/01-netcfg.yaml</code></p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      routes:\n        - to: 10.0.0.0/8\n          via: 192.168.1.1\n          metric: 100\n        - to: 172.16.0.0/12\n          via: 192.168.1.1\n        - to: 0.0.0.0/0\n          via: 192.168.1.254\n          metric: 200\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n</code></pre> <p>IPv6 example: <pre><code>network:\n  version: 2\n  ethernets:\n    eth0:\n      addresses:\n        - 2001:db8::100/64\n      gateway6: 2001:db8::1\n      routes:\n        - to: 2001:db8:1::/48\n          via: 2001:db8::1\n</code></pre></p> <p>Apply configuration: <pre><code>netplan try      # Test configuration\nnetplan apply    # Apply configuration\n</code></pre></p>"},{"location":"linux/network/static-routing/#systemd-networkd","title":"systemd-networkd","text":"<p>Configuration: <code>/etc/systemd/network/</code></p> <pre><code># /etc/systemd/network/20-wired.network\n[Match]\nName=eth0\n\n[Network]\nAddress=192.168.1.100/24\nGateway=192.168.1.1\n\n[Route]\nDestination=10.0.0.0/8\nGateway=192.168.1.1\nMetric=100\n\n[Route]\nDestination=172.16.0.0/12\nGateway=192.168.1.1\n\n[Route]\nDestination=0.0.0.0/0\nGateway=192.168.1.254\nMetric=200\n</code></pre> <p>Restart service: <pre><code>systemctl restart systemd-networkd\n</code></pre></p>"},{"location":"linux/network/static-routing/#multiple-default-gateways","title":"Multiple Default Gateways","text":""},{"location":"linux/network/static-routing/#metric-based-selection","title":"Metric-Based Selection","text":"<pre><code># Primary default gateway (lower metric)\nip route add default via 192.168.1.1 metric 100\n\n# Backup default gateway (higher metric)\nip route add default via 192.168.2.1 metric 200\n\n# View\nip route show\n</code></pre>"},{"location":"linux/network/static-routing/#multiple-gateways-load-balancing","title":"Multiple Gateways (Load Balancing)","text":"<pre><code># Equal-cost multi-path routing\nip route add default \\\n    nexthop via 192.168.1.1 dev eth0 weight 1 \\\n    nexthop via 192.168.2.1 dev eth1 weight 1\n</code></pre>"},{"location":"linux/network/static-routing/#policy-based-routing","title":"Policy-Based Routing","text":""},{"location":"linux/network/static-routing/#routing-tables","title":"Routing Tables","text":""},{"location":"linux/network/static-routing/#view-routing-tables","title":"View Routing Tables","text":"<pre><code># List all tables\ncat /etc/iproute2/rt_tables\n\n# Default tables:\n# 0     unspec\n# 253   default\n# 254   main\n# 255   local\n\n# Add custom table\necho \"100 custom\" &gt;&gt; /etc/iproute2/rt_tables\n</code></pre>"},{"location":"linux/network/static-routing/#manage-routes-in-custom-tables","title":"Manage Routes in Custom Tables","text":"<pre><code># Add route to custom table\nip route add 10.0.0.0/8 via 192.168.1.1 table custom\n\n# Add default gateway to custom table\nip route add default via 192.168.1.1 table custom\n\n# Show routes in custom table\nip route show table custom\n\n# Delete route from table\nip route del 10.0.0.0/8 table custom\n</code></pre>"},{"location":"linux/network/static-routing/#routing-rules-policy-routing","title":"Routing Rules (Policy Routing)","text":""},{"location":"linux/network/static-routing/#view-rules","title":"View Rules","text":"<pre><code># Show routing rules\nip rule show\nip rule list\n\n# Default rules:\n# 0: from all lookup local\n# 32766: from all lookup main\n# 32767: from all lookup default\n</code></pre>"},{"location":"linux/network/static-routing/#add-rules","title":"Add Rules","text":"<p>Source-based routing: <pre><code># Route traffic from specific source via custom table\nip rule add from 192.168.1.100 table custom priority 100\n\n# Route traffic from network\nip rule add from 192.168.1.0/24 table custom priority 100\n</code></pre></p> <p>Destination-based routing: <pre><code># Route traffic to specific destination via custom table\nip rule add to 10.0.0.0/8 table custom priority 100\n</code></pre></p> <p>Interface-based routing: <pre><code># Route traffic arriving on interface\nip rule add iif eth0 table custom priority 100\n\n# Route traffic leaving on interface\nip rule add oif eth1 table custom priority 100\n</code></pre></p> <p>TOS-based routing: <pre><code># Route based on Type of Service\nip rule add tos 0x10 table custom priority 100\n</code></pre></p> <p>Fwmark-based routing: <pre><code># Route based on firewall mark\nip rule add fwmark 1 table custom priority 100\n</code></pre></p> <p>Combined rules: <pre><code># Complex rule\nip rule add from 192.168.1.0/24 to 10.0.0.0/8 table custom priority 100\n</code></pre></p>"},{"location":"linux/network/static-routing/#delete-rules","title":"Delete Rules","text":"<pre><code># Delete by specification\nip rule del from 192.168.1.100 table custom\n\n# Delete by priority\nip rule del priority 100\n\n# Flush all rules (dangerous!)\nip rule flush\n</code></pre>"},{"location":"linux/network/static-routing/#complete-policy-routing-example","title":"Complete Policy Routing Example","text":"<p>Scenario: Route traffic from different networks through different gateways</p> <pre><code># Create custom routing tables\necho \"100 isp1\" &gt;&gt; /etc/iproute2/rt_tables\necho \"200 isp2\" &gt;&gt; /etc/iproute2/rt_tables\n\n# Add routes to tables\nip route add default via 10.0.1.1 table isp1\nip route add default via 10.0.2.1 table isp2\n\n# Add routing rules\nip rule add from 192.168.1.0/24 table isp1 priority 100\nip rule add from 192.168.2.0/24 table isp2 priority 200\n\n# Add routes for local networks in both tables\nip route add 192.168.1.0/24 dev eth1 table isp1\nip route add 192.168.2.0/24 dev eth2 table isp2\n\n# Flush routing cache\nip route flush cache\n</code></pre>"},{"location":"linux/network/static-routing/#source-based-routing-example","title":"Source-Based Routing Example","text":"<p>Route different users through different gateways:</p> <pre><code># Setup\necho \"100 admin_table\" &gt;&gt; /etc/iproute2/rt_tables\n\n# Add default gateway for admin table\nip route add default via 192.168.1.1 table admin_table\n\n# Add local network routes\nip route add 192.168.1.0/24 dev eth0 table admin_table\n\n# Route admin user (192.168.1.100) through specific gateway\nip rule add from 192.168.1.100 table admin_table priority 100\n\n# Verify\nip rule show\nip route show table admin_table\n</code></pre>"},{"location":"linux/network/static-routing/#equal-cost-multi-path-ecmp-routing","title":"Equal-Cost Multi-Path (ECMP) Routing","text":""},{"location":"linux/network/static-routing/#load-balancing-between-gateways","title":"Load Balancing Between Gateways","text":"<pre><code># Add multi-path default route\nip route add default \\\n    nexthop via 192.168.1.1 dev eth0 weight 1 \\\n    nexthop via 192.168.2.1 dev eth1 weight 1\n\n# Unequal weight distribution (2:1 ratio)\nip route add default \\\n    nexthop via 192.168.1.1 dev eth0 weight 2 \\\n    nexthop via 192.168.2.1 dev eth1 weight 1\n\n# View\nip route show\n</code></pre>"},{"location":"linux/network/static-routing/#reverse-path-filtering","title":"Reverse Path Filtering","text":""},{"location":"linux/network/static-routing/#configure-rp_filter","title":"Configure rp_filter","text":"<pre><code># Check current settings\ncat /proc/sys/net/ipv4/conf/all/rp_filter\ncat /proc/sys/net/ipv4/conf/eth0/rp_filter\n\n# Values:\n# 0 = No source validation\n# 1 = Strict mode (recommended)\n# 2 = Loose mode\n\n# Set temporarily\necho 1 &gt; /proc/sys/net/ipv4/conf/all/rp_filter\n\n# Set permanently\necho \"net.ipv4.conf.all.rp_filter = 1\" &gt;&gt; /etc/sysctl.conf\necho \"net.ipv4.conf.default.rp_filter = 1\" &gt;&gt; /etc/sysctl.conf\nsysctl -p\n</code></pre>"},{"location":"linux/network/static-routing/#advanced-routing-features","title":"Advanced Routing Features","text":""},{"location":"linux/network/static-routing/#nexthop-objects-newer-kernels","title":"Nexthop Objects (Newer Kernels)","text":"<pre><code># Create nexthop object\nip nexthop add id 1 via 192.168.1.1 dev eth0\nip nexthop add id 2 via 192.168.2.1 dev eth1\n\n# Create nexthop group\nip nexthop add id 10 group 1/2\n\n# Use nexthop in route\nip route add 10.0.0.0/8 nhid 10\n\n# View nexthops\nip nexthop show\n</code></pre>"},{"location":"linux/network/static-routing/#route-metrics-and-preferences","title":"Route Metrics and Preferences","text":"<pre><code># Lower metric is preferred\nip route add 10.0.0.0/8 via 192.168.1.1 metric 10\nip route add 10.0.0.0/8 via 192.168.2.1 metric 20\n\n# With both routes present, 192.168.1.1 is preferred\n</code></pre>"},{"location":"linux/network/static-routing/#administrative-distance","title":"Administrative Distance","text":"<p>Not directly configurable in Linux, but protocols have default preferences: - Connected: 0 - Static: 1 - OSPF: 110 - RIP: 120</p>"},{"location":"linux/network/static-routing/#route-attributes","title":"Route Attributes","text":"<pre><code># Add route with specific attributes\nip route add 10.0.0.0/8 via 192.168.1.1 \\\n    metric 100 \\\n    mtu 1400 \\\n    advmss 1360\n\n# Show route with all attributes\nip route show 10.0.0.0/8\n</code></pre>"},{"location":"linux/network/static-routing/#troubleshooting-routing","title":"Troubleshooting Routing","text":""},{"location":"linux/network/static-routing/#verify-routes","title":"Verify Routes","text":"<pre><code># Check routing table\nip route show\n\n# Test route to destination\nip route get 8.8.8.8\nip route get 10.0.0.5\n\n# Check specific table\nip route show table custom\n\n# Check rules\nip rule show\n</code></pre>"},{"location":"linux/network/static-routing/#trace-route-path","title":"Trace Route Path","text":"<pre><code># Traceroute\ntraceroute 8.8.8.8\ntraceroute -n 8.8.8.8  # No DNS resolution\n\n# MTR (better)\nmtr 8.8.8.8\nmtr -n 8.8.8.8\n</code></pre>"},{"location":"linux/network/static-routing/#check-ip-forwarding","title":"Check IP Forwarding","text":"<pre><code># Check if enabled\ncat /proc/sys/net/ipv4/ip_forward\n\n# Enable temporarily\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\n\n# Enable permanently\necho \"net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf\nsysctl -p\n</code></pre>"},{"location":"linux/network/static-routing/#debug-routing-issues","title":"Debug Routing Issues","text":"<pre><code># Check interface status\nip link show\nip addr show\n\n# Check if gateway is reachable\nping -c 4 192.168.1.1\n\n# Check ARP table\nip neigh show\narp -n\n\n# Monitor routing changes\nip monitor route\n\n# Check routing cache (older kernels)\nip route show cache\n</code></pre>"},{"location":"linux/network/static-routing/#common-issues","title":"Common Issues","text":"<p>Issue: No route to host <pre><code># Add missing route\nip route add 10.0.0.0/8 via 192.168.1.1\n\n# Or add default gateway\nip route add default via 192.168.1.1\n</code></pre></p> <p>Issue: Asymmetric routing <pre><code># May need to disable rp_filter\necho 0 &gt; /proc/sys/net/ipv4/conf/all/rp_filter\n\n# Or use policy routing\n</code></pre></p> <p>Issue: Routes not persisting <pre><code># Add to configuration files\n# RHEL: /etc/sysconfig/network-scripts/route-*\n# Ubuntu: /etc/netplan/*.yaml\n# Or use NetworkManager\n</code></pre></p>"},{"location":"linux/network/static-routing/#routing-with-multiple-interfaces","title":"Routing with Multiple Interfaces","text":""},{"location":"linux/network/static-routing/#setup-routing-between-interfaces","title":"Setup Routing Between Interfaces","text":"<pre><code># Enable IP forwarding\nsysctl -w net.ipv4.ip_forward=1\n\n# Add routes\nip route add 10.0.0.0/8 via 192.168.1.1 dev eth0\nip route add 172.16.0.0/12 via 192.168.2.1 dev eth1\n\n# Default route\nip route add default via 192.168.1.1 dev eth0\n</code></pre>"},{"location":"linux/network/static-routing/#interface-specific-routing","title":"Interface-Specific Routing","text":"<pre><code># Force traffic out specific interface\nip route add 10.0.0.0/8 dev eth1\nip route add 172.16.0.0/12 dev eth0\n\n# Source-based interface selection\nip rule add from 192.168.1.0/24 oif eth0\nip rule add from 192.168.2.0/24 oif eth1\n</code></pre>"},{"location":"linux/network/static-routing/#monitoring-routing","title":"Monitoring Routing","text":""},{"location":"linux/network/static-routing/#real-time-monitoring","title":"Real-Time Monitoring","text":"<pre><code># Monitor route changes\nip monitor route\n\n# Monitor all IP events\nip monitor\n\n# Monitor specific table\nip monitor route table custom\n\n# Watch routing table\nwatch -n 1 'ip route show'\n</code></pre>"},{"location":"linux/network/static-routing/#routing-statistics","title":"Routing Statistics","text":"<pre><code># View route cache statistics\nip -s route show cache\n\n# Interface statistics\nip -s link show eth0\n\n# Routing protocol statistics (if running dynamic routing)\nvtysh -c \"show ip route\"\n</code></pre>"},{"location":"linux/network/static-routing/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"linux/network/static-routing/#view-routes","title":"View Routes","text":"<pre><code>ip route show                          # Show routing table\nip route show table all                # All tables\nip route get 8.8.8.8                  # Route to destination\nip rule show                          # Show routing rules\n</code></pre>"},{"location":"linux/network/static-routing/#add-routes_1","title":"Add Routes","text":"<pre><code>ip route add 10.0.0.0/8 via 192.168.1.1                    # Basic route\nip route add default via 192.168.1.1                       # Default gateway\nip route add 10.0.0.0/8 via 192.168.1.1 metric 100        # With metric\nip route add 10.0.0.0/8 via 192.168.1.1 table custom      # Custom table\n</code></pre>"},{"location":"linux/network/static-routing/#policy-routing","title":"Policy Routing","text":"<pre><code>echo \"100 custom\" &gt;&gt; /etc/iproute2/rt_tables              # Add table\nip route add default via 192.168.1.1 table custom         # Add route to table\nip rule add from 192.168.1.0/24 table custom priority 100 # Add rule\n</code></pre>"},{"location":"linux/network/static-routing/#delete-routes_1","title":"Delete Routes","text":"<pre><code>ip route del 10.0.0.0/8               # Delete route\nip route del default                   # Delete default\nip rule del priority 100               # Delete rule\n</code></pre>"},{"location":"linux/network/static-routing/#persistent-configuration","title":"Persistent Configuration","text":"<pre><code># RHEL/CentOS\nvim /etc/sysconfig/network-scripts/route-eth0\nnmcli connection modify eth0 +ipv4.routes \"10.0.0.0/8 192.168.1.1\"\n\n# Ubuntu\nvim /etc/netplan/01-netcfg.yaml\nnetplan apply\n</code></pre>"},{"location":"linux/network/static-routing/#practical-examples","title":"Practical Examples","text":""},{"location":"linux/network/static-routing/#example-1-multi-homed-host","title":"Example 1: Multi-Homed Host","text":"<pre><code># Host with two network connections\n# eth0: 192.168.1.100/24 (ISP1 - gateway 192.168.1.1)\n# eth1: 192.168.2.100/24 (ISP2 - gateway 192.168.2.1)\n\n# Setup tables\necho \"100 isp1\" &gt;&gt; /etc/iproute2/rt_tables\necho \"200 isp2\" &gt;&gt; /etc/iproute2/rt_tables\n\n# Add routes\nip route add default via 192.168.1.1 table isp1\nip route add default via 192.168.2.1 table isp2\nip route add 192.168.1.0/24 dev eth0 table isp1\nip route add 192.168.2.0/24 dev eth1 table isp2\n\n# Add rules\nip rule add from 192.168.1.100 table isp1\nip rule add from 192.168.2.100 table isp2\n\n# Main table default (for locally generated traffic)\nip route add default via 192.168.1.1 metric 100\nip route add default via 192.168.2.1 metric 200\n</code></pre>"},{"location":"linux/network/static-routing/#example-2-vpn-routing","title":"Example 2: VPN Routing","text":"<pre><code># Route specific traffic through VPN\n# VPN interface: tun0, VPN gateway: 10.8.0.1\n\n# Add route for specific network through VPN\nip route add 10.0.0.0/8 via 10.8.0.1 dev tun0\n\n# Or use policy routing\necho \"100 vpn\" &gt;&gt; /etc/iproute2/rt_tables\nip route add default via 10.8.0.1 dev tun0 table vpn\nip rule add from 192.168.1.100 table vpn\n</code></pre>"},{"location":"linux/network/static-routing/#example-3-dmz-routing","title":"Example 3: DMZ Routing","text":"<pre><code># Router with three interfaces\n# eth0: WAN (Internet) - 203.0.113.5\n# eth1: LAN - 192.168.1.1/24\n# eth2: DMZ - 10.0.0.1/24\n\n# Enable forwarding\necho 1 &gt; /proc/sys/net/ipv4/ip_forward\n\n# Routes\nip route add default via 203.0.113.1 dev eth0\nip route add 192.168.1.0/24 dev eth1\nip route add 10.0.0.0/24 dev eth2\n\n# Allow LAN to DMZ\n# (firewall rules needed too)\n</code></pre>"},{"location":"linux/network/static-routing/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know how to add/delete/modify routes with <code>ip route</code></li> <li>Understand routing tables and policy-based routing</li> <li>Be familiar with persistent route configuration</li> <li>Know how to troubleshoot with <code>ip route get</code></li> <li>Understand metrics and route selection</li> <li>Practice multi-path routing scenarios</li> <li>Know the difference between runtime and persistent routes</li> <li>Be comfortable with both RHEL and Debian-based configurations</li> <li>Understand source-based routing concepts</li> <li>Know how to verify routing with traceroute/mtr</li> <li>Remember to enable IP forwarding for routing between interfaces</li> <li>Practice reading and understanding routing table output</li> </ul>"},{"location":"linux/network/time-synchronization/","title":"Set and Synchronize System Time Using Time Servers","text":""},{"location":"linux/network/time-synchronization/#overview","title":"Overview","text":"<p>This guide covers time synchronization, NTP (Network Time Protocol), Chrony, and time zone management in Linux systems.</p>"},{"location":"linux/network/time-synchronization/#time-concepts","title":"Time Concepts","text":"<ul> <li>System Time: Current time maintained by the kernel</li> <li>Hardware Clock (RTC): Real-Time Clock, battery-powered clock in the hardware</li> <li>UTC: Coordinated Universal Time (standard reference)</li> <li>Local Time: Time adjusted for timezone</li> <li>NTP: Network Time Protocol for time synchronization</li> <li>Stratum: Distance from reference clock (lower is better, 0 is atomic clock)</li> </ul>"},{"location":"linux/network/time-synchronization/#view-current-time","title":"View Current Time","text":""},{"location":"linux/network/time-synchronization/#date-command","title":"<code>date</code> Command","text":"<pre><code># Show current date and time\ndate\n\n# Show in UTC\ndate -u\n\n# Show in specific format\ndate \"+%Y-%m-%d %H:%M:%S\"\ndate \"+%A, %B %d, %Y\"\n\n# Show time in seconds since epoch (1970-01-01)\ndate +%s\n\n# Show date from timestamp\ndate -d @1609459200\n</code></pre>"},{"location":"linux/network/time-synchronization/#timedatectl-command-systemd","title":"<code>timedatectl</code> Command (systemd)","text":"<pre><code># Show time and date settings\ntimedatectl\n\n# Output includes:\n# - Local time\n# - Universal time (UTC)\n# - RTC time\n# - Time zone\n# - NTP enabled status\n# - NTP synchronized status\n\n# Show available timezones\ntimedatectl list-timezones\n\n# Show time status in detail\ntimedatectl status\n</code></pre>"},{"location":"linux/network/time-synchronization/#set-system-time","title":"Set System Time","text":""},{"location":"linux/network/time-synchronization/#manual-time-setting","title":"Manual Time Setting","text":""},{"location":"linux/network/time-synchronization/#using-date","title":"Using <code>date</code>","text":"<pre><code># Set time manually (format: MMDDhhmmYYYY.ss)\ndate 123123592024.00  # December 31, 23:59:00, 2024\n\n# Set from string\ndate -s \"2024-12-31 23:59:00\"\ndate -s \"31 DEC 2024 23:59:00\"\n\n# Set date only\ndate --set=\"2024-12-31\"\n\n# Set time only\ndate --set=\"23:59:00\"\n</code></pre>"},{"location":"linux/network/time-synchronization/#using-timedatectl","title":"Using <code>timedatectl</code>","text":"<pre><code># Set date and time\ntimedatectl set-time \"2024-12-31 23:59:00\"\n\n# Set date only\ntimedatectl set-time \"2024-12-31\"\n\n# Note: NTP must be disabled to set time manually\ntimedatectl set-ntp false\n</code></pre>"},{"location":"linux/network/time-synchronization/#time-zone-management","title":"Time Zone Management","text":""},{"location":"linux/network/time-synchronization/#view-time-zone","title":"View Time Zone","text":"<pre><code># Using timedatectl\ntimedatectl\n\n# Check timezone file\nls -l /etc/localtime\n\n# View timezone name\ncat /etc/timezone  # Debian/Ubuntu\n</code></pre>"},{"location":"linux/network/time-synchronization/#set-time-zone","title":"Set Time Zone","text":""},{"location":"linux/network/time-synchronization/#using-timedatectl_1","title":"Using <code>timedatectl</code>","text":"<pre><code># List all available timezones\ntimedatectl list-timezones\n\n# Filter timezones\ntimedatectl list-timezones | grep America\ntimedatectl list-timezones | grep Europe/\n\n# Set timezone\ntimedatectl set-timezone America/New_York\ntimedatectl set-timezone Europe/London\ntimedatectl set-timezone Asia/Tokyo\ntimedatectl set-timezone UTC\n\n# Verify\ntimedatectl\n</code></pre>"},{"location":"linux/network/time-synchronization/#manual-method","title":"Manual Method","text":"<pre><code># Create symbolic link to timezone file\nln -sf /usr/share/zoneinfo/America/New_York /etc/localtime\n\n# Update /etc/timezone (Debian/Ubuntu)\necho \"America/New_York\" &gt; /etc/timezone\n</code></pre>"},{"location":"linux/network/time-synchronization/#hardware-clock-rtc","title":"Hardware Clock (RTC)","text":""},{"location":"linux/network/time-synchronization/#hwclock-command","title":"<code>hwclock</code> Command","text":"<pre><code># Show hardware clock time\nhwclock --show\nhwclock -r\n\n# Show in UTC\nhwclock --show --utc\n\n# Show in local time\nhwclock --show --localtime\n\n# Set hardware clock from system time\nhwclock --systohc\n\n# Set system time from hardware clock\nhwclock --hctosys\n\n# Set hardware clock manually\nhwclock --set --date=\"2024-12-31 23:59:00\"\n</code></pre>"},{"location":"linux/network/time-synchronization/#hardware-clock-mode","title":"Hardware Clock Mode","text":"<pre><code># Check if RTC is in UTC or local time\ntimedatectl | grep \"RTC in local TZ\"\n\n# Set RTC to UTC (recommended)\ntimedatectl set-local-rtc 0\n\n# Set RTC to local time (not recommended, can cause issues)\ntimedatectl set-local-rtc 1\n</code></pre>"},{"location":"linux/network/time-synchronization/#ntp-network-time-protocol","title":"NTP - Network Time Protocol","text":""},{"location":"linux/network/time-synchronization/#check-ntp-status","title":"Check NTP Status","text":"<pre><code># Using timedatectl\ntimedatectl status\ntimedatectl timesync-status\n\n# Show NTP service status\ntimedatectl show-timesync --all\n</code></pre>"},{"location":"linux/network/time-synchronization/#enabledisable-ntp","title":"Enable/Disable NTP","text":"<pre><code># Enable NTP synchronization\ntimedatectl set-ntp true\n\n# Disable NTP synchronization\ntimedatectl set-ntp false\n\n# Check if enabled\ntimedatectl | grep \"NTP service\"\n</code></pre>"},{"location":"linux/network/time-synchronization/#chrony-modern-ntp-implementation","title":"Chrony (Modern NTP Implementation)","text":""},{"location":"linux/network/time-synchronization/#chrony-overview","title":"Chrony Overview","text":"<p>Chrony is the modern replacement for ntpd, designed for: - Better performance on systems that are intermittently connected - Faster synchronization - Better handling of network congestion - Works well with virtual machines</p>"},{"location":"linux/network/time-synchronization/#installation","title":"Installation","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install chrony\n\n# Ubuntu/Debian\napt install chrony\n</code></pre>"},{"location":"linux/network/time-synchronization/#chrony-service-management","title":"Chrony Service Management","text":"<pre><code># Start chronyd service\nsystemctl start chronyd\n\n# Stop chronyd service\nsystemctl stop chronyd\n\n# Restart chronyd service\nsystemctl restart chronyd\n\n# Enable at boot\nsystemctl enable chronyd\n\n# Check status\nsystemctl status chronyd\n\n# Check if running\nsystemctl is-active chronyd\n</code></pre>"},{"location":"linux/network/time-synchronization/#chrony-configuration-file","title":"Chrony Configuration File","text":"<p>Location: <code>/etc/chrony.conf</code> (RHEL) or <code>/etc/chrony/chrony.conf</code> (Ubuntu)</p> <p>Example configuration: <pre><code># Use public NTP servers from pool.ntp.org\npool pool.ntp.org iburst\npool 0.pool.ntp.org iburst\npool 1.pool.ntp.org iburst\n\n# Or use specific servers\nserver 0.rhel.pool.ntp.org iburst\nserver 1.rhel.pool.ntp.org iburst\nserver time.google.com iburst\n\n# Record rate of clock gain/loss\ndriftfile /var/lib/chrony/drift\n\n# Allow system clock to be stepped in the first three updates\nmakestep 1.0 3\n\n# Enable RTC synchronization\nrtcsync\n\n# Serve time to local network (optional)\nallow 192.168.1.0/24\n\n# Log directory\nlogdir /var/log/chrony\n</code></pre></p> <p>Configuration options explained: - <code>pool</code>: Use pool of NTP servers - <code>server</code>: Use specific NTP server - <code>iburst</code>: Send burst of packets at startup for faster sync - <code>makestep</code>: Allow clock to be stepped if offset is large - <code>driftfile</code>: File to record clock drift rate - <code>rtcsync</code>: Enable kernel RTC synchronization - <code>allow</code>: Allow clients from this network</p>"},{"location":"linux/network/time-synchronization/#chronyc-command-chrony-client","title":"<code>chronyc</code> Command (Chrony Client)","text":""},{"location":"linux/network/time-synchronization/#view-time-sources","title":"View Time Sources","text":"<pre><code># Show NTP sources\nchronyc sources\n\n# Show sources with verbose output\nchronyc sources -v\n\n# Columns explained:\n# M: Mode (^ = server, = = peer)\n# S: State (* = current sync source, + = acceptable, - = not acceptable)\n# Stratum: Distance from reference clock\n# Reach: Reachability (octal, 377 = all 8 recent attempts successful)\n# LastRx: Time since last sample\n# Poll: Polling interval\n\n# Show detailed source information\nchronyc sourcestats\n\n# Show source information with verbose output\nchronyc sourcestats -v\n</code></pre>"},{"location":"linux/network/time-synchronization/#tracking-information","title":"Tracking Information","text":"<pre><code># Show system clock performance\nchronyc tracking\n\n# Output includes:\n# - Reference ID and stratum\n# - System time offset\n# - Root delay and dispersion\n# - Update interval\n# - Leap status\n</code></pre>"},{"location":"linux/network/time-synchronization/#manual-time-synchronization","title":"Manual Time Synchronization","text":"<pre><code># Force immediate synchronization\nchronyc makestep\n\n# Add new server temporarily\nchronyc add server time.google.com\n\n# Delete server\nchronyc delete time.google.com\n</code></pre>"},{"location":"linux/network/time-synchronization/#activity-and-statistics","title":"Activity and Statistics","text":"<pre><code># Show how many servers/peers are online\nchronyc activity\n\n# Show NTP authentication status\nchronyc authdata\n\n# Show client access\nchronyc clients\n</code></pre>"},{"location":"linux/network/time-synchronization/#testing-and-diagnostics","title":"Testing and Diagnostics","text":"<pre><code># Perform burst of measurements\nchronyc burst 3/5\n\n# Check server reachability\nchronyc reachability\n\n# Dump all measurements\nchronyc ntpdata\n</code></pre>"},{"location":"linux/network/time-synchronization/#legacy-ntp-daemon-ntpd","title":"Legacy NTP Daemon (ntpd)","text":""},{"location":"linux/network/time-synchronization/#installation_1","title":"Installation","text":"<pre><code># RHEL/CentOS/Fedora\ndnf install ntp\n\n# Ubuntu/Debian\napt install ntp\n</code></pre>"},{"location":"linux/network/time-synchronization/#configuration","title":"Configuration","text":"<p>Location: <code>/etc/ntp.conf</code></p> <p>Example configuration: <pre><code># Use public servers\nserver 0.pool.ntp.org iburst\nserver 1.pool.ntp.org iburst\nserver 2.pool.ntp.org iburst\n\n# Drift file\ndriftfile /var/lib/ntp/drift\n\n# Access restrictions\nrestrict default nomodify notrap nopeer noquery\nrestrict 127.0.0.1\nrestrict ::1\n\n# Allow local network to query\nrestrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n</code></pre></p>"},{"location":"linux/network/time-synchronization/#service-management","title":"Service Management","text":"<pre><code># Start service\nsystemctl start ntpd\n\n# Enable at boot\nsystemctl enable ntpd\n\n# Check status\nsystemctl status ntpd\n</code></pre>"},{"location":"linux/network/time-synchronization/#ntpq-command","title":"<code>ntpq</code> Command","text":"<pre><code># Show peers\nntpq -p\n\n# Show more detailed peer information\nntpq -pn\n\n# Interactive mode\nntpq\nntpq&gt; peers\nntpq&gt; associations\nntpq&gt; quit\n</code></pre>"},{"location":"linux/network/time-synchronization/#ntpdate-command-deprecated","title":"<code>ntpdate</code> Command (deprecated)","text":"<pre><code># Synchronize time once (deprecated, use chronyc or ntpd)\nntpdate pool.ntp.org\n\n# Note: Cannot run while ntpd is running\nsystemctl stop ntpd\nntpdate pool.ntp.org\nsystemctl start ntpd\n</code></pre>"},{"location":"linux/network/time-synchronization/#systemd-timesyncd-lightweight-ntp","title":"Systemd-timesyncd (Lightweight NTP)","text":""},{"location":"linux/network/time-synchronization/#overview_1","title":"Overview","text":"<p>Simple SNTP client included with systemd, used when neither Chrony nor ntpd is installed.</p>"},{"location":"linux/network/time-synchronization/#configuration_1","title":"Configuration","text":"<p>Location: <code>/etc/systemd/timesyncd.conf</code></p> <pre><code>[Time]\nNTP=0.pool.ntp.org 1.pool.ntp.org\nFallbackNTP=time.google.com\n</code></pre>"},{"location":"linux/network/time-synchronization/#service-management_1","title":"Service Management","text":"<pre><code># Start service\nsystemctl start systemd-timesyncd\n\n# Enable at boot\nsystemctl enable systemd-timesyncd\n\n# Check status\nsystemctl status systemd-timesyncd\n\n# View sync status\ntimedatectl timesync-status\n</code></pre>"},{"location":"linux/network/time-synchronization/#public-ntp-server-pools","title":"Public NTP Server Pools","text":""},{"location":"linux/network/time-synchronization/#common-ntp-servers","title":"Common NTP Servers","text":"<pre><code># Generic pool\npool.ntp.org\n0.pool.ntp.org\n1.pool.ntp.org\n2.pool.ntp.org\n3.pool.ntp.org\n\n# Regional pools\nus.pool.ntp.org\neurope.pool.ntp.org\nasia.pool.ntp.org\n\n# Vendor-specific pools\n0.rhel.pool.ntp.org\n0.ubuntu.pool.ntp.org\n0.centos.pool.ntp.org\n\n# Public servers\ntime.google.com\ntime.cloudflare.com\ntime.nist.gov\n</code></pre>"},{"location":"linux/network/time-synchronization/#firewall-configuration-for-ntp","title":"Firewall Configuration for NTP","text":"<pre><code># Allow NTP traffic (UDP port 123)\nfirewall-cmd --permanent --add-service=ntp\nfirewall-cmd --reload\n\n# Or manually with port\nfirewall-cmd --permanent --add-port=123/udp\nfirewall-cmd --reload\n\n# For iptables\niptables -A INPUT -p udp --dport 123 -j ACCEPT\niptables -A OUTPUT -p udp --sport 123 -j ACCEPT\n</code></pre>"},{"location":"linux/network/time-synchronization/#troubleshooting-time-synchronization","title":"Troubleshooting Time Synchronization","text":""},{"location":"linux/network/time-synchronization/#check-time-status","title":"Check Time Status","text":"<pre><code># Overall status\ntimedatectl status\n\n# Chrony tracking\nchronyc tracking\nchronyc sources -v\n\n# Check service\nsystemctl status chronyd\njournalctl -u chronyd -f\n</code></pre>"},{"location":"linux/network/time-synchronization/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"linux/network/time-synchronization/#1-time-not-synchronizing","title":"1. Time Not Synchronizing","text":"<pre><code># Check if NTP is enabled\ntimedatectl | grep \"NTP service\"\n\n# Enable if disabled\ntimedatectl set-ntp true\n\n# Restart chronyd\nsystemctl restart chronyd\n\n# Check sources\nchronyc sources -v\n\n# Force synchronization\nchronyc makestep\n</code></pre>"},{"location":"linux/network/time-synchronization/#2-large-time-offset","title":"2. Large Time Offset","text":"<pre><code># Check current offset\nchronyc tracking\n\n# If offset is very large, may need to step\nchronyc makestep\n\n# Or restart service\nsystemctl restart chronyd\n</code></pre>"},{"location":"linux/network/time-synchronization/#3-no-sources-available","title":"3. No Sources Available","text":"<pre><code># Check network connectivity\nping pool.ntp.org\n\n# Check DNS resolution\nnslookup pool.ntp.org\n\n# Check firewall\nfirewall-cmd --list-all | grep ntp\n\n# Test NTP port\nnc -u pool.ntp.org 123\n</code></pre>"},{"location":"linux/network/time-synchronization/#4-sources-not-reachable","title":"4. Sources Not Reachable","text":"<pre><code># Check sources\nchronyc sources\n\n# Look at Reach column (should be 377 for good connectivity)\n# If showing 0, check:\n# - Firewall rules\n# - Network connectivity\n# - Server configuration\n\n# Try different servers\nchronyc add server time.google.com\n</code></pre>"},{"location":"linux/network/time-synchronization/#log-files","title":"Log Files","text":"<pre><code># Chrony logs\njournalctl -u chronyd\ntail -f /var/log/chrony/*.log\n\n# System logs\njournalctl -xe\n\n# Check for time-related errors\njournalctl | grep -i \"time\\|clock\\|ntp\\|chrony\"\n</code></pre>"},{"location":"linux/network/time-synchronization/#best-practices","title":"Best Practices","text":"<ol> <li>Use Chrony instead of ntpd for most modern systems</li> <li>Use pool servers (pool.ntp.org) for redundancy</li> <li>Use iburst option for faster initial synchronization</li> <li>Set RTC to UTC to avoid timezone issues</li> <li>Monitor synchronization regularly with chronyc tracking</li> <li>Allow firewall access for NTP (UDP 123)</li> <li>Use regional pools for better latency</li> <li>Keep chronyd running continuously for best accuracy</li> <li>Check logs regularly for synchronization issues</li> <li>Enable at boot to ensure time is correct after restart</li> </ol>"},{"location":"linux/network/time-synchronization/#quick-reference-commands","title":"Quick Reference Commands","text":""},{"location":"linux/network/time-synchronization/#view-time","title":"View Time","text":"<pre><code>date                          # Current date/time\ntimedatectl                   # Full time status\ntimedatectl status            # Detailed status\nhwclock --show                # Hardware clock\n</code></pre>"},{"location":"linux/network/time-synchronization/#set-time","title":"Set Time","text":"<pre><code>timedatectl set-time \"YYYY-MM-DD HH:MM:SS\"\ntimedatectl set-timezone America/New_York\ntimedatectl set-ntp true\n</code></pre>"},{"location":"linux/network/time-synchronization/#chrony","title":"Chrony","text":"<pre><code>systemctl start chronyd       # Start service\nchronyc sources               # Show sources\nchronyc tracking              # Show sync status\nchronyc makestep              # Force sync\n</code></pre>"},{"location":"linux/network/time-synchronization/#troubleshooting","title":"Troubleshooting","text":"<pre><code>timedatectl timesync-status   # Sync status\njournalctl -u chronyd         # View logs\nchronyc sources -v            # Detailed sources\nchronyc activity              # Source activity\n</code></pre>"},{"location":"linux/network/time-synchronization/#exam-tips","title":"Exam Tips","text":"<ul> <li>Know how to use both <code>timedatectl</code> and <code>chronyc</code></li> <li>Understand the difference between system time and hardware clock</li> <li>Be able to configure timezone correctly</li> <li>Know how to enable/disable NTP synchronization</li> <li>Understand chrony.conf configuration options</li> <li>Be able to troubleshoot synchronization issues</li> <li>Remember the <code>iburst</code> option for faster sync</li> <li>Know how to check synchronization status</li> <li>Understand the importance of UTC for RTC</li> <li>Practice manual time setting (with NTP disabled)</li> </ul>"},{"location":"linux/storage/automounters/","title":"Configure Filesystem Automounters","text":""},{"location":"linux/storage/automounters/#what-are-automounters","title":"What are Automounters?","text":"<p>Automounters automatically mount filesystems when you access them, and automatically unmount them when they\u2019re not being used. Think of them as smart mounting - the system handles the mounting/unmounting for you.</p>"},{"location":"linux/storage/automounters/#why-use-automounters","title":"Why Use Automounters?","text":"<p>Without automount:</p> <ul> <li>Mount 20 network shares at boot</li> <li>Uses resources even if not needed</li> <li>Boot takes longer</li> <li>More points of failure</li> </ul> <p>With automount:</p> <ul> <li>Mount on-demand (only when accessed)</li> <li>Unmount when idle (free resources)</li> <li>Faster boot</li> <li>More resilient to network issues</li> </ul> <p>Common uses:</p> <ul> <li>User home directories on networks</li> <li>Shared company data</li> <li>USB/CD-ROM auto-mounting</li> <li>NFS shares that aren\u2019t always needed</li> <li>Mounting many filesystems efficiently</li> </ul>"},{"location":"linux/storage/automounters/#how-automount-works","title":"How Automount Works","text":"<p>Traditional mounting:</p> <pre><code># You manually mount\nmount server:/home/john /home/john\n\n# Must manually unmount\numount /home/john\n</code></pre> <p>Automounting:</p> <pre><code># You just access the directory\ncd /home/john\n\n# System automatically:\n# 1. Detects access\n# 2. Mounts server:/home/john\n# 3. Gives you access\n\n# After 5 minutes of inactivity:\n# - System automatically unmounts\n</code></pre>"},{"location":"linux/storage/automounters/#components","title":"Components","text":"<p>Master Map (<code>/etc/auto.master</code>):</p> <ul> <li>Main configuration</li> <li>Points to other maps</li> <li>Sets global options</li> </ul> <p>Map Files:</p> <ul> <li>Define what to mount and where</li> <li>Can be files, LDAP, NIS, etc.</li> </ul> <p>autofs Service:</p> <ul> <li>The daemon that does the work</li> <li>Monitors access to mount points</li> <li>Handles mounting/unmounting</li> </ul>"},{"location":"linux/storage/automounters/#installing-autofs","title":"Installing autofs","text":"<pre><code># RHEL/CentOS/Rocky\ndnf install autofs\nsystemctl enable --now autofs\n\n# Debian/Ubuntu\napt install autofs\nsystemctl enable --now autofs\n\n# Check status\nsystemctl status autofs\n</code></pre>"},{"location":"linux/storage/automounters/#master-map-etcautomaster","title":"Master Map - /etc/auto.master","text":"<p>What it is: The main configuration file that tells autofs where to look for mount definitions.</p> <p>Format:</p> <pre><code>mount-point  map-file  [options]\n</code></pre> <p>Examples:</p> <pre><code># Simple indirect map\n/misc /etc/auto.misc\n\n# Direct map (special mount point /-)\n/- /etc/auto.direct\n\n# With timeout (unmount after 60 seconds)\n/home /etc/auto.home --timeout=60\n\n# Multiple maps\n/misc /etc/auto.misc\n/net /etc/auto.net\n/- /etc/auto.direct\n</code></pre> <p>Common options:</p> <ul> <li><code>--timeout=N</code> - Unmount after N seconds idle (default 300)</li> <li><code>--ghost</code> - Create empty directories for mount points</li> <li><code>--browse</code> - Show all available mounts (uses more resources)</li> </ul>"},{"location":"linux/storage/automounters/#indirect-maps-most-common-type","title":"Indirect Maps - Most Common Type","text":""},{"location":"linux/storage/automounters/#what-are-indirect-maps","title":"What are Indirect Maps?","text":"<p>With indirect maps, all mounts appear under a parent directory. The parent is defined in the master map, and the map file defines subdirectories.</p> <p>Example:</p> <ul> <li>Master map says: <code>/data</code> uses <code>/etc/auto.data</code></li> <li>Map file says: <code>projects</code> mounts from <code>server:/projects</code></li> <li>Result: Accessing <code>/data/projects</code> automatically mounts <code>server:/projects</code></li> </ul>"},{"location":"linux/storage/automounters/#creating-indirect-maps","title":"Creating Indirect Maps","text":"<p>Real-world scenario - Company file shares:</p> <pre><code># Step 1: Edit master map\nvi /etc/auto.master\n\n# Add line:\n/company /etc/auto.company --timeout=300\n\n# Step 2: Create map file\nvi /etc/auto.company\n\n# Add shares:\nprojects    -rw,soft,intr    nfs-server:/export/projects\ndocs        -ro,soft         nfs-server:/export/documentation  \nshared      -rw,soft,intr    nfs-server:/export/shared\n\n# Step 3: Reload autofs\nsystemctl reload autofs\n\n# Step 4: Test\nls /company/projects\n# Automatically mounts nfs-server:/export/projects!\n\n# Step 5: Check mount\ndf -h | grep projects\nmount | grep projects\n\n# After 5 minutes of inactivity, it auto-unmounts\n</code></pre>"},{"location":"linux/storage/automounters/#map-file-format","title":"Map File Format","text":"<pre><code>key  [options]  location\n</code></pre> <p>Components:</p> <ul> <li>key: Subdirectory name (becomes /mount-point/key)</li> <li>options: Mount options (optional)</li> <li>location: What to mount</li> </ul> <p>Examples:</p> <pre><code># NFS mount\ndata    -rw,soft,intr    server:/export/data\n\n# Multiple NFS servers (failover)\nbackup  -ro    server1:/backup  server2:/backup  server3:/backup\n\n# Local device\ncdrom   -fstype=iso9660,ro    :/dev/cdrom\n\n# Bind mount (mount local directory)\narchive -fstype=bind    :/backup/archive\n</code></pre>"},{"location":"linux/storage/automounters/#direct-maps-specific-paths","title":"Direct Maps - Specific Paths","text":""},{"location":"linux/storage/automounters/#what-are-direct-maps","title":"What are Direct Maps?","text":"<p>Direct maps let you mount to any specific path, not just under a parent directory.</p> <p>Example:</p> <ul> <li>Want to mount at <code>/data/warehouse</code> (not <code>/something/warehouse</code>)</li> <li>Use direct map with <code>/data/warehouse</code> as the path</li> </ul>"},{"location":"linux/storage/automounters/#creating-direct-maps","title":"Creating Direct Maps","text":"<p>Real-world scenario - Specific locations:</p> <pre><code># Step 1: Edit master map\nvi /etc/auto.master\n\n# Add direct map line:\n/- /etc/auto.direct\n\n# Step 2: Create direct map\nvi /etc/auto.direct\n\n# Add mounts with full paths:\n/data/warehouse    -rw,soft,intr    storage:/export/warehouse\n/data/analytics    -rw,soft,intr    storage:/export/analytics\n/opt/shared        -ro              fileserver:/export/tools\n/mnt/archive       -ro              backup:/export/archive\n\n# Step 3: Reload\nsystemctl reload autofs\n\n# Step 4: Test\nls /data/warehouse\n# Mounts automatically!\n</code></pre>"},{"location":"linux/storage/automounters/#common-configurations","title":"Common Configurations","text":""},{"location":"linux/storage/automounters/#user-home-directories","title":"User Home Directories","text":"<p>Scenario: Network home directories. When john logs in, their home mounts automatically.</p> <pre><code># Master map\n/home /etc/auto.home\n\n# Map file (/etc/auto.home)\n*    -rw,soft,intr    nfs-server:/home/&amp;\n\n# How it works:\n# User \"john\" accesses /home/john\n# * matches \"john\"\n# &amp; is replaced with \"john\"\n# Result: mounts nfs-server:/home/john to /home/john\n</code></pre> <p>Full example:</p> <pre><code># Step 1: Master map\necho \"/home /etc/auto.home --timeout=600\" &gt;&gt; /etc/auto.master\n\n# Step 2: Map file\ncat &gt; /etc/auto.home &lt;&lt; 'EOF'\n*    -rw,soft,intr,rsize=8192,wsize=8192    homeserver:/home/&amp;\nEOF\n\n# Step 3: Reload\nsystemctl reload autofs\n\n# Now when any user logs in, their home auto-mounts!\n</code></pre>"},{"location":"linux/storage/automounters/#multiple-data-shares","title":"Multiple Data Shares","text":"<p>Scenario: Company has several shared drives.</p> <pre><code># Master map\n/shares /etc/auto.shares\n\n# Map file\nvi /etc/auto.shares\n\nprojects    -rw,soft    proj-server:/projects\nfinance     -rw,soft    fin-server:/finance\nhr          -ro,soft    hr-server:/human-resources\nmarketing   -rw,soft    mkt-server:/marketing\n\n# Result:\n# /shares/projects \u2192 proj-server:/projects\n# /shares/finance  \u2192 fin-server:/finance\n# /shares/hr       \u2192 hr-server:/human-resources\n# /shares/marketing \u2192 mkt-server:/marketing\n</code></pre>"},{"location":"linux/storage/automounters/#windows-cifs-shares","title":"Windows (CIFS) Shares","text":"<p>Scenario: Mount Windows file servers.</p> <pre><code># Master map\n/windows /etc/auto.windows\n\n# Map file\nvi /etc/auto.windows\n\nshare1  -fstype=cifs,credentials=/root/.smbcreds,uid=1000,gid=1000  ://fileserver/share1\nshare2  -fstype=cifs,credentials=/root/.smbcreds,uid=1000,gid=1000  ://fileserver/share2\n\n# Credentials file\ncat &gt; /root/.smbcreds &lt;&lt; EOF\nusername=domain\\\\user\npassword=SecurePass123\ndomain=COMPANY\nEOF\nchmod 600 /root/.smbcreds\n\n# Reload\nsystemctl reload autofs\n</code></pre>"},{"location":"linux/storage/automounters/#removable-media","title":"Removable Media","text":"<p>Scenario: Auto-mount USB drives and CDs.</p> <pre><code># Master map\n/media /etc/auto.media\n\n# Map file\nvi /etc/auto.media\n\ncdrom   -fstype=iso9660,ro,nosuid,nodev    :/dev/cdrom\nusb     -fstype=auto,nodev,nosuid          :/dev/sdb1\n</code></pre>"},{"location":"linux/storage/automounters/#advanced-features","title":"Advanced Features","text":""},{"location":"linux/storage/automounters/#wildcards-and-variables","title":"Wildcards and Variables","text":"<p>Using wildcards:</p> <pre><code># In auto.home\n*    -rw    server:/home/&amp;\n\n# Matches any username\n# &amp; is replaced with matched value\n</code></pre> <p>Variables available:</p> <ul> <li><code>${key}</code> - The matched key</li> <li><code>${*}</code> - Everything matched</li> <li><code>$USER</code> - Current user (in some contexts)</li> </ul> <p>Example with subdirectories:</p> <pre><code># Map file\n*/*  -rw,soft  server:/dept/${0}\n\n# Accessing /data/sales/reports\n# Mounts: server:/dept/sales/reports\n</code></pre>"},{"location":"linux/storage/automounters/#multiple-server-failover","title":"Multiple Server Failover","text":"<p>Scenario: Use backup servers if primary fails.</p> <pre><code># Try servers in order\ndata  -ro  server1:/data  server2:/data  server3:/data\n\n# First available server is used\n# Automatic failover if one fails\n</code></pre>"},{"location":"linux/storage/automounters/#nested-automounts","title":"Nested Automounts","text":"<p>Scenario: Organize mounts in hierarchies.</p> <pre><code># Master map\n/company /etc/auto.company\n\n# /etc/auto.company\ndata    /etc/auto.company.data\nprojects /etc/auto.company.projects\n\n# /etc/auto.company.data\ncurrent  -rw,soft  server:/data/current\narchive  -ro,soft  server:/data/archive\n\n# Result:\n# /company/data/current\n# /company/data/archive\n# /company/projects/...\n</code></pre>"},{"location":"linux/storage/automounters/#managing-autofs","title":"Managing autofs","text":""},{"location":"linux/storage/automounters/#service-control","title":"Service Control","text":"<pre><code># Start autofs\nsystemctl start autofs\n\n# Stop autofs (unmounts all autofs mounts)\nsystemctl stop autofs\n\n# Reload configuration (safer, doesn't unmount)\nsystemctl reload autofs\n\n# Restart (unmounts everything, reloads)\nsystemctl restart autofs\n\n# Check status\nsystemctl status autofs\n\n# Enable at boot\nsystemctl enable autofs\n</code></pre> <p>Always use <code>reload</code> instead of <code>restart</code> when possible!</p>"},{"location":"linux/storage/automounters/#checking-configuration","title":"Checking Configuration","text":"<pre><code># Test configuration without starting\nautomount -f -v\n\n# Run in debug mode (foreground)\nsystemctl stop autofs\nautomount -f -d\n\n# View logs\njournalctl -u autofs -f\ntail -f /var/log/messages | grep automount\n</code></pre>"},{"location":"linux/storage/automounters/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/storage/automounters/#problem-mount-not-working","title":"Problem: Mount Not Working","text":"<p>Steps to diagnose:</p> <pre><code># Step 1: Check service\nsystemctl status autofs\n\n# Step 2: Check configuration syntax\ncat /etc/auto.master\ncat /etc/auto.misc\n\n# Step 3: Test access\nls /misc/share\ncd /misc/share\n\n# Step 4: Check logs\njournalctl -u autofs --since \"5 minutes ago\"\ndmesg | tail -20\n\n# Step 5: Verify server\nshowmount -e nfs-server\nping nfs-server\n</code></pre> <p>Common mistakes:</p> <pre><code># Wrong: Missing the colon for local device\ncdrom   -fstype=iso9660,ro    /dev/cdrom\n\n# Right: Add colon before local device\ncdrom   -fstype=iso9660,ro    :/dev/cdrom\n\n# Wrong: Full path in indirect map\n/data/projects  -rw,soft  server:/projects\n\n# Right: Just the key\nprojects  -rw,soft  server:/projects\n</code></pre>"},{"location":"linux/storage/automounters/#problem-permission-denied","title":"Problem: Permission Denied","text":"<p>For NFS:</p> <pre><code># Check server exports\nshowmount -e server\n\n# Verify client IP is allowed\nexportfs -v\n\n# Test manual mount\nmount -t nfs server:/export /mnt/test\n</code></pre> <p>For CIFS:</p> <pre><code># Check credentials file\ncat /root/.smbcreds\nls -l /root/.smbcreds  # Should be 600\n\n# Test with smbclient\nsmbclient //server/share -U username\n</code></pre>"},{"location":"linux/storage/automounters/#problem-mount-not-unmounting","title":"Problem: Mount Not Unmounting","text":"<p>Check timeout:</p> <pre><code># View current timeout\ngrep timeout /etc/auto.master\n\n# Increase timeout\n/data /etc/auto.data --timeout=600\n</code></pre> <p>Force unmount if needed:</p> <pre><code># Find what's using it\nlsof /data/projects\nfuser -m /data/projects\n\n# Kill processes\nfuser -k /data/projects\n\n# Manual unmount\numount -l /data/projects\n</code></pre>"},{"location":"linux/storage/automounters/#problem-slow-performance","title":"Problem: Slow Performance","text":"<p>Check network:</p> <pre><code># Test NFS performance\ndd if=/dev/zero of=/autofs/mount/test bs=1M count=100\n\n# Check mount options\nmount | grep autofs\n</code></pre> <p>Optimize options:</p> <pre><code># In map file, add performance options\ndata  -rw,soft,intr,rsize=32768,wsize=32768,noatime  server:/data\n</code></pre>"},{"location":"linux/storage/automounters/#debug-mode","title":"Debug Mode","text":"<p>When nothing works, use debug mode:</p> <pre><code># Stop service\nsystemctl stop autofs\n\n# Run in foreground with debug\nautomount -f -d\n\n# In another terminal, try to access mount\nls /autofs/path\n\n# Watch debug output in first terminal\n# Shows exactly what autofs is doing\n</code></pre> <p>Example output:</p> <pre><code>attempting to mount entry /misc/data\nlookup_mount: lookup(file): looking up data\nparse_mount: parse(sun): expanded entry: -rw,soft server:/data\nmount_mount: mounting /misc/data from server:/data with options rw,soft\nmounted /misc/data successfully\n</code></pre>"},{"location":"linux/storage/automounters/#best-practices","title":"Best Practices","text":"<p>1. Always use <code>_netdev</code> equivalent options:</p> <pre><code># Don't rely on network at boot\n# autofs handles network wait automatically\n</code></pre> <p>2. Set reasonable timeouts:</p> <pre><code># Too short: Constant mounting/unmounting\n# Too long: Resources held unnecessarily\n# Good default: 300 seconds (5 minutes)\n/data /etc/auto.data --timeout=300\n</code></pre> <p>3. Use indirect maps when possible:</p> <pre><code># Cleaner, more organized\n/shares /etc/auto.shares\n</code></pre> <p>4. Secure credentials:</p> <pre><code>chmod 600 /root/.smbcreds\nchown root:root /root/.smbcreds\n</code></pre> <p>5. Test before making permanent:</p> <pre><code># Test mount manually first\nmount -t nfs server:/data /mnt/test\n\n# Then add to autofs\n</code></pre> <p>6. Use <code>reload</code> not <code>restart</code>:</p> <pre><code># After config changes\nsystemctl reload autofs\n# Not: systemctl restart autofs\n</code></pre> <p>7. Monitor autofs:</p> <pre><code># Regular checks\nsystemctl status autofs\njournalctl -u autofs --since today\n</code></pre>"},{"location":"linux/storage/automounters/#real-world-complete-example","title":"Real-World Complete Example","text":"<p>Scenario: Company with multiple shares and user homes.</p> <pre><code># === Step 1: Master Map ===\ncat &gt; /etc/auto.master &lt;&lt; 'EOF'\n/home     /etc/auto.home --timeout=600\n/company  /etc/auto.company --timeout=300\n/-        /etc/auto.direct\nEOF\n\n# === Step 2: Home Directories ===\ncat &gt; /etc/auto.home &lt;&lt; 'EOF'\n*    -rw,soft,intr,rsize=8192,wsize=8192    homeserver.company.local:/home/&amp;\nEOF\n\n# === Step 3: Company Shares ===\ncat &gt; /etc/auto.company &lt;&lt; 'EOF'\nprojects    -rw,soft,intr    proj-server:/projects\nfinance     -rw,soft,intr    fin-server:/finance\ndocs        -ro,soft         doc-server:/documentation\nshared      -rw,soft,intr    file-server:/shared\nEOF\n\n# === Step 4: Direct Mounts ===\ncat &gt; /etc/auto.direct &lt;&lt; 'EOF'\n/data/warehouse    -rw,soft,intr    storage:/warehouse\n/opt/tools         -ro,soft         tools:/export/tools\nEOF\n\n# === Step 5: Reload ===\nsystemctl reload autofs\n\n# === Step 6: Test ===\n# User homes\nls /home/john           # Auto-mounts homeserver:/home/john\n\n# Company shares\nls /company/projects    # Auto-mounts proj-server:/projects\ncd /company/finance     # Auto-mounts fin-server:/finance\n\n# Direct mounts\ncd /data/warehouse      # Auto-mounts storage:/warehouse\n\n# === Step 7: Verify ===\nmount | grep autofs\ndf -h | grep autofs\n\n# === Step 8: Monitor ===\njournalctl -u autofs -f\n</code></pre>"},{"location":"linux/storage/automounters/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/automounters/#installation","title":"Installation","text":"<pre><code># Install\ndnf install autofs\nsystemctl enable --now autofs\n</code></pre>"},{"location":"linux/storage/automounters/#configuration-files","title":"Configuration Files","text":"<pre><code># Master map (main config)\n/etc/auto.master\n\n# Map files (mount definitions)\n/etc/auto.misc\n/etc/auto.home\n</code></pre>"},{"location":"linux/storage/automounters/#basic-indirect-map","title":"Basic Indirect Map","text":"<pre><code># Master map\n/mnt /etc/auto.mnt\n\n# Map file\ndata  -rw,soft,intr  server:/export/data\n\n# Result: /mnt/data\n</code></pre>"},{"location":"linux/storage/automounters/#basic-direct-map","title":"Basic Direct Map","text":"<pre><code># Master map\n/- /etc/auto.direct\n\n# Map file\n/data/warehouse  -rw,soft  server:/warehouse\n\n# Result: /data/warehouse\n</code></pre>"},{"location":"linux/storage/automounters/#service-management","title":"Service Management","text":"<pre><code>systemctl reload autofs     # Apply changes (safe)\nsystemctl status autofs     # Check status\njournalctl -u autofs -f     # View logs\nautomount -f -v             # Test config\n</code></pre>"},{"location":"linux/storage/automounters/#testing","title":"Testing","text":"<pre><code># Test by accessing\nls /mount/point\n\n# Check if mounted\nmount | grep autofs\ndf -h | grep autofs\n\n# Debug mode\nsystemctl stop autofs\nautomount -f -d\n</code></pre>"},{"location":"linux/storage/filesystems/","title":"Create, Manage, and Troubleshoot Filesystems","text":""},{"location":"linux/storage/filesystems/#what-is-a-filesystem","title":"What is a Filesystem?","text":"<p>A filesystem is the method and structure used to organize and store files on a storage device. Think of it as the filing system for your hard drive - it determines how data is stored, how files are named, what metadata is kept, and how space is managed.</p> <p>Without a filesystem, a hard drive is just a blank slate. The filesystem gives it structure and makes it usable.</p>"},{"location":"linux/storage/filesystems/#why-different-filesystems","title":"Why Different Filesystems?","text":"<p>Different filesystems are optimized for different uses:</p> <ul> <li>ext4: General purpose, very stable, great for Linux systems</li> <li>XFS: Excellent for large files, high performance, used in enterprise</li> <li>Btrfs: Modern features like snapshots and compression</li> <li>VFAT/FAT32: Cross-platform compatibility (Windows, Mac, Linux)</li> <li>NTFS: Windows native filesystem</li> <li>exFAT: Modern cross-platform for large files</li> </ul>"},{"location":"linux/storage/filesystems/#common-linux-filesystems","title":"Common Linux Filesystems","text":""},{"location":"linux/storage/filesystems/#ext4-fourth-extended-filesystem","title":"ext4 - Fourth Extended Filesystem","text":"<p>What it is: The most common Linux filesystem. Reliable, mature, and the default on most Linux distributions.</p> <p>Best for:</p> <ul> <li>Linux system partitions</li> <li>General purpose storage</li> <li>Root and /home partitions</li> <li>When you need stability and maturity</li> </ul> <p>Key features:</p> <ul> <li>Maximum file size: 16 TB</li> <li>Maximum partition size: 1 EB (Exabyte)</li> <li>Journaling (protects against corruption)</li> <li>Backwards compatible with ext3 and ext2</li> </ul> <p>When to use: Default choice for most Linux installations. If unsure, use ext4.</p>"},{"location":"linux/storage/filesystems/#xfs-high-performance-filesystem","title":"XFS - High Performance Filesystem","text":"<p>What it is: Originally from SGI, designed for high-performance computing.</p> <p>Best for:</p> <ul> <li>Large files (videos, databases, disk images)</li> <li>High throughput workloads</li> <li>Enterprise storage systems</li> <li>NAS devices</li> </ul> <p>Key features:</p> <ul> <li>Excellent performance with large files</li> <li>Online defragmentation</li> <li>Can grow online (but cannot shrink!)</li> <li>Maximum file size: 8 EB</li> </ul> <p>When to use: Database servers, video editing, large file storage.</p> <p>Important limitation: You CANNOT shrink XFS filesystems!</p>"},{"location":"linux/storage/filesystems/#btrfs-b-tree-filesystem","title":"Btrfs - B-Tree Filesystem","text":"<p>What it is: Modern filesystem with advanced features like built-in snapshots and compression.</p> <p>Best for:</p> <ul> <li>When you need snapshots</li> <li>When you want compression</li> <li>Desktop systems</li> <li>Development environments</li> </ul> <p>Key features:</p> <ul> <li>Built-in snapshots (no LVM needed)</li> <li>Online compression</li> <li>Self-healing (detects and repairs corruption)</li> <li>Subvolumes (like lightweight partitions)</li> </ul> <p>When to use: When you want modern features and don\u2019t mind some complexity.</p>"},{"location":"linux/storage/filesystems/#fat32-and-exfat","title":"FAT32 and exFAT","text":"<p>What they are: Simple filesystems that work on Windows, Mac, and Linux.</p> <p>Best for:</p> <ul> <li>USB flash drives</li> <li>External hard drives</li> <li>Sharing files between different operating systems</li> </ul> <p>Limitations:</p> <ul> <li>FAT32: Cannot handle files larger than 4GB</li> <li>exFAT: No file size limit, but not as widely supported as FAT32</li> </ul>"},{"location":"linux/storage/filesystems/#creating-filesystems","title":"Creating Filesystems","text":""},{"location":"linux/storage/filesystems/#mkfsext4-create-ext4-filesystem","title":"mkfs.ext4 - Create ext4 Filesystem","text":"<p>What it does: Formats a partition or disk with the ext4 filesystem.</p> <p>Why use it: To make a disk usable for storing files on Linux.</p> <p>\u26a0\ufe0f WARNING: This ERASES all data on the partition!</p> <p>Examples:</p> <pre><code># Basic ext4 creation\nmkfs.ext4 /dev/sdb1\n\n# With a label (helps identify the filesystem)\nmkfs.ext4 -L \"DATA\" /dev/sdb1\n\n# With less reserved space (default is 5%, which wastes space)\nmkfs.ext4 -m 1 /dev/sdb1\n\n# Force creation (even if filesystem already exists)\nmkfs.ext4 -F /dev/sdb1\n</code></pre> <p>Real-world scenario - New data drive:</p> <pre><code># You added a new 1TB drive to your server\n# Step 1: Create partition\nfdisk /dev/sdb\n# Press: n, p, 1, Enter, Enter, w\n\n# Step 2: Create ext4 filesystem with label\nmkfs.ext4 -L \"ServerData\" /dev/sdb1\n\n# Output:\n# Creating filesystem with 262144000 4k blocks and 65536000 inodes\n# Filesystem UUID: 1234abcd-5678-efgh...\n# Allocating group tables: done\n# Writing inode tables: done\n# Creating journal (32768 blocks): done\n# Writing superblocks and filesystem accounting information: done\n\n# Step 3: Create mount point and mount\nmkdir /data\nmount /dev/sdb1 /data\n\n# Step 4: Make it permanent\necho \"LABEL=ServerData /data ext4 defaults 0 2\" &gt;&gt; /etc/fstab\n</code></pre> <p>Understanding the output:</p> <ul> <li>UUID: Unique identifier for this filesystem</li> <li>Inode tables: Where file metadata is stored</li> <li>Journal: Protects against corruption during crashes</li> </ul>"},{"location":"linux/storage/filesystems/#mkfsxfs-create-xfs-filesystem","title":"mkfs.xfs - Create XFS Filesystem","text":"<p>What it does: Formats a partition with the XFS filesystem.</p> <p>Why use it: When you need high performance for large files or databases.</p> <p>Examples:</p> <pre><code># Basic XFS creation\nmkfs.xfs /dev/sdb1\n\n# With a label\nmkfs.xfs -L \"Database\" /dev/sdb1\n\n# Force creation (overwrite existing)\nmkfs.xfs -f /dev/sdb1\n</code></pre> <p>Real-world scenario - Database server:</p> <pre><code># Creating XFS for PostgreSQL database\nmkfs.xfs -L \"PostgreSQL\" /dev/sdb1\n\n# Mount it\nmkdir /var/lib/postgresql\nmount /dev/sdb1 /var/lib/postgresql\n\n# Permanent mount\necho \"LABEL=PostgreSQL /var/lib/postgresql xfs defaults 0 2\" &gt;&gt; /etc/fstab\n\n# Change ownership for PostgreSQL\nchown -R postgres:postgres /var/lib/postgresql\n</code></pre>"},{"location":"linux/storage/filesystems/#mkfsbtrfs-create-btrfs-filesystem","title":"mkfs.btrfs - Create Btrfs Filesystem","text":"<p>What it does: Creates a Btrfs filesystem with advanced features.</p> <p>Why use it: When you want snapshots, compression, or other modern features.</p> <p>Examples:</p> <pre><code># Basic Btrfs creation\nmkfs.btrfs /dev/sdb1\n\n# With a label\nmkfs.btrfs -L \"BtrfsData\" /dev/sdb1\n\n# Create with multiple devices (RAID-like)\nmkfs.btrfs -d raid1 -m raid1 /dev/sdb1 /dev/sdc1\n\n# Force creation\nmkfs.btrfs -f /dev/sdb1\n</code></pre> <p>Real-world scenario - Development workstation:</p> <pre><code># Create Btrfs for /home with snapshot capability\nmkfs.btrfs -L \"Home\" /dev/sdb1\n\n# Mount with compression\nmount -o compress=zstd /dev/sdb1 /home\n\n# Make permanent with compression\necho \"LABEL=Home /home btrfs compress=zstd 0 0\" &gt;&gt; /etc/fstab\n</code></pre>"},{"location":"linux/storage/filesystems/#mkfsvfat-create-fat32-filesystem","title":"mkfs.vfat - Create FAT32 Filesystem","text":"<p>What it does: Creates FAT32 filesystem for cross-platform compatibility.</p> <p>Why use it: USB drives, EFI boot partitions, sharing between operating systems.</p> <p>Examples:</p> <pre><code># Create FAT32\nmkfs.vfat -F 32 /dev/sdb1\n\n# With volume name\nmkfs.vfat -F 32 -n \"USB_DRIVE\" /dev/sdb1\n</code></pre> <p>Real-world scenario - USB flash drive:</p> <pre><code># Format USB drive for Windows/Mac/Linux compatibility\n# Step 1: Identify the drive\nlsblk\n# sdb is your USB drive\n\n# Step 2: Unmount if mounted\numount /dev/sdb1\n\n# Step 3: Create new partition (if needed)\nfdisk /dev/sdb\n# d (delete), n (new), p (primary), 1, Enter, Enter, t (type), c (W95 FAT32), w (write)\n\n# Step 4: Format as FAT32\nmkfs.vfat -F 32 -n \"MYUSB\" /dev/sdb1\n\n# Now it works on any computer\n</code></pre>"},{"location":"linux/storage/filesystems/#mounting-filesystems","title":"Mounting Filesystems","text":""},{"location":"linux/storage/filesystems/#understanding-mounting","title":"Understanding Mounting","text":"<p>In Linux, you don\u2019t access drives by letters like Windows (C:, D:). Instead, you \u201cmount\u201d them to directories. The mount point is where the filesystem appears in your directory tree.</p> <p>Example: Mount <code>/dev/sdb1</code> to <code>/data</code>, and the files on that disk appear at <code>/data</code>.</p>"},{"location":"linux/storage/filesystems/#mount-attach-filesystems","title":"mount - Attach Filesystems","text":"<p>What it does: Makes a filesystem accessible at a specific directory.</p> <p>Why use it: You can\u2019t access files on a disk until it\u2019s mounted!</p> <p>Examples:</p> <pre><code># Basic mount\nmount /dev/sdb1 /mnt\n\n# Mount with filesystem type specified\nmount -t ext4 /dev/sdb1 /mnt/data\n\n# Mount read-only\nmount -o ro /dev/sdb1 /mnt/data\n\n# Mount with multiple options\nmount -o rw,noatime /dev/sdb1 /mnt/data\n\n# Mount all entries in /etc/fstab\nmount -a\n\n# Remount with different options (no unmount needed)\nmount -o remount,rw /mnt/data\n\n# Mount an ISO file\nmount -o loop image.iso /mnt/iso\n\n# Bind mount (mount directory to another location)\nmount --bind /source/dir /dest/dir\n</code></pre> <p>Common mount options:</p> <ul> <li><code>ro</code> - Read-only (cannot modify files)</li> <li><code>rw</code> - Read-write (can modify files) </li> <li><code>noatime</code> - Don\u2019t update access times (faster)</li> <li><code>noexec</code> - Cannot execute binaries (security)</li> <li><code>nosuid</code> - Ignore setuid bits (security)</li> <li><code>nodev</code> - No device files (security)</li> </ul> <p>Real-world scenario - Mounting a new drive:</p> <pre><code># You've created filesystem on /dev/sdb1\n# Create mount point\nmkdir /data\n\n# Test mount first\nmount /dev/sdb1 /data\n\n# Check if it worked\ndf -h /data\nls /data\n\n# If good, make permanent\necho \"/dev/sdb1 /data ext4 defaults 0 2\" &gt;&gt; /etc/fstab\n\n# Unmount\numount /data\n\n# Test fstab entry\nmount -a\n\n# Verify\ndf -h /data\n</code></pre> <p>Real-world scenario - Mount with specific options:</p> <pre><code># Mount external drive with better performance\nmount -o noatime,nodiratime /dev/sdb1 /media/external\n\n# Mount with specific user ownership (for FAT32/exFAT)\nmount -o uid=1000,gid=1000 /dev/sdb1 /media/usb\n</code></pre>"},{"location":"linux/storage/filesystems/#umount-detach-filesystems","title":"umount - Detach Filesystems","text":"<p>What it does: Unmounts a filesystem, making it safe to remove.</p> <p>Why use it: Before unplugging USB drives or doing maintenance, always unmount!</p> <p>Examples:</p> <pre><code># Unmount by mount point\numount /mnt/data\n\n# Unmount by device\numount /dev/sdb1\n\n# Force unmount (if regular umount fails)\numount -f /mnt/data\n\n# Lazy unmount (detach now, cleanup when no longer busy)\numount -l /mnt/data\n\n# Unmount all\numount -a\n</code></pre> <p>Real-world scenario - \u201cDevice is busy\u201d error:</p> <pre><code># Try to unmount\numount /mnt/data\n# Error: target is busy\n\n# Find what's using it\nlsof /mnt/data\n# Shows: some-process is using a file\n\n# or\nfuser -m /mnt/data\n# Shows: 1234 (PID of process)\n\n# Option 1: Close the application\nkill 1234\n\n# Option 2: Force unmount\numount -f /mnt/data\n\n# Option 3: Lazy unmount (not recommended unless necessary)\numount -l /mnt/data\n</code></pre>"},{"location":"linux/storage/filesystems/#etcfstab-permanent-mounts","title":"/etc/fstab - Permanent Mounts","text":"<p>What it is: Configuration file that tells Linux what to mount automatically at boot.</p> <p>Why use it: So you don\u2019t have to manually mount filesystems every time you reboot.</p> <p>Format:</p> <pre><code>device  mount_point  filesystem_type  options  dump  pass\n</code></pre> <p>Examples:</p> <pre><code># Basic entry for data partition\n/dev/sdb1  /data  ext4  defaults  0  2\n\n# Using UUID (more reliable than /dev/sdX)\nUUID=1234-5678  /data  ext4  defaults  0  2\n\n# Using label\nLABEL=DATA  /data  ext4  defaults  0  2\n\n# Network filesystem (wait for network)\n192.168.1.100:/share  /mnt/nfs  nfs  defaults,_netdev  0  0\n\n# Swap partition\n/dev/sdb2  none  swap  sw  0  0\n\n# With performance options\nUUID=abcd-1234  /data  ext4  noatime,nodiratime  0  2\n\n# USB drive that might not always be present\nUUID=1234-5678  /media/usb  vfat  noauto,user  0  0\n</code></pre> <p>Understanding the fields:</p> <ol> <li>Device: <code>/dev/sdb1</code>, <code>UUID=...</code>, or <code>LABEL=...</code></li> <li>Mount point: Where it appears (<code>/data</code>, <code>/mnt/backup</code>)</li> <li>Filesystem: <code>ext4</code>, <code>xfs</code>, <code>ntfs</code>, <code>vfat</code>, etc.</li> <li>Options: <code>defaults</code>, <code>noatime</code>, <code>ro</code>, etc.</li> <li>Dump: Backup with dump (0=no, 1=yes) - rarely used</li> <li>Pass: fsck check order (0=no check, 1=first, 2=later)</li> </ol> <p>Real-world scenario - Adding entry:</p> <pre><code># Get UUID of partition\nblkid /dev/sdb1\n# Output: /dev/sdb1: UUID=\"1234abcd-...\" TYPE=\"ext4\" LABEL=\"DATA\"\n\n# Edit fstab\nvi /etc/fstab\n\n# Add entry (using UUID is more reliable)\nUUID=1234abcd-... /data ext4 defaults 0 2\n\n# Save and test (doesn't actually mount, just checks syntax)\nmount -a\n\n# If no errors, reboot to verify it mounts automatically\nreboot\n</code></pre>"},{"location":"linux/storage/filesystems/#managing-filesystems","title":"Managing Filesystems","text":""},{"location":"linux/storage/filesystems/#tune2fs-tune-ext4-filesystems","title":"tune2fs - Tune ext4 Filesystems","text":"<p>What it does: Adjusts parameters of ext2/ext3/ext4 filesystems.</p> <p>Why use it: Change labels, reserved space, mount counts, and other settings without reformatting.</p> <p>Examples:</p> <pre><code># View filesystem information\ntune2fs -l /dev/sdb1\n\n# Change filesystem label\ntune2fs -L \"NewLabel\" /dev/sdb1\n\n# Set reserved space to 1% (default is 5%)\ntune2fs -m 1 /dev/sdb1\n\n# Disable fsck on mount count\ntune2fs -c 0 /dev/sdb1\n\n# Disable fsck on time interval\ntune2fs -i 0 /dev/sdb1\n\n# Set error behavior to remount read-only\ntune2fs -e remount-ro /dev/sdb1\n</code></pre> <p>Real-world scenario - Free up reserved space:</p> <pre><code># ext4 reserves 5% for root by default\n# On large data drives, this wastes space\n\n# Check current settings\ntune2fs -l /dev/sdb1 | grep -i \"block count\\|reserved\"\n\n# Reserved block count:     5120000 (5% of 100GB = 5GB wasted!)\n# Change to 1%\ntune2fs -m 1 /dev/sdb1\n\n# Now you have 4GB more usable space\n</code></pre>"},{"location":"linux/storage/filesystems/#xfs_admin-manage-xfs-filesystems","title":"xfs_admin - Manage XFS Filesystems","text":"<p>What it does: Changes parameters of XFS filesystems.</p> <p>Why use it: Change labels or UUIDs on XFS.</p> <p>Examples:</p> <pre><code># Show current label\nxfs_admin -l /dev/sdb1\n\n# Set new label\nxfs_admin -L \"NewLabel\" /dev/sdb1\n\n# Show UUID\nxfs_admin -u /dev/sdb1\n\n# Generate new UUID\nxfs_admin -U generate /dev/sdb1\n</code></pre>"},{"location":"linux/storage/filesystems/#btrfs-manage-btrfs-filesystems","title":"btrfs - Manage Btrfs Filesystems","text":"<p>What it does: Comprehensive tool for managing Btrfs features.</p> <p>Why use it: Work with subvolumes, snapshots, and other Btrfs features.</p> <p>Examples:</p> <pre><code># Show Btrfs filesystems\nbtrfs filesystem show\n\n# Show space usage\nbtrfs filesystem df /mnt/btrfs\n\n# Create subvolume\nbtrfs subvolume create /mnt/btrfs/mysubvol\n\n# List subvolumes\nbtrfs subvolume list /mnt/btrfs\n\n# Create snapshot\nbtrfs subvolume snapshot /mnt/btrfs/mysubvol /mnt/btrfs/snapshot_2024\n\n# Resize filesystem (can grow or shrink)\nbtrfs filesystem resize +10G /mnt/btrfs\nbtrfs filesystem resize max /mnt/btrfs\n</code></pre> <p>Real-world scenario - Snapshots before update:</p> <pre><code># Take snapshot before system update\nbtrfs subvolume snapshot / /.snapshots/before-update\n\n# Perform update\ndnf update -y\n\n# If something breaks, boot from snapshot\n# (requires bootloader configuration)\n\n# If everything works, delete snapshot\nbtrfs subvolume delete /.snapshots/before-update\n</code></pre>"},{"location":"linux/storage/filesystems/#checking-and-repairing-filesystems","title":"Checking and Repairing Filesystems","text":""},{"location":"linux/storage/filesystems/#fsck-filesystem-check","title":"fsck - Filesystem Check","text":"<p>What it does: Checks and repairs filesystem errors.</p> <p>Why use it: Fix corruption, prepare for resize operations, routine maintenance.</p> <p>\u26a0\ufe0f CRITICAL: Always unmount before running fsck!</p> <p>Examples:</p> <pre><code># Check filesystem (unmount first!)\nfsck /dev/sdb1\n\n# Automatic repair\nfsck -y /dev/sdb1\n\n# Check even if marked clean\nfsck -f /dev/sdb1\n\n# Check all filesystems in /etc/fstab\nfsck -A\n</code></pre> <p>Real-world scenario - Fixing corruption:</p> <pre><code># System won't boot, dropped to emergency shell\n# Root filesystem has errors\n\n# Try to mount, fails with errors\nmount /dev/sda1 /mnt\n# Error: filesystem has errors\n\n# Check and repair\nfsck -y /dev/sda1\n# Pass 1: Checking inodes...\n# Pass 2: Checking directory structure...\n# Pass 3: Checking directory connectivity...\n# Pass 4: Checking reference counts...\n# Pass 5: Checking group summary information...\n# Fixed 15 errors\n\n# Now mount works\nmount /dev/sda1 /mnt\n</code></pre>"},{"location":"linux/storage/filesystems/#e2fsck-ext4-filesystem-check","title":"e2fsck - ext4 Filesystem Check","text":"<p>What it does: Specialized tool for ext2/ext3/ext4 filesystems.</p> <p>Why use it: More control than generic fsck for ext filesystems.</p> <p>Examples:</p> <pre><code># Automatic repair\ne2fsck -y /dev/sdb1\n\n# Force check even if clean\ne2fsck -f /dev/sdb1\n\n# Check for bad blocks\ne2fsck -c /dev/sdb1\n\n# Read-only check (no modifications)\ne2fsck -n /dev/sdb1\n</code></pre>"},{"location":"linux/storage/filesystems/#xfs_repair-xfs-filesystem-repair","title":"xfs_repair - XFS Filesystem Repair","text":"<p>What it does: Repairs XFS filesystems.</p> <p>Why use it: XFS doesn\u2019t use fsck; use this instead.</p> <p>Examples:</p> <pre><code># Dry run (check only)\nxfs_repair -n /dev/sdb1\n\n# Repair filesystem (unmount first!)\nxfs_repair /dev/sdb1\n\n# Force log zeroing (last resort, may lose data)\nxfs_repair -L /dev/sdb1\n</code></pre>"},{"location":"linux/storage/filesystems/#resizing-filesystems","title":"Resizing Filesystems","text":""},{"location":"linux/storage/filesystems/#resize2fs-resize-ext4","title":"resize2fs - Resize ext4","text":"<p>What it does: Grows or shrinks ext2/ext3/ext4 filesystems.</p> <p>Why use it: Adjust filesystem size to match partition size.</p> <p>Examples:</p> <pre><code># Grow to fill partition (after extending partition)\nresize2fs /dev/sdb1\n\n# Shrink to specific size (unmount first!)\nresize2fs /dev/sdb1 50G\n\n# Shrink to minimum possible size\nresize2fs -M /dev/sdb1\n</code></pre> <p>Real-world scenario - Growing filesystem:</p> <pre><code># You extended LVM volume from 50GB to 100GB\n# Filesystem is still 50GB\n\n# Step 1: Check current size\ndf -h /data\n# 50GB\n\n# Step 2: Resize filesystem\nresize2fs /dev/vg0/lv_data\n\n# Step 3: Verify\ndf -h /data\n# 100GB - done!\n</code></pre> <p>Real-world scenario - Shrinking filesystem:</p> <pre><code># You want to shrink partition from 100GB to 50GB\n# ALWAYS shrink filesystem BEFORE shrinking partition!\n\n# Step 1: Unmount\numount /data\n\n# Step 2: Check filesystem\ne2fsck -f /dev/sdb1\n\n# Step 3: Shrink filesystem to 50GB\nresize2fs /dev/sdb1 50G\n\n# Step 4: Shrink partition to 50GB (using fdisk, parted, or LVM)\nlvreduce -L 50G /dev/vg0/lv_data\n\n# Step 5: Mount\nmount /dev/vg0/lv_data /data\n</code></pre>"},{"location":"linux/storage/filesystems/#xfs_growfs-grow-xfs","title":"xfs_growfs - Grow XFS","text":"<p>What it does: Grows XFS filesystems (online - while mounted).</p> <p>Why use it: Expand XFS to use additional space.</p> <p>\u26a0\ufe0f Note: XFS can ONLY grow, never shrink!</p> <p>Examples:</p> <pre><code># Grow to fill device\nxfs_growfs /mnt/data\n\n# Grow by specific amount\nxfs_growfs -D 100g /mnt/data\n</code></pre> <p>Real-world scenario:</p> <pre><code># Extended partition, need to grow XFS\n# Step 1: Extend partition (already done)\n\n# Step 2: Grow filesystem (while mounted!)\nxfs_growfs /data\n\n# Step 3: Verify\ndf -h /data\n</code></pre>"},{"location":"linux/storage/filesystems/#checking-filesystem-information","title":"Checking Filesystem Information","text":""},{"location":"linux/storage/filesystems/#blkid-block-device-information","title":"blkid - Block Device Information","text":"<p>What it does: Shows UUID, label, and filesystem type of block devices.</p> <p>Why use it: Get information needed for /etc/fstab entries.</p> <p>Examples:</p> <pre><code># Show all block devices\nblkid\n\n# Show specific device\nblkid /dev/sdb1\n\n# Show only UUID\nblkid -s UUID -o value /dev/sdb1\n\n# Show only label\nblkid -s LABEL -o value /dev/sdb1\n</code></pre> <p>Output example:</p> <pre><code>blkid /dev/sdb1\n/dev/sdb1: UUID=\"1234abcd-...\" TYPE=\"ext4\" LABEL=\"DATA\" PARTLABEL=\"primary\" PARTUUID=\"...\"\n</code></pre>"},{"location":"linux/storage/filesystems/#lsblk-list-block-devices","title":"lsblk - List Block Devices","text":"<p>What it does: Shows tree view of all block devices with mount points.</p> <p>Why use it: Quick overview of all disks and partitions.</p> <p>Examples:</p> <pre><code># Basic tree view\nlsblk\n\n# With filesystem information\nlsblk -f\n\n# With full device paths\nlsblk -p\n\n# Custom columns\nlsblk -o NAME,SIZE,TYPE,MOUNTPOINT\n</code></pre> <p>Output example:</p> <pre><code>lsblk\nNAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda      8:0    0  100G  0 disk\n\u251c\u2500sda1   8:1    0   50G  0 part /\n\u2514\u2500sda2   8:2    0   50G  0 part /home\nsdb      8:16   0  500G  0 disk\n\u2514\u2500sdb1   8:17   0  500G  0 part /data\n</code></pre>"},{"location":"linux/storage/filesystems/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/storage/filesystems/#problem-filesystem-wont-mount","title":"Problem: Filesystem Won\u2019t Mount","text":"<p>Symptoms: Mount command fails with errors.</p> <p>Solutions:</p> <pre><code># Check if device exists\nls -l /dev/sdb1\n\n# Check filesystem type\nblkid /dev/sdb1\n\n# Try specifying filesystem type\nmount -t ext4 /dev/sdb1 /mnt\n\n# Check for errors\nfsck -y /dev/sdb1\n\n# Check system logs\ndmesg | tail -20\njournalctl -xe\n</code></pre>"},{"location":"linux/storage/filesystems/#problem-device-is-busy","title":"Problem: Device is Busy","text":"<p>Symptoms: Cannot unmount because device is in use.</p> <p>Solutions:</p> <pre><code># Find what's using it\nlsof /mnt/data\nfuser -vm /mnt/data\n\n# Change to different directory\ncd ~\n\n# Kill processes (careful!)\nfuser -k /mnt/data\n\n# Lazy unmount (last resort)\numount -l /mnt/data\n</code></pre>"},{"location":"linux/storage/filesystems/#problem-read-only-filesystem","title":"Problem: Read-only Filesystem","text":"<p>Symptoms: Cannot write to filesystem.</p> <p>Solutions:</p> <pre><code># Remount as read-write\nmount -o remount,rw /mount/point\n\n# If that fails, check for errors\numount /mount/point\nfsck -y /dev/sdb1\nmount /dev/sdb1 /mount/point\n</code></pre>"},{"location":"linux/storage/filesystems/#problem-no-space-left-on-device-but-df-shows-space","title":"Problem: No Space Left on Device (But df Shows Space)","text":"<p>Symptoms: Cannot create files even though df shows free space.</p> <p>Cause: Out of inodes (file metadata structures).</p> <p>Solution:</p> <pre><code># Check inodes\ndf -i\n\n# If inodes are at 100%, delete many small files\n# Or recreate filesystem with more inodes\n</code></pre>"},{"location":"linux/storage/filesystems/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/filesystems/#creating-filesystems_1","title":"Creating Filesystems","text":"<pre><code>mkfs.ext4 /dev/sdb1                # ext4\nmkfs.xfs /dev/sdb1                 # XFS\nmkfs.btrfs /dev/sdb1               # Btrfs\nmkfs.vfat -F 32 /dev/sdb1          # FAT32\n</code></pre>"},{"location":"linux/storage/filesystems/#mounting","title":"Mounting","text":"<pre><code>mount /dev/sdb1 /mnt               # Mount\numount /mnt                        # Unmount\nmount -a                           # Mount all (fstab)\n</code></pre>"},{"location":"linux/storage/filesystems/#checking","title":"Checking","text":"<pre><code>fsck -y /dev/sdb1                  # Check and repair\ne2fsck -f /dev/sdb1                # ext4 check\nxfs_repair /dev/sdb1               # XFS repair\n</code></pre>"},{"location":"linux/storage/filesystems/#resizing","title":"Resizing","text":"<pre><code>resize2fs /dev/sdb1                # Grow ext4\nxfs_growfs /mnt/data               # Grow XFS\n</code></pre>"},{"location":"linux/storage/filesystems/#information","title":"Information","text":"<pre><code>blkid /dev/sdb1                    # UUID, label, type\nlsblk -f                           # Tree with fs info\ndf -h                              # Space usage\ntune2fs -l /dev/sdb1               # ext4 details\n</code></pre>"},{"location":"linux/storage/lvm-storage/","title":"Configure and Manage LVM Storage","text":""},{"location":"linux/storage/lvm-storage/#what-is-lvm","title":"What is LVM?","text":"<p>LVM (Logical Volume Manager) is a flexible disk management system that sits between your physical hard drives and your filesystems. Think of it as a layer of abstraction that makes managing storage much easier and more flexible than traditional partitioning.</p>"},{"location":"linux/storage/lvm-storage/#why-use-lvm","title":"Why Use LVM?","text":"<p>Traditional Partitioning Problems: - Once you create a partition, resizing it is difficult and risky - You\u2019re limited by physical disk boundaries - Moving data between disks requires backup and restore - You can\u2019t easily combine multiple disks into one large volume</p> <p>LVM Solutions: - Resize volumes easily (grow or shrink) while the system is running - Combine multiple physical disks into one large pool of storage - Move data between disks without downtime - Create snapshots for backups - Add more storage space without reformatting</p>"},{"location":"linux/storage/lvm-storage/#lvm-architecture-the-three-layers","title":"LVM Architecture - The Three Layers","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Filesystems (ext4, xfs, etc.)          \u2502  \u2190 What users see\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Logical Volumes (LV)                   \u2502  \u2190 Virtual partitions\n\u2502  /dev/vg01/lv_data                      \u2502\n\u2502  /dev/vg01/lv_web                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Volume Groups (VG)                     \u2502  \u2190 Storage pool\n\u2502  vg01: combines all PVs                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Physical Volumes (PV)                  \u2502  \u2190 Physical disks/partitions\n\u2502  /dev/sdb, /dev/sdc, /dev/sdd          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>1. Physical Volumes (PV) - Your actual hard drives or partitions    - Example: /dev/sdb, /dev/sdc1    - These are the raw storage devices you\u2019ll use</p> <p>2. Volume Groups (VG) - A pool of storage made from one or more PVs    - Example: vg_data (combining /dev/sdb and /dev/sdc)    - Think of it as a big bucket of storage space</p> <p>3. Logical Volumes (LV) - Virtual partitions created from VG space    - Example: lv_database, lv_webserver    - These are what you format and mount, just like regular partitions</p>"},{"location":"linux/storage/lvm-storage/#physical-volume-management","title":"Physical Volume Management","text":""},{"location":"linux/storage/lvm-storage/#what-are-physical-volumes","title":"What Are Physical Volumes?","text":"<p>Physical Volumes are your actual hard drives or partitions that have been prepared for use with LVM. Before you can use a disk with LVM, you must initialize it as a Physical Volume.</p>"},{"location":"linux/storage/lvm-storage/#pvcreate-initialize-a-disk-for-lvm","title":"pvcreate - Initialize a Disk for LVM","text":"<p>What it does: Prepares a disk or partition to be used with LVM by writing special metadata.</p> <p>Why use it: This is always your first step when adding a new disk to LVM.</p> <p>Examples:</p> <pre><code># Initialize an entire disk for LVM\npvcreate /dev/sdb\n# Output: Physical volume \"/dev/sdb\" successfully created.\n\n# Initialize a partition (you must create the partition first with fdisk/parted)\npvcreate /dev/sdc1\n\n# Initialize multiple disks at once\npvcreate /dev/sdb /dev/sdc /dev/sdd\n</code></pre> <p>Real-world scenario: You\u2019ve just added a new 500GB disk (/dev/sdb) to your server. Before you can use it with LVM: <pre><code>pvcreate /dev/sdb\n</code></pre> Now /dev/sdb is ready to be added to a Volume Group.</p>"},{"location":"linux/storage/lvm-storage/#pvs-quick-overview-of-physical-volumes","title":"pvs - Quick Overview of Physical Volumes","text":"<p>What it does: Shows a simple summary of all Physical Volumes on your system.</p> <p>Why use it: Quick check to see what PVs exist, their size, and which VG they belong to.</p> <p>Example:</p> <pre><code>pvs\n</code></pre> <p>Output: <pre><code>PV         VG     Fmt  Attr PSize   PFree\n/dev/sdb   vg01   lvm2 a--  100.00g 50.00g\n/dev/sdc   vg01   lvm2 a--  200.00g 200.00g\n/dev/sdd   vg02   lvm2 a--  500.00g 100.00g\n</code></pre></p> <p>What this tells you: - /dev/sdb and /dev/sdc are both part of vg01 - /dev/sdb has 50GB free out of 100GB total - /dev/sdc is completely unused (200GB free out of 200GB)</p>"},{"location":"linux/storage/lvm-storage/#pvdisplay-detailed-information-about-physical-volumes","title":"pvdisplay - Detailed Information About Physical Volumes","text":"<p>What it does: Shows detailed information about one or all Physical Volumes.</p> <p>Why use it: When you need detailed information like UUID, exact sizes, or troubleshooting.</p> <p>Examples:</p> <pre><code># Show details for all PVs\npvdisplay\n\n# Show details for a specific PV\npvdisplay /dev/sdb\n</code></pre> <p>Output example: <pre><code>  --- Physical volume ---\n  PV Name               /dev/sdb\n  VG Name               vg01\n  PV Size               100.00 GiB\n  Allocatable           yes\n  PE Size               4.00 MiB\n  Total PE              25599\n  Free PE               12799\n  Allocated PE          12800\n  PV UUID               abc123-def456-...\n</code></pre></p> <p>What this means: - This PV is part of vg01 - Total size is 100GB - About half is used (12800 PE allocated out of 25599 total) - PE (Physical Extent) is the smallest unit of space LVM uses (4MB blocks)</p>"},{"location":"linux/storage/lvm-storage/#pvmove-move-data-off-a-physical-volume","title":"pvmove - Move Data Off a Physical Volume","text":"<p>What it does: Moves all data from one Physical Volume to other PVs in the same Volume Group.</p> <p>Why use it: You want to remove a disk from your system (maybe it\u2019s failing, or you\u2019re upgrading).</p> <p>Example:</p> <pre><code># Move all data from /dev/sdb to other disks in the VG\npvmove /dev/sdb\n\n# Move data from /dev/sdb to a specific disk\npvmove /dev/sdb /dev/sdc\n</code></pre> <p>Real-world scenario: Your /dev/sdb disk is showing SMART errors and needs to be replaced:</p> <pre><code># Step 1: Move all data off the failing disk\n# (This can take hours for large disks!)\npvmove /dev/sdb\n\n# Step 2: Remove it from the VG\nvgreduce vg01 /dev/sdb\n\n# Step 3: Remove PV label\npvremove /dev/sdb\n\n# Step 4: Physically replace the disk\n# Step 5: Add the new disk\npvcreate /dev/sdb\nvgextend vg01 /dev/sdb\n</code></pre>"},{"location":"linux/storage/lvm-storage/#pvremove-remove-physical-volume","title":"pvremove - Remove Physical Volume","text":"<p>What it does: Removes the LVM label from a disk, making it no longer a Physical Volume.</p> <p>Why use it: Clean up after removing a disk from LVM, or reusing a disk for something else.</p> <p>Example:</p> <pre><code># Remove PV label (must not be in use!)\npvremove /dev/sdb\n</code></pre> <p>Important: The PV must not be part of any VG. Remove it from the VG first with <code>vgreduce</code>.</p>"},{"location":"linux/storage/lvm-storage/#volume-group-management","title":"Volume Group Management","text":""},{"location":"linux/storage/lvm-storage/#what-are-volume-groups","title":"What Are Volume Groups?","text":"<p>A Volume Group is a storage pool created from one or more Physical Volumes. Think of it as combining multiple hard drives into one big pool of storage that you can then divide up however you want.</p>"},{"location":"linux/storage/lvm-storage/#vgcreate-create-a-new-volume-group","title":"vgcreate - Create a New Volume Group","text":"<p>What it does: Creates a new storage pool from one or more Physical Volumes.</p> <p>Why use it: This is how you combine disks into a unified storage pool.</p> <p>Examples:</p> <pre><code># Create a VG from a single PV\nvgcreate vg_data /dev/sdb\n\n# Create a VG from multiple PVs (combining 3 disks into one pool)\nvgcreate vg_data /dev/sdb /dev/sdc /dev/sdd\n\n# Create VG with a specific extent size (16MB instead of default 4MB)\n# Larger extents = slightly less overhead for very large volumes\nvgcreate -s 16M vg_bigdata /dev/sdb /dev/sdc\n</code></pre> <p>Real-world scenario: You have three 1TB disks and want to create one large storage pool:</p> <pre><code># Step 1: Initialize all disks\npvcreate /dev/sdb /dev/sdc /dev/sdd\n\n# Step 2: Create VG combining all three (total ~3TB)\nvgcreate vg_storage /dev/sdb /dev/sdc /dev/sdd\n\n# Step 3: Verify\nvgs vg_storage\n# Shows: vg_storage with ~3TB total size\n</code></pre>"},{"location":"linux/storage/lvm-storage/#vgs-quick-overview-of-volume-groups","title":"vgs - Quick Overview of Volume Groups","text":"<p>What it does: Shows a summary of all Volume Groups.</p> <p>Why use it: Quick check of VG size, free space, and how many PVs/LVs they contain.</p> <p>Example:</p> <pre><code>vgs\n</code></pre> <p>Output: <pre><code>VG          #PV #LV #SN Attr   VSize   VFree\nvg_data       2   3   0 wz--n- 300.00g  50.00g\nvg_backup     1   1   0 wz--n- 500.00g 400.00g\n</code></pre></p> <p>What this tells you: - vg_data has 2 PVs, 3 LVs, 300GB total, 50GB free - vg_backup has 1 PV, 1 LV, 500GB total, 400GB free</p>"},{"location":"linux/storage/lvm-storage/#vgdisplay-detailed-volume-group-information","title":"vgdisplay - Detailed Volume Group Information","text":"<p>What it does: Shows detailed information about Volume Groups.</p> <p>Why use it: Get complete details including UUIDs, extent information, and which LVs exist.</p> <p>Example:</p> <pre><code># Show all VGs in detail\nvgdisplay\n\n# Show specific VG\nvgdisplay vg_data\n</code></pre> <p>Output example: <pre><code>  --- Volume group ---\n  VG Name               vg_data\n  System ID\n  Format                lvm2\n  Metadata Areas        2\n  Metadata Sequence No  15\n  VG Access             read/write\n  VG Status             resizable\n  MAX LV                0\n  Cur LV                3\n  Open LV               2\n  Max PV                0\n  Cur PV                2\n  Act PV                2\n  VG Size               299.99 GiB\n  PE Size               4.00 MiB\n  Total PE              76798\n  Alloc PE / Size       64000 / 250.00 GiB\n  Free  PE / Size       12798 / 49.99 GiB\n  VG UUID               xyz789-abc123-...\n</code></pre></p>"},{"location":"linux/storage/lvm-storage/#vgextend-add-storage-to-a-volume-group","title":"vgextend - Add Storage to a Volume Group","text":"<p>What it does: Adds a Physical Volume to an existing Volume Group, increasing available space.</p> <p>Why use it: When you need more space and add a new disk to the system.</p> <p>Example:</p> <pre><code># Add a new disk to existing VG\npvcreate /dev/sdd\nvgextend vg_data /dev/sdd\n</code></pre> <p>Real-world scenario: Your vg_data is running low on space. You add a new 500GB disk:</p> <pre><code># Step 1: Initialize new disk\npvcreate /dev/sdd\n# Output: Physical volume \"/dev/sdd\" successfully created.\n\n# Step 2: Add to existing VG\nvgextend vg_data /dev/sdd\n# Output: Volume group \"vg_data\" successfully extended\n\n# Step 3: Verify new space available\nvgs vg_data\n# VSize will now show 500GB more space\n</code></pre>"},{"location":"linux/storage/lvm-storage/#vgreduce-remove-a-disk-from-volume-group","title":"vgreduce - Remove a Disk from Volume Group","text":"<p>What it does: Removes a Physical Volume from a Volume Group.</p> <p>Why use it: Before removing a disk or decommissioning storage.</p> <p>Example:</p> <pre><code># First, move data off the disk\npvmove /dev/sdd\n\n# Then remove it from the VG\nvgreduce vg_data /dev/sdd\n\n# Finally, remove PV label\npvremove /dev/sdd\n</code></pre> <p>Real-world scenario: You want to remove /dev/sdd from vg_data:</p> <pre><code># Check what's on it first\npvs /dev/sdd\n\n# Move any data to other disks in the VG\npvmove /dev/sdd\n# This may take a while...\n\n# Remove from VG\nvgreduce vg_data /dev/sdd\n# Output: Volume group \"vg_data\" successfully reduced\n\n# Clean up\npvremove /dev/sdd\n</code></pre>"},{"location":"linux/storage/lvm-storage/#vgremove-delete-a-volume-group","title":"vgremove - Delete a Volume Group","text":"<p>What it does: Completely removes a Volume Group.</p> <p>Why use it: Cleaning up or starting over with storage configuration.</p> <p>Example:</p> <pre><code># Remove all LVs first\nlvremove /dev/vg_data/lv_web\nlvremove /dev/vg_data/lv_db\n\n# Then remove the VG\nvgremove vg_data\n</code></pre> <p>Warning: This is destructive! All Logical Volumes must be removed first.</p>"},{"location":"linux/storage/lvm-storage/#logical-volume-management","title":"Logical Volume Management","text":""},{"location":"linux/storage/lvm-storage/#what-are-logical-volumes","title":"What Are Logical Volumes?","text":"<p>Logical Volumes are virtual partitions created from Volume Group space. They\u2019re what you actually format with filesystems and mount. Unlike traditional partitions, they can be easily resized, moved, and snapshotted.</p>"},{"location":"linux/storage/lvm-storage/#lvcreate-create-a-logical-volume","title":"lvcreate - Create a Logical Volume","text":"<p>What it does: Creates a new Logical Volume from available space in a Volume Group.</p> <p>Why use it: This creates the \u201cpartition\u201d you\u2019ll format and use for storing data.</p> <p>Examples:</p> <pre><code># Create a 20GB logical volume named \"lv_web\"\nlvcreate -L 20G -n lv_web vg_data\n\n# Create an LV using 50% of the VG\nlvcreate -l 50%VG -n lv_database vg_data\n\n# Create an LV using ALL free space\nlvcreate -l 100%FREE -n lv_backup vg_data\n\n# Create an LV with exactly 5000 extents (size depends on PE size)\nlvcreate -l 5000 -n lv_app vg_data\n</code></pre> <p>Real-world scenario - Setting up a web server:</p> <pre><code># You have vg_data with 500GB free space\n# Create volumes for different purposes:\n\n# 50GB for web files\nlvcreate -L 50G -n lv_web vg_data\n\n# 100GB for database\nlvcreate -L 100G -n lv_database vg_data\n\n# 30GB for logs\nlvcreate -L 30G -n lv_logs vg_data\n\n# Use remaining space for backups\nlvcreate -l 100%FREE -n lv_backup vg_data\n\n# Verify\nlvs vg_data\n</code></pre> <p>Complete workflow - From disk to mounted filesystem:</p> <pre><code># 1. Create the LV\nlvcreate -L 50G -n lv_webapp vg_data\n\n# 2. Create a filesystem on it\nmkfs.ext4 /dev/vg_data/lv_webapp\n\n# 3. Create mount point\nmkdir /var/www\n\n# 4. Mount it\nmount /dev/vg_data/lv_webapp /var/www\n\n# 5. Make it permanent in /etc/fstab\necho \"/dev/vg_data/lv_webapp /var/www ext4 defaults 0 2\" &gt;&gt; /etc/fstab\n\n# 6. Verify\ndf -h /var/www\n</code></pre>"},{"location":"linux/storage/lvm-storage/#lvs-quick-overview-of-logical-volumes","title":"lvs - Quick Overview of Logical Volumes","text":"<p>What it does: Shows a summary of all Logical Volumes.</p> <p>Why use it: Quick check of LV sizes, which VG they\u2019re in, and their status.</p> <p>Example:</p> <pre><code>lvs\n</code></pre> <p>Output: <pre><code>LV          VG       Attr       LSize   Pool Origin Data%\nlv_database vg_data  -wi-ao---- 100.00g\nlv_web      vg_data  -wi-ao----  50.00g\nlv_backup   vg_data  -wi-a----- 200.00g\n</code></pre></p> <p>What the attributes mean: - <code>w</code> = writable - <code>i</code> = inherited allocation policy - <code>a</code> = active (usable) - <code>o</code> = open (currently mounted)</p>"},{"location":"linux/storage/lvm-storage/#lvdisplay-detailed-logical-volume-information","title":"lvdisplay - Detailed Logical Volume Information","text":"<p>What it does: Shows detailed information about Logical Volumes.</p> <p>Why use it: Get full details including device paths, segments, and exact sizes.</p> <p>Example:</p> <pre><code># Show all LVs\nlvdisplay\n\n# Show specific LV\nlvdisplay /dev/vg_data/lv_web\n</code></pre> <p>Output example: <pre><code>  --- Logical volume ---\n  LV Path                /dev/vg_data/lv_web\n  LV Name                lv_web\n  VG Name                vg_data\n  LV UUID                mno789-pqr012-...\n  LV Write Access        read/write\n  LV Creation host, time server01, 2024-10-28 10:30:15\n  LV Status              available\n  # open                 1\n  LV Size                50.00 GiB\n  Current LE             12800\n  Segments               1\n  Allocation             inherit\n  Read ahead sectors     auto\n  Block device           253:0\n</code></pre></p>"},{"location":"linux/storage/lvm-storage/#lvextend-increase-logical-volume-size","title":"lvextend - Increase Logical Volume Size","text":"<p>What it does: Makes a Logical Volume larger by allocating more space from the Volume Group.</p> <p>Why use it: When you\u2019re running out of space on a filesystem and need more room.</p> <p>Examples:</p> <pre><code># Add 10GB to an LV\nlvextend -L +10G /dev/vg_data/lv_web\n\n# Extend to a total of 100GB\nlvextend -L 100G /dev/vg_data/lv_web\n\n# Use all remaining free space in VG\nlvextend -l +100%FREE /dev/vg_data/lv_web\n\n# Extend AND resize the filesystem in one command (convenient!)\nlvextend -L +10G -r /dev/vg_data/lv_web\n</code></pre> <p>Real-world scenario - Running out of space:</p> <p>You\u2019re getting warnings that /var/www is 90% full:</p> <pre><code># Check current situation\ndf -h /var/www\n# Shows: 45GB used out of 50GB (90% full)\n\nlvs /dev/vg_data/lv_web\n# Shows: 50GB LV\n\nvgs vg_data\n# Shows: 200GB free in VG\n\n# Solution: Add 30GB more\nlvextend -L +30G /dev/vg_data/lv_web\n# Output: Size of logical volume vg_data/lv_web changed from 50.00 GiB to 80.00 GiB\n\n# Resize the filesystem to use new space\nresize2fs /dev/vg_data/lv_web\n# Output: The filesystem is now 20971520 blocks long\n\n# Verify\ndf -h /var/www\n# Shows: 45GB used out of 80GB (56% full)\n</code></pre> <p>Important: After extending the LV, you must resize the filesystem: - ext4/ext3/ext2: <code>resize2fs /dev/vg_data/lv_name</code> - xfs: <code>xfs_growfs /mount/point</code> - Or use <code>-r</code> flag with lvextend to do both automatically</p>"},{"location":"linux/storage/lvm-storage/#lvreduce-decrease-logical-volume-size","title":"lvreduce - Decrease Logical Volume Size","text":"<p>What it does: Makes a Logical Volume smaller, freeing space back to the Volume Group.</p> <p>Why use it: When you over-allocated space and want to reclaim it for other uses.</p> <p>WARNING: This is dangerous! Always backup data first!</p> <p>Example:</p> <pre><code># CRITICAL: Shrink filesystem FIRST, then LV\n# If you shrink the LV first, you'll lose data!\n\n# For ext4:\n# Step 1: Unmount (required for shrinking)\numount /mnt/data\n\n# Step 2: Check filesystem\ne2fsck -f /dev/vg_data/lv_data\n\n# Step 3: Shrink filesystem to 30GB\nresize2fs /dev/vg_data/lv_data 30G\n\n# Step 4: Shrink LV to match\nlvreduce -L 30G /dev/vg_data/lv_data\n# It will ask for confirmation - type 'y'\n\n# Step 5: Remount\nmount /dev/vg_data/lv_data /mnt/data\n</code></pre> <p>Real-world scenario: You allocated 100GB for /opt/app but only use 25GB:</p> <pre><code># Check usage\ndf -h /opt/app\n# Shows: 25GB used out of 100GB\n\n# Back up data first! (Just in case)\ntar czf /backup/app-backup.tar.gz /opt/app\n\n# Unmount\numount /opt/app\n\n# Check and repair filesystem\ne2fsck -f /dev/vg_data/lv_app\n\n# Shrink filesystem to 40GB (leaving room for growth)\nresize2fs /dev/vg_data/lv_app 40G\n\n# Shrink LV to match\nlvreduce -L 40G /dev/vg_data/lv_app\n\n# Remount\nmount /dev/vg_data/lv_app /opt/app\n\n# Verify\ndf -h /opt/app\n# Now shows: 25GB used out of 40GB\n\n# The freed 60GB is now available in vg_data for other uses\nvgs vg_data\n</code></pre> <p>Note: XFS filesystems cannot be shrunk - only grown! Plan sizes carefully.</p>"},{"location":"linux/storage/lvm-storage/#lvremove-delete-a-logical-volume","title":"lvremove - Delete a Logical Volume","text":"<p>What it does: Completely removes a Logical Volume and frees its space back to the VG.</p> <p>Why use it: Cleaning up unused volumes or removing test environments.</p> <p>Example:</p> <pre><code># Unmount first\numount /mnt/old\n\n# Remove the LV\nlvremove /dev/vg_data/lv_old\n# Asks: \"Do you really want to remove...?\" type 'y'\n\n# Or force removal without confirmation (dangerous!)\nlvremove -f /dev/vg_data/lv_old\n</code></pre>"},{"location":"linux/storage/lvm-storage/#lvm-snapshots","title":"LVM Snapshots","text":""},{"location":"linux/storage/lvm-storage/#what-are-snapshots","title":"What Are Snapshots?","text":"<p>A snapshot is a point-in-time copy of a Logical Volume. It doesn\u2019t copy all the data immediately; instead, it uses copy-on-write technology: - When you create a snapshot, it initially uses very little space - As the original LV changes, the snapshot stores the old data - The snapshot shows how the LV looked at the moment you created it</p>"},{"location":"linux/storage/lvm-storage/#why-use-snapshots","title":"Why Use Snapshots?","text":"<p>Perfect for: - Backing up a live database without stopping it - Testing changes safely (take snapshot, test, revert if needed) - Creating consistent backups of busy filesystems</p> <p>Example Use Case: You need to backup a database that runs 24/7. You can\u2019t stop it, but you need a consistent backup: 1. Take a snapshot (takes seconds) 2. The snapshot is a frozen point-in-time view 3. Back up from the snapshot (take hours if needed) 4. Original database keeps running and changing 5. Delete snapshot when backup complete</p>"},{"location":"linux/storage/lvm-storage/#creating-snapshots","title":"Creating Snapshots","text":"<pre><code># Create a 10GB snapshot of lv_database\nlvcreate -L 10G -s -n lv_database_snap /dev/vg_data/lv_database\n\n# The size (10GB) is for storing changes, not the whole database\n# Size needed depends on how much changes during snapshot lifetime\n</code></pre> <p>Real-world scenario - Database backup:</p> <pre><code># Your database LV is 100GB, actively being used\n# Create snapshot (only needs space for changes during backup)\nlvcreate -L 20G -s -n lv_db_backup /dev/vg_data/lv_database\n# Output: Logical volume \"lv_db_backup\" created\n\n# Mount the snapshot read-only\nmkdir /mnt/snap\nmount -o ro /dev/vg_data/lv_db_backup /mnt/snap\n\n# Backup from snapshot (original database keeps running!)\ntar czf /backup/database_$(date +%Y%m%d).tar.gz -C /mnt/snap .\n\n# Cleanup\numount /mnt/snap\nlvremove /dev/vg_data/lv_db_backup\n</code></pre>"},{"location":"linux/storage/lvm-storage/#monitoring-snapshot-usage","title":"Monitoring Snapshot Usage","text":"<p>What to watch: Snapshots need space to store changes. If they fill up, they become invalid!</p> <pre><code># Check snapshot usage\nlvs -a -o +snap_percent\n\n# Output shows percentage used:\n# LV                VG      ...  Snap%\n# lv_database_snap  vg_data ...  15.23\n</code></pre> <p>If it reaches 100%, the snapshot becomes invalid and useless. Solution: make snapshot size larger.</p>"},{"location":"linux/storage/lvm-storage/#extending-a-snapshot","title":"Extending a Snapshot","text":"<pre><code># If snapshot is getting full, extend it\nlvextend -L +5G /dev/vg_data/lv_database_snap\n</code></pre>"},{"location":"linux/storage/lvm-storage/#reverting-with-snapshots-rollback","title":"Reverting with Snapshots (Rollback)","text":"<p>What it does: Merges the snapshot back to the original, reverting all changes.</p> <p>When to use: You tested something, it broke, and you want to undo everything.</p> <p>Example:</p> <pre><code># Before major system update:\n# Take snapshot\nlvcreate -L 20G -s -n lv_root_snap /dev/vg_system/lv_root\n\n# Perform risky operation (install updates, etc.)\ndnf update -y\n\n# If something breaks, revert:\numount /\nlvconvert --merge /dev/vg_system/lv_root_snap\n# Reboot required to complete merge\nreboot\n\n# System comes back to pre-update state!\n</code></pre> <p>Warning: Merging destroys the snapshot and reverts the original LV. Make sure this is what you want!</p>"},{"location":"linux/storage/lvm-storage/#complete-real-world-examples","title":"Complete Real-World Examples","text":""},{"location":"linux/storage/lvm-storage/#example-1-setting-up-lvm-from-scratch","title":"Example 1: Setting Up LVM from Scratch","text":"<p>Scenario: New server with three empty disks. Set up LVM for flexible storage.</p> <pre><code># Step 1: Initialize physical disks\npvcreate /dev/sdb /dev/sdc /dev/sdd\n# Output: Physical volume \"/dev/sdb\" successfully created.\n#         Physical volume \"/dev/sdc\" successfully created.\n#         Physical volume \"/dev/sdd\" successfully created.\n\n# Step 2: Create volume group combining all disks\nvgcreate vg_data /dev/sdb /dev/sdc /dev/sdd\n# Output: Volume group \"vg_data\" successfully created\n\n# Step 3: Check available space\nvgs vg_data\n# Shows total combined space (e.g., 1.5TB)\n\n# Step 4: Create logical volumes for different purposes\nlvcreate -L 200G -n lv_database vg_data\nlvcreate -L 100G -n lv_webapp vg_data\nlvcreate -L 50G -n lv_logs vg_data\nlvcreate -l 100%FREE -n lv_backup vg_data\n\n# Step 5: Create filesystems\nmkfs.ext4 /dev/vg_data/lv_database\nmkfs.xfs /dev/vg_data/lv_webapp\nmkfs.ext4 /dev/vg_data/lv_logs\nmkfs.ext4 /dev/vg_data/lv_backup\n\n# Step 6: Create mount points\nmkdir -p /data/database\nmkdir -p /var/www\nmkdir -p /var/log/apps\nmkdir -p /backup\n\n# Step 7: Mount filesystems\nmount /dev/vg_data/lv_database /data/database\nmount /dev/vg_data/lv_webapp /var/www\nmount /dev/vg_data/lv_logs /var/log/apps\nmount /dev/vg_data/lv_backup /backup\n\n# Step 8: Make permanent in /etc/fstab\ncat &gt;&gt; /etc/fstab &lt;&lt; EOF\n/dev/vg_data/lv_database /data/database ext4 defaults 0 2\n/dev/vg_data/lv_webapp /var/www xfs defaults 0 2\n/dev/vg_data/lv_logs /var/log/apps ext4 defaults 0 2\n/dev/vg_data/lv_backup /backup ext4 defaults 0 2\nEOF\n\n# Step 9: Verify everything\ndf -h\nlvs\n</code></pre>"},{"location":"linux/storage/lvm-storage/#example-2-expanding-storage-when-running-out-of-space","title":"Example 2: Expanding Storage When Running Out of Space","text":"<p>Scenario: /var/www is 95% full and you need more space immediately.</p> <pre><code># Step 1: Check current situation\ndf -h /var/www\n# Filesystem                Size  Used Avail Use% Mounted on\n# /dev/vg_data/lv_webapp    50G   48G   2G  96% /var/www\n\n# Step 2: Check if VG has free space\nvgs vg_data\n# VG       #PV #LV #SN Attr   VSize  VFree\n# vg_data    3   4   0 wz--n- 1.50t  500.00g\n\n# Good! We have 500GB free\n\n# Step 3: Extend the LV by 50GB\nlvextend -L +50G /dev/vg_data/lv_webapp\n# Output: Size of logical volume vg_data/lv_webapp changed from 50.00 GiB to 100.00 GiB\n\n# Step 4: Resize the filesystem (xfs in this case)\nxfs_growfs /var/www\n# Output: data blocks changed from 13107200 to 26214400\n\n# OR for ext4, use:\n# resize2fs /dev/vg_data/lv_webapp\n\n# Step 5: Verify\ndf -h /var/www\n# Filesystem                Size  Used Avail Use% Mounted on\n# /dev/vg_data/lv_webapp   100G   48G   52G  48% /var/www\n\n# Problem solved! No downtime needed.\n</code></pre>"},{"location":"linux/storage/lvm-storage/#example-3-adding-a-new-disk-to-existing-setup","title":"Example 3: Adding a New Disk to Existing Setup","text":"<p>Scenario: Server is running low on storage across all volumes. Add new 1TB disk.</p> <pre><code># Step 1: Initialize new disk\npvcreate /dev/sde\n# Output: Physical volume \"/dev/sde\" successfully created.\n\n# Step 2: Add to existing volume group\nvgextend vg_data /dev/sde\n# Output: Volume group \"vg_data\" successfully extended\n\n# Step 3: Verify new space available\nvgs vg_data\n# Now shows 1TB more space in VFree\n\n# Step 4: Extend volumes that need space\n# Database needs more space\nlvextend -L +200G /dev/vg_data/lv_database\nresize2fs /dev/vg_data/lv_database\n\n# Backup needs more space\nlvextend -L +300G /dev/vg_data/lv_backup\nresize2fs /dev/vg_data/lv_backup\n\n# Step 5: Verify\ndf -h\nlvs vg_data\n</code></pre>"},{"location":"linux/storage/lvm-storage/#example-4-safe-database-maintenance-with-snapshots","title":"Example 4: Safe Database Maintenance with Snapshots","text":"<p>Scenario: Need to perform risky database migrations. Want ability to rollback.</p> <pre><code># Step 1: Stop database (if possible) or at least sync\nsystemctl stop postgresql\n\n# Step 2: Create snapshot (20GB for changes)\nlvcreate -L 20G -s -n lv_db_premigration /dev/vg_data/lv_database\n# Output: Logical volume \"lv_db_premigration\" created\n\n# Step 3: Start database and perform migrations\nsystemctl start postgresql\n./run-database-migration.sh\n\n# Step 4a: If migration successful, remove snapshot\nlvremove /dev/vg_data/lv_db_premigration\n\n# Step 4b: If migration failed, rollback\nsystemctl stop postgresql\numount /data/database\nlvconvert --merge /dev/vg_data/lv_db_premigration\n# Merge will happen on next mount/reboot\nmount /dev/vg_data/lv_database /data/database\nsystemctl start postgresql\n# Database is now back to pre-migration state!\n</code></pre>"},{"location":"linux/storage/lvm-storage/#example-5-replacing-a-failing-disk","title":"Example 5: Replacing a Failing Disk","text":"<p>Scenario: SMART errors on /dev/sdc. Need to replace without downtime.</p> <pre><code># Step 1: Add new replacement disk\npvcreate /dev/sdf\nvgextend vg_data /dev/sdf\n\n# Step 2: Move data from failing disk to new disk\n# This can take hours! System stays online.\npvmove /dev/sdc /dev/sdf\n# Shows progress: /dev/sdc: Moved: 45.2%\n\n# Step 3: After pvmove completes, remove old disk from VG\nvgreduce vg_data /dev/sdc\n\n# Step 4: Remove PV label\npvremove /dev/sdc\n\n# Step 5: Physically remove /dev/sdc\n# No data loss, no downtime!\n</code></pre>"},{"location":"linux/storage/lvm-storage/#troubleshooting-common-issues","title":"Troubleshooting Common Issues","text":""},{"location":"linux/storage/lvm-storage/#issue-1-cannot-create-lv-insufficient-space","title":"Issue 1: \u201cCannot create LV - insufficient space\u201d","text":"<p>Problem: Trying to create LV but get error about insufficient space.</p> <pre><code># Check VG free space\nvgs vg_data\n\n# If VFree is 0, you need to either:\n# a) Add more disks\npvcreate /dev/sde\nvgextend vg_data /dev/sde\n\n# b) Remove or shrink other LVs to free space\nlvremove /dev/vg_data/lv_unused\n# or\nlvreduce -L 50G /dev/vg_data/lv_oversized\n</code></pre>"},{"location":"linux/storage/lvm-storage/#issue-2-device-or-resource-busy-when-removing-lv","title":"Issue 2: \u201cDevice or resource busy\u201d when removing LV","text":"<p>Problem: Can\u2019t remove an LV because it\u2019s in use.</p> <pre><code># Find what's using it\nlsof /dev/vg_data/lv_name\n# or\nfuser -m /mount/point\n\n# Unmount it\numount /mount/point\n\n# Try again\nlvremove /dev/vg_data/lv_name\n</code></pre>"},{"location":"linux/storage/lvm-storage/#issue-3-snapshot-became-invalid","title":"Issue 3: Snapshot became invalid","text":"<p>Problem: Snapshot shows \u201cSnapshot status: INVALID\u201d</p> <p>Cause: Snapshot ran out of space to store changes.</p> <pre><code># Check snapshot usage\nlvs -a -o +snap_percent\n\n# If near 100%, extend it quickly\nlvextend -L +10G /dev/vg_data/lv_snap\n\n# For future: create larger snapshots initially\n</code></pre>"},{"location":"linux/storage/lvm-storage/#issue-4-cannot-activate-lv","title":"Issue 4: Cannot activate LV","text":"<p>Problem: LV won\u2019t activate after reboot.</p> <pre><code># Scan for LVM volumes\npvscan\nvgscan\nlvscan\n\n# Activate all\nvgchange -ay\n\n# Activate specific VG\nvgchange -ay vg_data\n</code></pre>"},{"location":"linux/storage/lvm-storage/#best-practices","title":"Best Practices","text":"<p>1. Plan Before Creating - Think about future growth - Leave free space in VG (20-30%) for flexibility - Use logical naming (lv_database, not lv1)</p> <p>2. Regular Monitoring - Check space regularly: <code>df -h</code> and <code>lvs</code> - Monitor VG free space: <code>vgs</code> - Set up alerts at 80% full</p> <p>3. Backup Before Changes - Always backup before shrinking - Take snapshots before risky operations - Document your LVM layout</p> <p>4. Extent Size - Default 4MB is fine for most cases - Use larger (16MB+) for very large volumes (multiple TB)</p> <p>5. Snapshot Management - Size snapshots appropriately (10-30% of original) - Don\u2019t keep snapshots long-term (performance impact) - Monitor snapshot usage</p> <p>6. Documentation - Keep diagrams of your LVM setup - Document which LVs contain what data - Note any special configurations</p>"},{"location":"linux/storage/lvm-storage/#quick-command-reference","title":"Quick Command Reference","text":"<pre><code># === Creating LVM from scratch ===\npvcreate /dev/sdb                    # Initialize disk\nvgcreate vg_name /dev/sdb           # Create volume group\nlvcreate -L 50G -n lv_name vg_name  # Create logical volume\nmkfs.ext4 /dev/vg_name/lv_name      # Format with filesystem\nmount /dev/vg_name/lv_name /mnt     # Mount it\n\n# === Viewing status ===\npvs                                  # List physical volumes\nvgs                                  # List volume groups\nlvs                                  # List logical volumes\n\n# === Expanding storage ===\nlvextend -L +10G /dev/vg/lv         # Add 10GB to LV\nresize2fs /dev/vg/lv                # Grow ext4 filesystem\nxfs_growfs /mount/point             # Grow XFS filesystem\n\n# === Snapshots ===\nlvcreate -L 10G -s -n snap /dev/vg/lv  # Create snapshot\nlvremove /dev/vg/snap                   # Remove snapshot\nlvconvert --merge /dev/vg/snap          # Revert to snapshot\n\n# === Adding storage ===\npvcreate /dev/sdc                    # Initialize new disk\nvgextend vg_name /dev/sdc           # Add to volume group\n\n# === Removing storage ===\npvmove /dev/sdc                      # Move data off disk\nvgreduce vg_name /dev/sdc           # Remove from VG\npvremove /dev/sdc                    # Clean up\n</code></pre>"},{"location":"linux/storage/remote-filesystems/","title":"Use Remote Filesystems and Network Block Devices","text":""},{"location":"linux/storage/remote-filesystems/#what-are-remote-filesystems","title":"What Are Remote Filesystems?","text":"<p>Remote filesystems let you access files stored on another computer over the network as if they were local. Instead of copying files back and forth, you mount the remote location and work with files directly.</p> <p>Think of it like network drives in Windows, but more powerful and with different protocols for different needs.</p>"},{"location":"linux/storage/remote-filesystems/#why-use-remote-filesystems","title":"Why Use Remote Filesystems?","text":"<p>Central Storage:</p> <ul> <li>One server stores data, many clients access it</li> <li>Easy backups (backup one location, not many computers)</li> <li>Consistent data across multiple machines</li> </ul> <p>Resource Sharing:</p> <ul> <li>Share files between Linux, Windows, and Mac</li> <li>Access powerful storage from lightweight clients</li> <li>Cost effective (one big storage server vs many small disks)</li> </ul>"},{"location":"linux/storage/remote-filesystems/#nfs-network-file-system","title":"NFS - Network File System","text":""},{"location":"linux/storage/remote-filesystems/#what-is-nfs","title":"What is NFS?","text":"<p>NFS is the native file-sharing protocol for Unix/Linux. It\u2019s fast, efficient, and designed for Linux systems to share files with each other.</p> <p>Think of it as: Linux-to-Linux file sharing (though other OS can use it too).</p> <p>Common uses:</p> <ul> <li>Shared home directories on office networks</li> <li>Central storage for web servers</li> <li>Shared data between multiple Linux servers</li> <li>Development teams sharing code</li> </ul>"},{"location":"linux/storage/remote-filesystems/#nfs-versions","title":"NFS Versions","text":"<p>NFSv3:</p> <ul> <li>Older, widely supported</li> <li>Can use UDP or TCP</li> <li>Simpler but less features</li> </ul> <p>NFSv4: (Recommended)</p> <ul> <li>Modern standard</li> <li>Better security (includes Kerberos support)</li> <li>Better performance</li> <li>TCP only</li> <li>Stateful (tracks connections)</li> </ul>"},{"location":"linux/storage/remote-filesystems/#setting-up-nfs-server","title":"Setting Up NFS Server","text":""},{"location":"linux/storage/remote-filesystems/#installing-nfs-server","title":"Installing NFS Server","text":"<pre><code># RHEL/CentOS/Rocky/Alma\ndnf install nfs-utils\nsystemctl enable --now nfs-server\n\n# Debian/Ubuntu\napt install nfs-kernel-server\nsystemctl enable --now nfs-server\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#configuring-exports-etcexports","title":"Configuring Exports - /etc/exports","text":"<p>What it is: This file tells NFS what directories to share and who can access them.</p> <p>Format:</p> <pre><code>/path/to/share    client(options)\n</code></pre> <p>Examples:</p> <pre><code># Share /data with one specific computer\n/data 192.168.1.100(rw,sync,no_subtree_check)\n\n# Share with entire network\n/data 192.168.1.0/24(rw,sync,no_subtree_check)\n\n# Share read-only with everyone\n/public *(ro,sync,no_subtree_check)\n\n# Share /home with specific computers (root on client stays root on server)\n/home 192.168.1.100(rw,sync,no_subtree_check,no_root_squash)\n\n# Multiple clients, different permissions\n/data 192.168.1.100(rw) 192.168.1.0/24(ro)\n</code></pre> <p>Common options:</p> <ul> <li><code>rw</code> - Read-write access</li> <li><code>ro</code> - Read-only access</li> <li><code>sync</code> - Sync writes immediately (safer, slower)</li> <li><code>async</code> - Async writes (faster, less safe)</li> <li><code>no_subtree_check</code> - Don\u2019t check subdirectories (recommended, faster)</li> <li><code>no_root_squash</code> - Don\u2019t map root user to nobody (needed for some setups)</li> <li><code>root_squash</code> - Map root to nobody (default, safer)</li> </ul> <p>Real-world scenario - Company file share:</p> <pre><code># Edit /etc/exports\nvi /etc/exports\n\n# Add share for company data\n# Office computers (192.168.1.0/24) get read-write\n# Remote workers (192.168.2.0/24) get read-only\n/company/data 192.168.1.0/24(rw,sync,no_subtree_check) 192.168.2.0/24(ro,sync,no_subtree_check)\n\n# Apply changes\nexportfs -ra\n\n# Verify\nexportfs -v\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#exportfs-manage-exports","title":"exportfs - Manage Exports","text":"<p>What it does: Applies changes to /etc/exports without restarting NFS server.</p> <p>Why use it: Fast way to add/remove shares or change settings.</p> <p>Examples:</p> <pre><code># Show current exports\nexportfs -v\n\n# Reload /etc/exports (apply changes)\nexportfs -ra\n\n# Export all in /etc/exports\nexportfs -a\n\n# Unexport all\nexportfs -ua\n\n# Unexport specific directory\nexportfs -u 192.168.1.100:/data\n\n# Temporarily export (not in /etc/exports)\nexportfs -o rw,sync 192.168.1.100:/tmp/test\n</code></pre> <p>Real-world scenario:</p> <pre><code># Add new share to /etc/exports\necho \"/backups 192.168.1.0/24(ro,sync,no_subtree_check)\" &gt;&gt; /etc/exports\n\n# Apply without restarting\nexportfs -ra\n\n# Verify it's exported\nexportfs -v | grep backups\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#showmount-check-nfs-exports","title":"showmount - Check NFS Exports","text":"<p>What it does: Shows what a server is exporting.</p> <p>Why use it: Verify your exports or see what another server shares.</p> <p>Examples:</p> <pre><code># Show exports on local server\nshowmount -e localhost\n\n# Show exports on remote server\nshowmount -e nfs-server.example.com\n\n# Show all current mounts\nshowmount -a\n\n# Show directories being exported\nshowmount -d\n</code></pre> <p>Output example:</p> <pre><code>showmount -e nfs-server\nExport list for nfs-server:\n/data      192.168.1.0/24\n/home      192.168.1.100,192.168.1.101\n/public    *\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#firewall-configuration","title":"Firewall Configuration","text":"<pre><code># RHEL/CentOS\nfirewall-cmd --permanent --add-service=nfs\nfirewall-cmd --permanent --add-service=rpc-bind\nfirewall-cmd --permanent --add-service=mountd\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#using-nfs-as-client","title":"Using NFS as Client","text":""},{"location":"linux/storage/remote-filesystems/#installing-nfs-client","title":"Installing NFS Client","text":"<pre><code># RHEL/CentOS\ndnf install nfs-utils\n\n# Debian/Ubuntu\napt install nfs-common\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#mounting-nfs-shares","title":"Mounting NFS Shares","text":"<p>What it does: Connects to remote share and makes it accessible locally.</p> <p>Why use it: Access files stored on NFS server.</p> <p>Examples:</p> <pre><code># Basic mount\nmount nfs-server:/data /mnt/data\n\n# Specify NFSv4\nmount -t nfs4 nfs-server:/data /mnt/data\n\n# With options\nmount -t nfs -o rw,hard,intr nfs-server:/data /mnt/data\n\n# Mount read-only\nmount -t nfs -o ro nfs-server:/data /mnt/data\n</code></pre> <p>Common mount options:</p> <ul> <li><code>hard</code> - Keep trying if server unavailable (recommended for important data)</li> <li><code>soft</code> - Give up after timeout (can cause data loss)</li> <li><code>intr</code> - Allow interruption if mount hangs</li> <li><code>rsize=8192</code> - Read buffer size</li> <li><code>wsize=8192</code> - Write buffer size</li> <li><code>_netdev</code> - Wait for network before mounting (important for /etc/fstab)</li> </ul> <p>Real-world scenario - Mount company share:</p> <pre><code># Create mount point\nmkdir -p /mnt/company-data\n\n# Test mount first\nmount -t nfs nfs-server.company.com:/data /mnt/company-data\n\n# Check if it works\nls /mnt/company-data\ndf -h /mnt/company-data\n\n# If good, make permanent in /etc/fstab\necho \"nfs-server.company.com:/data /mnt/company-data nfs defaults,_netdev 0 0\" &gt;&gt; /etc/fstab\n\n# Test fstab\numount /mnt/company-data\nmount -a\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#permanent-nfs-mounts-etcfstab","title":"Permanent NFS Mounts - /etc/fstab","text":"<p>Format:</p> <pre><code>server:/export  /mount/point  nfs  options  0  0\n</code></pre> <p>Examples:</p> <pre><code># Basic NFS mount\nnfs-server:/data /mnt/data nfs defaults,_netdev 0 0\n\n# NFSv4 with specific options\nnfs-server:/data /mnt/data nfs4 rw,hard,intr,_netdev 0 0\n\n# With performance tuning\nnfs-server:/data /mnt/data nfs rw,hard,intr,rsize=8192,wsize=8192,_netdev 0 0\n\n# Read-only mount\nnfs-server:/public /mnt/public nfs ro,_netdev 0 0\n</code></pre> <p>Always use <code>_netdev</code>! This tells Linux to wait for the network before mounting, preventing boot failures.</p>"},{"location":"linux/storage/remote-filesystems/#cifssmb-windows-file-sharing","title":"CIFS/SMB - Windows File Sharing","text":""},{"location":"linux/storage/remote-filesystems/#what-is-cifssmb","title":"What is CIFS/SMB?","text":"<p>SMB (Server Message Block) is the file-sharing protocol used by Windows. CIFS is an older dialect of SMB. Linux can both connect to Windows shares and serve files to Windows computers.</p> <p>Think of it as: Linux-to-Windows file sharing (and vice versa).</p> <p>Common uses:</p> <ul> <li>Access Windows file servers from Linux</li> <li>Connect to NAS devices</li> <li>Share files between mixed Windows/Linux environments</li> <li>Access Samba shares</li> </ul>"},{"location":"linux/storage/remote-filesystems/#installing-cifs-client","title":"Installing CIFS Client","text":"<pre><code># RHEL/CentOS\ndnf install cifs-utils\n\n# Debian/Ubuntu\napt install cifs-utils\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#mounting-cifssmb-shares","title":"Mounting CIFS/SMB Shares","text":"<p>What it does: Connects to Windows/Samba shares.</p> <p>Why use it: Access files on Windows servers or NAS devices.</p> <p>Examples:</p> <pre><code># Basic mount with username/password (not secure!)\nmount -t cifs //server/share /mnt/share -o username=myuser,password=mypass\n\n# Using credentials file (recommended)\nmount -t cifs //server/share /mnt/share -o credentials=/root/.smbcreds\n\n# With domain\nmount -t cifs //server/share /mnt/share -o credentials=/root/.smbcreds,domain=COMPANY\n\n# Specify permissions\nmount -t cifs //server/share /mnt/share -o credentials=/root/.smbcreds,uid=1000,gid=1000\n\n# Guest access (no password)\nmount -t cifs //server/share /mnt/share -o guest\n</code></pre> <p>Common options:</p> <ul> <li><code>username=user</code> - Username for authentication</li> <li><code>password=pass</code> - Password (avoid, use credentials file!)</li> <li><code>credentials=file</code> - File with username/password</li> <li><code>domain=DOMAIN</code> - Windows domain</li> <li><code>uid=1000</code> - Set owner of files</li> <li><code>gid=1000</code> - Set group of files</li> <li><code>file_mode=0755</code> - Permissions for files</li> <li><code>dir_mode=0755</code> - Permissions for directories</li> </ul>"},{"location":"linux/storage/remote-filesystems/#credentials-file","title":"Credentials File","text":"<p>Why use it: Never put passwords directly in mount commands or /etc/fstab!</p> <p>Create credentials file:</p> <pre><code># Create file\nvi /root/.smbcreds\n\n# Add credentials\nusername=myuser\npassword=mypassword\ndomain=COMPANY\n\n# Secure it (CRITICAL!)\nchmod 600 /root/.smbcreds\nchown root:root /root/.smbcreds\n</code></pre> <p>Real-world scenario - Mount NAS share:</p> <pre><code># Step 1: Create credentials file\ncat &gt; /root/.nascreds &lt;&lt; EOF\nusername=admin\npassword=SecurePassword123\nEOF\nchmod 600 /root/.nascreds\n\n# Step 2: Create mount point\nmkdir /mnt/nas\n\n# Step 3: Test mount\nmount -t cifs //nas.local/backup /mnt/nas -o credentials=/root/.nascreds,uid=1000,gid=1000\n\n# Step 4: Make permanent\necho \"//nas.local/backup /mnt/nas cifs credentials=/root/.nascreds,uid=1000,gid=1000,_netdev 0 0\" &gt;&gt; /etc/fstab\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#etcfstab-for-cifs","title":"/etc/fstab for CIFS","text":"<pre><code># Using credentials file\n//server/share /mnt/share cifs credentials=/root/.smbcreds,_netdev 0 0\n\n# With specific permissions\n//server/share /mnt/share cifs credentials=/root/.smbcreds,uid=1000,gid=1000,file_mode=0755,dir_mode=0755,_netdev 0 0\n\n# Guest access\n//server/public /mnt/public cifs guest,_netdev 0 0\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#iscsi-network-block-devices","title":"iSCSI - Network Block Devices","text":""},{"location":"linux/storage/remote-filesystems/#what-is-iscsi","title":"What is iSCSI?","text":"<p>iSCSI (Internet SCSI) provides block-level access to storage over a network. Unlike NFS or SMB which share files, iSCSI makes a remote disk appear as if it\u2019s locally attached.</p> <p>Think of it as: A hard drive that\u2019s physically in another computer but appears local.</p> <p>Key Difference:</p> <ul> <li>NFS/CIFS: Share files (filesystem-level)</li> <li>iSCSI: Share entire disks (block-level)</li> </ul> <p>Common uses:</p> <ul> <li>SAN (Storage Area Network) connections</li> <li>Virtual machine storage</li> <li>Database servers needing fast storage</li> <li>Clustered filesystems</li> </ul> <p>Components:</p> <ul> <li>Target: The iSCSI server (provides storage)</li> <li>Initiator: The iSCSI client (uses storage)</li> <li>IQN: Unique identifier (like iqn.2024-01.com.example:server)</li> <li>LUN: Logical Unit Number (the actual storage unit)</li> </ul>"},{"location":"linux/storage/remote-filesystems/#iscsi-target-server","title":"iSCSI Target (Server)","text":""},{"location":"linux/storage/remote-filesystems/#installing-iscsi-target","title":"Installing iSCSI Target","text":"<pre><code># RHEL/CentOS\ndnf install targetcli\nsystemctl enable --now target\n\n# Debian/Ubuntu\napt install targetcli-fb\nsystemctl enable --now target\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#configuring-iscsi-target-with-targetcli","title":"Configuring iSCSI Target with targetcli","text":"<p>What it does: Interactive tool to configure iSCSI storage.</p> <p>Why use it: Easy way to share disks over network.</p> <p>Real-world scenario - Share a disk:</p> <pre><code># Enter interactive mode\ntargetcli\n\n# Create backing storage (file-based, 100GB)\n/backstores/fileio create disk01 /storage/disk01.img 100G\n\n# OR use a real disk\n/backstores/block create disk01 /dev/sdb\n\n# Create iSCSI target\n/iscsi create iqn.2024-01.com.example:storage01\n\n# Create LUN (connects storage to target)\n/iscsi/iqn.2024-01.com.example:storage01/tpg1/luns create /backstores/fileio/disk01\n\n# Allow specific initiator to connect\n/iscsi/iqn.2024-01.com.example:storage01/tpg1/acls create iqn.2024-01.com.example:client01\n\n# Configure network portal\n/iscsi/iqn.2024-01.com.example:storage01/tpg1/portals create 192.168.1.100\n\n# Save and exit\nsaveconfig\nexit\n</code></pre> <p>View configuration:</p> <pre><code>targetcli ls\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#firewall-for-iscsi","title":"Firewall for iSCSI","text":"<pre><code>firewall-cmd --permanent --add-port=3260/tcp\nfirewall-cmd --reload\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#iscsi-initiator-client","title":"iSCSI Initiator (Client)","text":""},{"location":"linux/storage/remote-filesystems/#installing-iscsi-initiator","title":"Installing iSCSI Initiator","text":"<pre><code># RHEL/CentOS\ndnf install iscsi-initiator-utils\nsystemctl enable --now iscsid\n\n# Debian/Ubuntu\napt install open-iscsi\nsystemctl enable --now iscsid\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#setting-initiator-name","title":"Setting Initiator Name","text":"<pre><code># Edit initiator name\nvi /etc/iscsi/initiatorname.iscsi\n\n# Set to match what target allows\nInitiatorName=iqn.2024-01.com.example:client01\n\n# Restart service\nsystemctl restart iscsid\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#connecting-to-iscsi-target","title":"Connecting to iSCSI Target","text":"<p>What it does: Discovers and connects to iSCSI storage.</p> <p>Why use it: Makes remote storage available as local disk.</p> <p>Real-world scenario:</p> <pre><code># Step 1: Discover available targets\niscsiadm -m discovery -t st -p 192.168.1.100\n\n# Output shows available targets:\n# 192.168.1.100:3260,1 iqn.2024-01.com.example:storage01\n\n# Step 2: Login to target (connect)\niscsiadm -m node --login\n\n# Step 3: Check for new disk\nlsblk\n# New disk appears (probably /dev/sdc)\n\n# Step 4: Use it like any disk\n# Create partition\nfdisk /dev/sdc\n\n# Create filesystem\nmkfs.ext4 /dev/sdc1\n\n# Mount\nmkdir /mnt/iscsi\nmount /dev/sdc1 /mnt/iscsi\n\n# Step 5: Make permanent\necho \"/dev/sdc1 /mnt/iscsi ext4 _netdev 0 0\" &gt;&gt; /etc/fstab\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#managing-iscsi-sessions","title":"Managing iSCSI Sessions","text":"<pre><code># Show active sessions\niscsiadm -m session\n\n# Show detailed session info\niscsiadm -m session -P 3\n\n# Logout (disconnect)\niscsiadm -m node -T iqn.2024-01.com.example:storage01 -p 192.168.1.100 --logout\n\n# Login\niscsiadm -m node -T iqn.2024-01.com.example:storage01 -p 192.168.1.100 --login\n\n# Automatic login at boot\niscsiadm -m node -T iqn.2024-01.com.example:storage01 -p 192.168.1.100 --op update -n node.startup -v automatic\n\n# Rescan for new LUNs\niscsiadm -m session --rescan\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#troubleshooting-remote-filesystems","title":"Troubleshooting Remote Filesystems","text":""},{"location":"linux/storage/remote-filesystems/#nfs-troubleshooting","title":"NFS Troubleshooting","text":"<p>Problem: Cannot mount NFS share</p> <pre><code># Step 1: Check if server is exporting\nshowmount -e nfs-server\n\n# Step 2: Test network connectivity\nping nfs-server\ntelnet nfs-server 2049\n\n# Step 3: Check firewall\nfirewall-cmd --list-services\n\n# Step 4: Try mounting with verbose\nmount -v -t nfs nfs-server:/data /mnt/data\n\n# Step 5: Check logs\njournalctl -u nfs-server\ndmesg | grep nfs\n</code></pre> <p>Problem: NFS mount hangs</p> <pre><code># Use soft mount for testing\nmount -t nfs -o soft,timeo=10 nfs-server:/data /mnt/data\n\n# Check if server is responsive\nrpcinfo -p nfs-server\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#cifs-troubleshooting","title":"CIFS Troubleshooting","text":"<p>Problem: Cannot mount Windows share</p> <pre><code># Step 1: List available shares\nsmbclient -L //server -U username\n\n# Step 2: Test connection\nsmbclient //server/share -U username\n\n# Step 3: Check credentials file\ncat /root/.smbcreds\nls -l /root/.smbcreds  # Should be 600\n\n# Step 4: Try with verbose\nmount -v -t cifs //server/share /mnt -o credentials=/root/.smbcreds\n\n# Step 5: Specify SMB version\nmount -t cifs //server/share /mnt -o credentials=/root/.smbcreds,vers=3.0\n</code></pre> <p>Problem: Permission denied on CIFS</p> <pre><code># Mount with specific UID/GID\nmount -t cifs //server/share /mnt -o credentials=/root/.smbcreds,uid=1000,gid=1000,file_mode=0755,dir_mode=0755\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#iscsi-troubleshooting","title":"iSCSI Troubleshooting","text":"<p>Problem: Cannot discover target</p> <pre><code># Check network\nping target-server\nnc -zv target-server 3260\n\n# Check firewall\nfirewall-cmd --list-ports\n\n# Check initiator name matches\ncat /etc/iscsi/initiatorname.iscsi\n\n# Restart service\nsystemctl restart iscsid\n</code></pre> <p>Problem: Lost connection</p> <pre><code># Check session status\niscsiadm -m session -P 3\n\n# Restart session\niscsiadm -m node --logout\niscsiadm -m node --login\n\n# Check logs\njournalctl -u iscsid\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#performance-tips","title":"Performance Tips","text":""},{"location":"linux/storage/remote-filesystems/#nfs-performance","title":"NFS Performance","text":"<pre><code># Increase buffer sizes\nmount -o rsize=32768,wsize=32768 server:/data /mnt/data\n\n# Use async for better performance (less safe)\nmount -o async server:/data /mnt/data\n\n# Combine options\nmount -o rsize=32768,wsize=32768,async,noatime server:/data /mnt/data\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#cifs-performance","title":"CIFS Performance","text":"<pre><code># Use SMB3 with multichannel\nmount -t cifs //server/share /mnt -o vers=3.0,multichannel\n\n# Increase cache\nmount -t cifs //server/share /mnt -o cache=strict\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/remote-filesystems/#nfs","title":"NFS","text":"<pre><code># Server\nexportfs -ra                      # Reload exports\nshowmount -e                      # Show exports\n\n# Client\nmount nfs-server:/data /mnt       # Mount NFS share\numount /mnt                       # Unmount\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#cifs","title":"CIFS","text":"<pre><code># Mount\nmount -t cifs //server/share /mnt -o credentials=/root/.creds\n\n# List shares\nsmbclient -L //server -U user\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#iscsi","title":"iSCSI","text":"<pre><code># Discover targets\niscsiadm -m discovery -t st -p server\n\n# Connect\niscsiadm -m node --login\n\n# Show sessions\niscsiadm -m session\n\n# Disconnect\niscsiadm -m node --logout\n</code></pre>"},{"location":"linux/storage/remote-filesystems/#credentials-file_1","title":"Credentials File","text":"<pre><code># Create CIFS credentials\ncat &gt; /root/.smbcreds &lt;&lt; EOF\nusername=myuser\npassword=mypass\ndomain=COMPANY\nEOF\nchmod 600 /root/.smbcreds\n</code></pre>"},{"location":"linux/storage/storage-performance/","title":"Monitor Storage Performance","text":""},{"location":"linux/storage/storage-performance/#what-is-storage-performance-monitoring","title":"What is Storage Performance Monitoring?","text":"<p>Storage performance monitoring is about watching how your disks and filesystems are performing. Are they fast enough? Are they bottlenecking your system? Are they about to fail?</p> <p>Think of it like checking your car\u2019s dashboard - you want to know if everything\u2019s running smoothly before problems occur.</p>"},{"location":"linux/storage/storage-performance/#why-monitor-storage","title":"Why Monitor Storage?","text":"<p>Prevent problems:</p> <ul> <li>Catch failing disks before they fail completely</li> <li>Identify bottlenecks before users complain</li> <li>Plan capacity before running out of space</li> </ul> <p>Optimize performance:</p> <ul> <li>Find slow I/O operations</li> <li>Identify what\u2019s causing disk activity</li> <li>Tune system for better performance</li> </ul> <p>Troubleshoot issues:</p> <ul> <li>System is slow - is it the disk?</li> <li>Application timing out - disk bottleneck?</li> <li>High load - what\u2019s accessing the disk?</li> </ul>"},{"location":"linux/storage/storage-performance/#key-performance-metrics","title":"Key Performance Metrics","text":""},{"location":"linux/storage/storage-performance/#understanding-the-numbers","title":"Understanding the Numbers","text":"<p>IOPS (Input/Output Operations Per Second):</p> <ul> <li>How many read/write operations per second</li> <li>Like \u201chow many files can I access per second\u201d</li> <li>Higher = better (especially for many small files)</li> <li>Example: Database servers need high IOPS</li> </ul> <p>Throughput (MB/s):</p> <ul> <li>How much data transferred per second</li> <li>Like \u201chow fast can I copy a large file\u201d</li> <li>Higher = better (especially for large files)</li> <li>Example: Video editing needs high throughput</li> </ul> <p>Latency (milliseconds):</p> <ul> <li>How long each operation takes</li> <li>Like \u201chow long do I wait for disk response\u201d</li> <li>Lower = better</li> <li>Good: &lt;10ms, Acceptable: 10-20ms, Bad: &gt;20ms</li> </ul> <p>Utilization (%):</p> <ul> <li>How busy the disk is</li> <li>100% means fully busy</li> <li> <p>80% sustained = potential bottleneck</p> </li> <li>Example: 95% util = disk can\u2019t keep up</li> </ul>"},{"location":"linux/storage/storage-performance/#iostat-io-statistics","title":"iostat - I/O Statistics","text":""},{"location":"linux/storage/storage-performance/#what-is-iostat","title":"What is iostat?","text":"<p>iostat shows how busy your disks are, how much data they\u2019re reading/writing, and if there are performance issues.</p> <p>Think of it as: A real-time dashboard for your disks.</p>"},{"location":"linux/storage/storage-performance/#installing-iostat","title":"Installing iostat","text":"<pre><code># RHEL/CentOS/Rocky\ndnf install sysstat\nsystemctl enable --now sysstat\n\n# Debian/Ubuntu\napt install sysstat\nsystemctl enable --now sysstat\n</code></pre>"},{"location":"linux/storage/storage-performance/#using-iostat","title":"Using iostat","text":"<p>Examples:</p> <pre><code># Basic snapshot\niostat\n\n# Extended statistics (most useful!)\niostat -x\n\n# Human-readable sizes\niostat -xh\n\n# Update every 2 seconds\niostat -x 2\n\n# 10 samples, 2 seconds apart\niostat -x 2 10\n\n# Show in megabytes\niostat -xm 2\n\n# With timestamps\niostat -xt 2\n</code></pre> <p>Real-world scenario - Check disk performance:</p> <pre><code># System feels slow, check disks\niostat -x 2\n\nDevice   r/s   w/s   rkB/s   wkB/s  await  %util\nsda     10.5  45.2   512     2048   8.3    45.2\nsdb    150.3  89.7  3072     4096   85.5   98.7\nsdc      2.1   1.3    64       32   2.1     5.3\n</code></pre> <p>Reading the output:</p> <ul> <li>sda: Normal activity, 45% busy, 8ms wait - Good!</li> <li>sdb: Very busy (98.7%), high wait (85ms) - BOTTLENECK!</li> <li>sdc: Barely used, 5% busy - Fine</li> </ul> <p>Solution: sdb is your problem. It\u2019s nearly 100% busy and operations are waiting 85ms.</p>"},{"location":"linux/storage/storage-performance/#key-iostat-columns","title":"Key iostat Columns","text":"<pre><code>Device:   Drive name (sda, sdb, nvme0n1)\nr/s:      Reads per second\nw/s:      Writes per second  \nrkB/s:    Kilobytes read per second\nwkB/s:    Kilobytes written per second\nawait:    Average wait time in milliseconds\n%util:    How busy the drive is (percentage)\n</code></pre> <p>What\u2019s good vs bad:</p> <pre><code>await    Interpretation\n&lt;10ms    Excellent (SSD territory)\n10-20ms  Good (normal HDD)\n20-50ms  Slow (loaded system)\n&gt;50ms    Problem! (bottleneck)\n\n%util    Interpretation\n&lt;50%     Plenty of capacity\n50-80%   Moderate load\n80-95%   Getting busy\n&gt;95%     Saturated (bottleneck!)\n</code></pre>"},{"location":"linux/storage/storage-performance/#iotop-io-by-process","title":"iotop - I/O by Process","text":""},{"location":"linux/storage/storage-performance/#what-is-iotop","title":"What is iotop?","text":"<p>iotop shows which programs are using disk I/O. Like <code>top</code> but for disk activity.</p> <p>Think of it as: \u201cWho\u2019s hogging my disk?\u201d</p>"},{"location":"linux/storage/storage-performance/#installing-iotop","title":"Installing iotop","text":"<pre><code># RHEL/CentOS\ndnf install iotop\n\n# Debian/Ubuntu\napt install iotop\n</code></pre>"},{"location":"linux/storage/storage-performance/#using-iotop","title":"Using iotop","text":"<p>Examples:</p> <pre><code># Basic view\niotop\n\n# Only show processes doing I/O (most useful!)\niotop -o\n\n# Accumulated I/O (total since start)\niotop -oa\n\n# With timestamps\niotop -oat\n\n# Batch mode (for logging)\niotop -ob -n 10\n\n# Monitor specific process\niotop -p 1234\n\n# Monitor specific user\niotop -u mysql\n</code></pre> <p>Interactive keys:</p> <ul> <li><code>o</code> - Toggle showing only active processes</li> <li><code>a</code> - Toggle accumulated mode</li> <li><code>r</code> - Reverse sort</li> <li><code>q</code> - Quit</li> </ul> <p>Real-world scenario - System slow, find culprit:</p> <pre><code>iotop -o\n\nTotal DISK READ: 85.3 MB/s | Total DISK WRITE: 120.5 MB/s\nTID  USER     DISK READ  DISK WRITE  COMMAND\n2341 mysql    65.3 MB/s   95.2 MB/s  mysqld\n3422 root     15.2 MB/s   20.1 MB/s  tar\n4551 www-data  4.8 MB/s    5.2 MB/s  apache2\n</code></pre> <p>Reading the output:</p> <ul> <li>MySQL is hammering the disk (65MB/s read, 95MB/s write)</li> <li>tar backup is also using disk</li> <li>Apache is minimal</li> </ul> <p>Solution: MySQL query or backup causing high I/O.</p>"},{"location":"linux/storage/storage-performance/#vmstat-system-statistics","title":"vmstat - System Statistics","text":""},{"location":"linux/storage/storage-performance/#what-is-vmstat","title":"What is vmstat?","text":"<p>vmstat shows overall system performance including memory, swap, and I/O wait. Good for seeing if disk is causing system slowness.</p> <p>Think of it as: Overall health monitor with disk focus.</p>"},{"location":"linux/storage/storage-performance/#using-vmstat","title":"Using vmstat","text":"<p>Examples:</p> <pre><code># Single snapshot\nvmstat\n\n# Update every 2 seconds\nvmstat 2\n\n# 10 updates\nvmstat 2 10\n\n# Show active/inactive memory\nvmstat -a 2\n\n# Disk statistics\nvmstat -d\n\n# Memory statistics\nvmstat -s\n</code></pre> <p>Real-world scenario - Is disk slowing system?</p> <pre><code>vmstat 2\n\nprocs -----------memory---------- ---swap-- -----io---- --cpu----\n r  b   swpd   free   buff  cache   si   so    bi    bo   wa\n 2  3  10240  2048  4096  8192     0    0   500  2000   35\n 1  4  10240  2048  4096  8192     0    0   800  3500   45\n 3  5  10240  2048  4096  8192     0    0  1200  5000   52\n</code></pre> <p>Reading the output:</p> <ul> <li>r: Processes waiting for CPU</li> <li>b: Processes blocked waiting for I/O (3-5 = high!)</li> <li>si/so: Swap in/out (0 = good, no swapping)</li> <li>bi/bo: Blocks in/out (high numbers = heavy I/O)</li> <li>wa: I/O wait (35-52% = PROBLEM!)</li> </ul> <p>Interpretation:</p> <p>When wa (I/O wait) is consistently above 20%, your system is waiting for disk operations. This is a bottleneck!</p>"},{"location":"linux/storage/storage-performance/#df-and-du-space-usage","title":"df and du - Space Usage","text":""},{"location":"linux/storage/storage-performance/#df-disk-free","title":"df - Disk Free","text":"<p>What it does: Shows how much space is used/available on filesystems.</p> <p>Think of it as: \u201cHow full is my disk?\u201d</p> <p>Examples:</p> <pre><code># Human-readable\ndf -h\n\n# With filesystem types\ndf -hT\n\n# Inode usage (number of files)\ndf -hi\n\n# Specific filesystem\ndf -h /var\n</code></pre> <p>Output example:</p> <pre><code>df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1        50G   35G   13G  73% /\n/dev/sdb1       500G  475G   25G  95% /data\ntmpfs           8.0G  1.0M  8.0G   1% /tmp\n</code></pre> <p>Critical thresholds:</p> <ul> <li>&lt;80%: Healthy</li> <li>80-90%: Monitor closely</li> <li>90-95%: Take action soon</li> <li> <p>95%: Critical! Free space immediately</p> </li> </ul> <p>Real-world scenario - Disk filling up:</p> <pre><code>df -h /\n# 95% full - need to find what's using space!\n\n# Find large directories\ndu -sh /* | sort -rh | head -10\n# Output:\n# 30G  /var\n# 10G  /usr\n# 5G   /home\n\n# Drill down\ndu -sh /var/* | sort -rh | head -5\n# 25G  /var/log\n# 3G   /var/cache\n# 2G   /var/lib\n\n# Found it! /var/log\nls -lh /var/log\n# old-logs.tar.gz is 20GB!\n</code></pre>"},{"location":"linux/storage/storage-performance/#du-disk-usage","title":"du - Disk Usage","text":"<p>What it does: Shows size of directories and files.</p> <p>Think of it as: \u201cWhat\u2019s taking up space?\u201d</p> <p>Examples:</p> <pre><code># Current directory total\ndu -sh .\n\n# Each subdirectory\ndu -sh *\n\n# Top level only\ndu -h --max-depth=1 /var\n\n# Sort by size\ndu -sh /var/* | sort -rh\n\n# Top 10 largest\ndu -ah /home | sort -rh | head -10\n\n# Exclude patterns\ndu -sh --exclude='*.log' /var\n</code></pre> <p>Real-world scenario - Find space hogs:</p> <pre><code># Root is 95% full\ndf -h /\n\n# Start at root\ndu -sh /* 2&gt;/dev/null | sort -rh\n# Output shows /var is huge\n\n# Go deeper\ndu -sh /var/* | sort -rh\n# /var/log is 50GB!\n\n# Find biggest logs\ndu -sh /var/log/* | sort -rh | head -5\n# application.log is 45GB!\n\n# Clean up\ngzip /var/log/application.log\n# or delete old logs\n</code></pre>"},{"location":"linux/storage/storage-performance/#lsof-and-fuser-find-open-files","title":"lsof and fuser - Find Open Files","text":""},{"location":"linux/storage/storage-performance/#lsof-list-open-files","title":"lsof - List Open Files","text":"<p>What it does: Shows which processes have which files open.</p> <p>Think of it as: \u201cWho\u2019s using this file/directory?\u201d</p> <p>Examples:</p> <pre><code># All open files in directory\nlsof +D /var/log\n\n# Files opened by user\nlsof -u mysql\n\n# Files opened by process\nlsof -p 1234\n\n# What's using a mount point\nlsof /mnt/data\n\n# Network connections\nlsof -i\n\n# What's using port 80\nlsof -i :80\n\n# Find deleted but open files (wasting space!)\nlsof | grep deleted\n</code></pre> <p>Real-world scenario - Can\u2019t unmount:</p> <pre><code># Try to unmount\numount /data\n# Error: device is busy\n\n# Find what's using it\nlsof +D /data\n# Output:\n# COMMAND  PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n# bash    1234 john  cwd    DIR    8,1     4096   12 /data/work\n# mysql   5678 mysql  4r    REG    8,1  5242880   45 /data/db/file.db\n\n# Kill the processes or close their files\n</code></pre>"},{"location":"linux/storage/storage-performance/#fuser-find-process-using-file","title":"fuser - Find Process Using File","text":"<p>What it does: Simpler than lsof, shows PIDs using a file.</p> <p>Think of it as: Quick \u201cwho\u2019s using this?\u201d</p> <p>Examples:</p> <pre><code># Show processes using file\nfuser /var/log/syslog\n\n# Verbose (show user and type)\nfuser -v /mnt/data\n\n# What's using the filesystem\nfuser -m /mnt/data\n\n# Kill all processes using it (dangerous!)\nfuser -k /mnt/data\n\n# Interactive kill (asks first)\nfuser -ki /mnt/data\n</code></pre>"},{"location":"linux/storage/storage-performance/#smartctl-disk-health","title":"smartctl - Disk Health","text":""},{"location":"linux/storage/storage-performance/#what-is-smartctl","title":"What is smartctl?","text":"<p>smartctl reads SMART (Self-Monitoring, Analysis and Reporting Technology) data from drives. This predicts disk failures before they happen!</p> <p>Think of it as: Your disk\u2019s health checkup.</p>"},{"location":"linux/storage/storage-performance/#installing-smartctl","title":"Installing smartctl","text":"<pre><code># RHEL/CentOS\ndnf install smartmontools\nsystemctl enable --now smartd\n\n# Debian/Ubuntu\napt install smartmontools\nsystemctl enable --now smartd\n</code></pre>"},{"location":"linux/storage/storage-performance/#using-smartctl","title":"Using smartctl","text":"<p>Examples:</p> <pre><code># Health status (most important!)\nsmartctl -H /dev/sda\n\n# All SMART data\nsmartctl -a /dev/sda\n\n# Attributes only\nsmartctl -A /dev/sda\n\n# Self-test log\nsmartctl -l selftest /dev/sda\n\n# Error log\nsmartctl -l error /dev/sda\n\n# Run short self-test\nsmartctl -t short /dev/sda\n\n# Run long self-test (takes hours)\nsmartctl -t long /dev/sda\n\n# For NVMe drives\nsmartctl -a /dev/nvme0\n</code></pre> <p>Real-world scenario - Check disk health:</p> <pre><code># Monthly health check\nsmartctl -H /dev/sda\n\n# Output:\n# === START OF READ SMART DATA SECTION ===\n# SMART overall-health self-assessment test result: PASSED\n\n# Good! Now check details\nsmartctl -A /dev/sda\n</code></pre>"},{"location":"linux/storage/storage-performance/#important-smart-attributes","title":"Important SMART Attributes","text":"<pre><code>ID  ATTRIBUTE_NAME          VALUE\n5   Reallocated_Sector_Ct   100    \u2190 Should be 0 or very low\n10  Spin_Retry_Count         100    \u2190 Should be 0\n196 Reallocated_Event_Count  100    \u2190 Should be 0\n197 Current_Pending_Sector   100    \u2190 Should be 0 (failing!)\n198 Offline_Uncorrectable    100    \u2190 Should be 0 (failing!)\n</code></pre> <p>Warning signs (REPLACE DISK!):</p> <ul> <li>Health status: FAILING</li> <li>Reallocated sectors increasing</li> <li>Current pending sectors &gt; 0</li> <li>High error count</li> <li>Multiple failed self-tests</li> </ul> <p>Example - Failing disk:</p> <pre><code>smartctl -A /dev/sdb\n\nID  ATTRIBUTE_NAME          VALUE\n5   Reallocated_Sector_Ct    85    \u2190 BAD! Was 100, now 85\n197 Current_Pending_Sector    1    \u2190 VERY BAD! Sectors failing\n198 Offline_Uncorrectable     2    \u2190 VERY BAD! Unreadable data\n\nsmartctl -H /dev/sdb\n# Result: FAILING!\n\n# ACTION REQUIRED:\n# 1. Backup immediately!\n# 2. Replace disk\n# 3. Do NOT wait!\n</code></pre>"},{"location":"linux/storage/storage-performance/#simple-performance-test","title":"Simple Performance Test","text":""},{"location":"linux/storage/storage-performance/#dd-basic-disk-speed-test","title":"dd - Basic Disk Speed Test","text":"<p>What it does: Tests raw disk read/write speed.</p> <p>Think of it as: Simple benchmark.</p> <p>Examples:</p> <pre><code># Write test (1GB file)\ndd if=/dev/zero of=/tmp/testfile bs=1M count=1000 oflag=direct\n\n# Output:\n# 1000+0 records in\n# 1000+0 records out\n# 1048576000 bytes (1.0 GB) copied, 5.2 s, 202 MB/s\n\n# Read test\ndd if=/tmp/testfile of=/dev/null bs=1M\n\n# Cleanup\nrm /tmp/testfile\n</code></pre> <p>Interpreting results:</p> <ul> <li>HDD: 100-200 MB/s typical</li> <li>SATA SSD: 500-600 MB/s</li> <li>NVMe SSD: 2000-7000 MB/s</li> </ul>"},{"location":"linux/storage/storage-performance/#troubleshooting-scenarios","title":"Troubleshooting Scenarios","text":""},{"location":"linux/storage/storage-performance/#scenario-1-system-very-slow","title":"Scenario 1: System Very Slow","text":"<p>Steps:</p> <pre><code># 1. Check I/O wait\nvmstat 2 5\n# If wa &gt; 20%, disk is the problem\n\n# 2. Find busy disk\niostat -x 2 5\n# Look for %util &gt; 90%\n\n# 3. Find culprit process\niotop -o\n# See what's hammering disk\n\n# 4. Fix\n# Kill process, optimize query, add cache, etc.\n</code></pre>"},{"location":"linux/storage/storage-performance/#scenario-2-disk-almost-full","title":"Scenario 2: Disk Almost Full","text":"<p>Steps:</p> <pre><code># 1. Confirm full\ndf -h\n\n# 2. Find large directories\ndu -sh /* | sort -rh | head -10\n\n# 3. Drill down\ndu -sh /var/* | sort -rh | head -5\n\n# 4. Find specific files\nfind /var/log -type f -size +100M\n\n# 5. Clean up\n# Delete, archive, or move files\n</code></pre>"},{"location":"linux/storage/storage-performance/#scenario-3-cannot-unmount","title":"Scenario 3: Cannot Unmount","text":"<p>Steps:</p> <pre><code># 1. Find what's using it\nlsof +D /mount/point\nfuser -vm /mount/point\n\n# 2. Kill processes\nkill PID\n\n# 3. If still busy, force\numount -l /mount/point\n</code></pre>"},{"location":"linux/storage/storage-performance/#monitoring-best-practices","title":"Monitoring Best Practices","text":"<p>1. Regular health checks:</p> <pre><code># Weekly disk health\nsmartctl -H /dev/sda\n\n# Daily space check\ndf -h | grep -v tmpfs\n</code></pre> <p>2. Set up alerts:</p> <pre><code># Alert when &gt;90% full\ndf -h | awk '$5 &gt; 90 {print $0}'\n\n# Alert on SMART warnings\nsmartctl -H /dev/sda | grep -i fail\n</code></pre> <p>3. Keep historical data:</p> <pre><code># Log iostat daily\niostat -x 60 1440 &gt; /var/log/iostat-$(date +%Y%m%d).log\n</code></pre> <p>4. Monitor trends:</p> <pre><code># Space usage over time\ndu -sh /var/log &gt;&gt; /var/log/space-usage.log\n</code></pre>"},{"location":"linux/storage/storage-performance/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/storage-performance/#check-performance","title":"Check Performance","text":"<pre><code>iostat -x 2              # Disk busy?\niotop -o                 # Who's using disk?\nvmstat 2                 # I/O wait high?\ndf -h                    # Space available?\n</code></pre>"},{"location":"linux/storage/storage-performance/#find-space-hogs","title":"Find Space Hogs","text":"<pre><code>du -sh /* | sort -rh     # Largest directories\ndu -sh * | sort -rh      # Current dir\nfind / -type f -size +1G # Files &gt; 1GB\n</code></pre>"},{"location":"linux/storage/storage-performance/#check-health","title":"Check Health","text":"<pre><code>smartctl -H /dev/sda     # Overall health\nsmartctl -A /dev/sda     # Detailed attributes\ndmesg | grep -i error    # System errors\n</code></pre>"},{"location":"linux/storage/storage-performance/#troubleshoot-issues","title":"Troubleshoot Issues","text":"<pre><code>lsof +D /path            # What's using path\nfuser -vm /path          # PIDs using path\nmount | grep /path       # Is it mounted?\n</code></pre>"},{"location":"linux/storage/storage-performance/#speed-test","title":"Speed Test","text":"<pre><code># Write speed\ndd if=/dev/zero of=/tmp/test bs=1M count=1000 oflag=direct\n\n# Read speed  \ndd if=/tmp/test of=/dev/null bs=1M\n</code></pre>"},{"location":"linux/storage/swap-space/","title":"Configure and Manage Swap Space","text":""},{"location":"linux/storage/swap-space/#what-is-swap-space","title":"What is Swap Space?","text":"<p>Swap is space on your hard drive that acts as extra (but slower) RAM. When your physical RAM fills up, Linux moves less-used data to swap to free up RAM for active programs.</p> <p>Think of it like this:</p> <ul> <li>RAM: Your desk - fast and convenient for work you\u2019re doing now</li> <li>Swap: A filing cabinet - slower to access, but expands your working space</li> </ul>"},{"location":"linux/storage/swap-space/#when-is-swap-used","title":"When is Swap Used?","text":"<p>Scenario 1: Running out of RAM</p> <p>You\u2019re running many programs and RAM fills up. Linux moves inactive pages to swap, freeing RAM for active processes.</p> <p>Scenario 2: Hibernation</p> <p>When you hibernate, Linux copies all RAM to swap, then powers off. On resume, it reads swap back into RAM.</p> <p>Scenario 3: Memory Management</p> <p>Even with free RAM, Linux might swap out rarely-used pages to have more free RAM for file caching (speeds up the system).</p>"},{"location":"linux/storage/swap-space/#swap-size-recommendations","title":"Swap Size Recommendations","text":"Physical RAM Swap Size (No Hibernation) With Hibernation &lt; 2 GB 2x RAM 3x RAM 2-8 GB = RAM 2x RAM 8-64 GB 4-8 GB (or 0.5x RAM) 1.5x RAM &gt; 64 GB 4-8 GB minimum Not practical <p>Note: These are guidelines. Your needs depend on your workload.</p>"},{"location":"linux/storage/swap-space/#creating-swap-space","title":"Creating Swap Space","text":""},{"location":"linux/storage/swap-space/#two-types-of-swap","title":"Two Types of Swap","text":"<p>1. Swap Partition:</p> <ul> <li>Dedicated disk partition for swap</li> <li>Slightly faster</li> <li>Fixed size (harder to change)</li> <li>Traditional approach</li> </ul> <p>2. Swap File:</p> <ul> <li>Regular file used as swap</li> <li>Easier to create/resize</li> <li>More flexible</li> <li>Modern approach</li> </ul> <p>Both work equally well. Swap files are more convenient.</p>"},{"location":"linux/storage/swap-space/#creating-swap-files","title":"Creating Swap Files","text":""},{"location":"linux/storage/swap-space/#fallocate-quick-file-creation","title":"fallocate - Quick File Creation","text":"<p>What it does: Instantly creates a file of specific size.</p> <p>Why use it: Fastest way to create swap file.</p> <p>Example - Creating 2GB swap file:</p> <pre><code># Step 1: Create the file (instant!)\nfallocate -l 2G /swapfile\n\n# Step 2: Set correct permissions (CRITICAL for security!)\nchmod 600 /swapfile\n\n# Step 3: Format as swap\nmkswap /swapfile\n\n# Step 4: Enable it\nswapon /swapfile\n\n# Step 5: Verify\nswapon --show\nfree -h\n\n# Step 6: Make permanent\necho '/swapfile none swap sw 0 0' &gt;&gt; /etc/fstab\n</code></pre> <p>Real-world scenario - VPS with no swap:</p> <pre><code># Many VPS providers don't include swap\n# Check current swap\nfree -h\n# Shows: Swap: 0B\n\n# Create 4GB swap file\nsudo fallocate -l 4G /swapfile\nsudo chmod 600 /swapfile\nsudo mkswap /swapfile\nsudo swapon /swapfile\n\n# Verify\nfree -h\n# Now shows: Swap: 4.0Gi\n\n# Make permanent\necho '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab\n</code></pre>"},{"location":"linux/storage/swap-space/#dd-alternative-file-creation","title":"dd - Alternative File Creation","text":"<p>What it does: Copies data to create file (slower but more compatible).</p> <p>Why use it: Works on all systems, shows progress.</p> <p>Example:</p> <pre><code># Create 2GB swap file with progress\ndd if=/dev/zero of=/swapfile bs=1M count=2048 status=progress\n\n# Then follow same steps as fallocate\nchmod 600 /swapfile\nmkswap /swapfile\nswapon /swapfile\n</code></pre>"},{"location":"linux/storage/swap-space/#creating-swap-partitions","title":"Creating Swap Partitions","text":""},{"location":"linux/storage/swap-space/#using-fdisk","title":"Using fdisk","text":"<p>Real-world scenario - New disk for swap:</p> <pre><code># Step 1: Identify disk\nlsblk\n# /dev/sdb is your new disk\n\n# Step 2: Create partition\nfdisk /dev/sdb\n\n# In fdisk:\n# Press: n (new partition)\n# Press: p (primary)\n# Press: 1 (partition number)\n# Press: Enter (default start)\n# Press: +8G (8GB size)\n# Press: t (change type)\n# Press: 82 (Linux swap)\n# Press: w (write changes)\n\n# Step 3: Format as swap\nmkswap /dev/sdb1\n\n# Step 4: Enable\nswapon /dev/sdb1\n\n# Step 5: Make permanent\necho '/dev/sdb1 none swap sw 0 0' &gt;&gt; /etc/fstab\n</code></pre>"},{"location":"linux/storage/swap-space/#swap-commands","title":"Swap Commands","text":""},{"location":"linux/storage/swap-space/#mkswap-format-as-swap","title":"mkswap - Format as Swap","text":"<p>What it does: Prepares a partition or file to be used as swap space.</p> <p>Why use it: Required before using any space as swap.</p> <p>Examples:</p> <pre><code># Format partition\nmkswap /dev/sdb1\n\n# Format file\nmkswap /swapfile\n\n# With label (helpful for identification)\nmkswap -L \"swap1\" /dev/sdb1\n</code></pre> <p>Output example:</p> <pre><code>Setting up swapspace version 1, size = 2 GiB (2147479552 bytes)\nno label, UUID=1234abcd-5678-...\n</code></pre>"},{"location":"linux/storage/swap-space/#swapon-enable-swap","title":"swapon - Enable Swap","text":"<p>What it does: Activates swap space so Linux can use it.</p> <p>Why use it: Swap isn\u2019t usable until you enable it.</p> <p>Examples:</p> <pre><code># Enable specific swap\nswapon /swapfile\nswapon /dev/sdb1\n\n# Enable all swap in /etc/fstab\nswapon -a\n\n# Enable with priority (higher number = used first)\nswapon -p 10 /dev/sdb1\nswapon -p 5 /swapfile\n\n# Show what's active\nswapon --show\n\n# Verbose mode\nswapon -v /swapfile\n</code></pre> <p>Understanding priority:</p> <pre><code># Fast SSD swap - high priority (used first)\nswapon -p 100 /dev/nvme0n1p3\n\n# Slow HDD swap - low priority (used last)\nswapon -p 10 /dev/sdb1\n</code></pre> <p>Output of swapon \u2013show:</p> <pre><code>NAME      TYPE SIZE USED PRIO\n/swapfile file   2G   0B   -2\n/dev/sdb1 partition 4G 512M 5\n</code></pre>"},{"location":"linux/storage/swap-space/#swapoff-disable-swap","title":"swapoff - Disable Swap","text":"<p>What it does: Deactivates swap space.</p> <p>Why use it: Before removing swap or making changes.</p> <p>Examples:</p> <pre><code># Disable specific swap\nswapoff /swapfile\n\n# Disable all swap\nswapoff -a\n\n# Verbose\nswapoff -v /swapfile\n</code></pre> <p>Real-world scenario - Resizing swap file:</p> <pre><code># Current 2GB swap is too small, need 4GB\n\n# Step 1: Disable swap\nswapoff /swapfile\n\n# Step 2: Delete old file\nrm /swapfile\n\n# Step 3: Create new 4GB file\nfallocate -l 4G /swapfile\nchmod 600 /swapfile\n\n# Step 4: Format and enable\nmkswap /swapfile\nswapon /swapfile\n\n# Step 5: Verify\nswapon --show\n</code></pre>"},{"location":"linux/storage/swap-space/#free-memory-and-swap-status","title":"free - Memory and Swap Status","text":"<p>What it does: Shows RAM and swap usage.</p> <p>Why use it: Quick check of memory situation.</p> <p>Examples:</p> <pre><code># Human-readable\nfree -h\n\n# In megabytes\nfree -m\n\n# In gigabytes  \nfree -g\n\n# Continuous updates (every 2 seconds)\nfree -h -s 2\n\n# With totals\nfree -ht\n\n# Wide mode (more detailed)\nfree -hw\n</code></pre> <p>Output example:</p> <pre><code>free -h\n              total        used        free      shared  buff/cache   available\nMem:           16Gi       8.0Gi       2.0Gi       100Mi       6.0Gi       7.5Gi\nSwap:          4.0Gi       512Mi       3.5Gi\n</code></pre> <p>What it means:</p> <ul> <li>total: Total RAM/swap installed</li> <li>used: Currently in use by programs</li> <li>free: Completely unused</li> <li>shared: Used by tmpfs/shared memory</li> <li>buff/cache: Used for caching (can be freed if needed)</li> <li>available: How much can be used by programs (free + reclaimable cache)</li> </ul>"},{"location":"linux/storage/swap-space/#vmstat-virtual-memory-statistics","title":"vmstat - Virtual Memory Statistics","text":"<p>What it does: Shows system activity including swap in/out.</p> <p>Why use it: Monitor if system is swapping heavily (performance problem).</p> <p>Examples:</p> <pre><code># Single snapshot\nvmstat\n\n# Update every 2 seconds\nvmstat 2\n\n# 10 updates, 2 seconds apart\nvmstat 2 10\n\n# Memory statistics\nvmstat -s\n\n# Active/inactive memory\nvmstat -a\n\n# Disk statistics\nvmstat -d\n</code></pre> <p>Output example:</p> <pre><code>vmstat 2\nprocs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n 1  0  10240 204800 102400 512000    0    0    10    50  100  200  5  2 90  3  0\n 0  1  10240 204800 102400 512000    5   10    20   100  150  250  8  4 85  3  0\n</code></pre> <p>Critical columns:</p> <ul> <li>si (swap in): KB/s reading from swap (from disk to RAM)</li> <li>so (swap out): KB/s writing to swap (from RAM to disk)</li> <li>wa: % CPU waiting for I/O</li> </ul> <p>What to watch for:</p> <pre><code>si  so  \u2190 Both zero: No swapping (good!)\n0   0\n\nsi  so  \u2190 Occasional swapping (normal)\n5   10\n\nsi   so  \u2190 Heavy swapping (performance problem!)\n100  200\n</code></pre> <p>If you see high si/so consistently, you need more RAM!</p>"},{"location":"linux/storage/swap-space/#persistent-swap-configuration","title":"Persistent Swap Configuration","text":""},{"location":"linux/storage/swap-space/#etcfstab-entries","title":"/etc/fstab Entries","text":"<p>Format:</p> <pre><code>device/file  none  swap  options  0  0\n</code></pre> <p>Examples:</p> <pre><code># Swap file\n/swapfile none swap sw 0 0\n\n# Swap partition\n/dev/sdb1 none swap sw 0 0\n\n# With priority\n/dev/sdb1 none swap pri=10 0 0\n/swapfile none swap pri=5 0 0\n\n# Using UUID (more reliable)\nUUID=1234abcd-... none swap sw 0 0\n\n# Using label\nLABEL=swap1 none swap sw 0 0\n</code></pre> <p>Multiple swap spaces:</p> <pre><code># Fast SSD swap (priority 100)\n/dev/nvme0n1p3 none swap pri=100 0 0\n\n# Slower SSD swap (priority 50)\n/dev/sda2 none swap pri=50 0 0\n\n# Emergency HDD swap (priority 10)\n/swapfile none swap pri=10 0 0\n</code></pre> <p>Priority rules:</p> <ul> <li>Higher number = used first</li> <li>Same priority = used in parallel (striped for performance)</li> <li>Default priority = -2</li> </ul>"},{"location":"linux/storage/swap-space/#tuning-swap-behavior","title":"Tuning Swap Behavior","text":""},{"location":"linux/storage/swap-space/#vmswappiness-control-swap-tendency","title":"vm.swappiness - Control Swap Tendency","text":"<p>What it is: Kernel parameter controlling how aggressively Linux swaps.</p> <p>Why tune it: Balance between RAM usage and swap usage.</p> <p>Value range: 0-100</p> <ul> <li>0: Avoid swapping except emergency</li> <li>1: Minimum swapping (recommended for servers)</li> <li>10: Very little swapping (good for servers)</li> <li>60: Default (balanced)</li> <li>100: Swap aggressively</li> </ul> <p>Examples:</p> <pre><code># Check current value\ncat /proc/sys/vm/swappiness\nsysctl vm.swappiness\n\n# Temporary change (until reboot)\nsysctl -w vm.swappiness=10\necho 10 &gt; /proc/sys/vm/swappiness\n\n# Permanent change\necho \"vm.swappiness=10\" &gt;&gt; /etc/sysctl.d/99-swappiness.conf\nsysctl -p /etc/sysctl.d/99-swappiness.conf\n\n# Or edit /etc/sysctl.conf\nvi /etc/sysctl.conf\n# Add: vm.swappiness=10\nsysctl -p\n</code></pre> <p>Recommendations:</p> <pre><code># Desktop/Laptop (more responsive)\nvm.swappiness=60\n\n# Server with plenty of RAM\nvm.swappiness=10\n\n# Server with limited RAM\nvm.swappiness=30\n\n# Database server\nvm.swappiness=1\n</code></pre> <p>Real-world scenario - Web server optimization:</p> <pre><code># Server has 32GB RAM, barely uses swap\n# Lower swappiness to keep more in RAM\n\n# Check current setting\ncat /proc/sys/vm/swappiness\n# 60 (default)\n\n# Set to minimal swapping\necho \"vm.swappiness=10\" &gt;&gt; /etc/sysctl.d/99-swappiness.conf\nsysctl -p /etc/sysctl.d/99-swappiness.conf\n\n# Monitor results\nvmstat 2\n# Watch si/so values (should be mostly 0)\n</code></pre>"},{"location":"linux/storage/swap-space/#swap-on-lvm","title":"Swap on LVM","text":""},{"location":"linux/storage/swap-space/#why-use-lvm-for-swap","title":"Why Use LVM for Swap?","text":"<p>Benefits:</p> <ul> <li>Easy to resize</li> <li>Can be on multiple disks</li> <li>Snapshots possible (though not common for swap)</li> </ul> <p>Example - Create LVM swap:</p> <pre><code># Step 1: Create logical volume\nlvcreate -L 8G -n lv_swap vg01\n\n# Step 2: Format as swap\nmkswap /dev/vg01/lv_swap\n\n# Step 3: Enable\nswapon /dev/vg01/lv_swap\n\n# Step 4: Make permanent\necho '/dev/vg01/lv_swap none swap sw 0 0' &gt;&gt; /etc/fstab\n</code></pre> <p>Resizing LVM swap:</p> <pre><code># Need more swap space\n\n# Step 1: Disable swap\nswapoff /dev/vg01/lv_swap\n\n# Step 2: Extend logical volume\nlvextend -L +4G /dev/vg01/lv_swap\n\n# Step 3: Reformat (required for swap!)\nmkswap /dev/vg01/lv_swap\n\n# Step 4: Re-enable\nswapon /dev/vg01/lv_swap\n\n# Step 5: Verify\nswapon --show\nfree -h\n</code></pre>"},{"location":"linux/storage/swap-space/#monitoring-swap-usage","title":"Monitoring Swap Usage","text":""},{"location":"linux/storage/swap-space/#check-whats-using-swap","title":"Check What\u2019s Using Swap","text":"<p>Find swap usage by process:</p> <pre><code># Quick check\nfor file in /proc/*/status; do\n    awk '/VmSwap|Name/{printf $2 \" \" $3}END{print \"\"}' $file\ndone | sort -k 2 -n -r | head\n\n# Output shows:\n# firefox 512000 (512MB)\n# chrome 256000 (256MB)\n# mysql 128000 (128MB)\n</code></pre> <p>Detailed swap analysis:</p> <pre><code># For each process, show swap usage\nfor pid in $(ls /proc | grep -E '^[0-9]+$'); do\n    if [ -f /proc/$pid/smaps ]; then\n        swap=$(grep Swap /proc/$pid/smaps 2&gt;/dev/null | awk '{sum+=$2} END {print sum}')\n        if [ ! -z \"$swap\" ] &amp;&amp; [ \"$swap\" -gt 0 ] 2&gt;/dev/null; then\n            name=$(cat /proc/$pid/comm 2&gt;/dev/null)\n            echo \"$swap KB - $name (PID: $pid)\"\n        fi\n    fi\ndone | sort -n -r | head -20\n</code></pre>"},{"location":"linux/storage/swap-space/#troubleshooting","title":"Troubleshooting","text":""},{"location":"linux/storage/swap-space/#problem-system-running-out-of-memory","title":"Problem: System Running Out of Memory","text":"<p>Symptoms: System very slow, heavy swapping.</p> <p>Solutions:</p> <pre><code># Check situation\nfree -h\nvmstat 2 5\n\n# If swap is full or nearly full:\n# Option 1: Add more swap (temporary fix)\nfallocate -l 4G /emergency-swap\nchmod 600 /emergency-swap\nmkswap /emergency-swap\nswapon /emergency-swap\n\n# Option 2: Find memory hogs\nps aux --sort=-%mem | head\ntop -o %MEM\n\n# Option 3: Kill memory-hungry processes (carefully!)\npkill firefox\npkill chrome\n\n# Long-term solution: Add more RAM!\n</code></pre>"},{"location":"linux/storage/swap-space/#problem-heavy-swapping-system-slow","title":"Problem: Heavy Swapping (System Slow)","text":"<p>Symptoms: High si/so in vmstat, system sluggish.</p> <p>Solutions:</p> <pre><code># Monitor swapping\nvmstat 2\n\n# If heavy swapping (si/so &gt; 100):\n# Solution 1: Lower swappiness\nsysctl -w vm.swappiness=10\n\n# Solution 2: Find what's swapped out\n# (See \"Check What's Using Swap\" above)\n\n# Solution 3: Clear swap and reload to RAM\n# WARNING: Only if you have enough free RAM!\nswapoff -a\nswapon -a\n</code></pre>"},{"location":"linux/storage/swap-space/#problem-cannot-enable-swap","title":"Problem: Cannot Enable Swap","text":"<p>Symptoms: swapon fails with error.</p> <p>Solutions:</p> <pre><code># Check if formatted as swap\nfile -s /swapfile\n# Should show: swap file\n\n# If not formatted:\nmkswap /swapfile\n\n# Check permissions (swap files must be 600)\nls -l /swapfile\nchmod 600 /swapfile\n\n# Check logs\ndmesg | grep swap\njournalctl | grep swap\n</code></pre>"},{"location":"linux/storage/swap-space/#problem-swap-not-activating-at-boot","title":"Problem: Swap Not Activating at Boot","text":"<p>Symptoms: After reboot, swap isn\u2019t active.</p> <p>Solutions:</p> <pre><code># Check fstab entry\ncat /etc/fstab | grep swap\n\n# Test manual activation\nswapon -a\n\n# Check for errors\nsystemctl status swap.target\nsystemctl list-units | grep swap\n\n# Verify file/partition exists\nls -l /swapfile\n</code></pre>"},{"location":"linux/storage/swap-space/#best-practices","title":"Best Practices","text":"<p>1. Secure swap files:</p> <pre><code># Always set 600 permissions\nchmod 600 /swapfile\n</code></pre> <p>2. Use appropriate size:</p> <pre><code># Server with 16GB RAM\n# 8GB swap is plenty\n</code></pre> <p>3. Tune swappiness:</p> <pre><code># Servers: 10\n# Desktops: 60 (default)\n</code></pre> <p>4. Monitor regularly:</p> <pre><code># Check weekly\nfree -h\nvmstat 2 5\n</code></pre> <p>5. Multiple swap for performance:</p> <pre><code># Equal priority for striping\n/dev/sda2 none swap pri=10 0 0\n/dev/sdb2 none swap pri=10 0 0\n</code></pre>"},{"location":"linux/storage/swap-space/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/swap-space/#creating-swap","title":"Creating Swap","text":"<pre><code># Swap file (recommended)\nfallocate -l 4G /swapfile\nchmod 600 /swapfile\nmkswap /swapfile\nswapon /swapfile\necho '/swapfile none swap sw 0 0' &gt;&gt; /etc/fstab\n</code></pre>"},{"location":"linux/storage/swap-space/#managing-swap","title":"Managing Swap","text":"<pre><code>swapon --show              # Show active swap\nswapon -a                  # Enable all\nswapoff -a                 # Disable all\nfree -h                    # Check usage\nvmstat 2                   # Monitor activity\n</code></pre>"},{"location":"linux/storage/swap-space/#tuning","title":"Tuning","text":"<pre><code># Check swappiness\ncat /proc/sys/vm/swappiness\n\n# Set permanently\necho \"vm.swappiness=10\" &gt;&gt; /etc/sysctl.d/99-swap.conf\nsysctl -p\n</code></pre>"},{"location":"linux/storage/swap-space/#monitoring","title":"Monitoring","text":"<pre><code># Current status\nfree -h\nswapon --show\n\n# Watch for swapping\nvmstat 2 10\n\n# Find what's using swap\ngrep VmSwap /proc/*/status | grep -v \"0 kB\"\n</code></pre>"},{"location":"linux/storage/virtual-file-system/","title":"Manage and Configure the Virtual File System","text":""},{"location":"linux/storage/virtual-file-system/#what-is-the-virtual-file-system","title":"What is the Virtual File System?","text":"<p>The Virtual File System (VFS) is Linux\u2019s way of providing a uniform interface to access different types of filesystems. It\u2019s like a translator that lets applications work with files the same way, whether they\u2019re on ext4, XFS, NFS, or any other filesystem.</p> <p>Think of VFS as the middleman between your applications and the actual storage. When you run <code>cat file.txt</code>, you don\u2019t need to know if that file is on a local disk, a network share, or even in memory - VFS handles all the complexity.</p>"},{"location":"linux/storage/virtual-file-system/#understanding-the-linux-directory-structure","title":"Understanding the Linux Directory Structure","text":""},{"location":"linux/storage/virtual-file-system/#why-this-matters","title":"Why This Matters","text":"<p>Unlike Windows with its C:, D:, E: drives, Linux has ONE unified directory tree. Everything starts from <code>/</code> (root), and all storage devices, network shares, and even system information appear as directories within this tree.</p>"},{"location":"linux/storage/virtual-file-system/#the-root-directory-","title":"The Root Directory - /","text":"<p>Everything in Linux starts here. This is not the home directory of the root user (that\u2019s <code>/root</code>), but the very top of the entire filesystem hierarchy.</p> <pre><code># View the root directory\nls /\n</code></pre> <p>Output: <pre><code>bin  boot  dev  etc  home  lib  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#critical-system-directories","title":"Critical System Directories","text":""},{"location":"linux/storage/virtual-file-system/#bin-essential-user-commands","title":"/bin - Essential User Commands","text":"<p>What it is: Contains essential command-line programs that all users need and that must be available even in single-user mode (emergency recovery).</p> <p>What\u2019s inside:</p> <ul> <li>Basic commands like <code>ls</code>, <code>cp</code>, <code>mv</code>, <code>cat</code>, <code>mkdir</code></li> <li>Shell programs like <code>bash</code>, <code>sh</code></li> <li>Basic utilities you need to fix a broken system</li> </ul> <p>Example:</p> <pre><code># See what's in /bin\nls /bin\n\n# Check where a command lives\nwhich ls\n# Output: /bin/ls\n</code></pre> <p>Why it matters: If these files get deleted or corrupted, your system becomes very difficult to use or repair.</p>"},{"location":"linux/storage/virtual-file-system/#boot-boot-files","title":"/boot - Boot Files","text":"<p>What it is: Everything needed to start your Linux system.</p> <p>What\u2019s inside:</p> <ul> <li>The Linux kernel (vmlinuz)</li> <li>Initial RAM disk (initramfs or initrd)</li> <li>Bootloader configuration (GRUB)</li> </ul> <p>Example:</p> <pre><code># View boot files\nls -lh /boot\n\n# Typical contents:\n# vmlinuz-5.15.0-58-generic    (Linux kernel)\n# initrd.img-5.15.0-58-generic (Initial RAM disk)\n# grub/                        (Bootloader)\n</code></pre> <p>Why it matters: Your computer can\u2019t start Linux without these files. Never delete anything here unless you know exactly what you\u2019re doing!</p> <p>Real-world scenario: If you\u2019re dual-booting Windows and Linux and Windows update breaks GRUB, you\u2019ll need to access <code>/boot/grub/</code> to fix the bootloader.</p>"},{"location":"linux/storage/virtual-file-system/#dev-device-files","title":"/dev - Device Files","text":"<p>What it is: Special files that represent hardware devices. In Linux, \u201ceverything is a file,\u201d including hardware.</p> <p>What\u2019s inside:</p> <ul> <li>Disk drives: <code>/dev/sda</code>, <code>/dev/sdb</code>, <code>/dev/nvme0n1</code></li> <li>Partitions: <code>/dev/sda1</code>, <code>/dev/sda2</code></li> <li>Terminals: <code>/dev/tty1</code>, <code>/dev/pts/0</code></li> <li>Null device: <code>/dev/null</code> (the \u201cblack hole\u201d)</li> <li>Random data: <code>/dev/random</code>, <code>/dev/urandom</code></li> </ul> <p>Examples:</p> <pre><code># List all disk devices\nls -l /dev/sd*\n\n# List NVMe devices\nls -l /dev/nvme*\n\n# View information about a disk\nfdisk -l /dev/sda\n\n# The \"black hole\" - discard output\necho \"This disappears\" &gt; /dev/null\n\n# Generate random data\nhead -c 16 /dev/urandom | base64\n</code></pre> <p>Real-world scenario: When you plug in a USB drive, it appears as <code>/dev/sdb</code> or similar. You can then mount it to access its contents.</p>"},{"location":"linux/storage/virtual-file-system/#etc-configuration-files","title":"/etc - Configuration Files","text":"<p>What it is: System-wide configuration files. Nearly every program stores its settings here.</p> <p>What\u2019s inside:</p> <ul> <li><code>/etc/fstab</code> - Filesystem mount configuration</li> <li><code>/etc/passwd</code> - User account information</li> <li><code>/etc/group</code> - Group information</li> <li><code>/etc/hosts</code> - Static hostname to IP mappings</li> <li><code>/etc/hostname</code> - System hostname</li> <li><code>/etc/ssh/sshd_config</code> - SSH server configuration</li> <li><code>/etc/network/</code> - Network configuration</li> </ul> <p>Examples:</p> <pre><code># View mount configuration\ncat /etc/fstab\n\n# Check system hostname\ncat /etc/hostname\n\n# View user accounts\ncat /etc/passwd\n\n# List all configuration files\nls /etc\n</code></pre> <p>Why it matters: This is where you configure most system behavior. Always backup files before editing them!</p> <p>Real-world scenario: You want a USB drive to mount automatically on boot. You add an entry to <code>/etc/fstab</code>: <pre><code>UUID=1234-5678 /mnt/usb vfat defaults 0 0\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#home-user-home-directories","title":"/home - User Home Directories","text":"<p>What it is: Personal directories for regular users. Each user gets their own space.</p> <p>What\u2019s inside:</p> <ul> <li><code>/home/john/</code> - John\u2019s personal files</li> <li><code>/home/jane/</code> - Jane\u2019s personal files</li> <li>Each user can only write to their own directory (by default)</li> </ul> <p>Examples:</p> <pre><code># Go to your home directory\ncd ~\n# or just\ncd\n\n# See whose home directories exist\nls /home\n\n# Check your current user\nwhoami\n\n# Check your home directory\necho $HOME\n</code></pre> <p>Why separate /home? Many people put <code>/home</code> on a separate partition or disk. This way, you can reinstall the operating system without losing your personal files.</p>"},{"location":"linux/storage/virtual-file-system/#root-root-users-home","title":"/root - Root User\u2019s Home","text":"<p>What it is: The home directory for the root (administrator) user.</p> <p>Why separate? The root user is special. Their home directory is in <code>/root</code> (not <code>/home/root</code>) to ensure it\u2019s available even if <code>/home</code> fails to mount.</p> <p>Example:</p> <pre><code># Switch to root\nsudo su -\n\n# Check location\npwd\n# Output: /root\n\n# Go back to regular user\nexit\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#tmp-temporary-files","title":"/tmp - Temporary Files","text":"<p>What it is: A place for programs to store temporary data. Gets cleaned out regularly (usually on reboot).</p> <p>What\u2019s inside:</p> <ul> <li>Temporary files created by applications</li> <li>Lock files</li> <li>Session data</li> </ul> <p>Examples:</p> <pre><code># Create a temp file\necho \"test\" &gt; /tmp/mytest.txt\n\n# List temp files\nls /tmp\n\n# Many systems clean /tmp on reboot\n# So don't store anything important here!\n</code></pre> <p>Why it matters: Perfect for testing or temporary work. After reboot, it\u2019s clean.</p> <p>Real-world scenario: You\u2019re testing a script that creates files. Use <code>/tmp</code> so you don\u2019t clutter your home directory, and it auto-cleans: <pre><code>./test-script.sh &gt; /tmp/output.log\n# After testing, reboot cleans it up automatically\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#var-variable-data","title":"/var - Variable Data","text":"<p>What it is: Data that changes frequently during system operation.</p> <p>What\u2019s inside:</p> <ul> <li><code>/var/log/</code> - Log files</li> <li><code>/var/spool/</code> - Print and mail queues</li> <li><code>/var/www/</code> - Web server files (common location)</li> <li><code>/var/lib/</code> - State information for applications</li> <li><code>/var/cache/</code> - Cached data</li> </ul> <p>Examples:</p> <pre><code># View system logs\nls /var/log\n\n# Check recent log entries\ntail /var/log/syslog\ntail /var/log/messages\n\n# Web server files (if Apache installed)\nls /var/www/html\n\n# Check disk usage (can grow large!)\ndu -sh /var/log\n</code></pre> <p>Why it matters: <code>/var/log</code> can fill up your disk! Regular monitoring is essential.</p> <p>Real-world scenario: Your root partition is full. Investigation shows: <pre><code>df -h /\n# Filesystem      Size  Used Avail Use% Mounted on\n# /dev/sda1        20G   19G     0 100% /\n\ndu -sh /var/log\n# 15G    /var/log\n\n# Old logs are filling the disk!\n# Solution: Clean old logs\nfind /var/log -name \"*.log\" -mtime +30 -delete\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#usr-user-programs-and-data","title":"/usr - User Programs and Data","text":"<p>What it is: Unix System Resources. Contains most user applications and utilities.</p> <p>What\u2019s inside:</p> <ul> <li><code>/usr/bin/</code> - Most command-line programs</li> <li><code>/usr/sbin/</code> - System administration programs</li> <li><code>/usr/lib/</code> - Libraries for programs</li> <li><code>/usr/local/</code> - Locally compiled/installed software</li> <li><code>/usr/share/</code> - Shared data (documentation, icons, etc.)</li> </ul> <p>Examples:</p> <pre><code># Most commands you use are here\nls /usr/bin\n\n# Where is Python?\nwhich python3\n# Output: /usr/bin/python3\n\n# Where is Apache?\nwhich apache2\n# Output: /usr/sbin/apache2\n\n# Locally installed software\nls /usr/local/bin\n</code></pre> <p>Why /usr/local? System package managers install to <code>/usr</code>, but software you compile yourself goes to <code>/usr/local</code>. This keeps them separate and organized.</p>"},{"location":"linux/storage/virtual-file-system/#special-virtual-filesystems","title":"Special Virtual Filesystems","text":""},{"location":"linux/storage/virtual-file-system/#proc-process-and-system-information","title":"/proc - Process and System Information","text":"<p>What it is: Not a real filesystem on disk! It\u2019s a window into the kernel\u2019s view of the system. Everything here is generated in real-time.</p> <p>What\u2019s inside:</p> <ul> <li>System information (CPU, memory, etc.)</li> <li>Process information (one directory per running process)</li> <li>Kernel parameters you can read and change</li> </ul> <p>Examples:</p> <pre><code># CPU information\ncat /proc/cpuinfo\n\n# Memory information\ncat /proc/meminfo\n\n# System load\ncat /proc/loadavg\n\n# Currently mounted filesystems\ncat /proc/mounts\n\n# Network connections\ncat /proc/net/tcp\n\n# Information about process 1234\nls /proc/1234/\ncat /proc/1234/status\ncat /proc/1234/cmdline\n\n# All running processes have a directory\nls /proc/ | grep -E '^[0-9]+$'\n</code></pre> <p>Real-world scenario - Checking memory: <pre><code># How much RAM do I have?\ngrep MemTotal /proc/meminfo\n# MemTotal:       16384000 kB\n\n# How much is free?\ngrep MemAvailable /proc/meminfo\n# MemAvailable:   8192000 kB\n</code></pre></p> <p>Real-world scenario - Finding what\u2019s listening on a port: <pre><code># What's listening on port 80?\ncat /proc/net/tcp | grep :0050\n# Then look up the process by its inode\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#sys-device-and-kernel-information","title":"/sys - Device and Kernel Information","text":"<p>What it is: Another virtual filesystem. Provides information about devices and allows you to configure hardware.</p> <p>What\u2019s inside:</p> <ul> <li>Device information</li> <li>Hardware configuration</li> <li>Kernel module parameters</li> </ul> <p>Examples:</p> <pre><code># Information about your disks\nls /sys/block/\n\n# Check if disk is rotational (HDD=1, SSD=0)\ncat /sys/block/sda/queue/rotational\n\n# Network interface information\nls /sys/class/net/\n\n# Check if network interface is up\ncat /sys/class/net/eth0/operstate\n\n# MAC address\ncat /sys/class/net/eth0/address\n</code></pre> <p>Real-world scenario - Check if drive is SSD: <pre><code># Check all drives\nfor drive in /sys/block/sd*; do\n    echo -n \"$(basename $drive): \"\n    cat $drive/queue/rotational\ndone\n\n# Output:\n# sda: 1  (HDD)\n# sdb: 0  (SSD)\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#working-with-files-and-directories","title":"Working with Files and Directories","text":""},{"location":"linux/storage/virtual-file-system/#ls-list-files","title":"ls - List Files","text":"<p>What it does: Shows you what files and directories exist in a location.</p> <p>Why use it: It\u2019s usually your first command when exploring a directory - \u201cwhat\u2019s here?\u201d</p> <p>Examples:</p> <pre><code># Basic list\nls\n\n# Detailed list with permissions, owner, size, date\nls -l\n\n# Show hidden files (names starting with .)\nls -a\n\n# Human-readable sizes\nls -lh\n\n# Sort by modification time, newest first\nls -lt\n\n# Sort by size, largest first\nls -lS\n\n# Show everything, sorted by time, human-readable\nls -lath\n\n# List a specific directory without entering it\nls -l /var/log\n</code></pre> <p>Understanding ls -l output: <pre><code>ls -l myfile.txt\n-rw-r--r-- 1 john users 1024 Oct 28 10:30 myfile.txt\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2502 \u2502    \u2502     \u2502    \u2502           \u2514\u2500 filename\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2502 \u2502    \u2502     \u2502    \u2514\u2500 date modified\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2502 \u2502    \u2502     \u2514\u2500 size (bytes)\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2502 \u2502    \u2514\u2500 group owner\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2502 \u2502\u2500 user owner\n\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502  \u2514\u2500 number of hard links\n\u2502\u2514\u2534\u2534\u2534\u2534\u2534\u2534\u2534\u2500 permissions\n\u2514\u2500 file type (- = regular file, d = directory, l = link)\n</code></pre></p> <p>File type indicators:</p> <ul> <li><code>-</code> Regular file</li> <li><code>d</code> Directory</li> <li><code>l</code> Symbolic link</li> <li><code>b</code> Block device (like hard drives)</li> <li><code>c</code> Character device (like terminals)</li> </ul>"},{"location":"linux/storage/virtual-file-system/#cd-change-directory","title":"cd - Change Directory","text":"<p>What it does: Moves you to a different directory.</p> <p>Why use it: Navigation! You need to be in the right place to work on files.</p> <p>Examples:</p> <pre><code># Go to /var/log\ncd /var/log\n\n# Go to your home directory\ncd ~\n# or just\ncd\n\n# Go back to previous directory\ncd -\n\n# Go up one level\ncd ..\n\n# Go up two levels\ncd ../..\n\n# Go to a subdirectory of current location\ncd ./subdir\n\n# Relative to home\ncd ~/Documents\n</code></pre> <p>Real-world scenario: <pre><code># Working in /var/www/html\ncd /var/www/html\n\n# Need to edit config in /etc\ncd /etc/nginx\n\n# Want to go back\ncd -\n# Now back in /var/www/html\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#pwd-print-working-directory","title":"pwd - Print Working Directory","text":"<p>What it does: Shows you where you currently are in the filesystem.</p> <p>Why use it: Ever get lost? <code>pwd</code> tells you exactly where you are.</p> <p>Examples:</p> <pre><code># Where am I?\npwd\n# Output: /home/john/Documents\n\n# After changing directories\ncd /var/log\npwd\n# Output: /var/log\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#mkdir-make-directory","title":"mkdir - Make Directory","text":"<p>What it does: Creates new directories.</p> <p>Why use it: You need a place to organize your files!</p> <p>Examples:</p> <pre><code># Create a single directory\nmkdir projects\n\n# Create nested directories (including parents)\nmkdir -p work/2024/reports\n\n# Create multiple directories\nmkdir dir1 dir2 dir3\n\n# Create with specific permissions\nmkdir -m 755 public_html\n\n# Create project structure\nmkdir -p myproject/{src,bin,docs,tests}\n</code></pre> <p>Real-world scenario - Project setup: <pre><code># Set up a new web project\nmkdir -p ~/projects/mywebsite/{html,css,js,images}\n\n# Result:\n# mywebsite/\n# \u251c\u2500\u2500 html/\n# \u251c\u2500\u2500 css/\n# \u251c\u2500\u2500 js/\n# \u2514\u2500\u2500 images/\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#rm-remove-files","title":"rm - Remove Files","text":"<p>What it does: Deletes files and directories.</p> <p>Why use it: Clean up unwanted files, free up space.</p> <p>\u26a0\ufe0f WARNING: There\u2019s no \u201cRecycle Bin\u201d in Linux command line. Deleted = GONE!</p> <p>Examples:</p> <pre><code># Delete a file\nrm oldfile.txt\n\n# Delete multiple files\nrm file1.txt file2.txt file3.txt\n\n# Delete a directory and its contents\nrm -r oldfolder\n\n# Force delete without asking\nrm -f stubborn.txt\n\n# Delete directory and everything in it (dangerous!)\nrm -rf directory\n\n# Interactive mode - asks before each deletion\nrm -i *.txt\n\n# Delete all .log files older than 30 days\nfind /var/log -name \"*.log\" -mtime +30 -exec rm {} \\;\n</code></pre> <p>Real-world scenario - Clean up old logs: <pre><code># Find large log files\nfind /var/log -type f -size +100M\n\n# Delete them (carefully!)\nfind /var/log -type f -size +100M -exec rm {} \\;\n</code></pre></p> <p>Safety tip: Use <code>rm -i</code> (interactive) when deleting important files: <pre><code>rm -i important*\n# rm: remove regular file 'important-data.txt'? n (you type 'n' to keep it)\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#cp-copy-files","title":"cp - Copy Files","text":"<p>What it does: Makes a copy of files or directories.</p> <p>Why use it: Backups, duplicating files, copying to different locations.</p> <p>Examples:</p> <pre><code># Copy a file\ncp original.txt copy.txt\n\n# Copy to a different directory\ncp file.txt /backup/\n\n# Copy directory and all contents\ncp -r folder/ /backup/\n\n# Copy and preserve permissions, ownership, timestamps\ncp -a /etc/nginx /backup/nginx-backup\n\n# Copy multiple files to a directory\ncp file1.txt file2.txt file3.txt /destination/\n\n# Interactive - ask before overwriting\ncp -i file.txt existing-file.txt\n\n# Update - only copy if source is newer\ncp -u *.txt /backup/\n</code></pre> <p>Real-world scenario - Backup before editing: <pre><code># Before editing important config\ncp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.backup\n\n# Make changes\nvi /etc/nginx/nginx.conf\n\n# If something breaks, restore\ncp /etc/nginx/nginx.conf.backup /etc/nginx/nginx.conf\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#mv-move-or-rename-files","title":"mv - Move or Rename Files","text":"<p>What it does: Moves files to new locations OR renames them (it\u2019s the same operation).</p> <p>Why use it: Organize files, rename things.</p> <p>Examples:</p> <pre><code># Rename a file\nmv oldname.txt newname.txt\n\n# Move to different directory\nmv file.txt /backup/\n\n# Move multiple files\nmv file1.txt file2.txt file3.txt /destination/\n\n# Rename a directory\nmv old-folder new-folder\n\n# Move and rename at the same time\nmv /tmp/file.txt /home/john/newfile.txt\n\n# Interactive mode\nmv -i file.txt existing.txt\n</code></pre> <p>Real-world scenario: <pre><code># Organizing downloaded files\nmv ~/Downloads/*.pdf ~/Documents/PDFs/\nmv ~/Downloads/*.jpg ~/Pictures/\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#find-search-for-files","title":"find - Search for Files","text":"<p>What it does: Searches for files based on various criteria (name, size, date, etc.).</p> <p>Why use it: \u201cI know I saved that file somewhere\u2026\u201d - <code>find</code> will locate it!</p> <p>Examples:</p> <pre><code># Find files by name\nfind /home -name \"report.pdf\"\n\n# Case-insensitive search\nfind /home -iname \"*.PDF\"\n\n# Find all directories\nfind /var -type d\n\n# Find all files\nfind /var -type f\n\n# Find files larger than 100MB\nfind /home -type f -size +100M\n\n# Find files modified in last 7 days\nfind /var/log -type f -mtime -7\n\n# Find files NOT modified in last 30 days\nfind /tmp -type f -mtime +30\n\n# Find and execute command on results\nfind /tmp -type f -mtime +30 -exec rm {} \\;\n\n# Find files by owner\nfind /home -user john\n\n# Find files with specific permissions\nfind /var/www -type f -perm 0777\n</code></pre> <p>Real-world scenario - Find large files: <pre><code># Disk is full, find what's using space\nfind / -type f -size +1G 2&gt;/dev/null\n\n# Output:\n# /var/log/huge.log (5GB)\n# /home/john/video.mp4 (2GB)\n</code></pre></p> <p>Real-world scenario - Find recently changed configs: <pre><code># What configs changed in last hour?\nfind /etc -type f -mmin -60\n\n# Useful after installing software to see what changed\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#file-permissions","title":"File Permissions","text":""},{"location":"linux/storage/virtual-file-system/#understanding-linux-permissions","title":"Understanding Linux Permissions","text":"<p>Every file has three levels of permissions:</p> <ul> <li>User (u): The owner of the file</li> <li>Group (g): The group that owns the file  </li> <li>Others (o): Everyone else</li> </ul> <p>Each level can have three types of permissions:</p> <ul> <li>Read \u00ae: Can view the file/list directory</li> <li>Write (w): Can modify the file/add files to directory</li> <li>Execute (x): Can run the file/enter the directory</li> </ul> <p>Example: <pre><code>ls -l script.sh\n-rwxr-xr-- 1 john developers 2048 Oct 28 10:30 script.sh\n \u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2502\n \u2502\u2502\u2502\u2502\u2502\u2502\u2502\u2514\u2534\u2500 others: r-- (read only)\n \u2502\u2502\u2502\u2514\u2534\u2534\u2500\u2500\u2500 group: r-x (read and execute)\n \u2514\u2534\u2534\u2500\u2500\u2500\u2500\u2500 user: rwx (read, write, execute)\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#chmod-change-permissions","title":"chmod - Change Permissions","text":"<p>What it does: Changes who can read, write, or execute a file.</p> <p>Why use it: Control access to your files, make scripts executable.</p> <p>Examples using symbolic mode:</p> <pre><code># Make file executable for everyone\nchmod +x script.sh\n\n# Make file executable only for owner\nchmod u+x script.sh\n\n# Remove write permission for group and others\nchmod go-w file.txt\n\n# Add read permission for everyone\nchmod a+r document.pdf\n\n# Set exact permissions: owner=rwx, group=rx, others=r\nchmod u=rwx,g=rx,o=r script.sh\n</code></pre> <p>Examples using numeric mode:</p> <p>Each permission has a number: - r (read) = 4 - w (write) = 2 - x (execute) = 1</p> <p>Add them up for each group:</p> <pre><code># 755 = rwxr-xr-x (common for executables)\nchmod 755 script.sh\n\n# 644 = rw-r--r-- (common for regular files)\nchmod 644 document.txt\n\n# 700 = rwx------ (only owner can do anything)\nchmod 700 private-script.sh\n\n# 600 = rw------- (only owner can read/write)\nchmod 600 private-data.txt\n\n# 777 = rwxrwxrwx (everyone can do everything - usually bad!)\nchmod 777 shared.sh\n</code></pre> <p>Real-world scenario - Make script executable: <pre><code># Download a script\nwget https://example.com/install.sh\n\n# Try to run it\n./install.sh\n# Error: Permission denied\n\n# Make it executable\nchmod +x install.sh\n\n# Now it works\n./install.sh\n</code></pre></p> <p>Real-world scenario - Secure private key: <pre><code># SSH won't work if private key is too open\nchmod 600 ~/.ssh/id_rsa\n\n# SSH directory itself\nchmod 700 ~/.ssh\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#chown-change-owner","title":"chown - Change Owner","text":"<p>What it does: Changes who owns a file or directory.</p> <p>Why use it: Fix ownership issues, give files to different users.</p> <p>Examples:</p> <pre><code># Change owner to john\nchown john file.txt\n\n# Change owner and group\nchown john:developers file.txt\n\n# Change only group (or use chgrp)\nchown :developers file.txt\n\n# Change ownership recursively\nchown -R www-data:www-data /var/www/html\n\n# Change using UID instead of username\nchown 1000:1000 file.txt\n</code></pre> <p>Real-world scenario - Web server files: <pre><code># Apache needs to own web files\nchown -R www-data:www-data /var/www/mysite\n\n# But you want to edit them too\n# Add yourself to www-data group\nusermod -a -G www-data john\n\n# Make files group-writable\nchmod -R g+w /var/www/mysite\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#links","title":"Links","text":""},{"location":"linux/storage/virtual-file-system/#what-are-links","title":"What Are Links?","text":"<p>Links are like shortcuts or pointers to files. Linux has two types:</p> <p>Symbolic Links (Soft Links):</p> <ul> <li>Like shortcuts in Windows</li> <li>Points to a file by its path</li> <li>If original is deleted, link breaks</li> <li>Can link to directories</li> <li>Can cross filesystem boundaries</li> </ul> <p>Hard Links:</p> <ul> <li>Direct reference to the file data on disk</li> <li>Multiple names for the same data</li> <li>If original is deleted, data still exists</li> <li>Cannot link to directories (usually)</li> <li>Must be on same filesystem</li> </ul>"},{"location":"linux/storage/virtual-file-system/#ln-create-links","title":"ln - Create Links","text":"<p>What it does: Creates symbolic or hard links to files.</p> <p>Why use it: Create shortcuts, maintain backward compatibility, organize files.</p> <p>Examples:</p> <pre><code># Create symbolic link\nln -s /path/to/original /path/to/link\n\n# Create hard link\nln /path/to/original /path/to/hardlink\n\n# Symbolic link to directory\nln -s /usr/share/docs ~/docs\n\n# Force overwrite existing link\nln -sf /new/target /existing/link\n\n# Create link in current directory\nln -s /var/log/syslog syslog\n</code></pre> <p>Real-world scenario - Python versions: <pre><code># You have Python 3.9 but some programs expect 'python3'\nln -s /usr/bin/python3.9 /usr/bin/python3\n\n# Now both work\npython3.9 --version\npython3 --version\n</code></pre></p> <p>Real-world scenario - Configuration management: <pre><code># Keep configs in version control\nmkdir ~/configs\nln -s ~/configs/vimrc ~/.vimrc\nln -s ~/configs/bashrc ~/.bashrc\n\n# Now you can edit ~/configs and commit changes\n</code></pre></p> <p>Checking links: <pre><code># List shows links with -&gt;\nls -l /usr/bin/python3\n# lrwxrwxrwx 1 root root 9 Mar 13  2023 /usr/bin/python3 -&gt; python3.9\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#checking-disk-usage","title":"Checking Disk Usage","text":""},{"location":"linux/storage/virtual-file-system/#df-disk-free","title":"df - Disk Free","text":"<p>What it does: Shows how much disk space is used and available on each filesystem.</p> <p>Why use it: \u201cIs my disk full?\u201d - Quick check of space on all mounted filesystems.</p> <p>Examples:</p> <pre><code># Human-readable sizes\ndf -h\n\n# Show filesystem type too\ndf -hT\n\n# Check specific filesystem\ndf -h /home\n\n# Show inode usage (number of files)\ndf -hi\n\n# All filesystems including pseudo ones\ndf -ha\n</code></pre> <p>Output example: <pre><code>df -h\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/sda1        50G   30G   18G  63% /\n/dev/sdb1       200G  150G   40G  79% /data\ntmpfs           8.0G  1.0M  8.0G   1% /run\n</code></pre></p> <p>Real-world scenario - Disk full warning: <pre><code>df -h /\n# Filesystem      Size  Used Avail Use% Mounted on\n# /dev/sda1        20G   19G  100M  99% /\n\n# Critical! Find what's using space:\ndu -sh /* | sort -h\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#du-disk-usage","title":"du - Disk Usage","text":"<p>What it does: Shows how much disk space files and directories are using.</p> <p>Why use it: \u201cWhat\u2019s taking up all my space?\u201d - Find large files and directories.</p> <p>Examples:</p> <pre><code># Size of current directory\ndu -sh .\n\n# Size of each item in current directory\ndu -sh *\n\n# Top level only, human readable\ndu -h --max-depth=1 /var\n\n# Sort by size, largest last\ndu -sh /home/* | sort -h\n\n# Sort by size, largest first\ndu -sh /home/* | sort -rh\n\n# Find directories larger than 1GB\ndu -h /var | grep '^[0-9.]*G'\n\n# Exclude certain patterns\ndu -sh --exclude='*.log' /var\n</code></pre> <p>Real-world scenario - Find space hogs: <pre><code># Check /var which is using lots of space\ndu -sh /var/*\n# Output:\n# 50M    /var/cache\n# 15G    /var/log\n# 100M   /var/lib\n# ...\n\n# /var/log is huge! What inside?\ndu -sh /var/log/* | sort -rh | head -5\n# Output:\n# 10G    /var/log/old-logs\n# 3G     /var/log/syslog\n# 2G     /var/log/auth.log\n</code></pre></p>"},{"location":"linux/storage/virtual-file-system/#quick-reference","title":"Quick Reference","text":""},{"location":"linux/storage/virtual-file-system/#navigation","title":"Navigation","text":"<pre><code>pwd                    # Where am I?\ncd /path              # Go to path\ncd                    # Go home\ncd -                  # Go back\nls -lah               # List files\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#file-operations","title":"File Operations","text":"<pre><code>mkdir dirname         # Create directory\nrm file               # Delete file\nrm -r dir             # Delete directory\ncp source dest        # Copy\nmv source dest        # Move/rename\nfind / -name file     # Search for file\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#permissions","title":"Permissions","text":"<pre><code>chmod 755 file        # Change permissions\nchown user:group file # Change owner\nls -l                 # View permissions\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#disk-usage","title":"Disk Usage","text":"<pre><code>df -h                 # Show disk space\ndu -sh directory      # Directory size\ndu -sh * | sort -h    # Sort by size\n</code></pre>"},{"location":"linux/storage/virtual-file-system/#system-information","title":"System Information","text":"<pre><code>cat /proc/cpuinfo     # CPU info\ncat /proc/meminfo     # Memory info\ncat /etc/os-release   # OS version\n</code></pre>"}]}